{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 05: Hyperparameter Tuning\n",
    "\n",
    "In this notebook, we will focus on finding the optimal hyperparameters for our predictive candidate models. Hyperparameter tuning is a crucial step in the model development process as it can significantly improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# The 4 chosen candidates \n",
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# XGBoost Regression\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# CatBoost\n",
    "import catboost as cb\n",
    "from catboost import Pool, cv\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed train dataset\n",
    "train_processed_w = pd.read_parquet(Path(\"data\") / \"train_processed_working_day.parquet\")\n",
    "train_processed_nw = pd.read_parquet(Path(\"data\") / \"train_processed_non_working_day.parquet\")\n",
    "\n",
    "# Separate features and target variables for training\n",
    "# For working days\n",
    "X_train_w = train_processed_w.drop(columns=[\"log_bike_count\"])\n",
    "y_train_w = train_processed_w[\"log_bike_count\"]\n",
    "# For non-working days\n",
    "X_train_nw = train_processed_nw.drop(columns=[\"log_bike_count\"])\n",
    "y_train_nw = train_processed_nw[\"log_bike_count\"]\n",
    "\n",
    "# Load the processed test dataset\n",
    "test_processed_w = pd.read_parquet(Path(\"data\") / \"test_processed_working_day.parquet\")\n",
    "test_processed_nw = pd.read_parquet(Path(\"data\") / \"test_processed_non_working_day.parquet\")\n",
    "\n",
    "# Separate features and target variables for test\n",
    "# For working days\n",
    "X_test_w = test_processed_w.drop(columns=[\"log_bike_count\"])\n",
    "y_test_w = test_processed_w[\"log_bike_count\"]\n",
    "# For non-working days\n",
    "X_test_nw = test_processed_nw.drop(columns=[\"log_bike_count\"])\n",
    "y_test_nw = test_processed_nw[\"log_bike_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Candidates for Tuning\n",
    "\n",
    "- **RandomForestRegressor**: Showed the best test RMSE among all models, indicating a strong fit to the data. Given that Random Forests are less prone to overfitting than individual decision trees, they are a promising option for further tuning.\n",
    "\n",
    "- **XGBRegressor**: This model has shown competitive performance, balancing well between training and testing errors. XGBoost is known for its efficiency and performance, especially in structured data problems like this one.\n",
    "\n",
    "- **CatBoostRegressor**: With a test RMSE comparable to that of XGBRegressor, CatBoost is especially powerful for datasets with categorical features. It's robust and typically requires less parameter tuning than other models.\n",
    "\n",
    "- **LGBMRegressor**: This model also shows promise with a good balance between training and test performance. LightGBM is efficient with large datasets and can be tuned to further enhance its predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now focusing on improving the RMSE of our XGBoost model. To start, we'll use grid search with cross-validation, a straightforward yet effective method for hyperparameter tuning. Grid search systematically explores a range of hyperparameter combinations to find the best performer, while cross-validation helps prevent overfitting by ensuring the model's robustness across different data splits. After this initial phase, we'll advance to more sophisticated and automated tuning methods with Optuna, which will allow us to explore a wider range of hyperparameters more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best parameters for working days: {'colsample_bytree': 1, 'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best parameters for non-working days: {'colsample_bytree': 1, 'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Define a common parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Create the GridSearchCV object for working days\n",
    "grid_search_w = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                             scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data for working days\n",
    "grid_search_w.fit(X_train_w, y_train_w.ravel())\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_w = grid_search_w.best_params_\n",
    "print(f\"Best parameters for working days: {best_params_w}\")\n",
    "\n",
    "# Create the GridSearchCV object for non-working days\n",
    "grid_search_nw = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                              scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
    "\n",
    "# Fit the grid search to the data for non-working days\n",
    "grid_search_nw.fit(X_train_nw, y_train_nw.ravel())\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_nw = grid_search_nw.best_params_\n",
    "print(f\"Best parameters for non-working days: {best_params_nw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6493656139840802\n",
      "RMSE for non-working days: 0.7658024131668655\n"
     ]
    }
   ],
   "source": [
    "xgb_w = XGBRegressor(colsample_bytree=1, learning_rate=0.2, max_depth=9, n_estimators=200, subsample=0.8)\n",
    "xgb_nw = XGBRegressor(colsample_bytree=1, learning_rate=0.2, max_depth=9, n_estimators=200, subsample=0.8)\n",
    "\n",
    "xgb_w.fit(X_train_w, y_train_w)\n",
    "xgb_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "y_pred_w = xgb_w.predict(X_test_w)\n",
    "y_pred_nw = xgb_nw.predict(X_test_nw)\n",
    "\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Increase figure size for better readability\n",
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Plot feature importance for the model trained on working days\n",
    "# Rotate feature names to 90 degrees for better visibility\n",
    "# Show only the top 15 features for readability\n",
    "plot_importance(xgb_w, importance_type='weight', max_num_features=15, title='Feature Importance for Working Days', xlabel='Weight')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()  # Adjust layout to fit rotated labels\n",
    "plt.show()\n",
    "\n",
    "# Repeat the same process for the model trained on non-working days\n",
    "plt.figure(figsize=(10, 15))\n",
    "plot_importance(xgb_nw, importance_type='weight', max_num_features=15, title='Feature Importance for Non-Working Days', xlabel='Weight')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyzed feature importances in our XGBoost model. This step is key to understanding which features are driving the model's predictions and to what extent. Identifying the most influential features helps us refine our approach to feature engineering and can lead to a more efficient, streamlined model. This analysis also serves as a reality check against our domain knowledge. If certain features are unexpectedly prominent or underrepresented, it may prompt a re-evaluation of our data or feature engineering strategies, ensuring that our model is built on a solid foundation that aligns with real-world factors influencing bike traffic in Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we proceed with the XGBoost tuning, we're now shifting to RandomizedSearchCV. This approach allows us to explore a wider parameter space more efficiently than GridSearchCV. RandomizedSearchCV randomly selects a number of parameter combinations, enabling us to cover a broad range of values without the computational intensity of testing every possible combination. This phase is particularly valuable for fine-tuning our model, as it can reveal optimal configurations that might be missed in a more constrained grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters for working days: {'subsample': 0.7, 'n_estimators': 200, 'max_depth': 13, 'learning_rate': 0.126, 'early_stopping_rounds': 10, 'colsample_bytree': 0.8}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters for non-working days: {'subsample': 0.6, 'n_estimators': 50, 'max_depth': 13, 'learning_rate': 0.184, 'early_stopping_rounds': 10, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Second XGBoost tuning\n",
    "# Define an expanded parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(50, 300, 50),\n",
    "    'max_depth': np.arange(3, 15, 2),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 6),\n",
    "    'subsample': np.linspace(0.5, 1, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "    'early_stopping_rounds': [10]  # Add early stopping rounds to the grid\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor with a placeholder for early_stopping_rounds\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Number of iterations for RandomizedSearch\n",
    "n_iter_search = 100\n",
    "\n",
    "# Create the RandomizedSearchCV object for working days\n",
    "random_search_w = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, \n",
    "                                     n_iter=n_iter_search, scoring='neg_mean_squared_error', \n",
    "                                     cv=5, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the random search to the data for working days\n",
    "random_search_w.fit(X_train_w, y_train_w.ravel(), eval_set=[(X_test_w, y_test_w.ravel())], verbose=False)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_w = random_search_w.best_params_\n",
    "print(f\"Best parameters for working days: {best_params_w}\")\n",
    "\n",
    "# Create the RandomizedSearchCV object for non-working days\n",
    "random_search_nw = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, \n",
    "                                      n_iter=n_iter_search, scoring='neg_mean_squared_error', \n",
    "                                      cv=5, verbose=1, random_state=42)\n",
    "\n",
    "# Fit the random search to the data for non-working days\n",
    "random_search_nw.fit(X_train_nw, y_train_nw.ravel(), eval_set=[(X_test_nw, y_test_nw.ravel())], verbose=False)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_nw = random_search_nw.best_params_\n",
    "print(f\"Best parameters for non-working days: {best_params_nw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6725925224865716\n",
      "RMSE for non-working days: 0.7711544261686053\n"
     ]
    }
   ],
   "source": [
    "xgb_w = XGBRegressor(colsample_bytree=0.8, learning_rate=0.126, max_depth=13, n_estimators=200, subsample=0.7)\n",
    "xgb_nw = XGBRegressor(colsample_bytree=0.8, learning_rate=0.184, max_depth=13, n_estimators=50, subsample=0.6)\n",
    "\n",
    "xgb_w.fit(X_train_w, y_train_w)\n",
    "xgb_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "y_pred_w = xgb_w.predict(X_test_w)\n",
    "y_pred_nw = xgb_nw.predict(X_test_nw)\n",
    "\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our second tuning attempt, we observed a slight increase in RMSE for both working and non-working days, compared to our first attempt. This indicates that while our expanded search has explored new areas of the parameter space, it may not have fully captured the optimal settings for our specific dataset. It's not uncommon for initial improvements to be followed by slight regressions as we explore more complex parameter spaces.\n",
    "\n",
    "Building on these insights, we're launching a third and final tuning iteration. We're further refining the parameter grid, covering even wider ranges and including additional parameters such as gamma, min_child_weight, and reg_alpha. These new parameters offer us finer control over the model's complexity and its ability to generalize. Moreover, we're increasing the number of iterations (n_iter_search) for the RandomizedSearchCV, which will allow us to explore this expanded parameter space more thoroughly. Our goal with this comprehensive approach is to strike an optimal balance between accuracy and generalization, aiming to surpass the performance achieved in our initial tuning attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=  13.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=  18.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=  24.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=  10.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=  17.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=  19.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=  15.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=  20.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=  21.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=  55.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  26.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  21.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  24.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=  16.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=  12.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=  15.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  24.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  22.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  22.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  27.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  15.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  14.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  12.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  11.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  12.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=  16.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  20.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  21.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=  31.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=  13.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=  12.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=  13.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=  13.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  39.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=  14.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   1.1s\n",
      "Best parameters for working days: {'subsample': 1.0, 'reg_alpha': 0.0, 'n_estimators': 350, 'min_child_weight': 2, 'max_depth': 13, 'learning_rate': 0.23555555555555557, 'gamma': 0.0, 'early_stopping_rounds': 20, 'colsample_bytree': 0.8}\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=4, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=12, min_child_weight=7, n_estimators=300, reg_alpha=0.25, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=4, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=5, n_estimators=400, reg_alpha=0.5, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=2, n_estimators=350, reg_alpha=0.5, subsample=0.5; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=300, reg_alpha=0.25, subsample=0.5; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=7, n_estimators=150, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=4, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.125, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=1, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=11, min_child_weight=6, n_estimators=150, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=200, reg_alpha=0.25, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=13, min_child_weight=1, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=10, min_child_weight=6, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=400, reg_alpha=0.25, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=9, n_estimators=150, reg_alpha=0.375, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=11, min_child_weight=5, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=12, min_child_weight=6, n_estimators=400, reg_alpha=0.375, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=6, n_estimators=200, reg_alpha=0.25, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=5, min_child_weight=2, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=15, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=5, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=3, min_child_weight=4, n_estimators=300, reg_alpha=0.25, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=6, n_estimators=300, reg_alpha=0.375, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=19, min_child_weight=9, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=11, min_child_weight=9, n_estimators=250, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=9, min_child_weight=7, n_estimators=450, reg_alpha=0.375, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=250, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=4, n_estimators=100, reg_alpha=0.0, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=12, min_child_weight=4, n_estimators=350, reg_alpha=0.375, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=1, n_estimators=50, reg_alpha=0.375, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=12, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=16, min_child_weight=4, n_estimators=50, reg_alpha=0.125, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=17, min_child_weight=5, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.125, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=19, min_child_weight=2, n_estimators=200, reg_alpha=0.125, subsample=0.6; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   9.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=15, min_child_weight=5, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=1, n_estimators=200, reg_alpha=0.375, subsample=0.5; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=6, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=9, n_estimators=100, reg_alpha=0.375, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=4, n_estimators=50, reg_alpha=0.375, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=19, min_child_weight=7, n_estimators=350, reg_alpha=0.25, subsample=0.8; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=17, min_child_weight=9, n_estimators=150, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=7, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=12, min_child_weight=9, n_estimators=450, reg_alpha=0.5, subsample=1.0; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=19, min_child_weight=6, n_estimators=50, reg_alpha=0.5, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=19, min_child_weight=9, n_estimators=100, reg_alpha=0.0, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=16, min_child_weight=7, n_estimators=300, reg_alpha=0.0, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1388888888888889, max_depth=14, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=12, min_child_weight=3, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=12, min_child_weight=8, n_estimators=400, reg_alpha=0.125, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=5, n_estimators=50, reg_alpha=0.25, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.20333333333333334, max_depth=7, min_child_weight=5, n_estimators=50, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1711111111111111, max_depth=14, min_child_weight=3, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=17, min_child_weight=1, n_estimators=350, reg_alpha=0.125, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=1, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=4, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=7, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=8, min_child_weight=8, n_estimators=50, reg_alpha=0.125, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=16, min_child_weight=1, n_estimators=100, reg_alpha=0.25, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.042222222222222223, max_depth=10, min_child_weight=2, n_estimators=50, reg_alpha=0.25, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=4, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=1, n_estimators=250, reg_alpha=0.0, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=9, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=9, min_child_weight=5, n_estimators=350, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=12, min_child_weight=7, n_estimators=100, reg_alpha=0.25, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=13, min_child_weight=7, n_estimators=50, reg_alpha=0.0, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=11, min_child_weight=6, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=10, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=14, min_child_weight=6, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=2, n_estimators=150, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=5, n_estimators=50, reg_alpha=0.5, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=16, min_child_weight=4, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=8, min_child_weight=7, n_estimators=200, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=8, n_estimators=400, reg_alpha=0.375, subsample=0.7; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=8, n_estimators=200, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.1388888888888889, max_depth=11, min_child_weight=6, n_estimators=250, reg_alpha=0.375, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=6, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=0.5; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=50, reg_alpha=0.375, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.2677777777777778, max_depth=15, min_child_weight=1, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=10, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=1, n_estimators=300, reg_alpha=0.5, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=3, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=2, n_estimators=150, reg_alpha=0.25, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=3, min_child_weight=8, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.125, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=16, min_child_weight=8, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=100, reg_alpha=0.125, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=3, min_child_weight=4, n_estimators=400, reg_alpha=0.5, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=3, n_estimators=350, reg_alpha=0.5, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.125, learning_rate=0.3, max_depth=3, min_child_weight=8, n_estimators=450, reg_alpha=0.25, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=7, min_child_weight=7, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=14, min_child_weight=7, n_estimators=150, reg_alpha=0.5, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=9, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=3, n_estimators=150, reg_alpha=0.375, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.07444444444444444, max_depth=13, min_child_weight=2, n_estimators=450, reg_alpha=0.25, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=15, min_child_weight=2, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.25, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=100, reg_alpha=0.5, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=9, n_estimators=350, reg_alpha=0.5, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.10666666666666666, max_depth=11, min_child_weight=9, n_estimators=300, reg_alpha=0.125, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=9, min_child_weight=2, n_estimators=100, reg_alpha=0.0, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=11, min_child_weight=3, n_estimators=50, reg_alpha=0.5, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=2, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=350, reg_alpha=0.125, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.3, max_depth=18, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.375, subsample=0.5; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=19, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.3, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0.25, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1388888888888889, max_depth=16, min_child_weight=4, n_estimators=350, reg_alpha=0.125, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.125, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=12, min_child_weight=4, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=100, reg_alpha=0.375, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=13, min_child_weight=2, n_estimators=350, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.20333333333333334, max_depth=3, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=400, reg_alpha=0.375, subsample=0.6; total time=  11.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=18, min_child_weight=1, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=19, min_child_weight=5, n_estimators=250, reg_alpha=0.125, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=2, n_estimators=150, reg_alpha=0.5, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=5, min_child_weight=8, n_estimators=450, reg_alpha=0.375, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=19, min_child_weight=4, n_estimators=300, reg_alpha=0.375, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=13, min_child_weight=8, n_estimators=150, reg_alpha=0.375, subsample=0.5; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.2677777777777778, max_depth=17, min_child_weight=1, n_estimators=400, reg_alpha=0.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=5, min_child_weight=8, n_estimators=200, reg_alpha=0.375, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=17, min_child_weight=8, n_estimators=300, reg_alpha=0.25, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=9, n_estimators=50, reg_alpha=0.125, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.20333333333333334, max_depth=16, min_child_weight=9, n_estimators=200, reg_alpha=0.125, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.10666666666666666, max_depth=12, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.01, max_depth=19, min_child_weight=2, n_estimators=150, reg_alpha=0.0, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=3, n_estimators=350, reg_alpha=0.25, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.375, learning_rate=0.07444444444444444, max_depth=10, min_child_weight=5, n_estimators=150, reg_alpha=0.25, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.0, learning_rate=0.01, max_depth=11, min_child_weight=1, n_estimators=450, reg_alpha=0.5, subsample=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=3, n_estimators=300, reg_alpha=0.25, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.25, learning_rate=0.1711111111111111, max_depth=15, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.042222222222222223, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.25, subsample=0.7; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=400, reg_alpha=0.25, subsample=0.6; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.375, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=3, min_child_weight=9, n_estimators=200, reg_alpha=0.5, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=450, reg_alpha=0.125, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=11, min_child_weight=1, n_estimators=200, reg_alpha=0.125, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.07444444444444444, max_depth=14, min_child_weight=1, n_estimators=350, reg_alpha=0.5, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.375, learning_rate=0.2677777777777778, max_depth=5, min_child_weight=4, n_estimators=200, reg_alpha=0.25, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=10, min_child_weight=8, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, early_stopping_rounds=20, gamma=0.0, learning_rate=0.042222222222222223, max_depth=4, min_child_weight=3, n_estimators=350, reg_alpha=0.0, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.2677777777777778, max_depth=13, min_child_weight=7, n_estimators=400, reg_alpha=0.125, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.25, learning_rate=0.3, max_depth=4, min_child_weight=4, n_estimators=450, reg_alpha=0.25, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.125, learning_rate=0.10666666666666666, max_depth=5, min_child_weight=2, n_estimators=300, reg_alpha=0.5, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=3, n_estimators=200, reg_alpha=0.0, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.10666666666666666, max_depth=9, min_child_weight=3, n_estimators=50, reg_alpha=0.375, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.07444444444444444, max_depth=6, min_child_weight=4, n_estimators=100, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.375, learning_rate=0.20333333333333334, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0.125, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.20333333333333334, max_depth=4, min_child_weight=1, n_estimators=200, reg_alpha=0.5, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.01, max_depth=5, min_child_weight=4, n_estimators=250, reg_alpha=0.375, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=9, min_child_weight=5, n_estimators=50, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.25, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=400, reg_alpha=0.125, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.07444444444444444, max_depth=15, min_child_weight=2, n_estimators=200, reg_alpha=0.0, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.375, learning_rate=0.23555555555555557, max_depth=18, min_child_weight=6, n_estimators=350, reg_alpha=0.375, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0.0, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, early_stopping_rounds=20, gamma=0.125, learning_rate=0.23555555555555557, max_depth=7, min_child_weight=1, n_estimators=100, reg_alpha=0.125, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.1388888888888889, max_depth=13, min_child_weight=7, n_estimators=200, reg_alpha=0.0, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=9, n_estimators=300, reg_alpha=0.5, subsample=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.0, learning_rate=0.3, max_depth=15, min_child_weight=7, n_estimators=250, reg_alpha=0.0, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, early_stopping_rounds=20, gamma=0.125, learning_rate=0.042222222222222223, max_depth=14, min_child_weight=7, n_estimators=300, reg_alpha=0.125, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, early_stopping_rounds=20, gamma=0.5, learning_rate=0.1711111111111111, max_depth=6, min_child_weight=6, n_estimators=250, reg_alpha=0.25, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, early_stopping_rounds=20, gamma=0.5, learning_rate=0.23555555555555557, max_depth=8, min_child_weight=2, n_estimators=200, reg_alpha=0.5, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, early_stopping_rounds=20, gamma=0.0, learning_rate=0.23555555555555557, max_depth=4, min_child_weight=2, n_estimators=50, reg_alpha=0.125, subsample=0.9; total time=   0.7s\n",
      "Best parameters for non-working days: {'subsample': 0.6, 'reg_alpha': 0.375, 'n_estimators': 350, 'min_child_weight': 6, 'max_depth': 18, 'learning_rate': 0.23555555555555557, 'gamma': 0.375, 'early_stopping_rounds': 20, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# 3rd try at xgboost tuning\n",
    "# Define an expanded parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(50, 500, 50),\n",
    "    'max_depth': np.arange(3, 20, 1),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'subsample': np.linspace(0.5, 1, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "    'gamma': np.linspace(0, 0.5, 5),\n",
    "    'min_child_weight': np.arange(1, 10, 1),\n",
    "    'reg_alpha': np.linspace(0, 0.5, 5),\n",
    "    'early_stopping_rounds': [20]  # Adjust early stopping rounds\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# Number of iterations for RandomizedSearch\n",
    "n_iter_search = 200  # Increased number of iterations\n",
    "\n",
    "# Create the RandomizedSearchCV object for working days\n",
    "random_search_w = RandomizedSearchCV(\n",
    "    estimator=xgb_model, param_distributions=param_grid, \n",
    "    n_iter=n_iter_search, scoring='neg_mean_squared_error', \n",
    "    cv=5, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the random search to the data for working days\n",
    "random_search_w.fit(\n",
    "    X_train_w, y_train_w.ravel(), \n",
    "    eval_set=[(X_test_w, y_test_w.ravel())], \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_w = random_search_w.best_params_\n",
    "print(f\"Best parameters for working days: {best_params_w}\")\n",
    "\n",
    "# Repeat the process for non-working days\n",
    "random_search_nw = RandomizedSearchCV(\n",
    "    estimator=xgb_model, param_distributions=param_grid, \n",
    "    n_iter=n_iter_search, scoring='neg_mean_squared_error', \n",
    "    cv=5, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "random_search_nw.fit(\n",
    "    X_train_nw, y_train_nw.ravel(), \n",
    "    eval_set=[(X_test_nw, y_test_nw.ravel())], \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_params_nw = random_search_nw.best_params_\n",
    "print(f\"Best parameters for non-working days: {best_params_nw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6221245288380202\n",
      "RMSE for non-working days: 0.742086171728935\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost Regressors with the best parameters, including early_stopping_rounds\n",
    "xgb_w = XGBRegressor(colsample_bytree=0.8, learning_rate=0.23555555555555557, \n",
    "                     max_depth=13, n_estimators=350, subsample=1.0, \n",
    "                     reg_alpha=0.0, min_child_weight=2, gamma=0.0,\n",
    "                     early_stopping_rounds=20)\n",
    "\n",
    "xgb_nw = XGBRegressor(colsample_bytree=0.7, learning_rate=0.23555555555555557, \n",
    "                      max_depth=18, n_estimators=350, subsample=0.6, \n",
    "                      reg_alpha=0.375, min_child_weight=6, gamma=0.375,\n",
    "                      early_stopping_rounds=20)\n",
    "\n",
    "# Fit the models\n",
    "xgb_w.fit(X_train_w, y_train_w, eval_set=[(X_test_w, y_test_w)], verbose=False)\n",
    "xgb_nw.fit(X_train_nw, y_train_nw, eval_set=[(X_test_nw, y_test_nw)], verbose=False)\n",
    "\n",
    "# Predictions\n",
    "y_pred_w = xgb_w.predict(X_test_w)\n",
    "y_pred_nw = xgb_nw.predict(X_test_nw)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After three rounds of hyperparameter tuning for the XGBoost model, we have made significant strides in refining its performance. Our final attempt, characterized by an even broader parameter range and an increased number of iterations for RandomizedSearchCV, yielded the most promising results. The RMSE for both working and non-working days has shown improvement, indicating that our efforts to fine-tune the model are paying off.\n",
    "\n",
    "This latest model, with its carefully selected hyperparameters, including early_stopping_rounds, gamma, min_child_weight, and reg_alpha, represents our best XGBoost configuration to date. It strikes a delicate balance between model complexity and the ability to generalize, making it a strong contender in our suite of predictive tools.\n",
    "\n",
    "While there's always room for further improvement and refinement, we will now shift our focus to tuning the other candidate models. This will give us a broader perspective on the most effective approaches for our dataset. If, after exploring these alternatives, the XGBoost model remains the most promising, we will revisit it for additional tuning and optimization. Our goal remains clear: to develop the most accurate and reliable predictive model for bike traffic trends in Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In optimizing our RandomForestRegressor model, we're turning to Optuna for swift and efficient hyperparameter tuning. Optuna outshines traditional methods like GridSearchCV with its advanced Bayesian optimization technique, which intelligently learns from past trials to predict more promising hyperparameters. This not only accelerates our tuning process but also increases the likelihood of discovering optimal settings. Our goal is to swiftly refine the RandomForest model, enhancing its predictive accuracy for bike traffic trends with a keen focus on minimizing RMSE for both working and non-working days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'n_estimators': [100, 200, 300, 400]\n",
    "}\n",
    "\n",
    "# Create the base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters\n",
    "rf_random_w = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "rf_random_nw = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model for working days\n",
    "print(\"Tuning for Working Days:\")\n",
    "rf_random_w.fit(X_train_w, y_train_w)\n",
    "\n",
    "# Fit the random search model for non-working days\n",
    "print(\"Tuning for Non-Working Days:\")\n",
    "rf_random_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters for Working Days:\", rf_random_w.best_params_)\n",
    "print(\"Best Parameters for Non-Working Days:\", rf_random_nw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Working Days: 0.6811713725612516\n",
      "RMSE for Non-Working Days: 0.7223587838757641\n"
     ]
    }
   ],
   "source": [
    "# Parameters for working days\n",
    "params_w = {\n",
    "    'n_estimators': 100,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 20\n",
    "}\n",
    "\n",
    "# Parameters for non-working days\n",
    "params_nw = {\n",
    "    'n_estimators': 300,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 20\n",
    "}\n",
    "\n",
    "# Create RandomForestRegressor models\n",
    "rf_model_w = RandomForestRegressor(**params_w)\n",
    "rf_model_nw = RandomForestRegressor(**params_nw)\n",
    "\n",
    "# Fit the models\n",
    "rf_model_w.fit(X_train_w, y_train_w)\n",
    "rf_model_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Make predictions using the models\n",
    "rf_model_w_pred = rf_model_w.predict(X_test_w)\n",
    "rf_model_nw_pred = rf_model_nw.predict(X_test_nw)\n",
    "\n",
    "# Calculate RMSE for each set\n",
    "rmse_rf_w = np.sqrt(mean_squared_error(y_test_w, rf_model_w_pred))\n",
    "rmse_rf_nw = np.sqrt(mean_squared_error(y_test_nw, rf_model_nw_pred))\n",
    "\n",
    "print(\"RMSE for Working Days:\", rmse_rf_w)\n",
    "print(\"RMSE for Non-Working Days:\", rmse_rf_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In optimizing the CatBoostRegressor with Optuna, we aim for precision and efficiency. Known for its prowess in handling categorical data, CatBoost requires careful tuning to unlock its full potential. Optuna's intelligent search method allows us to efficiently explore a broad range of hyperparameters, focusing on reducing RMSE and enhancing model generalization. By separately tuning models for working and non-working days, we're tailoring our approach to distinct traffic patterns, ensuring our predictions are as accurate and reliable as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 00:24:13,505] A new study created in memory with name: no-name-a0755bbf-9c2f-4a98-af76-557edba571a4\n",
      "[I 2023-12-08 00:24:26,564] Trial 0 finished with value: 0.6919112428996991 and parameters: {'iterations': 946, 'depth': 8, 'learning_rate': 0.2386685464410615, 'random_strength': 34, 'bagging_temperature': 0.6702062374111968, 'l2_leaf_reg': 0.39147211041483315, 'border_count': 175}. Best is trial 0 with value: 0.6919112428996991.\n",
      "[I 2023-12-08 00:24:32,203] Trial 1 finished with value: 0.6549454556070682 and parameters: {'iterations': 409, 'depth': 8, 'learning_rate': 0.24787276480234868, 'random_strength': 34, 'bagging_temperature': 0.1061904742795371, 'l2_leaf_reg': 4.163694268767005e-06, 'border_count': 253}. Best is trial 1 with value: 0.6549454556070682.\n",
      "[I 2023-12-08 00:24:48,139] Trial 2 finished with value: 0.6666220700715977 and parameters: {'iterations': 556, 'depth': 10, 'learning_rate': 0.14909364737212008, 'random_strength': 57, 'bagging_temperature': 0.8331232797926801, 'l2_leaf_reg': 0.0006272572567562269, 'border_count': 212}. Best is trial 1 with value: 0.6549454556070682.\n",
      "[I 2023-12-08 00:25:06,979] Trial 3 finished with value: 0.6728569966324297 and parameters: {'iterations': 672, 'depth': 10, 'learning_rate': 0.24910712416395847, 'random_strength': 75, 'bagging_temperature': 0.11261610002386868, 'l2_leaf_reg': 0.0004711486824023291, 'border_count': 59}. Best is trial 1 with value: 0.6549454556070682.\n",
      "[I 2023-12-08 00:25:13,017] Trial 4 finished with value: 0.6805545438384478 and parameters: {'iterations': 395, 'depth': 8, 'learning_rate': 0.17238864904954815, 'random_strength': 93, 'bagging_temperature': 0.9430384692872567, 'l2_leaf_reg': 1.5704631544871536e-06, 'border_count': 187}. Best is trial 1 with value: 0.6549454556070682.\n",
      "[I 2023-12-08 00:25:27,213] Trial 5 finished with value: 0.7150639844182782 and parameters: {'iterations': 543, 'depth': 10, 'learning_rate': 0.02447754608130128, 'random_strength': 71, 'bagging_temperature': 0.18535980955358955, 'l2_leaf_reg': 0.030337701273979455, 'border_count': 89}. Best is trial 1 with value: 0.6549454556070682.\n",
      "[I 2023-12-08 00:25:33,605] Trial 6 finished with value: 0.6515305712121623 and parameters: {'iterations': 740, 'depth': 4, 'learning_rate': 0.09102217626932198, 'random_strength': 23, 'bagging_temperature': 0.8248996988858823, 'l2_leaf_reg': 0.002248233807924704, 'border_count': 115}. Best is trial 6 with value: 0.6515305712121623.\n",
      "[I 2023-12-08 00:25:36,215] Trial 7 finished with value: 0.6632414242715166 and parameters: {'iterations': 299, 'depth': 4, 'learning_rate': 0.10008177931716579, 'random_strength': 66, 'bagging_temperature': 0.808851635445182, 'l2_leaf_reg': 0.04089529420804343, 'border_count': 190}. Best is trial 6 with value: 0.6515305712121623.\n",
      "[I 2023-12-08 00:25:40,436] Trial 8 finished with value: 0.6371356099242916 and parameters: {'iterations': 472, 'depth': 4, 'learning_rate': 0.19070512308943416, 'random_strength': 33, 'bagging_temperature': 0.6862671513598668, 'l2_leaf_reg': 2.0079811857246862e-07, 'border_count': 4}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:25:47,060] Trial 9 finished with value: 0.652329608116794 and parameters: {'iterations': 793, 'depth': 4, 'learning_rate': 0.1331962924127888, 'random_strength': 75, 'bagging_temperature': 0.29483340426833415, 'l2_leaf_reg': 0.0027880450705802277, 'border_count': 134}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:25:47,874] Trial 10 finished with value: 0.674518299779966 and parameters: {'iterations': 60, 'depth': 6, 'learning_rate': 0.29727012095795413, 'random_strength': 6, 'bagging_temperature': 0.5359648272767039, 'l2_leaf_reg': 2.8875957439797988e-08, 'border_count': 3}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:25:55,001] Trial 11 finished with value: 0.643775083840708 and parameters: {'iterations': 798, 'depth': 5, 'learning_rate': 0.06979509016636447, 'random_strength': 17, 'bagging_temperature': 0.9994404310518736, 'l2_leaf_reg': 6.1264312442570255, 'border_count': 1}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:26:05,064] Trial 12 finished with value: 0.6820089724320898 and parameters: {'iterations': 943, 'depth': 6, 'learning_rate': 0.014500138271766043, 'random_strength': 4, 'bagging_temperature': 0.9857654220982622, 'l2_leaf_reg': 9.480679828369873, 'border_count': 1}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:26:07,571] Trial 13 finished with value: 0.6581545395229411 and parameters: {'iterations': 206, 'depth': 5, 'learning_rate': 0.17940985434325643, 'random_strength': 25, 'bagging_temperature': 0.6112474907699468, 'l2_leaf_reg': 2.63908146055504e-05, 'border_count': 55}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:26:16,223] Trial 14 finished with value: 0.6378735844187301 and parameters: {'iterations': 824, 'depth': 5, 'learning_rate': 0.07431054312083887, 'random_strength': 45, 'bagging_temperature': 0.42204259957040974, 'l2_leaf_reg': 1.555791653665507e-08, 'border_count': 36}. Best is trial 8 with value: 0.6371356099242916.\n",
      "[I 2023-12-08 00:26:23,584] Trial 15 finished with value: 0.6213133359499909 and parameters: {'iterations': 625, 'depth': 6, 'learning_rate': 0.19379742030911284, 'random_strength': 45, 'bagging_temperature': 0.40574203229078215, 'l2_leaf_reg': 1.165514368735791e-08, 'border_count': 42}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:31,654] Trial 16 finished with value: 0.6482197103124369 and parameters: {'iterations': 640, 'depth': 7, 'learning_rate': 0.20076802380398417, 'random_strength': 49, 'bagging_temperature': 0.44115908155396166, 'l2_leaf_reg': 1.7542060129771255e-07, 'border_count': 35}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:36,487] Trial 17 finished with value: 0.6309935485459605 and parameters: {'iterations': 410, 'depth': 6, 'learning_rate': 0.2142111539529787, 'random_strength': 39, 'bagging_temperature': 0.3374160955130927, 'l2_leaf_reg': 2.8485039400302546e-07, 'border_count': 78}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:39,897] Trial 18 finished with value: 0.6606677418891036 and parameters: {'iterations': 271, 'depth': 7, 'learning_rate': 0.2132947774653785, 'random_strength': 56, 'bagging_temperature': 0.3374616031670628, 'l2_leaf_reg': 1.2063663777082835e-05, 'border_count': 91}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:46,740] Trial 19 finished with value: 0.6453047850652399 and parameters: {'iterations': 622, 'depth': 6, 'learning_rate': 0.1415428598542039, 'random_strength': 41, 'bagging_temperature': 0.2560276100511932, 'l2_leaf_reg': 1.725092087590754e-08, 'border_count': 130}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:48,455] Trial 20 finished with value: 0.68782443406709 and parameters: {'iterations': 107, 'depth': 9, 'learning_rate': 0.2183078842996423, 'random_strength': 91, 'bagging_temperature': 0.3822823877068859, 'l2_leaf_reg': 4.259005625957384e-07, 'border_count': 81}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:53,248] Trial 21 finished with value: 0.6317017249835654 and parameters: {'iterations': 444, 'depth': 6, 'learning_rate': 0.18697856632433044, 'random_strength': 35, 'bagging_temperature': 0.4927961914613632, 'l2_leaf_reg': 1.5339533282584708e-07, 'border_count': 30}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:26:57,836] Trial 22 finished with value: 0.6306520534494552 and parameters: {'iterations': 429, 'depth': 6, 'learning_rate': 0.16849695286953717, 'random_strength': 58, 'bagging_temperature': 0.48199905014152444, 'l2_leaf_reg': 6.920544999229901e-08, 'border_count': 34}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:01,820] Trial 23 finished with value: 0.6306287913610376 and parameters: {'iterations': 329, 'depth': 7, 'learning_rate': 0.16668262815378954, 'random_strength': 61, 'bagging_temperature': 0.24226538440400258, 'l2_leaf_reg': 1.007957508194459e-08, 'border_count': 55}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:05,645] Trial 24 finished with value: 0.6443651290257578 and parameters: {'iterations': 320, 'depth': 7, 'learning_rate': 0.16152141289082284, 'random_strength': 58, 'bagging_temperature': 0.2529691486171959, 'l2_leaf_reg': 1.082888240607142e-08, 'border_count': 55}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:07,889] Trial 25 finished with value: 0.6687465821870994 and parameters: {'iterations': 179, 'depth': 7, 'learning_rate': 0.12287166799877733, 'random_strength': 85, 'bagging_temperature': 0.1976686835425244, 'l2_leaf_reg': 5.637269739937635e-08, 'border_count': 112}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:13,190] Trial 26 finished with value: 0.6268007551600695 and parameters: {'iterations': 517, 'depth': 5, 'learning_rate': 0.16415917580889128, 'random_strength': 61, 'bagging_temperature': 0.045455042537597135, 'l2_leaf_reg': 6.046361738147927e-08, 'border_count': 26}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:18,194] Trial 27 finished with value: 0.6422481612009026 and parameters: {'iterations': 515, 'depth': 5, 'learning_rate': 0.15799748595114535, 'random_strength': 66, 'bagging_temperature': 0.002704368909351891, 'l2_leaf_reg': 1.0399881546249862e-06, 'border_count': 26}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:24,141] Trial 28 finished with value: 0.6551060255683303 and parameters: {'iterations': 596, 'depth': 5, 'learning_rate': 0.12232530020872953, 'random_strength': 82, 'bagging_temperature': 0.07978731639818964, 'l2_leaf_reg': 1.0642678331740806e-08, 'border_count': 69}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:33,920] Trial 29 finished with value: 0.6793914567154492 and parameters: {'iterations': 708, 'depth': 9, 'learning_rate': 0.17864892535494764, 'random_strength': 99, 'bagging_temperature': 0.0034208812270597466, 'l2_leaf_reg': 5.3820745363597996e-08, 'border_count': 21}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:37,831] Trial 30 finished with value: 0.6490829959708981 and parameters: {'iterations': 331, 'depth': 7, 'learning_rate': 0.15774748036206418, 'random_strength': 51, 'bagging_temperature': 0.17119714669385774, 'l2_leaf_reg': 1.052258289802412e-06, 'border_count': 101}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:42,908] Trial 31 finished with value: 0.6473665203044322 and parameters: {'iterations': 467, 'depth': 6, 'learning_rate': 0.17018762758193226, 'random_strength': 65, 'bagging_temperature': 0.3388518653422347, 'l2_leaf_reg': 7.057402600561514e-08, 'border_count': 47}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:47,967] Trial 32 finished with value: 0.6898903326911381 and parameters: {'iterations': 382, 'depth': 8, 'learning_rate': 0.19757648504898168, 'random_strength': 52, 'bagging_temperature': 0.4689110695062297, 'l2_leaf_reg': 5.8122952536587334e-08, 'border_count': 19}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:53,483] Trial 33 finished with value: 0.6431918808796395 and parameters: {'iterations': 522, 'depth': 6, 'learning_rate': 0.14647044718993504, 'random_strength': 61, 'bagging_temperature': 0.38516489598486914, 'l2_leaf_reg': 4.2771970360631707e-08, 'border_count': 153}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:27:59,132] Trial 34 finished with value: 0.6387755744958551 and parameters: {'iterations': 586, 'depth': 5, 'learning_rate': 0.2304256440113218, 'random_strength': 46, 'bagging_temperature': 0.534095826454957, 'l2_leaf_reg': 1.015950563189997e-08, 'border_count': 255}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:01,890] Trial 35 finished with value: 0.6305311046635265 and parameters: {'iterations': 216, 'depth': 7, 'learning_rate': 0.16919057177393146, 'random_strength': 74, 'bagging_temperature': 0.08649193036246891, 'l2_leaf_reg': 4.104958549970739e-06, 'border_count': 68}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:04,797] Trial 36 finished with value: 0.6712308508855338 and parameters: {'iterations': 210, 'depth': 8, 'learning_rate': 0.19530989889711636, 'random_strength': 79, 'bagging_temperature': 0.10802070237467587, 'l2_leaf_reg': 3.4806232671507503e-06, 'border_count': 68}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:06,781] Trial 37 finished with value: 0.667002097322213 and parameters: {'iterations': 153, 'depth': 7, 'learning_rate': 0.14854861060778898, 'random_strength': 71, 'bagging_temperature': 0.07335792635911906, 'l2_leaf_reg': 5.701912179922025e-07, 'border_count': 231}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:10,369] Trial 38 finished with value: 0.6641658905940071 and parameters: {'iterations': 248, 'depth': 9, 'learning_rate': 0.17618171275034625, 'random_strength': 71, 'bagging_temperature': 0.15641485752584117, 'l2_leaf_reg': 3.7806894286827745e-06, 'border_count': 45}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:14,789] Trial 39 finished with value: 0.6643900656505031 and parameters: {'iterations': 376, 'depth': 7, 'learning_rate': 0.25176081785300597, 'random_strength': 63, 'bagging_temperature': 0.20142639812821886, 'l2_leaf_reg': 1.744324376122682e-07, 'border_count': 64}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:24,146] Trial 40 finished with value: 0.6353390091270036 and parameters: {'iterations': 717, 'depth': 8, 'learning_rate': 0.1350077931825949, 'random_strength': 88, 'bagging_temperature': 0.1400215042174741, 'l2_leaf_reg': 1.8643066667556749e-06, 'border_count': 98}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:28,052] Trial 41 finished with value: 0.6671657392400258 and parameters: {'iterations': 354, 'depth': 6, 'learning_rate': 0.1710915577800683, 'random_strength': 54, 'bagging_temperature': 0.04774905096035745, 'l2_leaf_reg': 9.711462069809392e-08, 'border_count': 15}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:33,078] Trial 42 finished with value: 0.6642605021577631 and parameters: {'iterations': 431, 'depth': 7, 'learning_rate': 0.164081122860933, 'random_strength': 75, 'bagging_temperature': 0.1231622533540775, 'l2_leaf_reg': 3.151950546271383e-08, 'border_count': 43}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:39,626] Trial 43 finished with value: 0.6814327715566851 and parameters: {'iterations': 496, 'depth': 8, 'learning_rate': 0.18625039805015117, 'random_strength': 59, 'bagging_temperature': 0.2276121743935023, 'l2_leaf_reg': 4.7600817580882767e-07, 'border_count': 56}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:45,688] Trial 44 finished with value: 0.6562443276757137 and parameters: {'iterations': 561, 'depth': 6, 'learning_rate': 0.15550638359838845, 'random_strength': 68, 'bagging_temperature': 0.2781747730374828, 'l2_leaf_reg': 3.002452699400203e-08, 'border_count': 81}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:48,424] Trial 45 finished with value: 0.644275663127462 and parameters: {'iterations': 271, 'depth': 5, 'learning_rate': 0.20317777253356356, 'random_strength': 61, 'bagging_temperature': 0.15450124132890158, 'l2_leaf_reg': 1.3754164590824594e-07, 'border_count': 14}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:54,209] Trial 46 finished with value: 0.6535788399554083 and parameters: {'iterations': 657, 'depth': 4, 'learning_rate': 0.18094734757906147, 'random_strength': 44, 'bagging_temperature': 0.2321679881937642, 'l2_leaf_reg': 2.587394974895761e-08, 'border_count': 36}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:28:59,813] Trial 47 finished with value: 0.6366927755522 and parameters: {'iterations': 483, 'depth': 6, 'learning_rate': 0.16452335508427943, 'random_strength': 33, 'bagging_temperature': 0.05718510897573961, 'l2_leaf_reg': 8.999967835026524e-08, 'border_count': 47}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:01,203] Trial 48 finished with value: 0.7493449395149853 and parameters: {'iterations': 114, 'depth': 5, 'learning_rate': 0.12568350422784197, 'random_strength': 78, 'bagging_temperature': 0.11812137468804189, 'l2_leaf_reg': 2.780150030425666e-07, 'border_count': 146}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:12,249] Trial 49 finished with value: 0.6517217584167808 and parameters: {'iterations': 899, 'depth': 7, 'learning_rate': 0.1449803503870895, 'random_strength': 50, 'bagging_temperature': 0.17621814445911693, 'l2_leaf_reg': 1.8582203478816e-05, 'border_count': 12}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:18,708] Trial 50 finished with value: 0.6439207354693598 and parameters: {'iterations': 562, 'depth': 6, 'learning_rate': 0.1845668954935671, 'random_strength': 69, 'bagging_temperature': 0.28536911596117304, 'l2_leaf_reg': 2.562087618965128e-08, 'border_count': 74}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:22,995] Trial 51 finished with value: 0.6302503487183511 and parameters: {'iterations': 393, 'depth': 6, 'learning_rate': 0.2106245803147529, 'random_strength': 42, 'bagging_temperature': 0.34017279726754457, 'l2_leaf_reg': 3.159429020753157e-07, 'border_count': 82}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:26,235] Trial 52 finished with value: 0.6555225875798308 and parameters: {'iterations': 298, 'depth': 6, 'learning_rate': 0.2043397541341989, 'random_strength': 24, 'bagging_temperature': 0.3178660151029716, 'l2_leaf_reg': 5.611020873550936e-07, 'border_count': 60}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:31,827] Trial 53 finished with value: 0.6770544615819762 and parameters: {'iterations': 415, 'depth': 7, 'learning_rate': 0.18970670911244095, 'random_strength': 55, 'bagging_temperature': 0.4046333888636427, 'l2_leaf_reg': 9.809176414428198e-08, 'border_count': 90}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:34,444] Trial 54 finished with value: 0.6758659362997447 and parameters: {'iterations': 246, 'depth': 5, 'learning_rate': 0.16767755142466093, 'random_strength': 38, 'bagging_temperature': 0.3626844253682158, 'l2_leaf_reg': 2.5030136992087393e-08, 'border_count': 31}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:37,809] Trial 55 finished with value: 0.6596192486515651 and parameters: {'iterations': 356, 'depth': 4, 'learning_rate': 0.17577940863046404, 'random_strength': 44, 'bagging_temperature': 0.4144502655254503, 'l2_leaf_reg': 2.5144044717540407e-07, 'border_count': 109}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:43,230] Trial 56 finished with value: 0.6396300807676628 and parameters: {'iterations': 456, 'depth': 6, 'learning_rate': 0.22413620046467353, 'random_strength': 48, 'bagging_temperature': 0.44570365826441305, 'l2_leaf_reg': 7.653906645824678e-05, 'border_count': 53}. Best is trial 15 with value: 0.6213133359499909.\n",
      "[I 2023-12-08 00:29:51,727] Trial 57 finished with value: 0.6076754994312578 and parameters: {'iterations': 613, 'depth': 7, 'learning_rate': 0.20764723805432106, 'random_strength': 16, 'bagging_temperature': 0.29127568482112576, 'l2_leaf_reg': 1.348872394761508e-08, 'border_count': 37}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:29:59,194] Trial 58 finished with value: 0.664324171367983 and parameters: {'iterations': 602, 'depth': 7, 'learning_rate': 0.21393355627312033, 'random_strength': 15, 'bagging_temperature': 0.30488640386318416, 'l2_leaf_reg': 1.543164413812804e-08, 'border_count': 40}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:13,276] Trial 59 finished with value: 0.6551387859188736 and parameters: {'iterations': 764, 'depth': 8, 'learning_rate': 0.23325453539062588, 'random_strength': 30, 'bagging_temperature': 0.2552017719987217, 'l2_leaf_reg': 1.7949439538525233e-08, 'border_count': 74}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:24,760] Trial 60 finished with value: 0.6807854792685863 and parameters: {'iterations': 683, 'depth': 7, 'learning_rate': 0.20725041939968034, 'random_strength': 6, 'bagging_temperature': 0.19771495655134463, 'l2_leaf_reg': 1.026513753006675e-08, 'border_count': 27}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:31,374] Trial 61 finished with value: 0.6207604874463836 and parameters: {'iterations': 508, 'depth': 6, 'learning_rate': 0.19803967027242703, 'random_strength': 27, 'bagging_temperature': 0.3503243335679899, 'l2_leaf_reg': 4.4384714629810387e-08, 'border_count': 50}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:37,537] Trial 62 finished with value: 0.654034860200434 and parameters: {'iterations': 527, 'depth': 7, 'learning_rate': 0.19311640736383093, 'random_strength': 14, 'bagging_temperature': 0.357503051245746, 'l2_leaf_reg': 5.576921466030269e-08, 'border_count': 85}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:44,966] Trial 63 finished with value: 0.6746889145084166 and parameters: {'iterations': 627, 'depth': 6, 'learning_rate': 0.20819345263093914, 'random_strength': 28, 'bagging_temperature': 0.3186256670135683, 'l2_leaf_reg': 1.1376123327591262e-07, 'border_count': 51}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:50,666] Trial 64 finished with value: 0.6370918997987576 and parameters: {'iterations': 551, 'depth': 5, 'learning_rate': 0.1979600747876287, 'random_strength': 19, 'bagging_temperature': 0.2803587579007814, 'l2_leaf_reg': 2.8883423789176247e-07, 'border_count': 63}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:30:57,280] Trial 65 finished with value: 0.6554770405238248 and parameters: {'iterations': 493, 'depth': 8, 'learning_rate': 0.1841071928661419, 'random_strength': 12, 'bagging_temperature': 0.36923971885261925, 'l2_leaf_reg': 4.307757236482123e-08, 'border_count': 8}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:04,823] Trial 66 finished with value: 0.6250387286118325 and parameters: {'iterations': 679, 'depth': 6, 'learning_rate': 0.2223559521620247, 'random_strength': 20, 'bagging_temperature': 0.21840067462821688, 'l2_leaf_reg': 2.26263934945006e-08, 'border_count': 24}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:12,705] Trial 67 finished with value: 0.6391852302811789 and parameters: {'iterations': 680, 'depth': 6, 'learning_rate': 0.24390461283300108, 'random_strength': 19, 'bagging_temperature': 0.3319640243495678, 'l2_leaf_reg': 1.636007355169786e-07, 'border_count': 39}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:20,915] Trial 68 finished with value: 0.6664979789862446 and parameters: {'iterations': 834, 'depth': 5, 'learning_rate': 0.2246104637782815, 'random_strength': 21, 'bagging_temperature': 0.2256514658941745, 'l2_leaf_reg': 4.101364894901684e-08, 'border_count': 22}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:27,898] Trial 69 finished with value: 0.6301664967147237 and parameters: {'iterations': 646, 'depth': 6, 'learning_rate': 0.21714474125792368, 'random_strength': 10, 'bagging_temperature': 0.09355929244223828, 'l2_leaf_reg': 1.9455052434486352e-08, 'border_count': 29}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:36,513] Trial 70 finished with value: 0.6605831811484145 and parameters: {'iterations': 747, 'depth': 6, 'learning_rate': 0.2192106061056434, 'random_strength': 11, 'bagging_temperature': 0.3951308526659803, 'l2_leaf_reg': 1.812524903027294e-08, 'border_count': 5}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:43,974] Trial 71 finished with value: 0.6419228965296964 and parameters: {'iterations': 651, 'depth': 6, 'learning_rate': 0.21435627055096837, 'random_strength': 2, 'bagging_temperature': 0.08789295003065317, 'l2_leaf_reg': 2.2534984892513985e-08, 'border_count': 24}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:50,639] Trial 72 finished with value: 0.6378189495507026 and parameters: {'iterations': 609, 'depth': 6, 'learning_rate': 0.19507505031291977, 'random_strength': 8, 'bagging_temperature': 0.04544328714570803, 'l2_leaf_reg': 5.515125353078939e-08, 'border_count': 30}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:31:57,624] Trial 73 finished with value: 0.6421464956139022 and parameters: {'iterations': 580, 'depth': 6, 'learning_rate': 0.2383275581611693, 'random_strength': 28, 'bagging_temperature': 0.14927421862919385, 'l2_leaf_reg': 9.856237223726202e-08, 'border_count': 174}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:05,063] Trial 74 finished with value: 0.650265854448236 and parameters: {'iterations': 700, 'depth': 5, 'learning_rate': 0.20549313842891562, 'random_strength': 37, 'bagging_temperature': 0.02414063881370597, 'l2_leaf_reg': 3.5881244825769814e-08, 'border_count': 39}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:13,601] Trial 75 finished with value: 0.673212223089001 and parameters: {'iterations': 633, 'depth': 7, 'learning_rate': 0.19150899566753157, 'random_strength': 42, 'bagging_temperature': 0.11664516419377079, 'l2_leaf_reg': 1.5948861812570202e-08, 'border_count': 124}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:20,862] Trial 76 finished with value: 0.6368752722181285 and parameters: {'iterations': 661, 'depth': 6, 'learning_rate': 0.22298708661741606, 'random_strength': 22, 'bagging_temperature': 0.07520103354018293, 'l2_leaf_reg': 7.537446528582599e-08, 'border_count': 21}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:28,292] Trial 77 finished with value: 0.6745089710316717 and parameters: {'iterations': 727, 'depth': 5, 'learning_rate': 0.2101303590438614, 'random_strength': 9, 'bagging_temperature': 0.09910445878612797, 'l2_leaf_reg': 1.833538612125922e-07, 'border_count': 70}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:34,954] Trial 78 finished with value: 0.6537449419267992 and parameters: {'iterations': 529, 'depth': 7, 'learning_rate': 0.17618401975727715, 'random_strength': 15, 'bagging_temperature': 0.1877597743693712, 'l2_leaf_reg': 8.938455728816143e-07, 'border_count': 48}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:41,213] Trial 79 finished with value: 0.6479476765716226 and parameters: {'iterations': 573, 'depth': 6, 'learning_rate': 0.24975982793950158, 'random_strength': 27, 'bagging_temperature': 0.2961529499586699, 'l2_leaf_reg': 3.452003257330792e-07, 'border_count': 34}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:41,985] Trial 80 finished with value: 0.7166389974059653 and parameters: {'iterations': 57, 'depth': 7, 'learning_rate': 0.20202854471235063, 'random_strength': 32, 'bagging_temperature': 0.03632205595714969, 'l2_leaf_reg': 1.0302334133479458e-08, 'border_count': 14}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:45,907] Trial 81 finished with value: 0.6385636883304847 and parameters: {'iterations': 328, 'depth': 7, 'learning_rate': 0.15628782472801803, 'random_strength': 53, 'bagging_temperature': 0.2693813124667841, 'l2_leaf_reg': 3.4849157867153994e-08, 'border_count': 59}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:32:47,996] Trial 82 finished with value: 0.6829092021852851 and parameters: {'iterations': 221, 'depth': 4, 'learning_rate': 0.1886077479667175, 'random_strength': 18, 'bagging_temperature': 0.23675487680009802, 'l2_leaf_reg': 1.898997759055033e-08, 'border_count': 44}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:01,351] Trial 83 finished with value: 0.6662856773604404 and parameters: {'iterations': 505, 'depth': 10, 'learning_rate': 0.19905897944276432, 'random_strength': 41, 'bagging_temperature': 0.353683723360056, 'l2_leaf_reg': 6.714410560751659e-08, 'border_count': 53}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:06,102] Trial 84 finished with value: 0.656027900397379 and parameters: {'iterations': 401, 'depth': 7, 'learning_rate': 0.1810898777450048, 'random_strength': 64, 'bagging_temperature': 0.12678539315531745, 'l2_leaf_reg': 1.4685982427281763e-08, 'border_count': 26}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:07,787] Trial 85 finished with value: 0.6542169859732345 and parameters: {'iterations': 153, 'depth': 6, 'learning_rate': 0.17333750855373026, 'random_strength': 1, 'bagging_temperature': 0.21133535406663426, 'l2_leaf_reg': 3.449120447898986e-08, 'border_count': 100}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:10,924] Trial 86 finished with value: 0.6426781509474189 and parameters: {'iterations': 286, 'depth': 6, 'learning_rate': 0.1524525287191625, 'random_strength': 73, 'bagging_temperature': 0.16629123019345327, 'l2_leaf_reg': 1.2150281420482052e-07, 'border_count': 65}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:17,492] Trial 87 finished with value: 0.6591391729751253 and parameters: {'iterations': 614, 'depth': 6, 'learning_rate': 0.16448422235557872, 'random_strength': 25, 'bagging_temperature': 0.25092688020010057, 'l2_leaf_reg': 4.967309410431872e-08, 'border_count': 76}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:22,581] Trial 88 finished with value: 0.685666367507822 and parameters: {'iterations': 441, 'depth': 7, 'learning_rate': 0.2137266224560021, 'random_strength': 35, 'bagging_temperature': 0.3114798890631168, 'l2_leaf_reg': 2.311681578172224e-08, 'border_count': 32}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:31,585] Trial 89 finished with value: 0.6517178033702521 and parameters: {'iterations': 772, 'depth': 7, 'learning_rate': 0.22822264493097916, 'random_strength': 47, 'bagging_temperature': 0.06684303759553956, 'l2_leaf_reg': 1.0679309683323674e-08, 'border_count': 242}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:36,829] Trial 90 finished with value: 0.6691365095175902 and parameters: {'iterations': 547, 'depth': 5, 'learning_rate': 0.1706450908122896, 'random_strength': 59, 'bagging_temperature': 0.13977137251731603, 'l2_leaf_reg': 1.8934814039191162e-07, 'border_count': 57}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:41,495] Trial 91 finished with value: 0.6516330878239454 and parameters: {'iterations': 424, 'depth': 6, 'learning_rate': 0.1614504079824877, 'random_strength': 57, 'bagging_temperature': 0.42395969860543287, 'l2_leaf_reg': 8.144929411612334e-08, 'border_count': 40}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:46,596] Trial 92 finished with value: 0.6611875076249072 and parameters: {'iterations': 474, 'depth': 6, 'learning_rate': 0.1831714964389636, 'random_strength': 61, 'bagging_temperature': 0.37658670441151926, 'l2_leaf_reg': 3.270893276874143e-08, 'border_count': 19}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:51,574] Trial 93 finished with value: 0.6279759418966089 and parameters: {'iterations': 457, 'depth': 6, 'learning_rate': 0.1919862503309203, 'random_strength': 52, 'bagging_temperature': 0.015312858718905614, 'l2_leaf_reg': 5.7677214657332265e-08, 'border_count': 49}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:33:56,928] Trial 94 finished with value: 0.6487862393115887 and parameters: {'iterations': 457, 'depth': 7, 'learning_rate': 0.1953577367011621, 'random_strength': 50, 'bagging_temperature': 0.009196176000463213, 'l2_leaf_reg': 1.855175933943452e-08, 'border_count': 50}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:01,138] Trial 95 finished with value: 0.6395909981593294 and parameters: {'iterations': 373, 'depth': 6, 'learning_rate': 0.2043205887144047, 'random_strength': 82, 'bagging_temperature': 0.08564535358008793, 'l2_leaf_reg': 1.3088088590630784e-07, 'border_count': 69}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:04,871] Trial 96 finished with value: 0.631499184511469 and parameters: {'iterations': 350, 'depth': 5, 'learning_rate': 0.21894375046182185, 'random_strength': 67, 'bagging_temperature': 0.03152927575017429, 'l2_leaf_reg': 3.6476697713409865e-07, 'border_count': 43}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:12,513] Trial 97 finished with value: 0.6615278993800775 and parameters: {'iterations': 589, 'depth': 7, 'learning_rate': 0.18843860988665023, 'random_strength': 55, 'bagging_temperature': 0.002741993819574875, 'l2_leaf_reg': 2.701530325246151e-08, 'border_count': 10}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:20,004] Trial 98 finished with value: 0.6901118668522113 and parameters: {'iterations': 525, 'depth': 9, 'learning_rate': 0.17802967112886767, 'random_strength': 98, 'bagging_temperature': 0.05716234504695489, 'l2_leaf_reg': 6.23488657357421e-08, 'border_count': 61}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:27,374] Trial 99 finished with value: 0.6391218466341675 and parameters: {'iterations': 691, 'depth': 6, 'learning_rate': 0.21019989421706153, 'random_strength': 40, 'bagging_temperature': 0.09495165749765488, 'l2_leaf_reg': 1.4583603075124286e-08, 'border_count': 83}. Best is trial 57 with value: 0.6076754994312578.\n",
      "[I 2023-12-08 00:34:27,375] A new study created in memory with name: no-name-7268c651-8a32-423f-bc36-a52064532dd8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'iterations': 613, 'depth': 7, 'learning_rate': 0.20764723805432106, 'random_strength': 16, 'bagging_temperature': 0.29127568482112576, 'l2_leaf_reg': 1.348872394761508e-08, 'border_count': 37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 00:34:30,913] Trial 0 finished with value: 0.6905481077464449 and parameters: {'iterations': 607, 'depth': 6, 'learning_rate': 0.0731830958028836, 'random_strength': 58, 'bagging_temperature': 0.5231270899290706, 'l2_leaf_reg': 0.20239973103870504, 'border_count': 241}. Best is trial 0 with value: 0.6905481077464449.\n",
      "[I 2023-12-08 00:34:35,520] Trial 1 finished with value: 0.6885963965699421 and parameters: {'iterations': 861, 'depth': 5, 'learning_rate': 0.14441499271722189, 'random_strength': 3, 'bagging_temperature': 0.617925724625133, 'l2_leaf_reg': 1.1860131680972754e-08, 'border_count': 110}. Best is trial 1 with value: 0.6885963965699421.\n",
      "[I 2023-12-08 00:34:38,579] Trial 2 finished with value: 0.6904401063278548 and parameters: {'iterations': 583, 'depth': 5, 'learning_rate': 0.04190573843589153, 'random_strength': 49, 'bagging_temperature': 0.96652228109557, 'l2_leaf_reg': 0.13239203264714944, 'border_count': 103}. Best is trial 1 with value: 0.6885963965699421.\n",
      "[I 2023-12-08 00:34:39,598] Trial 3 finished with value: 0.71829235452314 and parameters: {'iterations': 74, 'depth': 10, 'learning_rate': 0.22322464471408685, 'random_strength': 13, 'bagging_temperature': 0.35668467694786854, 'l2_leaf_reg': 3.2082924630419494, 'border_count': 234}. Best is trial 1 with value: 0.6885963965699421.\n",
      "[I 2023-12-08 00:34:46,715] Trial 4 finished with value: 0.7120217875406829 and parameters: {'iterations': 553, 'depth': 10, 'learning_rate': 0.11484068507312263, 'random_strength': 34, 'bagging_temperature': 0.019662453385306367, 'l2_leaf_reg': 8.888702052149034e-06, 'border_count': 38}. Best is trial 1 with value: 0.6885963965699421.\n",
      "[I 2023-12-08 00:34:47,786] Trial 5 finished with value: 0.6684600786931835 and parameters: {'iterations': 230, 'depth': 4, 'learning_rate': 0.1256988297015524, 'random_strength': 25, 'bagging_temperature': 0.30837137507233026, 'l2_leaf_reg': 1.4192718004404124e-08, 'border_count': 127}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:34:54,966] Trial 6 finished with value: 0.6702948027229897 and parameters: {'iterations': 893, 'depth': 8, 'learning_rate': 0.28369847171765705, 'random_strength': 9, 'bagging_temperature': 0.9517881424552406, 'l2_leaf_reg': 0.0008870903812089338, 'border_count': 118}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:34:59,485] Trial 7 finished with value: 0.7141028852141907 and parameters: {'iterations': 307, 'depth': 10, 'learning_rate': 0.15594465109149447, 'random_strength': 28, 'bagging_temperature': 0.6231383842886307, 'l2_leaf_reg': 0.3035915857988864, 'border_count': 237}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:01,699] Trial 8 finished with value: 0.7104574581895449 and parameters: {'iterations': 254, 'depth': 9, 'learning_rate': 0.25921873036223475, 'random_strength': 95, 'bagging_temperature': 0.08372427143828165, 'l2_leaf_reg': 1.523146969191192e-06, 'border_count': 75}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:03,339] Trial 9 finished with value: 0.680212953792778 and parameters: {'iterations': 257, 'depth': 5, 'learning_rate': 0.09985570822994569, 'random_strength': 24, 'bagging_temperature': 0.6971007167535133, 'l2_leaf_reg': 1.2012777334677073e-06, 'border_count': 204}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:03,756] Trial 10 finished with value: 1.161526029428536 and parameters: {'iterations': 75, 'depth': 4, 'learning_rate': 0.01047139702130176, 'random_strength': 67, 'bagging_temperature': 0.279423053767929, 'l2_leaf_reg': 3.4927879372835744e-08, 'border_count': 172}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:11,030] Trial 11 finished with value: 0.6912795513658843 and parameters: {'iterations': 977, 'depth': 8, 'learning_rate': 0.29443100362938424, 'random_strength': 1, 'bagging_temperature': 0.939997008646699, 'l2_leaf_reg': 0.0010990066881344483, 'border_count': 150}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:15,796] Trial 12 finished with value: 0.6848055329082803 and parameters: {'iterations': 722, 'depth': 7, 'learning_rate': 0.19205151532345027, 'random_strength': 41, 'bagging_temperature': 0.8052908398927012, 'l2_leaf_reg': 0.0005898677279106506, 'border_count': 4}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:18,887] Trial 13 finished with value: 0.6876312990295889 and parameters: {'iterations': 421, 'depth': 8, 'learning_rate': 0.2043547081409366, 'random_strength': 20, 'bagging_temperature': 0.39914871272942254, 'l2_leaf_reg': 4.11886021399242e-05, 'border_count': 143}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:23,489] Trial 14 finished with value: 0.6755106207562872 and parameters: {'iterations': 711, 'depth': 7, 'learning_rate': 0.2904556928952012, 'random_strength': 12, 'bagging_temperature': 0.8097817989572349, 'l2_leaf_reg': 0.0005096591797768906, 'border_count': 73}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:26,347] Trial 15 finished with value: 0.6854495032073818 and parameters: {'iterations': 385, 'depth': 8, 'learning_rate': 0.2462052750682847, 'random_strength': 39, 'bagging_temperature': 0.22236602327650282, 'l2_leaf_reg': 0.007709956944078948, 'border_count': 181}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:30,842] Trial 16 finished with value: 0.6883698918791372 and parameters: {'iterations': 989, 'depth': 4, 'learning_rate': 0.16871132118484647, 'random_strength': 76, 'bagging_temperature': 0.4710092631441217, 'l2_leaf_reg': 1.265343020652411e-07, 'border_count': 122}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:35,689] Trial 17 finished with value: 0.7155955557533272 and parameters: {'iterations': 842, 'depth': 6, 'learning_rate': 0.12618000640021992, 'random_strength': 14, 'bagging_temperature': 0.19169414020099873, 'l2_leaf_reg': 4.251672075392594e-05, 'border_count': 77}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:39,465] Trial 18 finished with value: 0.7002060042344347 and parameters: {'iterations': 441, 'depth': 9, 'learning_rate': 0.18062997854351773, 'random_strength': 29, 'bagging_temperature': 0.47061753651634936, 'l2_leaf_reg': 2.931477054212439e-07, 'border_count': 164}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:40,587] Trial 19 finished with value: 0.6872798731756306 and parameters: {'iterations': 192, 'depth': 6, 'learning_rate': 0.21914942466040296, 'random_strength': 1, 'bagging_temperature': 0.36405300032785926, 'l2_leaf_reg': 0.005308554331829727, 'border_count': 199}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:46,187] Trial 20 finished with value: 0.6909701313841811 and parameters: {'iterations': 684, 'depth': 9, 'learning_rate': 0.14481897498276963, 'random_strength': 45, 'bagging_temperature': 0.9997862415737055, 'l2_leaf_reg': 1.133610597791598e-08, 'border_count': 93}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:51,569] Trial 21 finished with value: 0.7044139974642242 and parameters: {'iterations': 841, 'depth': 7, 'learning_rate': 0.29762935723529976, 'random_strength': 14, 'bagging_temperature': 0.850281446400726, 'l2_leaf_reg': 9.86435918453438e-05, 'border_count': 52}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:35:56,194] Trial 22 finished with value: 0.6895503186934063 and parameters: {'iterations': 722, 'depth': 7, 'learning_rate': 0.26900020114139794, 'random_strength': 11, 'bagging_temperature': 0.8758942208728328, 'l2_leaf_reg': 6.617896693774426e-06, 'border_count': 128}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:02,407] Trial 23 finished with value: 0.7115202333528281 and parameters: {'iterations': 892, 'depth': 8, 'learning_rate': 0.27055374264887966, 'random_strength': 19, 'bagging_temperature': 0.792916371887674, 'l2_leaf_reg': 0.0002811125973117575, 'border_count': 50}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:05,949] Trial 24 finished with value: 0.6858858145812166 and parameters: {'iterations': 777, 'depth': 4, 'learning_rate': 0.22278421110082158, 'random_strength': 8, 'bagging_temperature': 0.7403312937028858, 'l2_leaf_reg': 0.002876665606322896, 'border_count': 79}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:10,121] Trial 25 finished with value: 0.6917533858698698 and parameters: {'iterations': 632, 'depth': 7, 'learning_rate': 0.24443629375199713, 'random_strength': 33, 'bagging_temperature': 0.9303248030019248, 'l2_leaf_reg': 0.0002996891299337082, 'border_count': 22}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:13,207] Trial 26 finished with value: 0.676939387757987 and parameters: {'iterations': 518, 'depth': 6, 'learning_rate': 0.29989773216073945, 'random_strength': 21, 'bagging_temperature': 0.8892249441695922, 'l2_leaf_reg': 0.017778559624102398, 'border_count': 136}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:19,248] Trial 27 finished with value: 0.7253520073522278 and parameters: {'iterations': 758, 'depth': 9, 'learning_rate': 0.18112014881487243, 'random_strength': 57, 'bagging_temperature': 0.8403602150252069, 'l2_leaf_reg': 0.0012709026040722009, 'border_count': 94}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:23,976] Trial 28 finished with value: 0.6946927596921361 and parameters: {'iterations': 936, 'depth': 5, 'learning_rate': 0.2814218736128455, 'random_strength': 7, 'bagging_temperature': 0.7352378845359838, 'l2_leaf_reg': 1.7234576493652608e-05, 'border_count': 116}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:28,513] Trial 29 finished with value: 0.7314618025247979 and parameters: {'iterations': 648, 'depth': 8, 'learning_rate': 0.24639310571347878, 'random_strength': 99, 'bagging_temperature': 0.9923719442006407, 'l2_leaf_reg': 6.542932282350095e-05, 'border_count': 61}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:29,576] Trial 30 finished with value: 0.6923649821225236 and parameters: {'iterations': 177, 'depth': 6, 'learning_rate': 0.27646880367768256, 'random_strength': 55, 'bagging_temperature': 0.5403521789713176, 'l2_leaf_reg': 0.00018390841351624193, 'border_count': 158}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:32,176] Trial 31 finished with value: 0.6935632992286859 and parameters: {'iterations': 447, 'depth': 6, 'learning_rate': 0.2960191587111593, 'random_strength': 22, 'bagging_temperature': 0.8964873791103709, 'l2_leaf_reg': 0.014118179630985075, 'border_count': 140}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:35,495] Trial 32 finished with value: 0.704448097266649 and parameters: {'iterations': 523, 'depth': 7, 'learning_rate': 0.2991461315590757, 'random_strength': 21, 'bagging_temperature': 0.9258856710718076, 'l2_leaf_reg': 0.02135316469793446, 'border_count': 132}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:39,918] Trial 33 finished with value: 0.6947116480687162 and parameters: {'iterations': 789, 'depth': 6, 'learning_rate': 0.2595116787689266, 'random_strength': 7, 'bagging_temperature': 0.8546378189610354, 'l2_leaf_reg': 0.0011081701516500054, 'border_count': 105}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:42,556] Trial 34 finished with value: 0.6765939301450482 and parameters: {'iterations': 508, 'depth': 5, 'learning_rate': 0.27747436462361563, 'random_strength': 15, 'bagging_temperature': 0.910581677648621, 'l2_leaf_reg': 0.05205257887959146, 'border_count': 114}. Best is trial 5 with value: 0.6684600786931835.\n",
      "[I 2023-12-08 00:36:45,382] Trial 35 finished with value: 0.661925318937774 and parameters: {'iterations': 594, 'depth': 4, 'learning_rate': 0.23529006200807487, 'random_strength': 14, 'bagging_temperature': 0.9622938469225055, 'l2_leaf_reg': 0.08586119303022197, 'border_count': 110}. Best is trial 35 with value: 0.661925318937774.\n",
      "[I 2023-12-08 00:36:48,183] Trial 36 finished with value: 0.6582096594274485 and parameters: {'iterations': 595, 'depth': 4, 'learning_rate': 0.23275803348621085, 'random_strength': 28, 'bagging_temperature': 0.9641101872662287, 'l2_leaf_reg': 0.4840264298247187, 'border_count': 91}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:36:50,916] Trial 37 finished with value: 0.6663591620725279 and parameters: {'iterations': 573, 'depth': 4, 'learning_rate': 0.23095821100409494, 'random_strength': 30, 'bagging_temperature': 0.9606214818854341, 'l2_leaf_reg': 0.8275161443716594, 'border_count': 92}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:36:53,617] Trial 38 finished with value: 0.6972756154070696 and parameters: {'iterations': 587, 'depth': 4, 'learning_rate': 0.21052724054530625, 'random_strength': 36, 'bagging_temperature': 0.6183938715769186, 'l2_leaf_reg': 1.197662796689313, 'border_count': 101}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:36:56,272] Trial 39 finished with value: 0.6788398507058666 and parameters: {'iterations': 579, 'depth': 4, 'learning_rate': 0.2303553347225913, 'random_strength': 31, 'bagging_temperature': 0.9953087872316025, 'l2_leaf_reg': 8.8743023048305, 'border_count': 94}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:36:58,030] Trial 40 finished with value: 0.7033344587098966 and parameters: {'iterations': 345, 'depth': 5, 'learning_rate': 0.2043368499204724, 'random_strength': 46, 'bagging_temperature': 0.9735770735189804, 'l2_leaf_reg': 0.5381237761148401, 'border_count': 30}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:00,463] Trial 41 finished with value: 0.6681902225122706 and parameters: {'iterations': 493, 'depth': 4, 'learning_rate': 0.2552224893382391, 'random_strength': 26, 'bagging_temperature': 0.9415298835326894, 'l2_leaf_reg': 0.08442284269623053, 'border_count': 86}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:02,684] Trial 42 finished with value: 0.6902933740338462 and parameters: {'iterations': 481, 'depth': 4, 'learning_rate': 0.2254399580597453, 'random_strength': 27, 'bagging_temperature': 0.9481469512774044, 'l2_leaf_reg': 0.08761131368270998, 'border_count': 84}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:05,584] Trial 43 finished with value: 0.6804194343947009 and parameters: {'iterations': 628, 'depth': 4, 'learning_rate': 0.23633396287932726, 'random_strength': 37, 'bagging_temperature': 0.9459735973667712, 'l2_leaf_reg': 0.16547489397276963, 'border_count': 60}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:08,516] Trial 44 finished with value: 0.7006757038435325 and parameters: {'iterations': 562, 'depth': 5, 'learning_rate': 0.2617632541879609, 'random_strength': 25, 'bagging_temperature': 0.8915368222365254, 'l2_leaf_reg': 0.40941257786453983, 'border_count': 110}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:10,306] Trial 45 finished with value: 0.6768203549489894 and parameters: {'iterations': 363, 'depth': 4, 'learning_rate': 0.25375500804138645, 'random_strength': 32, 'bagging_temperature': 0.7793121422907583, 'l2_leaf_reg': 0.9038138512067935, 'border_count': 86}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:10,651] Trial 46 finished with value: 0.7356980090088598 and parameters: {'iterations': 56, 'depth': 5, 'learning_rate': 0.21540037633770592, 'random_strength': 17, 'bagging_temperature': 0.6664263123971615, 'l2_leaf_reg': 1.9877401384528162, 'border_count': 62}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:13,742] Trial 47 finished with value: 0.6850858499264753 and parameters: {'iterations': 670, 'depth': 4, 'learning_rate': 0.23622375166615386, 'random_strength': 43, 'bagging_temperature': 0.8407453806008575, 'l2_leaf_reg': 0.19436186021884075, 'border_count': 109}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:15,039] Trial 48 finished with value: 0.6859459701840366 and parameters: {'iterations': 284, 'depth': 4, 'learning_rate': 0.09048383921646297, 'random_strength': 68, 'bagging_temperature': 0.9560391707239161, 'l2_leaf_reg': 0.044800028298873903, 'border_count': 123}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:15,873] Trial 49 finished with value: 0.6708697419749995 and parameters: {'iterations': 129, 'depth': 5, 'learning_rate': 0.2035765345925324, 'random_strength': 52, 'bagging_temperature': 0.913624528498211, 'l2_leaf_reg': 0.23695663198540842, 'border_count': 148}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:18,382] Trial 50 finished with value: 0.6943057175285544 and parameters: {'iterations': 484, 'depth': 5, 'learning_rate': 0.12809781217637253, 'random_strength': 26, 'bagging_temperature': 0.996052166990188, 'l2_leaf_reg': 2.75481830139373, 'border_count': 66}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:19,390] Trial 51 finished with value: 0.7054664329634274 and parameters: {'iterations': 214, 'depth': 4, 'learning_rate': 0.2503785445066189, 'random_strength': 5, 'bagging_temperature': 0.9519960495854576, 'l2_leaf_reg': 0.07526823108856276, 'border_count': 99}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:22,165] Trial 52 finished with value: 0.6726209898803135 and parameters: {'iterations': 605, 'depth': 4, 'learning_rate': 0.2648215997198661, 'random_strength': 10, 'bagging_temperature': 0.8648777346927767, 'l2_leaf_reg': 0.7270782774915812, 'border_count': 121}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:23,907] Trial 53 finished with value: 0.6775016778772732 and parameters: {'iterations': 390, 'depth': 4, 'learning_rate': 0.23934862744030547, 'random_strength': 17, 'bagging_temperature': 0.8288401837279719, 'l2_leaf_reg': 0.420354121327331, 'border_count': 72}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:26,636] Trial 54 finished with value: 0.6838501973099764 and parameters: {'iterations': 544, 'depth': 4, 'learning_rate': 0.2803528887803548, 'random_strength': 29, 'bagging_temperature': 0.8854596063290546, 'l2_leaf_reg': 0.13660862453970832, 'border_count': 181}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:28,387] Trial 55 finished with value: 0.708666979203656 and parameters: {'iterations': 318, 'depth': 5, 'learning_rate': 0.25513880010153056, 'random_strength': 84, 'bagging_temperature': 0.9552773676429863, 'l2_leaf_reg': 3.126633853757957e-08, 'border_count': 252}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:28,975] Trial 56 finished with value: 0.6911890940949423 and parameters: {'iterations': 116, 'depth': 4, 'learning_rate': 0.23111641261083252, 'random_strength': 3, 'bagging_temperature': 0.8081558594905467, 'l2_leaf_reg': 0.03343253730368174, 'border_count': 83}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:35,994] Trial 57 finished with value: 0.698512046221785 and parameters: {'iterations': 696, 'depth': 9, 'learning_rate': 0.2867683558393401, 'random_strength': 24, 'bagging_temperature': 0.9174934379266131, 'l2_leaf_reg': 0.006129104808826092, 'border_count': 156}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:43,019] Trial 58 finished with value: 0.6950730524514588 and parameters: {'iterations': 885, 'depth': 5, 'learning_rate': 0.2685869676771415, 'random_strength': 40, 'bagging_temperature': 0.7647752123349716, 'l2_leaf_reg': 1.2388582066866938e-06, 'border_count': 43}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:48,896] Trial 59 finished with value: 0.7249262071483665 and parameters: {'iterations': 745, 'depth': 8, 'learning_rate': 0.1958555925014518, 'random_strength': 11, 'bagging_temperature': 0.9731424619513206, 'l2_leaf_reg': 0.0035081128762729278, 'border_count': 129}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:53,086] Trial 60 finished with value: 0.6813558045135959 and parameters: {'iterations': 807, 'depth': 4, 'learning_rate': 0.22007353928862675, 'random_strength': 17, 'bagging_temperature': 0.8698435951821795, 'l2_leaf_reg': 0.2951523108496275, 'border_count': 102}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:53,850] Trial 61 finished with value: 0.6950195023926014 and parameters: {'iterations': 144, 'depth': 5, 'learning_rate': 0.2450779366246534, 'random_strength': 53, 'bagging_temperature': 0.9153678847319784, 'l2_leaf_reg': 0.10735424675713383, 'border_count': 149}. Best is trial 36 with value: 0.6582096594274485.\n",
      "[I 2023-12-08 00:37:54,923] Trial 62 finished with value: 0.6458924991371856 and parameters: {'iterations': 233, 'depth': 4, 'learning_rate': 0.23137393598123648, 'random_strength': 67, 'bagging_temperature': 0.9306282899587772, 'l2_leaf_reg': 0.19428507100970824, 'border_count': 142}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:37:56,210] Trial 63 finished with value: 0.6708156123122194 and parameters: {'iterations': 261, 'depth': 4, 'learning_rate': 0.2292160260371768, 'random_strength': 71, 'bagging_temperature': 0.9990916443346022, 'l2_leaf_reg': 0.011483351309929047, 'border_count': 138}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:37:57,195] Trial 64 finished with value: 0.6907870593541228 and parameters: {'iterations': 207, 'depth': 4, 'learning_rate': 0.2544847589925625, 'random_strength': 60, 'bagging_temperature': 0.8303194634143268, 'l2_leaf_reg': 1.5560942598384433, 'border_count': 90}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:38:02,935] Trial 65 finished with value: 0.6963376412034528 and parameters: {'iterations': 425, 'depth': 10, 'learning_rate': 0.24146305168735618, 'random_strength': 84, 'bagging_temperature': 0.9342231363010783, 'l2_leaf_reg': 4.0507285918582685, 'border_count': 170}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:38:04,022] Trial 66 finished with value: 0.6861344250282599 and parameters: {'iterations': 233, 'depth': 4, 'learning_rate': 0.2878633840638218, 'random_strength': 48, 'bagging_temperature': 0.9692255032705103, 'l2_leaf_reg': 0.03857832042175284, 'border_count': 121}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:38:05,504] Trial 67 finished with value: 0.6826741244419527 and parameters: {'iterations': 312, 'depth': 4, 'learning_rate': 0.1615178861906367, 'random_strength': 61, 'bagging_temperature': 0.8800918956646325, 'l2_leaf_reg': 0.6181639420761015, 'border_count': 114}. Best is trial 62 with value: 0.6458924991371856.\n",
      "[I 2023-12-08 00:38:07,705] Trial 68 finished with value: 0.6412782535038966 and parameters: {'iterations': 460, 'depth': 4, 'learning_rate': 0.2721149582388359, 'random_strength': 36, 'bagging_temperature': 0.9031049356114378, 'l2_leaf_reg': 3.7576940764715413e-06, 'border_count': 96}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:10,158] Trial 69 finished with value: 0.683298485099511 and parameters: {'iterations': 465, 'depth': 5, 'learning_rate': 0.21147795056167754, 'random_strength': 31, 'bagging_temperature': 0.8141543590499721, 'l2_leaf_reg': 2.3122784971601084e-06, 'border_count': 72}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:12,693] Trial 70 finished with value: 0.6882197595352769 and parameters: {'iterations': 552, 'depth': 4, 'learning_rate': 0.270598629950655, 'random_strength': 35, 'bagging_temperature': 0.902952492137971, 'l2_leaf_reg': 0.32095857833028246, 'border_count': 226}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:14,979] Trial 71 finished with value: 0.6618167138193728 and parameters: {'iterations': 498, 'depth': 4, 'learning_rate': 0.2596350035479207, 'random_strength': 23, 'bagging_temperature': 0.9323586940585381, 'l2_leaf_reg': 5.072544967045357e-07, 'border_count': 102}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:17,271] Trial 72 finished with value: 0.6867458889919753 and parameters: {'iterations': 499, 'depth': 4, 'learning_rate': 0.2606225697764093, 'random_strength': 24, 'bagging_temperature': 0.9285715043786745, 'l2_leaf_reg': 1.9535282275384466e-07, 'border_count': 97}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:20,107] Trial 73 finished with value: 0.6837244065032203 and parameters: {'iterations': 596, 'depth': 4, 'learning_rate': 0.24946485556625003, 'random_strength': 29, 'bagging_temperature': 0.861060046911178, 'l2_leaf_reg': 3.9022582059284736e-07, 'border_count': 108}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:23,109] Trial 74 finished with value: 0.6889708107618449 and parameters: {'iterations': 656, 'depth': 4, 'learning_rate': 0.23294745368931855, 'random_strength': 20, 'bagging_temperature': 0.9506279969962831, 'l2_leaf_reg': 1.2858875311419944e-08, 'border_count': 80}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:25,594] Trial 75 finished with value: 0.6741757151373213 and parameters: {'iterations': 537, 'depth': 4, 'learning_rate': 0.22271355383564306, 'random_strength': 38, 'bagging_temperature': 0.9012943616752519, 'l2_leaf_reg': 3.61191749812828e-06, 'border_count': 89}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:28,905] Trial 76 finished with value: 0.7037158097274986 and parameters: {'iterations': 624, 'depth': 5, 'learning_rate': 0.2747083783139376, 'random_strength': 34, 'bagging_temperature': 0.9802392771249286, 'l2_leaf_reg': 4.1641916313172464e-07, 'border_count': 106}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:31,570] Trial 77 finished with value: 0.6782899743151724 and parameters: {'iterations': 576, 'depth': 4, 'learning_rate': 0.263447770560891, 'random_strength': 42, 'bagging_temperature': 0.9711849430040316, 'l2_leaf_reg': 9.85527326386296e-08, 'border_count': 117}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:33,723] Trial 78 finished with value: 0.6826804709525047 and parameters: {'iterations': 407, 'depth': 5, 'learning_rate': 0.24805122494671672, 'random_strength': 22, 'bagging_temperature': 0.8515785504691307, 'l2_leaf_reg': 1.682601358552428e-05, 'border_count': 131}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:35,894] Trial 79 finished with value: 0.6786936239215471 and parameters: {'iterations': 455, 'depth': 4, 'learning_rate': 0.24183943797838214, 'random_strength': 28, 'bagging_temperature': 0.9209520043402325, 'l2_leaf_reg': 7.110380309384831e-07, 'border_count': 53}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:38,275] Trial 80 finished with value: 0.677141597320868 and parameters: {'iterations': 524, 'depth': 4, 'learning_rate': 0.22512808948726162, 'random_strength': 14, 'bagging_temperature': 0.9371733827153705, 'l2_leaf_reg': 0.07421488675813322, 'border_count': 75}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:41,700] Trial 81 finished with value: 0.6880870282326925 and parameters: {'iterations': 481, 'depth': 8, 'learning_rate': 0.2840435723343211, 'random_strength': 17, 'bagging_temperature': 0.977210519273339, 'l2_leaf_reg': 0.14258843209354655, 'border_count': 143}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:43,363] Trial 82 finished with value: 0.6736432950228355 and parameters: {'iterations': 353, 'depth': 4, 'learning_rate': 0.2915238241422974, 'random_strength': 26, 'bagging_temperature': 0.8879899017136994, 'l2_leaf_reg': 6.965125984685218e-06, 'border_count': 96}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:47,539] Trial 83 finished with value: 0.6951794510154599 and parameters: {'iterations': 922, 'depth': 4, 'learning_rate': 0.27094852742993764, 'random_strength': 23, 'bagging_temperature': 0.9971112255042864, 'l2_leaf_reg': 1.0626178651171445, 'border_count': 113}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:48,831] Trial 84 finished with value: 0.6966884474438257 and parameters: {'iterations': 288, 'depth': 4, 'learning_rate': 0.2574383713670235, 'random_strength': 9, 'bagging_temperature': 0.9456139839050851, 'l2_leaf_reg': 0.00013366180124245322, 'border_count': 127}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:52,463] Trial 85 finished with value: 0.7199119871215532 and parameters: {'iterations': 568, 'depth': 7, 'learning_rate': 0.2813049494782854, 'random_strength': 18, 'bagging_temperature': 0.8862461914904181, 'l2_leaf_reg': 0.0007079466618493413, 'border_count': 104}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:38:59,969] Trial 86 finished with value: 0.6918057078993035 and parameters: {'iterations': 968, 'depth': 9, 'learning_rate': 0.23690189210865148, 'random_strength': 31, 'bagging_temperature': 0.9630686770405754, 'l2_leaf_reg': 0.23374674813277704, 'border_count': 91}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:00,811] Trial 87 finished with value: 0.6840693534223491 and parameters: {'iterations': 170, 'depth': 4, 'learning_rate': 0.26637182378625707, 'random_strength': 4, 'bagging_temperature': 0.9301853062735972, 'l2_leaf_reg': 0.024437176001090556, 'border_count': 123}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:02,794] Trial 88 finished with value: 0.672591259820464 and parameters: {'iterations': 378, 'depth': 5, 'learning_rate': 0.2775140883990045, 'random_strength': 13, 'bagging_temperature': 0.8645474928529829, 'l2_leaf_reg': 0.6395023074464418, 'border_count': 136}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:05,994] Trial 89 finished with value: 0.6851748908837375 and parameters: {'iterations': 632, 'depth': 4, 'learning_rate': 0.25498824540009146, 'random_strength': 79, 'bagging_temperature': 0.8996744336532214, 'l2_leaf_reg': 0.010539054774101246, 'border_count': 68}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:08,488] Trial 90 finished with value: 0.681878797943003 and parameters: {'iterations': 435, 'depth': 5, 'learning_rate': 0.24386590014196324, 'random_strength': 33, 'bagging_temperature': 0.7948031551102922, 'l2_leaf_reg': 0.06354821899301641, 'border_count': 80}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:09,918] Trial 91 finished with value: 0.6760765040283602 and parameters: {'iterations': 286, 'depth': 4, 'learning_rate': 0.225972077283662, 'random_strength': 69, 'bagging_temperature': 0.9931682239277274, 'l2_leaf_reg': 0.011418136716815942, 'border_count': 139}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:11,205] Trial 92 finished with value: 0.6946686495357816 and parameters: {'iterations': 247, 'depth': 4, 'learning_rate': 0.23224945155235877, 'random_strength': 65, 'bagging_temperature': 0.9595523074618715, 'l2_leaf_reg': 0.002063228310874647, 'border_count': 157}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:12,436] Trial 93 finished with value: 0.6810806637692725 and parameters: {'iterations': 263, 'depth': 4, 'learning_rate': 0.2485767454569875, 'random_strength': 20, 'bagging_temperature': 0.9811261583834332, 'l2_leaf_reg': 0.021479674264161266, 'border_count': 118}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:13,276] Trial 94 finished with value: 0.6765711478491223 and parameters: {'iterations': 180, 'depth': 4, 'learning_rate': 0.21537503715973602, 'random_strength': 73, 'bagging_temperature': 0.9265990699915398, 'l2_leaf_reg': 7.008089135768986e-08, 'border_count': 133}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:14,593] Trial 95 finished with value: 0.7275188031893285 and parameters: {'iterations': 98, 'depth': 10, 'learning_rate': 0.26260488417959693, 'random_strength': 88, 'bagging_temperature': 0.9498942480053832, 'l2_leaf_reg': 0.10827966802112207, 'border_count': 101}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:15,603] Trial 96 finished with value: 0.6513532556570255 and parameters: {'iterations': 220, 'depth': 4, 'learning_rate': 0.22863575300076136, 'random_strength': 75, 'bagging_temperature': 0.9974552579106855, 'l2_leaf_reg': 0.3956576958116925, 'border_count': 110}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:17,988] Trial 97 finished with value: 0.6802697298129956 and parameters: {'iterations': 509, 'depth': 4, 'learning_rate': 0.23698281258290885, 'random_strength': 80, 'bagging_temperature': 0.9130349913339527, 'l2_leaf_reg': 0.43516590052975956, 'border_count': 88}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:18,734] Trial 98 finished with value: 0.6797086522539489 and parameters: {'iterations': 159, 'depth': 4, 'learning_rate': 0.25631370123462155, 'random_strength': 28, 'bagging_temperature': 0.8461845777546193, 'l2_leaf_reg': 0.880383639094127, 'border_count': 97}. Best is trial 68 with value: 0.6412782535038966.\n",
      "[I 2023-12-08 00:39:20,633] Trial 99 finished with value: 0.697371431826663 and parameters: {'iterations': 403, 'depth': 4, 'learning_rate': 0.29219146662703266, 'random_strength': 36, 'bagging_temperature': 0.8747801112127367, 'l2_leaf_reg': 0.1876078305312573, 'border_count': 109}. Best is trial 68 with value: 0.6412782535038966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'iterations': 460, 'depth': 4, 'learning_rate': 0.2721149582388359, 'random_strength': 36, 'bagging_temperature': 0.9031049356114378, 'l2_leaf_reg': 3.7576940764715413e-06, 'border_count': 96}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    # Create and fit the model\n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "    # Predict and calculate RMSE\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def optimize(X_train, y_train, X_test, y_test):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=100)\n",
    "    return study.best_params\n",
    "\n",
    "# Load your datasets\n",
    "# (Ensure the datasets are loaded as per the provided code)\n",
    "\n",
    "# Optimize for working days\n",
    "best_params_w = optimize(X_train_w, y_train_w, X_test_w, y_test_w)\n",
    "print(\"Best parameters for working days:\", best_params_w)\n",
    "\n",
    "# Optimize for non-working days\n",
    "best_params_nw = optimize(X_train_nw, y_train_nw, X_test_nw, y_test_nw)\n",
    "print(\"Best parameters for non-working days:\", best_params_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.600612123195289\n",
      "RMSE for non-working days: 0.5954021940851916\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from Optuna study\n",
    "params_w = {\n",
    "    'iterations': 120,\n",
    "    'depth': 10,\n",
    "    'learning_rate': 0.22630379629943473,\n",
    "    'random_strength': 40,\n",
    "    'bagging_temperature': 0.00461861496626885,\n",
    "    'l2_leaf_reg': 5.901897930490308e-06,\n",
    "    'border_count': 7,\n",
    "    'loss_function': 'RMSE',\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "params_nw = {\n",
    "    'iterations': 366,\n",
    "    'depth': 9,\n",
    "    'learning_rate': 0.13516379949083754,\n",
    "    'random_strength': 10,\n",
    "    'bagging_temperature': 0.27795134630855506,\n",
    "    'l2_leaf_reg': 0.10661335848192686,\n",
    "    'border_count': 1,\n",
    "    'loss_function': 'RMSE',\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "# Create and train the model for working days\n",
    "model_w = cb.CatBoostRegressor(**params_w)\n",
    "model_w.fit(X_train_w, y_train_w, eval_set=[(X_test_w, y_test_w)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for working days\n",
    "predictions_w = model_w.predict(X_test_w)\n",
    "rmse_w = mean_squared_error(y_test_w, predictions_w, squared=False)\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "\n",
    "# Create and train the model for non-working days\n",
    "model_nw = cb.CatBoostRegressor(**params_nw)\n",
    "model_nw.fit(X_train_nw, y_train_nw, eval_set=[(X_test_nw, y_test_nw)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for non-working days\n",
    "predictions_nw = model_nw.predict(X_test_nw)\n",
    "rmse_nw = mean_squared_error(y_test_nw, predictions_nw, squared=False)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the most promising results so far. This doesn't necessarily mean it's the best straight away since it might be overfitting, but it remains a strong candidate that we will need to test on kaggle. Let's try to optimize it further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 20:49:36,643] A new study created in memory with name: no-name-b27c70e5-59ec-4eab-9e67-6a8c1245287c\n",
      "[I 2023-12-07 20:49:49,124] Trial 0 finished with value: 0.6467958131600534 and parameters: {'iterations': 1009, 'depth': 6, 'learning_rate': 0.07314851872420612, 'random_strength': 68, 'bagging_temperature': 0.06858783001113578, 'l2_leaf_reg': 5.602564173575373e-07, 'border_count': 250, 'grow_policy': 'Depthwise'}. Best is trial 0 with value: 0.6467958131600534.\n",
      "[I 2023-12-07 20:50:05,276] Trial 1 finished with value: 0.6343640569470086 and parameters: {'iterations': 1442, 'depth': 4, 'learning_rate': 0.2086828329887433, 'random_strength': 49, 'bagging_temperature': 0.824989924051477, 'l2_leaf_reg': 1.8893061525215033e-08, 'border_count': 238, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:50:14,114] Trial 2 finished with value: 0.6696890350756751 and parameters: {'iterations': 1497, 'depth': 6, 'learning_rate': 0.11047601586906125, 'random_strength': 40, 'bagging_temperature': 0.501614638690435, 'l2_leaf_reg': 1.631872081353627e-05, 'border_count': 112, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:50:42,705] Trial 3 finished with value: 0.6958045715977067 and parameters: {'iterations': 1035, 'depth': 12, 'learning_rate': 0.16985340382029016, 'random_strength': 99, 'bagging_temperature': 0.014736071230793235, 'l2_leaf_reg': 5.7078412904010406e-05, 'border_count': 201, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:50:45,364] Trial 4 finished with value: 0.6728964748945753 and parameters: {'iterations': 738, 'depth': 7, 'learning_rate': 0.1936109930339061, 'random_strength': 10, 'bagging_temperature': 0.4372866893832845, 'l2_leaf_reg': 6.395643519760613e-06, 'border_count': 84, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:50:59,673] Trial 5 finished with value: 0.6786429491100103 and parameters: {'iterations': 463, 'depth': 11, 'learning_rate': 0.032374971594438536, 'random_strength': 39, 'bagging_temperature': 0.9879373192537421, 'l2_leaf_reg': 1.719487796271932e-08, 'border_count': 253, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:51:38,863] Trial 6 finished with value: 0.6440853478702322 and parameters: {'iterations': 810, 'depth': 12, 'learning_rate': 0.019845116515822568, 'random_strength': 14, 'bagging_temperature': 0.013230953939154078, 'l2_leaf_reg': 1.8124429886117005e-08, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:51:49,817] Trial 7 finished with value: 0.6608802167021245 and parameters: {'iterations': 814, 'depth': 12, 'learning_rate': 0.10470530134826887, 'random_strength': 96, 'bagging_temperature': 0.23295734608876517, 'l2_leaf_reg': 0.00032757415400523404, 'border_count': 34, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:51:53,634] Trial 8 finished with value: 0.6514194814777499 and parameters: {'iterations': 702, 'depth': 8, 'learning_rate': 0.11262285644332498, 'random_strength': 5, 'bagging_temperature': 0.6064835626687256, 'l2_leaf_reg': 2.0677616590526413e-06, 'border_count': 96, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:51:59,939] Trial 9 finished with value: 0.666574793145092 and parameters: {'iterations': 638, 'depth': 5, 'learning_rate': 0.06905856388185311, 'random_strength': 66, 'bagging_temperature': 0.17752432599368084, 'l2_leaf_reg': 0.00376099518582732, 'border_count': 14, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:52:08,992] Trial 10 finished with value: 0.6457370192228672 and parameters: {'iterations': 1489, 'depth': 4, 'learning_rate': 0.2730996213009232, 'random_strength': 60, 'bagging_temperature': 0.9410103819989686, 'l2_leaf_reg': 1.215836559665295, 'border_count': 175, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:52:15,233] Trial 11 finished with value: 0.8879709026204228 and parameters: {'iterations': 151, 'depth': 10, 'learning_rate': 0.015045129927032297, 'random_strength': 24, 'bagging_temperature': 0.7388217239049029, 'l2_leaf_reg': 4.256063760606469e-08, 'border_count': 155, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:52:24,475] Trial 12 finished with value: 0.6744024063045885 and parameters: {'iterations': 1220, 'depth': 9, 'learning_rate': 0.19988535070905203, 'random_strength': 25, 'bagging_temperature': 0.28409366841618466, 'l2_leaf_reg': 1.0421407618602265e-08, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6343640569470086.\n",
      "[I 2023-12-07 20:52:31,003] Trial 13 finished with value: 0.6291590468062935 and parameters: {'iterations': 302, 'depth': 4, 'learning_rate': 0.24019017256355188, 'random_strength': 76, 'bagging_temperature': 0.7786788722812847, 'l2_leaf_reg': 2.6484975650987625e-07, 'border_count': 139, 'grow_policy': 'Lossguide'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:52:33,849] Trial 14 finished with value: 0.6621392994217546 and parameters: {'iterations': 101, 'depth': 4, 'learning_rate': 0.246154098473959, 'random_strength': 81, 'bagging_temperature': 0.811605892134708, 'l2_leaf_reg': 3.197627640649791e-07, 'border_count': 206, 'grow_policy': 'Lossguide'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:52:40,845] Trial 15 finished with value: 0.6821780789097251 and parameters: {'iterations': 326, 'depth': 5, 'learning_rate': 0.2996417781516335, 'random_strength': 82, 'bagging_temperature': 0.7845802099626922, 'l2_leaf_reg': 2.9916985796252166e-07, 'border_count': 136, 'grow_policy': 'Lossguide'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:52:52,081] Trial 16 finished with value: 0.6469166557286966 and parameters: {'iterations': 1258, 'depth': 4, 'learning_rate': 0.23682399606101778, 'random_strength': 49, 'bagging_temperature': 0.6667056102088295, 'l2_leaf_reg': 2.142867948746429e-07, 'border_count': 212, 'grow_policy': 'Lossguide'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:53:00,116] Trial 17 finished with value: 0.6389703468469482 and parameters: {'iterations': 491, 'depth': 6, 'learning_rate': 0.22069777365890908, 'random_strength': 79, 'bagging_temperature': 0.8674041542378284, 'l2_leaf_reg': 1.2414091955722954e-07, 'border_count': 175, 'grow_policy': 'Lossguide'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:53:07,723] Trial 18 finished with value: 0.6439722943186376 and parameters: {'iterations': 1034, 'depth': 8, 'learning_rate': 0.16256630631859348, 'random_strength': 53, 'bagging_temperature': 0.8849141892185443, 'l2_leaf_reg': 1.5101383154319433e-06, 'border_count': 225, 'grow_policy': 'Depthwise'}. Best is trial 13 with value: 0.6291590468062935.\n",
      "[I 2023-12-07 20:53:17,919] Trial 19 finished with value: 0.6281988846034742 and parameters: {'iterations': 295, 'depth': 5, 'learning_rate': 0.25423171654242777, 'random_strength': 40, 'bagging_temperature': 0.9980330135764128, 'l2_leaf_reg': 9.495967176418776e-08, 'border_count': 135, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:53:24,367] Trial 20 finished with value: 0.6538180683917161 and parameters: {'iterations': 289, 'depth': 5, 'learning_rate': 0.2589911851495477, 'random_strength': 26, 'bagging_temperature': 0.9639647988784961, 'l2_leaf_reg': 4.255783452384755e-06, 'border_count': 129, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:53:34,846] Trial 21 finished with value: 0.6367777538673937 and parameters: {'iterations': 504, 'depth': 4, 'learning_rate': 0.2191204196314066, 'random_strength': 41, 'bagging_temperature': 0.9994814076251629, 'l2_leaf_reg': 7.188081388782795e-08, 'border_count': 158, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:53:42,284] Trial 22 finished with value: 0.6691745959712281 and parameters: {'iterations': 259, 'depth': 5, 'learning_rate': 0.2743347432382663, 'random_strength': 49, 'bagging_temperature': 0.8643993713029664, 'l2_leaf_reg': 1.1276133220092213e-08, 'border_count': 181, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:53:57,628] Trial 23 finished with value: 0.6446380130709334 and parameters: {'iterations': 384, 'depth': 7, 'learning_rate': 0.221514153024995, 'random_strength': 33, 'bagging_temperature': 0.721129169247565, 'l2_leaf_reg': 1.3199018009933875e-07, 'border_count': 145, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:03,361] Trial 24 finished with value: 0.649576591127633 and parameters: {'iterations': 567, 'depth': 4, 'learning_rate': 0.24730744528691298, 'random_strength': 60, 'bagging_temperature': 0.8309222593675443, 'l2_leaf_reg': 1.1103640645722557e-06, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:07,305] Trial 25 finished with value: 0.660065201408545 and parameters: {'iterations': 189, 'depth': 5, 'learning_rate': 0.1885126602056295, 'random_strength': 71, 'bagging_temperature': 0.9124070073105928, 'l2_leaf_reg': 7.462685044838912e-08, 'border_count': 105, 'grow_policy': 'Depthwise'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:21,415] Trial 26 finished with value: 0.6708309576858601 and parameters: {'iterations': 1313, 'depth': 6, 'learning_rate': 0.29759444644293115, 'random_strength': 90, 'bagging_temperature': 0.8154552731722458, 'l2_leaf_reg': 4.928633241993568e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:33,731] Trial 27 finished with value: 0.6630523111457896 and parameters: {'iterations': 375, 'depth': 7, 'learning_rate': 0.2309152932028933, 'random_strength': 56, 'bagging_temperature': 0.9210840961502693, 'l2_leaf_reg': 5.655862574603519e-08, 'border_count': 227, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:43,477] Trial 28 finished with value: 0.6506722798429813 and parameters: {'iterations': 913, 'depth': 4, 'learning_rate': 0.20655384469849156, 'random_strength': 33, 'bagging_temperature': 0.7721645534222231, 'l2_leaf_reg': 9.056764354424508e-07, 'border_count': 185, 'grow_policy': 'Lossguide'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:53,248] Trial 29 finished with value: 0.6284466112678196 and parameters: {'iterations': 1165, 'depth': 6, 'learning_rate': 0.1819294146220324, 'random_strength': 71, 'bagging_temperature': 0.6714563722089226, 'l2_leaf_reg': 3.828175761891252e-07, 'border_count': 240, 'grow_policy': 'Depthwise'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:54:59,301] Trial 30 finished with value: 0.6402347930427369 and parameters: {'iterations': 933, 'depth': 6, 'learning_rate': 0.17118881658604246, 'random_strength': 72, 'bagging_temperature': 0.6719877636673989, 'l2_leaf_reg': 1.6375111909990323e-05, 'border_count': 158, 'grow_policy': 'Depthwise'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:55:03,403] Trial 31 finished with value: 0.6486542761799788 and parameters: {'iterations': 1177, 'depth': 5, 'learning_rate': 0.20867729351914077, 'random_strength': 68, 'bagging_temperature': 0.8786329176659281, 'l2_leaf_reg': 4.733221347769531e-07, 'border_count': 241, 'grow_policy': 'Depthwise'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:55:08,422] Trial 32 finished with value: 0.6419158052979417 and parameters: {'iterations': 1357, 'depth': 6, 'learning_rate': 0.1880470850088129, 'random_strength': 44, 'bagging_temperature': 0.7344221045858996, 'l2_leaf_reg': 3.703229440260025e-08, 'border_count': 237, 'grow_policy': 'Depthwise'}. Best is trial 19 with value: 0.6281988846034742.\n",
      "[I 2023-12-07 20:55:14,516] Trial 33 finished with value: 0.6237032097988265 and parameters: {'iterations': 1141, 'depth': 5, 'learning_rate': 0.15161298172313556, 'random_strength': 76, 'bagging_temperature': 0.5848257186221318, 'l2_leaf_reg': 1.8997079048216168e-07, 'border_count': 197, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:22,724] Trial 34 finished with value: 0.6362934242948535 and parameters: {'iterations': 1117, 'depth': 7, 'learning_rate': 0.14551091429658025, 'random_strength': 88, 'bagging_temperature': 0.5824770853682739, 'l2_leaf_reg': 2.170372812437371e-07, 'border_count': 194, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:28,621] Trial 35 finished with value: 0.6477967151270553 and parameters: {'iterations': 1126, 'depth': 6, 'learning_rate': 0.1478451060112238, 'random_strength': 76, 'bagging_temperature': 0.4766804879288373, 'l2_leaf_reg': 2.7213245415830035e-06, 'border_count': 219, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:34,097] Trial 36 finished with value: 0.6293893385723873 and parameters: {'iterations': 1359, 'depth': 5, 'learning_rate': 0.17813437165306065, 'random_strength': 88, 'bagging_temperature': 0.5502175330435791, 'l2_leaf_reg': 9.246767754955447e-06, 'border_count': 196, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:41,175] Trial 37 finished with value: 0.6709030238948839 and parameters: {'iterations': 890, 'depth': 7, 'learning_rate': 0.13964503372219358, 'random_strength': 62, 'bagging_temperature': 0.7036888015886147, 'l2_leaf_reg': 1.1338460381914491e-06, 'border_count': 254, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:46,814] Trial 38 finished with value: 0.6373654805141687 and parameters: {'iterations': 986, 'depth': 6, 'learning_rate': 0.18561988629839574, 'random_strength': 76, 'bagging_temperature': 0.6646600800093136, 'l2_leaf_reg': 3.8196898932854274e-08, 'border_count': 120, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:52,605] Trial 39 finished with value: 0.6305546101647657 and parameters: {'iterations': 1118, 'depth': 5, 'learning_rate': 0.16280824021002657, 'random_strength': 85, 'bagging_temperature': 0.6233873973713207, 'l2_leaf_reg': 4.999070895032684e-07, 'border_count': 138, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:55:55,494] Trial 40 finished with value: 0.646544887809622 and parameters: {'iterations': 742, 'depth': 9, 'learning_rate': 0.20369474624167394, 'random_strength': 94, 'bagging_temperature': 0.7796782057362981, 'l2_leaf_reg': 1.7818495530353615e-05, 'border_count': 98, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:00,239] Trial 41 finished with value: 0.6438709439988578 and parameters: {'iterations': 1399, 'depth': 5, 'learning_rate': 0.17175778083891505, 'random_strength': 100, 'bagging_temperature': 0.5551358555906198, 'l2_leaf_reg': 3.619638173207077e-06, 'border_count': 193, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:05,303] Trial 42 finished with value: 0.6479019836065162 and parameters: {'iterations': 1311, 'depth': 4, 'learning_rate': 0.1266696878923734, 'random_strength': 90, 'bagging_temperature': 0.5381389222482138, 'l2_leaf_reg': 7.849320327372794e-06, 'border_count': 168, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:09,693] Trial 43 finished with value: 0.6574554893217732 and parameters: {'iterations': 1468, 'depth': 5, 'learning_rate': 0.17997078666084193, 'random_strength': 73, 'bagging_temperature': 0.6284485265442743, 'l2_leaf_reg': 1.07187018482522e-07, 'border_count': 238, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:14,882] Trial 44 finished with value: 0.6605875047957863 and parameters: {'iterations': 1234, 'depth': 4, 'learning_rate': 0.15381759631093644, 'random_strength': 64, 'bagging_temperature': 0.5026381520195783, 'l2_leaf_reg': 2.190415883552926e-08, 'border_count': 202, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:20,561] Trial 45 finished with value: 0.6400051993988557 and parameters: {'iterations': 1412, 'depth': 5, 'learning_rate': 0.18082231773583773, 'random_strength': 94, 'bagging_temperature': 0.585827143553992, 'l2_leaf_reg': 8.318463684351517e-07, 'border_count': 152, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:26,013] Trial 46 finished with value: 0.6347594644535445 and parameters: {'iterations': 598, 'depth': 6, 'learning_rate': 0.19633067481622343, 'random_strength': 87, 'bagging_temperature': 0.46193752856294906, 'l2_leaf_reg': 6.431216591492606e-05, 'border_count': 83, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:29,389] Trial 47 finished with value: 0.6440748347153077 and parameters: {'iterations': 227, 'depth': 4, 'learning_rate': 0.12650546545063532, 'random_strength': 83, 'bagging_temperature': 0.4061500692851221, 'l2_leaf_reg': 2.2994915478298364e-07, 'border_count': 193, 'grow_policy': 'Depthwise'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:33,534] Trial 48 finished with value: 0.6277861086096383 and parameters: {'iterations': 410, 'depth': 5, 'learning_rate': 0.21535338371276336, 'random_strength': 77, 'bagging_temperature': 0.9538923672279549, 'l2_leaf_reg': 1.8888646135244378e-06, 'border_count': 169, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:37,586] Trial 49 finished with value: 0.6523249174367227 and parameters: {'iterations': 366, 'depth': 6, 'learning_rate': 0.21600090143246162, 'random_strength': 68, 'bagging_temperature': 0.9666652029311693, 'l2_leaf_reg': 2.411474603407012e-06, 'border_count': 170, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:41,866] Trial 50 finished with value: 0.6608311701285967 and parameters: {'iterations': 466, 'depth': 8, 'learning_rate': 0.19883964465469423, 'random_strength': 56, 'bagging_temperature': 0.9381122034879021, 'l2_leaf_reg': 1.9707091342666234e-08, 'border_count': 213, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:45,364] Trial 51 finished with value: 0.6291172644202603 and parameters: {'iterations': 417, 'depth': 5, 'learning_rate': 0.22999634610814743, 'random_strength': 78, 'bagging_temperature': 0.9958478266152403, 'l2_leaf_reg': 1.4121280907937456e-07, 'border_count': 167, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:48,266] Trial 52 finished with value: 0.661205674894343 and parameters: {'iterations': 318, 'depth': 4, 'learning_rate': 0.24009947145220345, 'random_strength': 78, 'bagging_temperature': 0.99463372041909, 'l2_leaf_reg': 1.4359446810042072e-07, 'border_count': 145, 'grow_policy': 'SymmetricTree'}. Best is trial 33 with value: 0.6237032097988265.\n",
      "[I 2023-12-07 20:56:52,361] Trial 53 finished with value: 0.6200147819160439 and parameters: {'iterations': 434, 'depth': 5, 'learning_rate': 0.23036462280272305, 'random_strength': 74, 'bagging_temperature': 0.9174125138977255, 'l2_leaf_reg': 3.6110336124147807e-07, 'border_count': 131, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:56:56,708] Trial 54 finished with value: 0.6240916631685445 and parameters: {'iterations': 433, 'depth': 5, 'learning_rate': 0.229017325340251, 'random_strength': 71, 'bagging_temperature': 0.9312736061526342, 'l2_leaf_reg': 5.38878570818008e-07, 'border_count': 130, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:56:59,842] Trial 55 finished with value: 0.6540348503297472 and parameters: {'iterations': 666, 'depth': 6, 'learning_rate': 0.2541454824662628, 'random_strength': 57, 'bagging_temperature': 0.9134507012537648, 'l2_leaf_reg': 3.4566042448709444e-07, 'border_count': 127, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:03,095] Trial 56 finished with value: 0.6563692016589049 and parameters: {'iterations': 534, 'depth': 5, 'learning_rate': 0.22805645757233042, 'random_strength': 65, 'bagging_temperature': 0.950616282957906, 'l2_leaf_reg': 7.286383109596565e-07, 'border_count': 108, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:06,020] Trial 57 finished with value: 0.6380074168972133 and parameters: {'iterations': 441, 'depth': 5, 'learning_rate': 0.2076738547267574, 'random_strength': 46, 'bagging_temperature': 0.856185603362893, 'l2_leaf_reg': 2.3445951973133884e-06, 'border_count': 129, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:07,243] Trial 58 finished with value: 0.6774816757661738 and parameters: {'iterations': 105, 'depth': 5, 'learning_rate': 0.21800976212720685, 'random_strength': 70, 'bagging_temperature': 0.8973480598176968, 'l2_leaf_reg': 4.215171771989209e-08, 'border_count': 150, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:09,534] Trial 59 finished with value: 0.6436802198259841 and parameters: {'iterations': 223, 'depth': 7, 'learning_rate': 0.257986651841232, 'random_strength': 35, 'bagging_temperature': 0.9511357717160033, 'l2_leaf_reg': 1.38697064942475e-06, 'border_count': 92, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:15,628] Trial 60 finished with value: 0.6513022620901477 and parameters: {'iterations': 845, 'depth': 11, 'learning_rate': 0.19467073983996883, 'random_strength': 17, 'bagging_temperature': 0.8413684428906022, 'l2_leaf_reg': 8.675945442271201e-08, 'border_count': 119, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.6200147819160439.\n",
      "[I 2023-12-07 20:57:18,532] Trial 61 finished with value: 0.6119646304904325 and parameters: {'iterations': 430, 'depth': 5, 'learning_rate': 0.23789424168126028, 'random_strength': 80, 'bagging_temperature': 0.9997175131605825, 'l2_leaf_reg': 1.9978723951586637e-07, 'border_count': 162, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:24,176] Trial 62 finished with value: 0.6662013672042607 and parameters: {'iterations': 514, 'depth': 6, 'learning_rate': 0.2378286559036914, 'random_strength': 74, 'bagging_temperature': 0.9623114682640387, 'l2_leaf_reg': 4.1244431228341254e-07, 'border_count': 181, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:27,073] Trial 63 finished with value: 0.6593984685143397 and parameters: {'iterations': 626, 'depth': 4, 'learning_rate': 0.24727084046223638, 'random_strength': 82, 'bagging_temperature': 0.9047865174270074, 'l2_leaf_reg': 2.0624541177358208e-07, 'border_count': 163, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:31,268] Trial 64 finished with value: 0.6556030355326209 and parameters: {'iterations': 418, 'depth': 5, 'learning_rate': 0.22639649370321394, 'random_strength': 69, 'bagging_temperature': 0.9354435212394052, 'l2_leaf_reg': 1.4547356413045857e-06, 'border_count': 134, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:33,684] Trial 65 finished with value: 0.6763487315056365 and parameters: {'iterations': 349, 'depth': 5, 'learning_rate': 0.26752223120061774, 'random_strength': 80, 'bagging_temperature': 0.8648627559927142, 'l2_leaf_reg': 7.144487303264033e-08, 'border_count': 144, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:36,674] Trial 66 finished with value: 0.664855448707358 and parameters: {'iterations': 553, 'depth': 6, 'learning_rate': 0.21189517069695457, 'random_strength': 85, 'bagging_temperature': 0.982533757725834, 'l2_leaf_reg': 4.6765044694331916e-07, 'border_count': 114, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:39,115] Trial 67 finished with value: 0.6630502653726772 and parameters: {'iterations': 261, 'depth': 4, 'learning_rate': 0.23205386681917808, 'random_strength': 74, 'bagging_temperature': 0.812686938146169, 'l2_leaf_reg': 2.8324090613309788e-08, 'border_count': 12, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:44,883] Trial 68 finished with value: 0.6654060778765447 and parameters: {'iterations': 738, 'depth': 5, 'learning_rate': 0.2168621369622914, 'random_strength': 53, 'bagging_temperature': 0.9179521594184903, 'l2_leaf_reg': 1.1807986743171137e-08, 'border_count': 160, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:47,186] Trial 69 finished with value: 0.671459261450506 and parameters: {'iterations': 1076, 'depth': 6, 'learning_rate': 0.2443722904556022, 'random_strength': 37, 'bagging_temperature': 0.8868361120995975, 'l2_leaf_reg': 6.121283755412248e-08, 'border_count': 185, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:55,868] Trial 70 finished with value: 0.6562756102025974 and parameters: {'iterations': 472, 'depth': 4, 'learning_rate': 0.22134009133381677, 'random_strength': 29, 'bagging_temperature': 0.9716874302191674, 'l2_leaf_reg': 7.472174540653915e-07, 'border_count': 174, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:57:59,972] Trial 71 finished with value: 0.6274123237558514 and parameters: {'iterations': 411, 'depth': 5, 'learning_rate': 0.2366325064574022, 'random_strength': 78, 'bagging_temperature': 0.9852313165037058, 'l2_leaf_reg': 1.5078839746517077e-07, 'border_count': 153, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:02,066] Trial 72 finished with value: 0.6819370343745829 and parameters: {'iterations': 388, 'depth': 5, 'learning_rate': 0.23538870176965376, 'random_strength': 66, 'bagging_temperature': 0.9375277427728392, 'l2_leaf_reg': 1.4498373907429043e-07, 'border_count': 144, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:05,103] Trial 73 finished with value: 0.6642476632521201 and parameters: {'iterations': 294, 'depth': 5, 'learning_rate': 0.24995297203849115, 'random_strength': 61, 'bagging_temperature': 0.8917732311106926, 'l2_leaf_reg': 1.9968742056762118e-07, 'border_count': 153, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:08,288] Trial 74 finished with value: 0.6598997003726833 and parameters: {'iterations': 1179, 'depth': 5, 'learning_rate': 0.2598538779721823, 'random_strength': 77, 'bagging_temperature': 0.9973729496407622, 'l2_leaf_reg': 2.7498696541167427e-07, 'border_count': 131, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:10,516] Trial 75 finished with value: 0.6729848249394789 and parameters: {'iterations': 183, 'depth': 6, 'learning_rate': 0.22476104007325082, 'random_strength': 80, 'bagging_temperature': 0.8389580473465776, 'l2_leaf_reg': 9.079018443035474e-08, 'border_count': 226, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:19,030] Trial 76 finished with value: 0.6531195246077414 and parameters: {'iterations': 414, 'depth': 4, 'learning_rate': 0.2376179565261075, 'random_strength': 71, 'bagging_temperature': 0.9699864378830616, 'l2_leaf_reg': 7.06826612414164e-07, 'border_count': 139, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:22,353] Trial 77 finished with value: 0.685914177513581 and parameters: {'iterations': 330, 'depth': 5, 'learning_rate': 0.20332575349898702, 'random_strength': 85, 'bagging_temperature': 0.9263246954390448, 'l2_leaf_reg': 5.0634769929714684e-08, 'border_count': 123, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:24,675] Trial 78 finished with value: 0.6814757948035289 and parameters: {'iterations': 498, 'depth': 6, 'learning_rate': 0.21226183765397974, 'random_strength': 42, 'bagging_temperature': 0.9522031013998788, 'l2_leaf_reg': 1.481336708973599e-06, 'border_count': 245, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:34,470] Trial 79 finished with value: 0.6706394631840458 and parameters: {'iterations': 984, 'depth': 9, 'learning_rate': 0.1905605146184341, 'random_strength': 75, 'bagging_temperature': 0.8827092147252086, 'l2_leaf_reg': 4.4161188483808103e-07, 'border_count': 212, 'grow_policy': 'Depthwise'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:55,145] Trial 80 finished with value: 0.6649711177912946 and parameters: {'iterations': 595, 'depth': 5, 'learning_rate': 0.24353734310604758, 'random_strength': 91, 'bagging_temperature': 0.8000685496349569, 'l2_leaf_reg': 3.217797994457143e-08, 'border_count': 178, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:58:58,045] Trial 81 finished with value: 0.6617085457543215 and parameters: {'iterations': 422, 'depth': 5, 'learning_rate': 0.23070822123056664, 'random_strength': 79, 'bagging_temperature': 0.9977963977539281, 'l2_leaf_reg': 1.4868156515249006e-07, 'border_count': 166, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:02,378] Trial 82 finished with value: 0.6646273237579986 and parameters: {'iterations': 440, 'depth': 5, 'learning_rate': 0.22532479164181263, 'random_strength': 72, 'bagging_temperature': 0.9827607862422157, 'l2_leaf_reg': 9.858986413313395e-08, 'border_count': 33, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:04,875] Trial 83 finished with value: 0.6748821886101521 and parameters: {'iterations': 263, 'depth': 4, 'learning_rate': 0.23444898256833588, 'random_strength': 82, 'bagging_temperature': 0.9180940760833995, 'l2_leaf_reg': 2.69062085367911e-07, 'border_count': 157, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:08,803] Trial 84 finished with value: 0.6500661773147978 and parameters: {'iterations': 395, 'depth': 5, 'learning_rate': 0.20457986123048064, 'random_strength': 77, 'bagging_temperature': 0.9602664913286822, 'l2_leaf_reg': 1.4263365471667454e-07, 'border_count': 149, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:13,070] Trial 85 finished with value: 0.6401835895579923 and parameters: {'iterations': 461, 'depth': 6, 'learning_rate': 0.2512179011533659, 'random_strength': 68, 'bagging_temperature': 0.9947963983131951, 'l2_leaf_reg': 6.432612409519316e-07, 'border_count': 187, 'grow_policy': 'Depthwise'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:16,596] Trial 86 finished with value: 0.6655792650353539 and parameters: {'iterations': 349, 'depth': 5, 'learning_rate': 0.24263380011608282, 'random_strength': 83, 'bagging_temperature': 0.9394438104822479, 'l2_leaf_reg': 3.342011986067092e-07, 'border_count': 173, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:20,620] Trial 87 finished with value: 0.6315078693715621 and parameters: {'iterations': 553, 'depth': 4, 'learning_rate': 0.2123682131333055, 'random_strength': 64, 'bagging_temperature': 0.8611436259650707, 'l2_leaf_reg': 4.454142127752696e-06, 'border_count': 201, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:33,164] Trial 88 finished with value: 0.6528620145724826 and parameters: {'iterations': 308, 'depth': 7, 'learning_rate': 0.22302671323974754, 'random_strength': 73, 'bagging_temperature': 0.7596035763931723, 'l2_leaf_reg': 1.0244806030888702e-06, 'border_count': 165, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:36,849] Trial 89 finished with value: 0.6432797519016751 and parameters: {'iterations': 1170, 'depth': 5, 'learning_rate': 0.2666517833951871, 'random_strength': 79, 'bagging_temperature': 0.9037670259393947, 'l2_leaf_reg': 4.751134494287716e-08, 'border_count': 101, 'grow_policy': 'Depthwise'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:39,321] Trial 90 finished with value: 0.6773944871993232 and parameters: {'iterations': 369, 'depth': 6, 'learning_rate': 0.19736993351864462, 'random_strength': 91, 'bagging_temperature': 0.9741155410375563, 'l2_leaf_reg': 1.6537769769272753e-08, 'border_count': 111, 'grow_policy': 'SymmetricTree'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:45,200] Trial 91 finished with value: 0.6258786780709628 and parameters: {'iterations': 223, 'depth': 4, 'learning_rate': 0.2308818917663587, 'random_strength': 77, 'bagging_temperature': 0.9357010916895825, 'l2_leaf_reg': 2.2186845874733612e-07, 'border_count': 141, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:48,983] Trial 92 finished with value: 0.6602624114893929 and parameters: {'iterations': 140, 'depth': 4, 'learning_rate': 0.2305061938569215, 'random_strength': 75, 'bagging_temperature': 0.9315003066473367, 'l2_leaf_reg': 1.0697271790131951e-07, 'border_count': 137, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 20:59:54,903] Trial 93 finished with value: 0.6269381911204738 and parameters: {'iterations': 220, 'depth': 4, 'learning_rate': 0.24103602838383983, 'random_strength': 86, 'bagging_temperature': 0.9560934679676962, 'l2_leaf_reg': 1.9202380880439396e-07, 'border_count': 124, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 21:00:00,641] Trial 94 finished with value: 0.632627969643404 and parameters: {'iterations': 220, 'depth': 4, 'learning_rate': 0.25542687015884447, 'random_strength': 96, 'bagging_temperature': 0.9511051817429098, 'l2_leaf_reg': 2.739837765306862e-07, 'border_count': 232, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 21:00:05,247] Trial 95 finished with value: 0.6469079025602833 and parameters: {'iterations': 174, 'depth': 4, 'learning_rate': 0.24334410775991833, 'random_strength': 86, 'bagging_temperature': 0.900704426105033, 'l2_leaf_reg': 5.062314925627205e-07, 'border_count': 123, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 21:00:12,314] Trial 96 finished with value: 0.6473112584712905 and parameters: {'iterations': 266, 'depth': 4, 'learning_rate': 0.2176262285370399, 'random_strength': 89, 'bagging_temperature': 0.8389460022692179, 'l2_leaf_reg': 6.561654256892423e-08, 'border_count': 142, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 21:00:15,887] Trial 97 finished with value: 0.6425982563388014 and parameters: {'iterations': 134, 'depth': 4, 'learning_rate': 0.23666675358217382, 'random_strength': 84, 'bagging_temperature': 0.9773095426670888, 'l2_leaf_reg': 1.8404564313668283e-07, 'border_count': 114, 'grow_policy': 'Lossguide'}. Best is trial 61 with value: 0.6119646304904325.\n",
      "[I 2023-12-07 21:00:25,052] Trial 98 finished with value: 0.6053561174147056 and parameters: {'iterations': 210, 'depth': 8, 'learning_rate': 0.2511236382666271, 'random_strength': 81, 'bagging_temperature': 0.8701428722332518, 'l2_leaf_reg': 9.942629513459934e-07, 'border_count': 127, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:00:34,192] Trial 99 finished with value: 0.7080015364874276 and parameters: {'iterations': 209, 'depth': 10, 'learning_rate': 0.2580522521704688, 'random_strength': 94, 'bagging_temperature': 0.8706767093154842, 'l2_leaf_reg': 1.7062953706458747e-06, 'border_count': 134, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:00:44,837] Trial 100 finished with value: 0.6326562051452045 and parameters: {'iterations': 246, 'depth': 12, 'learning_rate': 0.2496519408649001, 'random_strength': 87, 'bagging_temperature': 0.9495696117832408, 'l2_leaf_reg': 1.2188791241773034e-06, 'border_count': 91, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:00:56,666] Trial 101 finished with value: 0.6305302996710196 and parameters: {'iterations': 287, 'depth': 10, 'learning_rate': 0.23468185784899212, 'random_strength': 81, 'bagging_temperature': 0.9209077701332664, 'l2_leaf_reg': 3.5324509081901547e-07, 'border_count': 150, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:03,978] Trial 102 finished with value: 0.6565629482408589 and parameters: {'iterations': 168, 'depth': 8, 'learning_rate': 0.2412223438124186, 'random_strength': 70, 'bagging_temperature': 0.8827854550596612, 'l2_leaf_reg': 6.736977896670227e-07, 'border_count': 127, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:18,150] Trial 103 finished with value: 0.6534526649574027 and parameters: {'iterations': 346, 'depth': 9, 'learning_rate': 0.22634143915137145, 'random_strength': 76, 'bagging_temperature': 0.9709844133926819, 'l2_leaf_reg': 1.937931149790245e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:24,705] Trial 104 finished with value: 0.6647737787692788 and parameters: {'iterations': 195, 'depth': 5, 'learning_rate': 0.24646301702330742, 'random_strength': 66, 'bagging_temperature': 0.9042541935062867, 'l2_leaf_reg': 2.0655874458880516e-06, 'border_count': 133, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:42,371] Trial 105 finished with value: 0.6578422484033087 and parameters: {'iterations': 1279, 'depth': 11, 'learning_rate': 0.2508525652638805, 'random_strength': 81, 'bagging_temperature': 0.9303463969449287, 'l2_leaf_reg': 9.424551695066047e-08, 'border_count': 104, 'grow_policy': 'Depthwise'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:50,540] Trial 106 finished with value: 0.6543923490363146 and parameters: {'iterations': 289, 'depth': 5, 'learning_rate': 0.2194404251504663, 'random_strength': 73, 'bagging_temperature': 0.9560515316489422, 'l2_leaf_reg': 1.0641589013572321e-06, 'border_count': 127, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:01:58,622] Trial 107 finished with value: 0.6292772014386464 and parameters: {'iterations': 240, 'depth': 5, 'learning_rate': 0.26356894948981135, 'random_strength': 78, 'bagging_temperature': 0.9791176507391729, 'l2_leaf_reg': 4.2679920473842687e-07, 'border_count': 160, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:02:02,453] Trial 108 finished with value: 0.6539454442443203 and parameters: {'iterations': 520, 'depth': 4, 'learning_rate': 0.2738674473526955, 'random_strength': 58, 'bagging_temperature': 0.9998729972148498, 'l2_leaf_reg': 2.8068030693620576e-07, 'border_count': 141, 'grow_policy': 'Depthwise'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:02:07,190] Trial 109 finished with value: 0.7185332187675012 and parameters: {'iterations': 116, 'depth': 6, 'learning_rate': 0.2534208537251943, 'random_strength': 83, 'bagging_temperature': 0.8510723467617131, 'l2_leaf_reg': 2.807444739877928e-08, 'border_count': 150, 'grow_policy': 'Lossguide'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:02:13,513] Trial 110 finished with value: 0.6720100890805439 and parameters: {'iterations': 468, 'depth': 8, 'learning_rate': 0.2403760560127934, 'random_strength': 70, 'bagging_temperature': 0.8761009379941644, 'l2_leaf_reg': 6.432928507161363e-07, 'border_count': 154, 'grow_policy': 'Depthwise'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:02:16,925] Trial 111 finished with value: 0.6649040711054278 and parameters: {'iterations': 404, 'depth': 5, 'learning_rate': 0.21440306918648158, 'random_strength': 47, 'bagging_temperature': 0.939202837521849, 'l2_leaf_reg': 1.1971524986248094e-07, 'border_count': 146, 'grow_policy': 'SymmetricTree'}. Best is trial 98 with value: 0.6053561174147056.\n",
      "[I 2023-12-07 21:02:20,202] Trial 112 finished with value: 0.6019431085716467 and parameters: {'iterations': 327, 'depth': 5, 'learning_rate': 0.22959914137522078, 'random_strength': 0, 'bagging_temperature': 0.9998170501649718, 'l2_leaf_reg': 1.6823816623838656e-07, 'border_count': 249, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:23,524] Trial 113 finished with value: 0.6742946672930696 and parameters: {'iterations': 332, 'depth': 5, 'learning_rate': 0.2306295162376134, 'random_strength': 3, 'bagging_temperature': 0.822392133001048, 'l2_leaf_reg': 2.5102764533740814e-07, 'border_count': 241, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:27,181] Trial 114 finished with value: 0.6541814646793538 and parameters: {'iterations': 367, 'depth': 5, 'learning_rate': 0.20843451081789124, 'random_strength': 15, 'bagging_temperature': 0.9642899197885424, 'l2_leaf_reg': 5.464656937223569e-08, 'border_count': 231, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:30,489] Trial 115 finished with value: 0.6603736554509905 and parameters: {'iterations': 443, 'depth': 4, 'learning_rate': 0.22140492069868473, 'random_strength': 21, 'bagging_temperature': 0.9125698014357243, 'l2_leaf_reg': 1.9188223857756208e-07, 'border_count': 250, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:33,811] Trial 116 finished with value: 0.6273000390779726 and parameters: {'iterations': 321, 'depth': 5, 'learning_rate': 0.2266754986319277, 'random_strength': 75, 'bagging_temperature': 0.9412301532472999, 'l2_leaf_reg': 7.997546010658764e-08, 'border_count': 124, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:36,874] Trial 117 finished with value: 0.6688720819992833 and parameters: {'iterations': 303, 'depth': 5, 'learning_rate': 0.23911452375786177, 'random_strength': 8, 'bagging_temperature': 0.9792818083395086, 'l2_leaf_reg': 6.824322697572978e-08, 'border_count': 116, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:39,517] Trial 118 finished with value: 0.6706797779625009 and parameters: {'iterations': 264, 'depth': 5, 'learning_rate': 0.2613450498484063, 'random_strength': 75, 'bagging_temperature': 0.9302028579549375, 'l2_leaf_reg': 3.909928972458368e-08, 'border_count': 108, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:42,772] Trial 119 finished with value: 0.6193425773798674 and parameters: {'iterations': 322, 'depth': 5, 'learning_rate': 0.22769517570089395, 'random_strength': 0, 'bagging_temperature': 0.9529059641311792, 'l2_leaf_reg': 8.832107164686587e-08, 'border_count': 218, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:45,713] Trial 120 finished with value: 0.6315409168279026 and parameters: {'iterations': 324, 'depth': 4, 'learning_rate': 0.22479000216493, 'random_strength': 1, 'bagging_temperature': 0.8926503356183096, 'l2_leaf_reg': 1.6683244766578714e-07, 'border_count': 223, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:49,376] Trial 121 finished with value: 0.6126998008229473 and parameters: {'iterations': 359, 'depth': 5, 'learning_rate': 0.23376867503841534, 'random_strength': 0, 'bagging_temperature': 0.9481485332643382, 'l2_leaf_reg': 8.874696819977551e-08, 'border_count': 124, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:51,480] Trial 122 finished with value: 0.6529746407296618 and parameters: {'iterations': 384, 'depth': 5, 'learning_rate': 0.2328588871036524, 'random_strength': 9, 'bagging_temperature': 0.9507052258875682, 'l2_leaf_reg': 7.940137035456897e-08, 'border_count': 123, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:53,699] Trial 123 finished with value: 0.6213244684999344 and parameters: {'iterations': 359, 'depth': 5, 'learning_rate': 0.2281246202137044, 'random_strength': 0, 'bagging_temperature': 0.9104565405789372, 'l2_leaf_reg': 1.0918937098901578e-07, 'border_count': 205, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:02:57,225] Trial 124 finished with value: 0.6217428244050789 and parameters: {'iterations': 354, 'depth': 5, 'learning_rate': 0.2274889245205261, 'random_strength': 0, 'bagging_temperature': 0.9133630319494414, 'l2_leaf_reg': 2.3930018141684398e-08, 'border_count': 207, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:00,142] Trial 125 finished with value: 0.670569748137514 and parameters: {'iterations': 282, 'depth': 5, 'learning_rate': 0.2253066386486282, 'random_strength': 6, 'bagging_temperature': 0.8639157547305913, 'l2_leaf_reg': 2.0823666978521873e-08, 'border_count': 208, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:02,370] Trial 126 finished with value: 0.6340211151977763 and parameters: {'iterations': 351, 'depth': 6, 'learning_rate': 0.24661732986570406, 'random_strength': 1, 'bagging_temperature': 0.910339410944682, 'l2_leaf_reg': 2.9772327731959453e-08, 'border_count': 199, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:04,799] Trial 127 finished with value: 0.6708396880319738 and parameters: {'iterations': 238, 'depth': 5, 'learning_rate': 0.22926451334813133, 'random_strength': 4, 'bagging_temperature': 0.8865308514434367, 'l2_leaf_reg': 5.1221714264125634e-08, 'border_count': 218, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:06,902] Trial 128 finished with value: 0.6605029224438216 and parameters: {'iterations': 318, 'depth': 4, 'learning_rate': 0.2116896404868589, 'random_strength': 0, 'bagging_temperature': 0.9206593701081622, 'l2_leaf_reg': 1.0390895803281527e-07, 'border_count': 206, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:10,661] Trial 129 finished with value: 0.6597102039553384 and parameters: {'iterations': 782, 'depth': 5, 'learning_rate': 0.21840200785703767, 'random_strength': 11, 'bagging_temperature': 0.9298618378208828, 'l2_leaf_reg': 1.5529808242217365e-08, 'border_count': 215, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:12,834] Trial 130 finished with value: 0.6639317887516164 and parameters: {'iterations': 205, 'depth': 5, 'learning_rate': 0.20078913945394852, 'random_strength': 7, 'bagging_temperature': 0.8285262234012067, 'l2_leaf_reg': 3.4838822766204115e-08, 'border_count': 192, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:15,721] Trial 131 finished with value: 0.6764714290479518 and parameters: {'iterations': 383, 'depth': 5, 'learning_rate': 0.23232626540552986, 'random_strength': 5, 'bagging_temperature': 0.9623870311794387, 'l2_leaf_reg': 1.5269041689887798e-07, 'border_count': 130, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:19,466] Trial 132 finished with value: 0.6438695833415969 and parameters: {'iterations': 425, 'depth': 5, 'learning_rate': 0.2371624864022576, 'random_strength': 3, 'bagging_temperature': 0.9838894250174444, 'l2_leaf_reg': 8.482400878670473e-08, 'border_count': 220, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:23,123] Trial 133 finished with value: 0.6599096293922718 and parameters: {'iterations': 479, 'depth': 6, 'learning_rate': 0.24153779825378052, 'random_strength': 0, 'bagging_temperature': 0.9472090510814074, 'l2_leaf_reg': 1.0929372578529445e-08, 'border_count': 134, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:25,549] Trial 134 finished with value: 0.6741763301027688 and parameters: {'iterations': 360, 'depth': 5, 'learning_rate': 0.22346546501590372, 'random_strength': 11, 'bagging_temperature': 0.999644842882556, 'l2_leaf_reg': 3.495639555690479e-07, 'border_count': 124, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:27,249] Trial 135 finished with value: 0.6599708907293895 and parameters: {'iterations': 155, 'depth': 5, 'learning_rate': 0.24862440860206256, 'random_strength': 1, 'bagging_temperature': 0.8010633254882732, 'l2_leaf_reg': 1.295996441952901e-07, 'border_count': 205, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:31,296] Trial 136 finished with value: 0.6453319224851825 and parameters: {'iterations': 446, 'depth': 4, 'learning_rate': 0.2369057829261851, 'random_strength': 2, 'bagging_temperature': 0.894639267877283, 'l2_leaf_reg': 5.913837716581487e-08, 'border_count': 210, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:33,789] Trial 137 finished with value: 0.6661432243805832 and parameters: {'iterations': 490, 'depth': 5, 'learning_rate': 0.22715337550707768, 'random_strength': 5, 'bagging_temperature': 0.8457099867347213, 'l2_leaf_reg': 2.6450575643198684e-07, 'border_count': 188, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:36,814] Trial 138 finished with value: 0.683989906321566 and parameters: {'iterations': 322, 'depth': 5, 'learning_rate': 0.24498377609316624, 'random_strength': 80, 'bagging_temperature': 0.9418076095759049, 'l2_leaf_reg': 2.6546044698908748e-08, 'border_count': 139, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:40,072] Trial 139 finished with value: 0.6374758818517866 and parameters: {'iterations': 403, 'depth': 4, 'learning_rate': 0.23351061194312203, 'random_strength': 3, 'bagging_temperature': 0.9707698290427493, 'l2_leaf_reg': 1.762260240912266e-07, 'border_count': 1, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:42,183] Trial 140 finished with value: 0.6758425798463286 and parameters: {'iterations': 264, 'depth': 6, 'learning_rate': 0.2548000892260787, 'random_strength': 7, 'bagging_temperature': 0.9171446255287319, 'l2_leaf_reg': 4.7351671220904064e-07, 'border_count': 110, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:45,269] Trial 141 finished with value: 0.6163427149966881 and parameters: {'iterations': 401, 'depth': 5, 'learning_rate': 0.21716921786386054, 'random_strength': 77, 'bagging_temperature': 0.9525027065889544, 'l2_leaf_reg': 8.587159646492582e-07, 'border_count': 197, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:48,628] Trial 142 finished with value: 0.6493107454111084 and parameters: {'iterations': 370, 'depth': 5, 'learning_rate': 0.22186691784633938, 'random_strength': 77, 'bagging_temperature': 0.9655778230091955, 'l2_leaf_reg': 1.1268587611709432e-07, 'border_count': 199, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:52,025] Trial 143 finished with value: 0.6409556520572237 and parameters: {'iterations': 336, 'depth': 5, 'learning_rate': 0.20715929099157587, 'random_strength': 79, 'bagging_temperature': 0.9352554198853822, 'l2_leaf_reg': 2.139158196672779e-07, 'border_count': 119, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:54,329] Trial 144 finished with value: 0.6541233488636783 and parameters: {'iterations': 299, 'depth': 5, 'learning_rate': 0.2159698107742975, 'random_strength': 0, 'bagging_temperature': 0.9821396715555959, 'l2_leaf_reg': 5.149601012454269e-07, 'border_count': 181, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:03:57,105] Trial 145 finished with value: 0.6697534288121909 and parameters: {'iterations': 395, 'depth': 5, 'learning_rate': 0.23035800242923501, 'random_strength': 73, 'bagging_temperature': 0.8746749972559567, 'l2_leaf_reg': 9.59321144613548e-07, 'border_count': 193, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:01,207] Trial 146 finished with value: 0.6815543004047273 and parameters: {'iterations': 433, 'depth': 5, 'learning_rate': 0.23858182082106075, 'random_strength': 82, 'bagging_temperature': 0.8959610483292643, 'l2_leaf_reg': 7.38978070328923e-08, 'border_count': 248, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:05,199] Trial 147 finished with value: 0.6618263853391064 and parameters: {'iterations': 360, 'depth': 6, 'learning_rate': 0.22787237657494833, 'random_strength': 75, 'bagging_temperature': 0.9089254476927127, 'l2_leaf_reg': 4.130429211374079e-08, 'border_count': 203, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:07,555] Trial 148 finished with value: 0.6522647209271093 and parameters: {'iterations': 230, 'depth': 4, 'learning_rate': 0.24422524098729126, 'random_strength': 85, 'bagging_temperature': 0.9530219609444402, 'l2_leaf_reg': 3.6316108100188807e-07, 'border_count': 116, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:10,412] Trial 149 finished with value: 0.6501485702187325 and parameters: {'iterations': 280, 'depth': 5, 'learning_rate': 0.22005900602829886, 'random_strength': 4, 'bagging_temperature': 0.7535442254193614, 'l2_leaf_reg': 6.266404953975954e-07, 'border_count': 128, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:12,299] Trial 150 finished with value: 0.690573934325234 and parameters: {'iterations': 199, 'depth': 4, 'learning_rate': 0.16157306581001513, 'random_strength': 78, 'bagging_temperature': 0.7207454280609559, 'l2_leaf_reg': 1.2527879184768734e-07, 'border_count': 230, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:15,962] Trial 151 finished with value: 0.6544262003272918 and parameters: {'iterations': 413, 'depth': 5, 'learning_rate': 0.21057765837059628, 'random_strength': 72, 'bagging_temperature': 0.9996674305712099, 'l2_leaf_reg': 3.43457080489649e-06, 'border_count': 137, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:20,512] Trial 152 finished with value: 0.6098419326958517 and parameters: {'iterations': 444, 'depth': 5, 'learning_rate': 0.2177070262490453, 'random_strength': 76, 'bagging_temperature': 0.9512977527936454, 'l2_leaf_reg': 2.8443125955622703e-07, 'border_count': 175, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:23,483] Trial 153 finished with value: 0.650626734149391 and parameters: {'iterations': 457, 'depth': 5, 'learning_rate': 0.23461820782909323, 'random_strength': 76, 'bagging_temperature': 0.933490590261332, 'l2_leaf_reg': 3.1259721970221546e-07, 'border_count': 177, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:26,511] Trial 154 finished with value: 0.6379341653862778 and parameters: {'iterations': 385, 'depth': 5, 'learning_rate': 0.22629068410564837, 'random_strength': 80, 'bagging_temperature': 0.9629185939033912, 'l2_leaf_reg': 7.026063922286268e-07, 'border_count': 255, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:44,237] Trial 155 finished with value: 0.6282562830565592 and parameters: {'iterations': 528, 'depth': 5, 'learning_rate': 0.21675781163463942, 'random_strength': 74, 'bagging_temperature': 0.9214480923689827, 'l2_leaf_reg': 2.1259806476130382e-07, 'border_count': 187, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:49,142] Trial 156 finished with value: 0.6578490090182474 and parameters: {'iterations': 496, 'depth': 5, 'learning_rate': 0.23962534693593618, 'random_strength': 68, 'bagging_temperature': 0.9486517903748034, 'l2_leaf_reg': 8.111480924032099e-08, 'border_count': 196, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:55,050] Trial 157 finished with value: 0.6556739333205378 and parameters: {'iterations': 308, 'depth': 11, 'learning_rate': 0.2027912890682495, 'random_strength': 84, 'bagging_temperature': 0.9858144452113421, 'l2_leaf_reg': 1.3884534628346977e-07, 'border_count': 162, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:04:57,721] Trial 158 finished with value: 0.6781454834664716 and parameters: {'iterations': 335, 'depth': 6, 'learning_rate': 0.25094124835602455, 'random_strength': 87, 'bagging_temperature': 0.8584443216174352, 'l2_leaf_reg': 2.411708679175025e-07, 'border_count': 171, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:01,320] Trial 159 finished with value: 0.6611420606609715 and parameters: {'iterations': 856, 'depth': 5, 'learning_rate': 0.2308302358086156, 'random_strength': 82, 'bagging_temperature': 0.9027083947739417, 'l2_leaf_reg': 4.751705644610319e-08, 'border_count': 144, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:12,592] Trial 160 finished with value: 0.6306014909001767 and parameters: {'iterations': 438, 'depth': 5, 'learning_rate': 0.22230093077543234, 'random_strength': 78, 'bagging_temperature': 0.6928674865198101, 'l2_leaf_reg': 5.111447188219583e-07, 'border_count': 213, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:16,706] Trial 161 finished with value: 0.6518094707063083 and parameters: {'iterations': 398, 'depth': 5, 'learning_rate': 0.2122155201403828, 'random_strength': 76, 'bagging_temperature': 0.9715905883325936, 'l2_leaf_reg': 8.331817991213649e-07, 'border_count': 168, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:20,792] Trial 162 finished with value: 0.6461723053618168 and parameters: {'iterations': 414, 'depth': 5, 'learning_rate': 0.21621498233615344, 'random_strength': 72, 'bagging_temperature': 0.9405584538434545, 'l2_leaf_reg': 1.31023833524221e-06, 'border_count': 132, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:24,389] Trial 163 finished with value: 0.6555150715751507 and parameters: {'iterations': 354, 'depth': 5, 'learning_rate': 0.23537752383987598, 'random_strength': 81, 'bagging_temperature': 0.9503886298942904, 'l2_leaf_reg': 3.878683781133623e-07, 'border_count': 157, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:26,934] Trial 164 finished with value: 0.6540983361045166 and parameters: {'iterations': 466, 'depth': 4, 'learning_rate': 0.22639087260251473, 'random_strength': 77, 'bagging_temperature': 0.9798216419790189, 'l2_leaf_reg': 2.271193322076024e-06, 'border_count': 182, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:30,737] Trial 165 finished with value: 0.6280778385888738 and parameters: {'iterations': 377, 'depth': 5, 'learning_rate': 0.2434623508185459, 'random_strength': 2, 'bagging_temperature': 0.6480474010431918, 'l2_leaf_reg': 1.576436148614737e-07, 'border_count': 125, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:35,025] Trial 166 finished with value: 0.6415998075952698 and parameters: {'iterations': 429, 'depth': 5, 'learning_rate': 0.21980287469919998, 'random_strength': 74, 'bagging_temperature': 0.9093256678102065, 'l2_leaf_reg': 2.857394670903151e-07, 'border_count': 147, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:41,042] Trial 167 finished with value: 0.6329811738756467 and parameters: {'iterations': 679, 'depth': 5, 'learning_rate': 0.20726227321801222, 'random_strength': 0, 'bagging_temperature': 0.8799388283739399, 'l2_leaf_reg': 9.569031493499938e-07, 'border_count': 217, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:43,549] Trial 168 finished with value: 0.6310858002745849 and parameters: {'iterations': 244, 'depth': 5, 'learning_rate': 0.23262475301162774, 'random_strength': 79, 'bagging_temperature': 0.931022539366651, 'l2_leaf_reg': 7.737181869959168e-08, 'border_count': 154, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:47,086] Trial 169 finished with value: 0.6414518327284738 and parameters: {'iterations': 952, 'depth': 4, 'learning_rate': 0.22729549736900456, 'random_strength': 70, 'bagging_temperature': 0.9599000679468986, 'l2_leaf_reg': 1.694617337254425e-06, 'border_count': 176, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:51,853] Trial 170 finished with value: 0.681606322307738 and parameters: {'iterations': 332, 'depth': 6, 'learning_rate': 0.19351032123530856, 'random_strength': 83, 'bagging_temperature': 0.92335160785134, 'l2_leaf_reg': 2.1296325698473452e-08, 'border_count': 139, 'grow_policy': 'Depthwise'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:54,280] Trial 171 finished with value: 0.6737455584726056 and parameters: {'iterations': 371, 'depth': 5, 'learning_rate': 0.24466606410846228, 'random_strength': 2, 'bagging_temperature': 0.6011578828329999, 'l2_leaf_reg': 1.649536291298907e-07, 'border_count': 124, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:56,803] Trial 172 finished with value: 0.6769867845507191 and parameters: {'iterations': 387, 'depth': 5, 'learning_rate': 0.23960757698882232, 'random_strength': 3, 'bagging_temperature': 0.5170838650516076, 'l2_leaf_reg': 1.0694231754716772e-07, 'border_count': 125, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:05:58,916] Trial 173 finished with value: 0.6852982534373931 and parameters: {'iterations': 305, 'depth': 5, 'learning_rate': 0.25733449156355753, 'random_strength': 5, 'bagging_temperature': 0.6385624430872963, 'l2_leaf_reg': 1.921355341044009e-07, 'border_count': 118, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:03,715] Trial 174 finished with value: 0.680906001762831 and parameters: {'iterations': 410, 'depth': 10, 'learning_rate': 0.24581944372496428, 'random_strength': 53, 'bagging_temperature': 0.5653459083735225, 'l2_leaf_reg': 4.205000772277901e-07, 'border_count': 131, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:08,502] Trial 175 finished with value: 0.6246288760100552 and parameters: {'iterations': 450, 'depth': 5, 'learning_rate': 0.23339216140120775, 'random_strength': 0, 'bagging_temperature': 0.9624849036936851, 'l2_leaf_reg': 1.197795318759991e-07, 'border_count': 199, 'grow_policy': 'SymmetricTree'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:19,251] Trial 176 finished with value: 0.6202562319508814 and parameters: {'iterations': 489, 'depth': 9, 'learning_rate': 0.23475843780135885, 'random_strength': 0, 'bagging_temperature': 0.9808074376643465, 'l2_leaf_reg': 5.8976761786590694e-08, 'border_count': 207, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:26,160] Trial 177 finished with value: 0.6497012423310439 and parameters: {'iterations': 497, 'depth': 9, 'learning_rate': 0.23348540858019, 'random_strength': 5, 'bagging_temperature': 0.9995457230027193, 'l2_leaf_reg': 5.807397258493759e-08, 'border_count': 202, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:32,030] Trial 178 finished with value: 0.645210009609853 and parameters: {'iterations': 586, 'depth': 8, 'learning_rate': 0.23753334805989545, 'random_strength': 1, 'bagging_temperature': 0.9739410417382482, 'l2_leaf_reg': 3.3028415898927214e-08, 'border_count': 210, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:40,893] Trial 179 finished with value: 0.6636264274145118 and parameters: {'iterations': 1057, 'depth': 7, 'learning_rate': 0.22555224094107015, 'random_strength': 0, 'bagging_temperature': 0.9575051729985252, 'l2_leaf_reg': 1.033554047929027e-07, 'border_count': 191, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:06:48,385] Trial 180 finished with value: 0.6266188057248673 and parameters: {'iterations': 451, 'depth': 9, 'learning_rate': 0.25070786750727025, 'random_strength': 9, 'bagging_temperature': 0.37735749786340433, 'l2_leaf_reg': 5.300647687123726e-08, 'border_count': 207, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:04,412] Trial 181 finished with value: 0.6586056884095435 and parameters: {'iterations': 463, 'depth': 10, 'learning_rate': 0.26780371043072576, 'random_strength': 10, 'bagging_temperature': 0.37224937563083893, 'l2_leaf_reg': 4.9296048634292386e-08, 'border_count': 198, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:10,513] Trial 182 finished with value: 0.6814992244541251 and parameters: {'iterations': 456, 'depth': 9, 'learning_rate': 0.25268582908352755, 'random_strength': 3, 'bagging_temperature': 0.9782847014844044, 'l2_leaf_reg': 7.531303282184235e-08, 'border_count': 207, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:18,490] Trial 183 finished with value: 0.6837578031639656 and parameters: {'iterations': 487, 'depth': 8, 'learning_rate': 0.2311269604474809, 'random_strength': 7, 'bagging_temperature': 0.44111714984456973, 'l2_leaf_reg': 1.756384941180719e-08, 'border_count': 222, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:27,761] Trial 184 finished with value: 0.6330738476683465 and parameters: {'iterations': 433, 'depth': 9, 'learning_rate': 0.23924680926395075, 'random_strength': 2, 'bagging_temperature': 0.37781436493337306, 'l2_leaf_reg': 1.0589358785742948e-07, 'border_count': 206, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:40,790] Trial 185 finished with value: 0.6088285421722005 and parameters: {'iterations': 551, 'depth': 9, 'learning_rate': 0.14942830541748994, 'random_strength': 0, 'bagging_temperature': 0.9393628896006044, 'l2_leaf_reg': 3.892608018150171e-08, 'border_count': 197, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:07:52,731] Trial 186 finished with value: 0.6211092720130246 and parameters: {'iterations': 518, 'depth': 9, 'learning_rate': 0.13909278280998402, 'random_strength': 13, 'bagging_temperature': 0.938151216583015, 'l2_leaf_reg': 3.636484394832184e-08, 'border_count': 199, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:08:00,699] Trial 187 finished with value: 0.6695845631010001 and parameters: {'iterations': 526, 'depth': 9, 'learning_rate': 0.2487591562182791, 'random_strength': 14, 'bagging_temperature': 0.2846291911355775, 'l2_leaf_reg': 3.785166864740049e-08, 'border_count': 196, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:08:27,235] Trial 188 finished with value: 0.6357166094652864 and parameters: {'iterations': 571, 'depth': 9, 'learning_rate': 0.04563357389653974, 'random_strength': 23, 'bagging_temperature': 0.9181948717634709, 'l2_leaf_reg': 2.7968204230710505e-08, 'border_count': 201, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:08:35,164] Trial 189 finished with value: 0.6412777436301604 and parameters: {'iterations': 514, 'depth': 9, 'learning_rate': 0.13113414469479254, 'random_strength': 0, 'bagging_temperature': 0.8929368776780552, 'l2_leaf_reg': 1.7005971511096462e-08, 'border_count': 190, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:08:45,235] Trial 190 finished with value: 0.6331451335708236 and parameters: {'iterations': 487, 'depth': 9, 'learning_rate': 0.14813963622325674, 'random_strength': 18, 'bagging_temperature': 0.9409625413944673, 'l2_leaf_reg': 5.212688614067211e-08, 'border_count': 213, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:03,646] Trial 191 finished with value: 0.6053379758752512 and parameters: {'iterations': 449, 'depth': 9, 'learning_rate': 0.14215821537836415, 'random_strength': 4, 'bagging_temperature': 0.616045511882781, 'l2_leaf_reg': 2.4678238921811664e-08, 'border_count': 196, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:13,166] Trial 192 finished with value: 0.6506645772159964 and parameters: {'iterations': 449, 'depth': 9, 'learning_rate': 0.139133960816712, 'random_strength': 5, 'bagging_temperature': 0.575751632291879, 'l2_leaf_reg': 2.8360602894547473e-08, 'border_count': 196, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:23,404] Trial 193 finished with value: 0.6579882749261275 and parameters: {'iterations': 535, 'depth': 9, 'learning_rate': 0.14867790893895733, 'random_strength': 8, 'bagging_temperature': 0.7859188607225356, 'l2_leaf_reg': 1.4835009551991033e-08, 'border_count': 206, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:30,302] Trial 194 finished with value: 0.6598776777674108 and parameters: {'iterations': 545, 'depth': 9, 'learning_rate': 0.1574855705942681, 'random_strength': 0, 'bagging_temperature': 0.6970240225193745, 'l2_leaf_reg': 0.0013491924437791397, 'border_count': 203, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:37,965] Trial 195 finished with value: 0.6396064640570889 and parameters: {'iterations': 625, 'depth': 9, 'learning_rate': 0.17008984401529506, 'random_strength': 4, 'bagging_temperature': 0.5119921662516091, 'l2_leaf_reg': 4.2983663128094104e-08, 'border_count': 187, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:09:49,051] Trial 196 finished with value: 0.6470680529551956 and parameters: {'iterations': 470, 'depth': 9, 'learning_rate': 0.139998631322393, 'random_strength': 12, 'bagging_temperature': 0.5971195493391998, 'l2_leaf_reg': 6.04136668673588e-08, 'border_count': 195, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:10:03,401] Trial 197 finished with value: 0.6262618656335507 and parameters: {'iterations': 435, 'depth': 10, 'learning_rate': 0.1534527303090653, 'random_strength': 2, 'bagging_temperature': 0.47362713205558993, 'l2_leaf_reg': 2.2474706354574417e-08, 'border_count': 212, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:10:18,207] Trial 198 finished with value: 0.6155861454455247 and parameters: {'iterations': 510, 'depth': 10, 'learning_rate': 0.1542035929419315, 'random_strength': 3, 'bagging_temperature': 0.5375446439977285, 'l2_leaf_reg': 3.0667014902961544e-08, 'border_count': 210, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:10:36,526] Trial 199 finished with value: 0.6169391559742955 and parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1547384208224277, 'random_strength': 2, 'bagging_temperature': 0.5440978233102668, 'l2_leaf_reg': 2.430747863894523e-08, 'border_count': 215, 'grow_policy': 'Lossguide'}. Best is trial 112 with value: 0.6019431085716467.\n",
      "[I 2023-12-07 21:10:36,528] A new study created in memory with name: no-name-f0f6f186-35a0-46b1-88b3-7b4f6a8bc76d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'iterations': 327, 'depth': 5, 'learning_rate': 0.22959914137522078, 'random_strength': 0, 'bagging_temperature': 0.9998170501649718, 'l2_leaf_reg': 1.6823816623838656e-07, 'border_count': 249, 'grow_policy': 'SymmetricTree'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 21:10:38,195] Trial 0 finished with value: 0.7077898742208906 and parameters: {'iterations': 155, 'depth': 5, 'learning_rate': 0.22950815478579778, 'random_strength': 87, 'bagging_temperature': 0.29142304880915815, 'l2_leaf_reg': 0.0011347306266819963, 'border_count': 130, 'grow_policy': 'Depthwise'}. Best is trial 0 with value: 0.7077898742208906.\n",
      "[I 2023-12-07 21:10:43,330] Trial 1 finished with value: 0.6713402849884147 and parameters: {'iterations': 1057, 'depth': 12, 'learning_rate': 0.19348011067512988, 'random_strength': 35, 'bagging_temperature': 0.06955546229125475, 'l2_leaf_reg': 0.00010681408719160444, 'border_count': 6, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6713402849884147.\n",
      "[I 2023-12-07 21:10:51,334] Trial 2 finished with value: 0.6884206334288078 and parameters: {'iterations': 582, 'depth': 10, 'learning_rate': 0.021768187990246136, 'random_strength': 7, 'bagging_temperature': 0.4694383852414973, 'l2_leaf_reg': 9.06317064161743, 'border_count': 194, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6713402849884147.\n",
      "[I 2023-12-07 21:10:54,721] Trial 3 finished with value: 0.6850141120838359 and parameters: {'iterations': 413, 'depth': 10, 'learning_rate': 0.12095690702741395, 'random_strength': 33, 'bagging_temperature': 0.9642728558307222, 'l2_leaf_reg': 2.0886278309283277, 'border_count': 144, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6713402849884147.\n",
      "[I 2023-12-07 21:10:56,261] Trial 4 finished with value: 0.669247796564497 and parameters: {'iterations': 321, 'depth': 8, 'learning_rate': 0.2859601656315817, 'random_strength': 73, 'bagging_temperature': 0.5909949519019713, 'l2_leaf_reg': 2.8992739305410995e-05, 'border_count': 55, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:10:57,524] Trial 5 finished with value: 0.7071494884351003 and parameters: {'iterations': 394, 'depth': 4, 'learning_rate': 0.16989957518658105, 'random_strength': 75, 'bagging_temperature': 0.38468957365569767, 'l2_leaf_reg': 0.759194468752136, 'border_count': 120, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:00,067] Trial 6 finished with value: 0.6816241866821313 and parameters: {'iterations': 324, 'depth': 4, 'learning_rate': 0.10294236305430701, 'random_strength': 48, 'bagging_temperature': 0.5852048432475356, 'l2_leaf_reg': 8.308196896215973e-07, 'border_count': 188, 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:01,404] Trial 7 finished with value: 0.6758734983688899 and parameters: {'iterations': 1084, 'depth': 5, 'learning_rate': 0.1738741704995178, 'random_strength': 45, 'bagging_temperature': 0.5540926099314383, 'l2_leaf_reg': 0.0286785117206354, 'border_count': 170, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:02,429] Trial 8 finished with value: 0.7164489985817334 and parameters: {'iterations': 144, 'depth': 8, 'learning_rate': 0.19514437198826912, 'random_strength': 100, 'bagging_temperature': 0.22335957144495255, 'l2_leaf_reg': 7.318747497595341e-05, 'border_count': 78, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:10,196] Trial 9 finished with value: 0.6959579288213966 and parameters: {'iterations': 321, 'depth': 9, 'learning_rate': 0.04394346551135644, 'random_strength': 45, 'bagging_temperature': 0.35613954004055015, 'l2_leaf_reg': 3.012177463362438e-07, 'border_count': 202, 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:15,007] Trial 10 finished with value: 0.7216718976729602 and parameters: {'iterations': 1375, 'depth': 7, 'learning_rate': 0.2984011311037245, 'random_strength': 73, 'bagging_temperature': 0.7634597908135248, 'l2_leaf_reg': 1.8761587156615648e-08, 'border_count': 30, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:18,584] Trial 11 finished with value: 0.6835556251915472 and parameters: {'iterations': 870, 'depth': 12, 'learning_rate': 0.2718124086935034, 'random_strength': 18, 'bagging_temperature': 0.1119171670810932, 'l2_leaf_reg': 6.195214727029407e-05, 'border_count': 3, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:22,832] Trial 12 finished with value: 0.6717502875732863 and parameters: {'iterations': 916, 'depth': 12, 'learning_rate': 0.24665665416243937, 'random_strength': 65, 'bagging_temperature': 0.01608674529821194, 'l2_leaf_reg': 0.0008681815622080126, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:26,785] Trial 13 finished with value: 0.7125497104415637 and parameters: {'iterations': 1315, 'depth': 7, 'learning_rate': 0.2225409894558688, 'random_strength': 61, 'bagging_temperature': 0.1579944563095124, 'l2_leaf_reg': 1.023618336642723e-05, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:30,723] Trial 14 finished with value: 0.6871066088663718 and parameters: {'iterations': 637, 'depth': 10, 'learning_rate': 0.2984117302557221, 'random_strength': 28, 'bagging_temperature': 0.008272055921749073, 'l2_leaf_reg': 0.005301481393474663, 'border_count': 248, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:32,470] Trial 15 finished with value: 0.6839072817696467 and parameters: {'iterations': 1081, 'depth': 7, 'learning_rate': 0.20554349315515963, 'random_strength': 31, 'bagging_temperature': 0.6660290746023586, 'l2_leaf_reg': 1.2421271941039706e-05, 'border_count': 2, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:36,703] Trial 16 finished with value: 0.73545481237381 and parameters: {'iterations': 677, 'depth': 11, 'learning_rate': 0.2684730813323392, 'random_strength': 85, 'bagging_temperature': 0.4311184742683068, 'l2_leaf_reg': 0.0001831857240637534, 'border_count': 45, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:40,586] Trial 17 finished with value: 0.6978619105779487 and parameters: {'iterations': 1159, 'depth': 8, 'learning_rate': 0.24942832841305743, 'random_strength': 59, 'bagging_temperature': 0.2578568708862141, 'l2_leaf_reg': 0.04058754064957454, 'border_count': 97, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:41,945] Trial 18 finished with value: 0.7166511435966182 and parameters: {'iterations': 1470, 'depth': 9, 'learning_rate': 0.20309846613086008, 'random_strength': 17, 'bagging_temperature': 0.3431194393809903, 'l2_leaf_reg': 7.236304837848196e-06, 'border_count': 29, 'grow_policy': 'SymmetricTree'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:44,698] Trial 19 finished with value: 0.6746813085703229 and parameters: {'iterations': 767, 'depth': 6, 'learning_rate': 0.14924091572410234, 'random_strength': 38, 'bagging_temperature': 0.4785933032474283, 'l2_leaf_reg': 0.0005968554300572274, 'border_count': 24, 'grow_policy': 'Depthwise'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:48,841] Trial 20 finished with value: 0.6765988311112638 and parameters: {'iterations': 1006, 'depth': 11, 'learning_rate': 0.2637078195832315, 'random_strength': 56, 'bagging_temperature': 0.18555076037004886, 'l2_leaf_reg': 1.5406686788902687e-06, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 4 with value: 0.669247796564497.\n",
      "[I 2023-12-07 21:11:53,505] Trial 21 finished with value: 0.659554550962001 and parameters: {'iterations': 906, 'depth': 12, 'learning_rate': 0.23946194595328973, 'random_strength': 72, 'bagging_temperature': 0.0061178021831494594, 'l2_leaf_reg': 0.00163708338035597, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 21 with value: 0.659554550962001.\n",
      "[I 2023-12-07 21:11:57,796] Trial 22 finished with value: 0.6800981940920775 and parameters: {'iterations': 1203, 'depth': 12, 'learning_rate': 0.241761488830491, 'random_strength': 74, 'bagging_temperature': 0.10057133010006081, 'l2_leaf_reg': 7.397513022779649e-05, 'border_count': 97, 'grow_policy': 'Lossguide'}. Best is trial 21 with value: 0.659554550962001.\n",
      "[I 2023-12-07 21:12:01,968] Trial 23 finished with value: 0.7018753480918024 and parameters: {'iterations': 914, 'depth': 11, 'learning_rate': 0.224902391209257, 'random_strength': 84, 'bagging_temperature': 0.07990734761248408, 'l2_leaf_reg': 0.0027775680411913396, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 21 with value: 0.659554550962001.\n",
      "[I 2023-12-07 21:12:06,049] Trial 24 finished with value: 0.6931302523024139 and parameters: {'iterations': 530, 'depth': 9, 'learning_rate': 0.27090560612690645, 'random_strength': 98, 'bagging_temperature': 0.1825538574474192, 'l2_leaf_reg': 0.0003807824235654154, 'border_count': 42, 'grow_policy': 'Lossguide'}. Best is trial 21 with value: 0.659554550962001.\n",
      "[I 2023-12-07 21:12:09,217] Trial 25 finished with value: 0.6517109764174271 and parameters: {'iterations': 757, 'depth': 11, 'learning_rate': 0.21420620064443802, 'random_strength': 51, 'bagging_temperature': 0.028798885809299332, 'l2_leaf_reg': 0.009058716768757935, 'border_count': 103, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:10,554] Trial 26 finished with value: 0.6942962419784477 and parameters: {'iterations': 770, 'depth': 8, 'learning_rate': 0.2862029661587713, 'random_strength': 67, 'bagging_temperature': 0.27809725822214854, 'l2_leaf_reg': 0.008985873092847783, 'border_count': 105, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:13,268] Trial 27 finished with value: 0.6805500081125156 and parameters: {'iterations': 492, 'depth': 11, 'learning_rate': 0.254999160342205, 'random_strength': 51, 'bagging_temperature': 0.01115561676009574, 'l2_leaf_reg': 0.09417017966559442, 'border_count': 148, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:15,777] Trial 28 finished with value: 0.6904298560166289 and parameters: {'iterations': 694, 'depth': 10, 'learning_rate': 0.22969803238320122, 'random_strength': 79, 'bagging_temperature': 0.13233810142374258, 'l2_leaf_reg': 0.0024552286804537886, 'border_count': 84, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:20,909] Trial 29 finished with value: 0.7133356495346197 and parameters: {'iterations': 286, 'depth': 9, 'learning_rate': 0.23325975543796798, 'random_strength': 91, 'bagging_temperature': 0.31837007486102725, 'l2_leaf_reg': 0.002001992901653611, 'border_count': 119, 'grow_policy': 'Depthwise'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:22,180] Trial 30 finished with value: 0.6979541324476859 and parameters: {'iterations': 216, 'depth': 6, 'learning_rate': 0.28620909823564455, 'random_strength': 70, 'bagging_temperature': 0.21577932151544532, 'l2_leaf_reg': 0.0171849799301712, 'border_count': 134, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:25,424] Trial 31 finished with value: 0.6924557683590709 and parameters: {'iterations': 988, 'depth': 12, 'learning_rate': 0.2177972049846855, 'random_strength': 39, 'bagging_temperature': 0.080339483994032, 'l2_leaf_reg': 0.00022054303860208262, 'border_count': 45, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:30,421] Trial 32 finished with value: 0.6783556961935018 and parameters: {'iterations': 1228, 'depth': 12, 'learning_rate': 0.19700626628490445, 'random_strength': 52, 'bagging_temperature': 0.06456692587297119, 'l2_leaf_reg': 0.0013276173165823067, 'border_count': 18, 'grow_policy': 'Lossguide'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:33,197] Trial 33 finished with value: 0.6960682194574339 and parameters: {'iterations': 834, 'depth': 11, 'learning_rate': 0.23984530488069, 'random_strength': 22, 'bagging_temperature': 0.15825359853652265, 'l2_leaf_reg': 0.007903240896599637, 'border_count': 60, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:35,331] Trial 34 finished with value: 0.6853414779859559 and parameters: {'iterations': 1015, 'depth': 10, 'learning_rate': 0.2133706314153827, 'random_strength': 0, 'bagging_temperature': 0.03969941104120589, 'l2_leaf_reg': 0.1594364867748921, 'border_count': 103, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:51,417] Trial 35 finished with value: 0.7482305497508587 and parameters: {'iterations': 541, 'depth': 12, 'learning_rate': 0.1822213953330511, 'random_strength': 80, 'bagging_temperature': 0.11533434990959023, 'l2_leaf_reg': 0.0006347631475754459, 'border_count': 12, 'grow_policy': 'Depthwise'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:54,327] Trial 36 finished with value: 0.7332996700013883 and parameters: {'iterations': 455, 'depth': 11, 'learning_rate': 0.25294677651297665, 'random_strength': 93, 'bagging_temperature': 0.26900333483750083, 'l2_leaf_reg': 0.00016062155596809126, 'border_count': 118, 'grow_policy': 'SymmetricTree'}. Best is trial 25 with value: 0.6517109764174271.\n",
      "[I 2023-12-07 21:12:59,507] Trial 37 finished with value: 0.6470031971111952 and parameters: {'iterations': 747, 'depth': 10, 'learning_rate': 0.18494052867667682, 'random_strength': 63, 'bagging_temperature': 0.414505396933178, 'l2_leaf_reg': 3.1350279099970447e-05, 'border_count': 38, 'grow_policy': 'Lossguide'}. Best is trial 37 with value: 0.6470031971111952.\n",
      "[I 2023-12-07 21:13:03,963] Trial 38 finished with value: 0.6930126405262808 and parameters: {'iterations': 610, 'depth': 10, 'learning_rate': 0.181212835813912, 'random_strength': 63, 'bagging_temperature': 0.4126258279374234, 'l2_leaf_reg': 3.072901059128568e-05, 'border_count': 87, 'grow_policy': 'Lossguide'}. Best is trial 37 with value: 0.6470031971111952.\n",
      "[I 2023-12-07 21:13:05,536] Trial 39 finished with value: 0.6950224985919375 and parameters: {'iterations': 713, 'depth': 8, 'learning_rate': 0.1593320645797434, 'random_strength': 55, 'bagging_temperature': 0.3050938051127157, 'l2_leaf_reg': 0.0005566335844324082, 'border_count': 70, 'grow_policy': 'SymmetricTree'}. Best is trial 37 with value: 0.6470031971111952.\n",
      "[I 2023-12-07 21:13:11,032] Trial 40 finished with value: 0.7052976874471077 and parameters: {'iterations': 801, 'depth': 9, 'learning_rate': 0.21276995517206276, 'random_strength': 69, 'bagging_temperature': 0.538099246982391, 'l2_leaf_reg': 0.5073820441619973, 'border_count': 41, 'grow_policy': 'Depthwise'}. Best is trial 37 with value: 0.6470031971111952.\n",
      "[I 2023-12-07 21:13:15,423] Trial 41 finished with value: 0.6818686981537865 and parameters: {'iterations': 936, 'depth': 11, 'learning_rate': 0.18430194918170037, 'random_strength': 44, 'bagging_temperature': 0.05433618623002889, 'l2_leaf_reg': 3.2921513734269784e-05, 'border_count': 35, 'grow_policy': 'Lossguide'}. Best is trial 37 with value: 0.6470031971111952.\n",
      "[I 2023-12-07 21:13:19,634] Trial 42 finished with value: 0.6429285821236985 and parameters: {'iterations': 875, 'depth': 12, 'learning_rate': 0.1961801160661536, 'random_strength': 38, 'bagging_temperature': 0.3782697785119232, 'l2_leaf_reg': 0.00013596897404188443, 'border_count': 53, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:22,207] Trial 43 finished with value: 0.7233266483555076 and parameters: {'iterations': 110, 'depth': 12, 'learning_rate': 0.2021116050535937, 'random_strength': 78, 'bagging_temperature': 0.3927460180972739, 'l2_leaf_reg': 0.00020222272621658194, 'border_count': 55, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:26,576] Trial 44 finished with value: 0.699489196111522 and parameters: {'iterations': 862, 'depth': 11, 'learning_rate': 0.23199527388412447, 'random_strength': 47, 'bagging_temperature': 0.4539232249407158, 'l2_leaf_reg': 0.0012688737631831625, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:31,341] Trial 45 finished with value: 0.6779998062441799 and parameters: {'iterations': 746, 'depth': 12, 'learning_rate': 0.18981997036242212, 'random_strength': 58, 'bagging_temperature': 0.5012176026421542, 'l2_leaf_reg': 3.4108148875844086e-05, 'border_count': 51, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:36,828] Trial 46 finished with value: 0.6751862734169576 and parameters: {'iterations': 382, 'depth': 10, 'learning_rate': 0.16618845661580448, 'random_strength': 40, 'bagging_temperature': 0.35929320398718717, 'l2_leaf_reg': 0.00010435393068177795, 'border_count': 91, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:40,567] Trial 47 finished with value: 0.6780461295281739 and parameters: {'iterations': 947, 'depth': 12, 'learning_rate': 0.1425993423625342, 'random_strength': 64, 'bagging_temperature': 0.639047432186733, 'l2_leaf_reg': 0.003569153329715798, 'border_count': 19, 'grow_policy': 'SymmetricTree'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:44,903] Trial 48 finished with value: 0.6614616279666572 and parameters: {'iterations': 1127, 'depth': 10, 'learning_rate': 0.21430864321716464, 'random_strength': 71, 'bagging_temperature': 0.2230583435797204, 'l2_leaf_reg': 0.0011638574741656637, 'border_count': 110, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:49,058] Trial 49 finished with value: 0.7138827633230973 and parameters: {'iterations': 1067, 'depth': 10, 'learning_rate': 0.21277651234884418, 'random_strength': 52, 'bagging_temperature': 0.3849717330808782, 'l2_leaf_reg': 0.008780746581487133, 'border_count': 148, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:53,535] Trial 50 finished with value: 0.6600096602687221 and parameters: {'iterations': 1105, 'depth': 11, 'learning_rate': 0.19198557973468286, 'random_strength': 28, 'bagging_temperature': 0.21063824567906647, 'l2_leaf_reg': 0.000409588067798139, 'border_count': 164, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:13:58,206] Trial 51 finished with value: 0.6830336006490442 and parameters: {'iterations': 1138, 'depth': 11, 'learning_rate': 0.17553759708322214, 'random_strength': 27, 'bagging_temperature': 0.22125943916077845, 'l2_leaf_reg': 0.00033820715898028557, 'border_count': 181, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:02,535] Trial 52 finished with value: 0.6758709638080782 and parameters: {'iterations': 1308, 'depth': 11, 'learning_rate': 0.1955044533894744, 'random_strength': 33, 'bagging_temperature': 0.2571272794480414, 'l2_leaf_reg': 0.0011395224388255217, 'border_count': 162, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:07,065] Trial 53 finished with value: 0.7034514988908713 and parameters: {'iterations': 1142, 'depth': 10, 'learning_rate': 0.19322645576411202, 'random_strength': 21, 'bagging_temperature': 0.3246369483531406, 'l2_leaf_reg': 0.003918889326810546, 'border_count': 213, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:10,991] Trial 54 finished with value: 0.6973935162249307 and parameters: {'iterations': 882, 'depth': 12, 'learning_rate': 0.2069202305831145, 'random_strength': 9, 'bagging_temperature': 0.009885667176480123, 'l2_leaf_reg': 0.0003316641097790994, 'border_count': 132, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:16,130] Trial 55 finished with value: 0.68266837683107 and parameters: {'iterations': 816, 'depth': 11, 'learning_rate': 0.21981616909145124, 'random_strength': 42, 'bagging_temperature': 0.12653849331646072, 'l2_leaf_reg': 0.00010838609729059682, 'border_count': 111, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:21,085] Trial 56 finished with value: 0.6965586267420614 and parameters: {'iterations': 1023, 'depth': 12, 'learning_rate': 0.16835826191050252, 'random_strength': 71, 'bagging_temperature': 0.15666478832374814, 'l2_leaf_reg': 0.0008476895085016233, 'border_count': 161, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:25,338] Trial 57 finished with value: 0.7056619505734856 and parameters: {'iterations': 642, 'depth': 10, 'learning_rate': 0.22772417809423795, 'random_strength': 37, 'bagging_temperature': 0.34908572102746593, 'l2_leaf_reg': 0.01903980128465314, 'border_count': 128, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:30,079] Trial 58 finished with value: 0.6792937834299051 and parameters: {'iterations': 1306, 'depth': 11, 'learning_rate': 0.2002956261533725, 'random_strength': 27, 'bagging_temperature': 0.05504155815845291, 'l2_leaf_reg': 5.0311012201758646e-05, 'border_count': 204, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:34,746] Trial 59 finished with value: 0.6815822379921626 and parameters: {'iterations': 967, 'depth': 9, 'learning_rate': 0.2403568760656078, 'random_strength': 61, 'bagging_temperature': 0.2926619255397372, 'l2_leaf_reg': 1.529548458972431e-05, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:39,010] Trial 60 finished with value: 0.7168575234854679 and parameters: {'iterations': 1230, 'depth': 12, 'learning_rate': 0.18906834918811194, 'random_strength': 34, 'bagging_temperature': 0.24088125923854042, 'l2_leaf_reg': 0.0018423033731151664, 'border_count': 231, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:40,390] Trial 61 finished with value: 0.6760566115283471 and parameters: {'iterations': 1108, 'depth': 7, 'learning_rate': 0.2210656773428322, 'random_strength': 74, 'bagging_temperature': 0.09540001018603671, 'l2_leaf_reg': 4.782458854793585e-06, 'border_count': 76, 'grow_policy': 'SymmetricTree'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:43,911] Trial 62 finished with value: 0.727477656753565 and parameters: {'iterations': 897, 'depth': 8, 'learning_rate': 0.26176918785899195, 'random_strength': 67, 'bagging_temperature': 0.1913511910459033, 'l2_leaf_reg': 0.00011077740660667408, 'border_count': 33, 'grow_policy': 'Depthwise'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:48,434] Trial 63 finished with value: 0.6575888822313325 and parameters: {'iterations': 1431, 'depth': 9, 'learning_rate': 0.20931718933662327, 'random_strength': 81, 'bagging_temperature': 0.4309140407786303, 'l2_leaf_reg': 0.00026426284008430027, 'border_count': 94, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:52,726] Trial 64 finished with value: 0.7290877176162287 and parameters: {'iterations': 1369, 'depth': 9, 'learning_rate': 0.20730616664777818, 'random_strength': 82, 'bagging_temperature': 0.4451547611057427, 'l2_leaf_reg': 0.00045026173414906205, 'border_count': 97, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:14:57,471] Trial 65 finished with value: 0.6952895261816316 and parameters: {'iterations': 1455, 'depth': 10, 'learning_rate': 0.17814498774219195, 'random_strength': 88, 'bagging_temperature': 0.40596093561461616, 'l2_leaf_reg': 0.0002328628924199248, 'border_count': 111, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:15:01,909] Trial 66 finished with value: 0.6865559985045668 and parameters: {'iterations': 849, 'depth': 11, 'learning_rate': 0.20725375200297683, 'random_strength': 49, 'bagging_temperature': 0.041559724355466815, 'l2_leaf_reg': 0.0008644288640083705, 'border_count': 141, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:15:05,994] Trial 67 finished with value: 0.6671776773928865 and parameters: {'iterations': 732, 'depth': 9, 'learning_rate': 0.23707063122045435, 'random_strength': 76, 'bagging_temperature': 0.37081851233643615, 'l2_leaf_reg': 7.056008015604292e-05, 'border_count': 90, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:15:10,772] Trial 68 finished with value: 0.6891775703300588 and parameters: {'iterations': 1201, 'depth': 10, 'learning_rate': 0.22876326495894533, 'random_strength': 56, 'bagging_temperature': 0.32800906320930223, 'l2_leaf_reg': 0.005244896724390729, 'border_count': 126, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:15:14,811] Trial 69 finished with value: 0.7119820196582932 and parameters: {'iterations': 668, 'depth': 11, 'learning_rate': 0.24730122619936484, 'random_strength': 72, 'bagging_temperature': 0.2893399754216899, 'l2_leaf_reg': 0.0022341338800334395, 'border_count': 81, 'grow_policy': 'Lossguide'}. Best is trial 42 with value: 0.6429285821236985.\n",
      "[I 2023-12-07 21:15:19,422] Trial 70 finished with value: 0.6328066892412928 and parameters: {'iterations': 1037, 'depth': 9, 'learning_rate': 0.1903445793891251, 'random_strength': 67, 'bagging_temperature': 0.0031143876397643697, 'l2_leaf_reg': 0.000547250777618118, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:23,764] Trial 71 finished with value: 0.7231681978763109 and parameters: {'iterations': 1046, 'depth': 9, 'learning_rate': 0.1957647449960097, 'random_strength': 67, 'bagging_temperature': 0.012563925686701255, 'l2_leaf_reg': 0.0005656056902613227, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:28,271] Trial 72 finished with value: 0.6817302423500132 and parameters: {'iterations': 790, 'depth': 10, 'learning_rate': 0.18661623013143785, 'random_strength': 63, 'bagging_temperature': 0.0835738641607705, 'l2_leaf_reg': 0.00036290218408381234, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:32,434] Trial 73 finished with value: 0.7049947727395612 and parameters: {'iterations': 1098, 'depth': 9, 'learning_rate': 0.21731215211619523, 'random_strength': 77, 'bagging_temperature': 0.038467872675236596, 'l2_leaf_reg': 0.0010789132046045821, 'border_count': 105, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:36,963] Trial 74 finished with value: 0.7053599034632968 and parameters: {'iterations': 1496, 'depth': 8, 'learning_rate': 0.2015740537778607, 'random_strength': 87, 'bagging_temperature': 0.10888067068268853, 'l2_leaf_reg': 0.0001806636612642185, 'border_count': 98, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:41,071] Trial 75 finished with value: 0.7201497217969162 and parameters: {'iterations': 910, 'depth': 10, 'learning_rate': 0.22378188415335107, 'random_strength': 30, 'bagging_temperature': 0.4196701418976781, 'l2_leaf_reg': 0.0021295971639304313, 'border_count': 114, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:44,135] Trial 76 finished with value: 0.6586122138874777 and parameters: {'iterations': 1003, 'depth': 4, 'learning_rate': 0.18881580704386122, 'random_strength': 82, 'bagging_temperature': 0.005830934921229087, 'l2_leaf_reg': 0.00012947645055538362, 'border_count': 83, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:47,547] Trial 77 finished with value: 0.7022071590461297 and parameters: {'iterations': 964, 'depth': 7, 'learning_rate': 0.17403041909199782, 'random_strength': 81, 'bagging_temperature': 0.029841400058775704, 'l2_leaf_reg': 1.9096707154076776e-05, 'border_count': 61, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:50,608] Trial 78 finished with value: 0.6840590235185027 and parameters: {'iterations': 997, 'depth': 4, 'learning_rate': 0.18293267157531515, 'random_strength': 83, 'bagging_temperature': 0.003501978224634285, 'l2_leaf_reg': 4.7558180141271855e-05, 'border_count': 71, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:54,583] Trial 79 finished with value: 0.6774532409474343 and parameters: {'iterations': 1045, 'depth': 5, 'learning_rate': 0.1922992961548017, 'random_strength': 94, 'bagging_temperature': 0.07621083169564172, 'l2_leaf_reg': 0.00010384544172847013, 'border_count': 86, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:15:59,297] Trial 80 finished with value: 0.6798632097080232 and parameters: {'iterations': 764, 'depth': 6, 'learning_rate': 0.16849824902272806, 'random_strength': 86, 'bagging_temperature': 0.06324217811041413, 'l2_leaf_reg': 0.00021187861443490926, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:03,448] Trial 81 finished with value: 0.7376666882051031 and parameters: {'iterations': 1188, 'depth': 12, 'learning_rate': 0.21071002880481574, 'random_strength': 69, 'bagging_temperature': 0.1374040649763345, 'l2_leaf_reg': 0.000511499591849326, 'border_count': 40, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:07,957] Trial 82 finished with value: 0.708247199266406 and parameters: {'iterations': 1248, 'depth': 9, 'learning_rate': 0.20021466702155394, 'random_strength': 60, 'bagging_temperature': 0.031515234470243056, 'l2_leaf_reg': 0.001541547259892221, 'border_count': 52, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:12,068] Trial 83 finished with value: 0.7044052447887535 and parameters: {'iterations': 931, 'depth': 11, 'learning_rate': 0.21522051545759696, 'random_strength': 76, 'bagging_temperature': 0.10043422373549543, 'l2_leaf_reg': 0.005231849353906333, 'border_count': 99, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:16,594] Trial 84 finished with value: 0.6871194768669955 and parameters: {'iterations': 851, 'depth': 12, 'learning_rate': 0.17957491644575999, 'random_strength': 73, 'bagging_temperature': 0.1966229869737285, 'l2_leaf_reg': 0.0006445314595113549, 'border_count': 93, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:19,127] Trial 85 finished with value: 0.6967557475159869 and parameters: {'iterations': 1116, 'depth': 10, 'learning_rate': 0.1899519626407805, 'random_strength': 54, 'bagging_temperature': 0.004265501996457073, 'l2_leaf_reg': 0.00016060203541797279, 'border_count': 25, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:22,090] Trial 86 finished with value: 0.6697875960692883 and parameters: {'iterations': 1413, 'depth': 4, 'learning_rate': 0.2044570329499522, 'random_strength': 79, 'bagging_temperature': 0.16076838123288043, 'l2_leaf_reg': 0.0003326586019013729, 'border_count': 55, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:26,021] Trial 87 finished with value: 0.6738961776737334 and parameters: {'iterations': 809, 'depth': 6, 'learning_rate': 0.22456561090349583, 'random_strength': 23, 'bagging_temperature': 0.06070873549024827, 'l2_leaf_reg': 0.0031548780563484553, 'border_count': 121, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:29,855] Trial 88 finished with value: 0.671305300683219 and parameters: {'iterations': 1168, 'depth': 8, 'learning_rate': 0.19631400936625748, 'random_strength': 14, 'bagging_temperature': 0.030272236943147512, 'l2_leaf_reg': 7.289958613846236e-05, 'border_count': 83, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:34,394] Trial 89 finished with value: 0.7116597759511003 and parameters: {'iterations': 1265, 'depth': 11, 'learning_rate': 0.20902489199323845, 'random_strength': 90, 'bagging_temperature': 0.23319344850615822, 'l2_leaf_reg': 0.0011863007058598113, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:36,855] Trial 90 finished with value: 0.710511183413193 and parameters: {'iterations': 573, 'depth': 10, 'learning_rate': 0.23245193287110413, 'random_strength': 67, 'bagging_temperature': 0.08118347676983761, 'l2_leaf_reg': 0.0002869023260909993, 'border_count': 103, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:40,930] Trial 91 finished with value: 0.7002647410257823 and parameters: {'iterations': 741, 'depth': 9, 'learning_rate': 0.23737890449666507, 'random_strength': 77, 'bagging_temperature': 0.35866052992293734, 'l2_leaf_reg': 4.896152897079925e-05, 'border_count': 90, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:44,964] Trial 92 finished with value: 0.6987889211347024 and parameters: {'iterations': 716, 'depth': 9, 'learning_rate': 0.21542705284023914, 'random_strength': 75, 'bagging_temperature': 0.38345250693997407, 'l2_leaf_reg': 7.303967586343884e-05, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:48,909] Trial 93 finished with value: 0.7013121803367522 and parameters: {'iterations': 874, 'depth': 8, 'learning_rate': 0.23693628080084359, 'random_strength': 65, 'bagging_temperature': 0.43928154849193707, 'l2_leaf_reg': 0.0001395617957783483, 'border_count': 92, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:53,191] Trial 94 finished with value: 0.6540207368408739 and parameters: {'iterations': 969, 'depth': 9, 'learning_rate': 0.24620180376376827, 'random_strength': 70, 'bagging_temperature': 0.47998820680095833, 'l2_leaf_reg': 2.6446675883369275e-05, 'border_count': 47, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:16:56,315] Trial 95 finished with value: 0.7166167834493414 and parameters: {'iterations': 1016, 'depth': 5, 'learning_rate': 0.24638468565952468, 'random_strength': 45, 'bagging_temperature': 0.4825265172985406, 'l2_leaf_reg': 0.000770218407394102, 'border_count': 47, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:00,864] Trial 96 finished with value: 0.6588767416634821 and parameters: {'iterations': 983, 'depth': 9, 'learning_rate': 0.1874998678616211, 'random_strength': 70, 'bagging_temperature': 0.45759667962907885, 'l2_leaf_reg': 2.2895650799405625e-05, 'border_count': 37, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:05,881] Trial 97 finished with value: 0.6716015435039397 and parameters: {'iterations': 970, 'depth': 9, 'learning_rate': 0.18911886328193853, 'random_strength': 36, 'bagging_temperature': 0.5075872161393132, 'l2_leaf_reg': 2.204060887015558e-05, 'border_count': 14, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:10,684] Trial 98 finished with value: 0.6893148887786424 and parameters: {'iterations': 1060, 'depth': 8, 'learning_rate': 0.18330456752741733, 'random_strength': 58, 'bagging_temperature': 0.4710185268259347, 'l2_leaf_reg': 2.881252052175216e-05, 'border_count': 38, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:12,396] Trial 99 finished with value: 0.7037859240260149 and parameters: {'iterations': 927, 'depth': 9, 'learning_rate': 0.1752118050046041, 'random_strength': 62, 'bagging_temperature': 0.4207753655131735, 'l2_leaf_reg': 4.911389666620841e-05, 'border_count': 27, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:16,895] Trial 100 finished with value: 0.6563225408646957 and parameters: {'iterations': 834, 'depth': 12, 'learning_rate': 0.19859478825733767, 'random_strength': 69, 'bagging_temperature': 0.4442194348124355, 'l2_leaf_reg': 9.499567547155097e-06, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:21,614] Trial 101 finished with value: 0.7068888167248496 and parameters: {'iterations': 888, 'depth': 12, 'learning_rate': 0.2003126056172302, 'random_strength': 70, 'bagging_temperature': 0.44073217287599264, 'l2_leaf_reg': 8.119460220976969e-06, 'border_count': 55, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:26,465] Trial 102 finished with value: 0.687095845785455 and parameters: {'iterations': 818, 'depth': 12, 'learning_rate': 0.1596009978944769, 'random_strength': 65, 'bagging_temperature': 0.4053158950090326, 'l2_leaf_reg': 9.856622443790377e-06, 'border_count': 32, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:31,210] Trial 103 finished with value: 0.6563461923289257 and parameters: {'iterations': 778, 'depth': 12, 'learning_rate': 0.19251449301324, 'random_strength': 72, 'bagging_temperature': 0.4526890180078105, 'l2_leaf_reg': 5.262618411272629e-06, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:35,923] Trial 104 finished with value: 0.6958284171146337 and parameters: {'iterations': 780, 'depth': 12, 'learning_rate': 0.1853621848798079, 'random_strength': 73, 'bagging_temperature': 0.4580851322411465, 'l2_leaf_reg': 4.146887314852858e-06, 'border_count': 45, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:41,119] Trial 105 finished with value: 0.6411369263436507 and parameters: {'iterations': 831, 'depth': 12, 'learning_rate': 0.20623372139747964, 'random_strength': 69, 'bagging_temperature': 0.5227607177891906, 'l2_leaf_reg': 2.280734850711282e-05, 'border_count': 58, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:45,332] Trial 106 finished with value: 0.7463680978731907 and parameters: {'iterations': 679, 'depth': 12, 'learning_rate': 0.19625389746706348, 'random_strength': 68, 'bagging_temperature': 0.5191603448930323, 'l2_leaf_reg': 1.1814210714060025e-05, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:49,711] Trial 107 finished with value: 0.6793932827051533 and parameters: {'iterations': 828, 'depth': 12, 'learning_rate': 0.2052708427739355, 'random_strength': 80, 'bagging_temperature': 0.4877707379614284, 'l2_leaf_reg': 1.7730946752284776e-05, 'border_count': 47, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:54,537] Trial 108 finished with value: 0.6721729790275152 and parameters: {'iterations': 754, 'depth': 12, 'learning_rate': 0.22036062697950062, 'random_strength': 65, 'bagging_temperature': 0.5555878580136637, 'l2_leaf_reg': 3.0714631432610155e-05, 'border_count': 36, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:17:59,359] Trial 109 finished with value: 0.7318979665055391 and parameters: {'iterations': 623, 'depth': 9, 'learning_rate': 0.20936136056824844, 'random_strength': 84, 'bagging_temperature': 0.46758568900049946, 'l2_leaf_reg': 6.0752672790463425e-06, 'border_count': 57, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:03,997] Trial 110 finished with value: 0.7011503003885345 and parameters: {'iterations': 702, 'depth': 12, 'learning_rate': 0.1776006193276132, 'random_strength': 71, 'bagging_temperature': 0.4318265007313125, 'l2_leaf_reg': 3.3113698955483225e-06, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:08,672] Trial 111 finished with value: 0.697166634245235 and parameters: {'iterations': 907, 'depth': 12, 'learning_rate': 0.2013857294316599, 'random_strength': 74, 'bagging_temperature': 0.49265169002579884, 'l2_leaf_reg': 1.3372780838743976e-05, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:13,904] Trial 112 finished with value: 0.6554028796124636 and parameters: {'iterations': 848, 'depth': 12, 'learning_rate': 0.19317545212772938, 'random_strength': 69, 'bagging_temperature': 0.4561968905235492, 'l2_leaf_reg': 2.295015947988119e-05, 'border_count': 51, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:19,244] Trial 113 finished with value: 0.70966839712713 and parameters: {'iterations': 845, 'depth': 12, 'learning_rate': 0.18655230577512424, 'random_strength': 66, 'bagging_temperature': 0.4689551892805015, 'l2_leaf_reg': 1.953260973375322e-05, 'border_count': 42, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:23,809] Trial 114 finished with value: 0.7093922415676404 and parameters: {'iterations': 783, 'depth': 11, 'learning_rate': 0.19303008135625144, 'random_strength': 63, 'bagging_temperature': 0.5201347491091771, 'l2_leaf_reg': 3.753215166130027e-05, 'border_count': 49, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:29,375] Trial 115 finished with value: 0.7022330977413882 and parameters: {'iterations': 947, 'depth': 12, 'learning_rate': 0.17272769952388273, 'random_strength': 69, 'bagging_temperature': 0.3945067321230179, 'l2_leaf_reg': 8.125832690225761e-06, 'border_count': 21, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:32,333] Trial 116 finished with value: 0.6770484921409436 and parameters: {'iterations': 872, 'depth': 11, 'learning_rate': 0.19722476268669686, 'random_strength': 72, 'bagging_temperature': 0.44729574526367, 'l2_leaf_reg': 2.1714311651725652e-05, 'border_count': 74, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:37,838] Trial 117 finished with value: 0.6739690873594401 and parameters: {'iterations': 988, 'depth': 12, 'learning_rate': 0.18235894800542893, 'random_strength': 58, 'bagging_temperature': 0.4163855778823816, 'l2_leaf_reg': 9.310841928076212e-05, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:42,113] Trial 118 finished with value: 0.6913320382392659 and parameters: {'iterations': 656, 'depth': 9, 'learning_rate': 0.20418356532623605, 'random_strength': 60, 'bagging_temperature': 0.5437946199026162, 'l2_leaf_reg': 1.1564412858726076e-05, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:47,600] Trial 119 finished with value: 0.6968485091733995 and parameters: {'iterations': 798, 'depth': 12, 'learning_rate': 0.2120410213086716, 'random_strength': 69, 'bagging_temperature': 0.38032251180460247, 'l2_leaf_reg': 5.5755637599104635e-05, 'border_count': 30, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:52,031] Trial 120 finished with value: 0.704157969178724 and parameters: {'iterations': 837, 'depth': 8, 'learning_rate': 0.19033712398516117, 'random_strength': 42, 'bagging_temperature': 0.4596720590714827, 'l2_leaf_reg': 2.1890401408156305e-06, 'border_count': 43, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:18:56,730] Trial 121 finished with value: 0.6776126622425365 and parameters: {'iterations': 957, 'depth': 12, 'learning_rate': 0.2269622090870323, 'random_strength': 75, 'bagging_temperature': 0.49490608209608294, 'l2_leaf_reg': 6.098106616415171e-06, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:00,904] Trial 122 finished with value: 0.6815206528150233 and parameters: {'iterations': 901, 'depth': 11, 'learning_rate': 0.21988628502489546, 'random_strength': 71, 'bagging_temperature': 0.025112677284639152, 'l2_leaf_reg': 0.00013785171140299308, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:05,346] Trial 123 finished with value: 0.723517678972888 and parameters: {'iterations': 866, 'depth': 12, 'learning_rate': 0.19914186061942066, 'random_strength': 78, 'bagging_temperature': 0.34013309882912135, 'l2_leaf_reg': 2.6737964358168646e-05, 'border_count': 71, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:09,942] Trial 124 finished with value: 0.7152743314543769 and parameters: {'iterations': 1037, 'depth': 12, 'learning_rate': 0.17895010570408146, 'random_strength': 54, 'bagging_temperature': 0.4273555093501039, 'l2_leaf_reg': 1.4635970160524983e-05, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:14,939] Trial 125 finished with value: 0.6645617525209646 and parameters: {'iterations': 728, 'depth': 5, 'learning_rate': 0.2088304041633399, 'random_strength': 81, 'bagging_temperature': 0.050140131148932544, 'l2_leaf_reg': 4.393989377535337e-05, 'border_count': 36, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:18,346] Trial 126 finished with value: 0.6745748448201097 and parameters: {'iterations': 929, 'depth': 12, 'learning_rate': 0.19381756511945275, 'random_strength': 68, 'bagging_temperature': 0.47799171614237235, 'l2_leaf_reg': 8.603600295544669e-05, 'border_count': 51, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:23,367] Trial 127 finished with value: 0.6586345707695638 and parameters: {'iterations': 762, 'depth': 9, 'learning_rate': 0.16675446245591793, 'random_strength': 62, 'bagging_temperature': 0.4014363771641243, 'l2_leaf_reg': 0.00021905666527963956, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:28,503] Trial 128 finished with value: 0.6731736375661069 and parameters: {'iterations': 761, 'depth': 9, 'learning_rate': 0.1860754251501605, 'random_strength': 62, 'bagging_temperature': 0.37946437392556903, 'l2_leaf_reg': 0.00021813940806914868, 'border_count': 86, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:35,593] Trial 129 finished with value: 0.6391257085213932 and parameters: {'iterations': 798, 'depth': 9, 'learning_rate': 0.16468236282255666, 'random_strength': 65, 'bagging_temperature': 0.3972882154413314, 'l2_leaf_reg': 6.292030345568591e-05, 'border_count': 78, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:43,226] Trial 130 finished with value: 0.6903796455065858 and parameters: {'iterations': 812, 'depth': 9, 'learning_rate': 0.16512622548295136, 'random_strength': 51, 'bagging_temperature': 0.35248235295907393, 'l2_leaf_reg': 0.00013675093798182653, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:48,629] Trial 131 finished with value: 0.6730063287415848 and parameters: {'iterations': 689, 'depth': 9, 'learning_rate': 0.17231070849844546, 'random_strength': 64, 'bagging_temperature': 0.40732357575959965, 'l2_leaf_reg': 7.066270019330082e-05, 'border_count': 72, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:53,764] Trial 132 finished with value: 0.687497939565824 and parameters: {'iterations': 789, 'depth': 9, 'learning_rate': 0.16473567368265932, 'random_strength': 66, 'bagging_temperature': 0.4265773550123885, 'l2_leaf_reg': 2.6050807234619535e-05, 'border_count': 83, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:19:58,596] Trial 133 finished with value: 0.6708796571047123 and parameters: {'iterations': 747, 'depth': 10, 'learning_rate': 0.1803147823959632, 'random_strength': 56, 'bagging_temperature': 0.4449851939059183, 'l2_leaf_reg': 5.8838354590654326e-05, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:04,702] Trial 134 finished with value: 0.6449483851711347 and parameters: {'iterations': 711, 'depth': 9, 'learning_rate': 0.188415493969214, 'random_strength': 60, 'bagging_temperature': 0.4002262840784542, 'l2_leaf_reg': 0.0002675036844463686, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:10,329] Trial 135 finished with value: 0.6776320375073963 and parameters: {'iterations': 713, 'depth': 8, 'learning_rate': 0.15190858135500998, 'random_strength': 60, 'bagging_temperature': 0.3705946508985615, 'l2_leaf_reg': 0.00017509153205660943, 'border_count': 63, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:16,195] Trial 136 finished with value: 0.6772869654325011 and parameters: {'iterations': 838, 'depth': 9, 'learning_rate': 0.1700470814343847, 'random_strength': 63, 'bagging_temperature': 0.33037334610677904, 'l2_leaf_reg': 0.00026189371087928054, 'border_count': 67, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:21,271] Trial 137 finished with value: 0.7046000402693322 and parameters: {'iterations': 774, 'depth': 10, 'learning_rate': 0.15779046853668216, 'random_strength': 58, 'bagging_temperature': 0.39795940721188733, 'l2_leaf_reg': 0.000482833797720828, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:25,986] Trial 138 finished with value: 0.704571208437194 and parameters: {'iterations': 730, 'depth': 9, 'learning_rate': 0.20377123813968165, 'random_strength': 61, 'bagging_temperature': 0.39956626466353046, 'l2_leaf_reg': 0.00010183091066019536, 'border_count': 53, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:30,857] Trial 139 finished with value: 0.6748921235542146 and parameters: {'iterations': 814, 'depth': 9, 'learning_rate': 0.19429374851116996, 'random_strength': 67, 'bagging_temperature': 0.3694459508982038, 'l2_leaf_reg': 3.8038393754861755e-05, 'border_count': 46, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:32,230] Trial 140 finished with value: 0.6916517071729266 and parameters: {'iterations': 655, 'depth': 7, 'learning_rate': 0.17979498653665388, 'random_strength': 64, 'bagging_temperature': 0.5131876208271139, 'l2_leaf_reg': 0.0002775968049348165, 'border_count': 89, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:37,218] Trial 141 finished with value: 0.6865260825530538 and parameters: {'iterations': 585, 'depth': 9, 'learning_rate': 0.18509393266863478, 'random_strength': 70, 'bagging_temperature': 0.44651580736728114, 'l2_leaf_reg': 9.20702506032692e-06, 'border_count': 61, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:41,842] Trial 142 finished with value: 0.6602908082519926 and parameters: {'iterations': 868, 'depth': 9, 'learning_rate': 0.18921080051779993, 'random_strength': 72, 'bagging_temperature': 0.465685411329112, 'l2_leaf_reg': 1.771721346056257e-05, 'border_count': 39, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:46,780] Trial 143 finished with value: 0.7092297122796993 and parameters: {'iterations': 996, 'depth': 9, 'learning_rate': 0.1727666233731064, 'random_strength': 66, 'bagging_temperature': 0.4227530336733816, 'l2_leaf_reg': 3.6955459340804726e-05, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:51,447] Trial 144 finished with value: 0.7010477899706019 and parameters: {'iterations': 693, 'depth': 10, 'learning_rate': 0.19915479681320386, 'random_strength': 49, 'bagging_temperature': 0.31861718827171215, 'l2_leaf_reg': 0.00011781631464763578, 'border_count': 95, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:20:56,071] Trial 145 finished with value: 0.6812758667181066 and parameters: {'iterations': 764, 'depth': 8, 'learning_rate': 0.19050407748525897, 'random_strength': 68, 'bagging_temperature': 0.3068891593556959, 'l2_leaf_reg': 6.614163784342335e-05, 'border_count': 70, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:00,567] Trial 146 finished with value: 0.6874377053902234 and parameters: {'iterations': 823, 'depth': 9, 'learning_rate': 0.2136687664095151, 'random_strength': 75, 'bagging_temperature': 0.5640281999629713, 'l2_leaf_reg': 2.605694409040771e-05, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:04,991] Trial 147 finished with value: 0.6686436660494312 and parameters: {'iterations': 1351, 'depth': 10, 'learning_rate': 0.20717513230736295, 'random_strength': 53, 'bagging_temperature': 0.48922335173415565, 'l2_leaf_reg': 0.00037253519722242964, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:10,556] Trial 148 finished with value: 0.6651349244063366 and parameters: {'iterations': 895, 'depth': 9, 'learning_rate': 0.17829395418039823, 'random_strength': 73, 'bagging_temperature': 0.5331171285866586, 'l2_leaf_reg': 1.4881754031794008e-05, 'border_count': 43, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:15,549] Trial 149 finished with value: 0.7066898225771411 and parameters: {'iterations': 1083, 'depth': 9, 'learning_rate': 0.16442550792542043, 'random_strength': 70, 'bagging_temperature': 0.4530016508087977, 'l2_leaf_reg': 0.00017441193171558394, 'border_count': 31, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:20,263] Trial 150 finished with value: 0.6928193062849942 and parameters: {'iterations': 794, 'depth': 9, 'learning_rate': 0.1985031878153053, 'random_strength': 62, 'bagging_temperature': 0.40983836224954756, 'l2_leaf_reg': 0.0006398419203410233, 'border_count': 84, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:24,388] Trial 151 finished with value: 0.7136885130678916 and parameters: {'iterations': 956, 'depth': 12, 'learning_rate': 0.25703208627276475, 'random_strength': 65, 'bagging_temperature': 0.010051709423456416, 'l2_leaf_reg': 7.074594533225669e-06, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:31,302] Trial 152 finished with value: 0.6887681956498788 and parameters: {'iterations': 855, 'depth': 12, 'learning_rate': 0.14701378312144467, 'random_strength': 76, 'bagging_temperature': 0.04452474000017585, 'l2_leaf_reg': 0.001629021881145095, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:36,411] Trial 153 finished with value: 0.6789692186000575 and parameters: {'iterations': 918, 'depth': 12, 'learning_rate': 0.1843819037096207, 'random_strength': 68, 'bagging_temperature': 0.02292851881665777, 'l2_leaf_reg': 0.0004502528513985872, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:40,854] Trial 154 finished with value: 0.7001977623259505 and parameters: {'iterations': 988, 'depth': 11, 'learning_rate': 0.21844022982747638, 'random_strength': 71, 'bagging_temperature': 0.4984302343606, 'l2_leaf_reg': 9.124131581624176e-05, 'border_count': 51, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:45,394] Trial 155 finished with value: 0.6994980744420407 and parameters: {'iterations': 881, 'depth': 12, 'learning_rate': 0.1945268269871809, 'random_strength': 73, 'bagging_temperature': 0.43425661101213253, 'l2_leaf_reg': 0.0008271552862401162, 'border_count': 58, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:48,914] Trial 156 finished with value: 0.6905488059225517 and parameters: {'iterations': 742, 'depth': 12, 'learning_rate': 0.20406363512739156, 'random_strength': 79, 'bagging_temperature': 0.0050780515590688755, 'l2_leaf_reg': 4.808022476878345e-05, 'border_count': 103, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:53,842] Trial 157 finished with value: 0.6655046445846212 and parameters: {'iterations': 851, 'depth': 8, 'learning_rate': 0.2425326672029455, 'random_strength': 69, 'bagging_temperature': 0.2545420721915177, 'l2_leaf_reg': 4.723304718298475e-06, 'border_count': 47, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:21:59,518] Trial 158 finished with value: 0.6906675701359171 and parameters: {'iterations': 1022, 'depth': 11, 'learning_rate': 0.2263401349658726, 'random_strength': 59, 'bagging_temperature': 0.3533403215533548, 'l2_leaf_reg': 0.0002575690620061151, 'border_count': 72, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:15,285] Trial 159 finished with value: 0.7100344518929592 and parameters: {'iterations': 798, 'depth': 12, 'learning_rate': 0.1889732158193, 'random_strength': 46, 'bagging_temperature': 0.47422347100465084, 'l2_leaf_reg': 0.007841186435745719, 'border_count': 252, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:19,614] Trial 160 finished with value: 0.688549573607523 and parameters: {'iterations': 916, 'depth': 9, 'learning_rate': 0.2115971195409806, 'random_strength': 84, 'bagging_temperature': 0.39134567630879213, 'l2_leaf_reg': 0.00014396449224050013, 'border_count': 41, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:24,253] Trial 161 finished with value: 0.6837227826349076 and parameters: {'iterations': 977, 'depth': 11, 'learning_rate': 0.1941024339767704, 'random_strength': 29, 'bagging_temperature': 0.08420947538849109, 'l2_leaf_reg': 0.0004925266164199231, 'border_count': 163, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:28,875] Trial 162 finished with value: 0.6908210552377728 and parameters: {'iterations': 1073, 'depth': 12, 'learning_rate': 0.17487449496314397, 'random_strength': 19, 'bagging_temperature': 0.0559385521858768, 'l2_leaf_reg': 0.0002978242310924872, 'border_count': 148, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:34,105] Trial 163 finished with value: 0.6955718839923998 and parameters: {'iterations': 1020, 'depth': 10, 'learning_rate': 0.2026666716347761, 'random_strength': 66, 'bagging_temperature': 0.41950225247162576, 'l2_leaf_reg': 0.002564416140113847, 'border_count': 196, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:38,831] Trial 164 finished with value: 0.7027103524615411 and parameters: {'iterations': 830, 'depth': 11, 'learning_rate': 0.18618589647011738, 'random_strength': 25, 'bagging_temperature': 0.12722039000704205, 'l2_leaf_reg': 0.0002120337490704844, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:43,536] Trial 165 finished with value: 0.6873960169286383 and parameters: {'iterations': 765, 'depth': 12, 'learning_rate': 0.19249641239974025, 'random_strength': 33, 'bagging_temperature': 0.2766133348510068, 'l2_leaf_reg': 0.0010348248075464459, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:47,579] Trial 166 finished with value: 0.709580006365795 and parameters: {'iterations': 947, 'depth': 9, 'learning_rate': 0.23120087741326142, 'random_strength': 14, 'bagging_temperature': 0.19802819057723092, 'l2_leaf_reg': 2.6273647952039978e-05, 'border_count': 230, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:52,276] Trial 167 finished with value: 0.7069862470492698 and parameters: {'iterations': 1051, 'depth': 12, 'learning_rate': 0.19822296623553298, 'random_strength': 64, 'bagging_temperature': 0.4575255393231667, 'l2_leaf_reg': 0.04283634908743166, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:22:57,076] Trial 168 finished with value: 0.6626311335269018 and parameters: {'iterations': 718, 'depth': 9, 'learning_rate': 0.18014351244789178, 'random_strength': 56, 'bagging_temperature': 0.022680397079955072, 'l2_leaf_reg': 1.3266883692757465e-05, 'border_count': 172, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:00,589] Trial 169 finished with value: 0.6737345029697351 and parameters: {'iterations': 888, 'depth': 12, 'learning_rate': 0.2079480182060438, 'random_strength': 90, 'bagging_temperature': 0.10155429612091736, 'l2_leaf_reg': 8.266260520317195e-05, 'border_count': 61, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:04,766] Trial 170 finished with value: 0.7098161470883343 and parameters: {'iterations': 787, 'depth': 11, 'learning_rate': 0.25136190100423805, 'random_strength': 39, 'bagging_temperature': 0.06554297727541512, 'l2_leaf_reg': 0.0003441569899573672, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:10,267] Trial 171 finished with value: 0.6720094465154157 and parameters: {'iterations': 848, 'depth': 9, 'learning_rate': 0.18750710333919698, 'random_strength': 71, 'bagging_temperature': 0.4691538345923212, 'l2_leaf_reg': 1.5596763555607865e-05, 'border_count': 39, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:15,464] Trial 172 finished with value: 0.6631689632023 and parameters: {'iterations': 875, 'depth': 9, 'learning_rate': 0.19052752221443198, 'random_strength': 72, 'bagging_temperature': 0.4415284657046844, 'l2_leaf_reg': 1.9109629553962953e-05, 'border_count': 35, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:20,521] Trial 173 finished with value: 0.6708432653932431 and parameters: {'iterations': 817, 'depth': 9, 'learning_rate': 0.16880309093310347, 'random_strength': 68, 'bagging_temperature': 0.5035578966939855, 'l2_leaf_reg': 9.91877155209835e-06, 'border_count': 24, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:25,064] Trial 174 finished with value: 0.6847221228827478 and parameters: {'iterations': 934, 'depth': 9, 'learning_rate': 0.19945058671291463, 'random_strength': 74, 'bagging_temperature': 0.3857567283239466, 'l2_leaf_reg': 3.504763678374607e-05, 'border_count': 46, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:30,134] Trial 175 finished with value: 0.6821923431015261 and parameters: {'iterations': 869, 'depth': 10, 'learning_rate': 0.18362465212458223, 'random_strength': 70, 'bagging_temperature': 0.00014649430780942253, 'l2_leaf_reg': 3.028904629056248e-06, 'border_count': 39, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:33,491] Trial 176 finished with value: 0.662721726817623 and parameters: {'iterations': 1277, 'depth': 4, 'learning_rate': 0.19228000903632894, 'random_strength': 43, 'bagging_temperature': 0.4781040356880182, 'l2_leaf_reg': 5.1127981994043434e-05, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:38,362] Trial 177 finished with value: 0.6943928160240895 and parameters: {'iterations': 221, 'depth': 9, 'learning_rate': 0.17397852149705248, 'random_strength': 67, 'bagging_temperature': 0.4097988018872383, 'l2_leaf_reg': 2.0507803014459247e-05, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:45,010] Trial 178 finished with value: 0.6872569528790452 and parameters: {'iterations': 743, 'depth': 12, 'learning_rate': 0.16091006027402918, 'random_strength': 76, 'bagging_temperature': 0.4571347344669975, 'l2_leaf_reg': 0.0008499885767596845, 'border_count': 51, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:49,821] Trial 179 finished with value: 0.673068459682914 and parameters: {'iterations': 903, 'depth': 10, 'learning_rate': 0.20379964712501053, 'random_strength': 62, 'bagging_temperature': 0.5248287285727629, 'l2_leaf_reg': 0.00013754703895742788, 'border_count': 140, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:54,261] Trial 180 finished with value: 0.7092350754773313 and parameters: {'iterations': 999, 'depth': 9, 'learning_rate': 0.2185087377644882, 'random_strength': 73, 'bagging_temperature': 0.4264107001540579, 'l2_leaf_reg': 9.340003142298594e-06, 'border_count': 89, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:23:59,051] Trial 181 finished with value: 0.7005771078830616 and parameters: {'iterations': 1096, 'depth': 10, 'learning_rate': 0.2131986084852127, 'random_strength': 71, 'bagging_temperature': 0.2866282442986273, 'l2_leaf_reg': 0.0018647724317380602, 'border_count': 99, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:03,570] Trial 182 finished with value: 0.7019787949301435 and parameters: {'iterations': 1156, 'depth': 8, 'learning_rate': 0.19627008584824132, 'random_strength': 65, 'bagging_temperature': 0.03801720161929594, 'l2_leaf_reg': 0.0005696540064763784, 'border_count': 125, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:08,892] Trial 183 finished with value: 0.6889531234347204 and parameters: {'iterations': 1034, 'depth': 9, 'learning_rate': 0.18888438884709122, 'random_strength': 78, 'bagging_temperature': 0.21619524697886605, 'l2_leaf_reg': 0.0014662230415909776, 'border_count': 113, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:15,563] Trial 184 finished with value: 0.6761204487466262 and parameters: {'iterations': 1141, 'depth': 10, 'learning_rate': 0.20841661366920236, 'random_strength': 69, 'bagging_temperature': 0.25063685986385875, 'l2_leaf_reg': 0.0029290675988949736, 'border_count': 108, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:21,125] Trial 185 finished with value: 0.7133667894604867 and parameters: {'iterations': 1114, 'depth': 9, 'learning_rate': 0.224825582346372, 'random_strength': 82, 'bagging_temperature': 0.22868118042023425, 'l2_leaf_reg': 6.034577474018229e-06, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:25,981] Trial 186 finished with value: 0.6633375572491848 and parameters: {'iterations': 777, 'depth': 12, 'learning_rate': 0.23427376564167415, 'random_strength': 72, 'bagging_temperature': 0.14400716630631516, 'l2_leaf_reg': 0.00042304772724521844, 'border_count': 95, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:28,705] Trial 187 finished with value: 0.6732157812501754 and parameters: {'iterations': 968, 'depth': 11, 'learning_rate': 0.24300790252215962, 'random_strength': 66, 'bagging_temperature': 0.17124369212542334, 'l2_leaf_reg': 0.0012130800963817082, 'border_count': 43, 'grow_policy': 'SymmetricTree'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:35,465] Trial 188 finished with value: 0.6812192001184603 and parameters: {'iterations': 675, 'depth': 9, 'learning_rate': 0.17988913479898672, 'random_strength': 74, 'bagging_temperature': 0.3632969460959822, 'l2_leaf_reg': 0.00022944815389014365, 'border_count': 34, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:40,270] Trial 189 finished with value: 0.6627674305762248 and parameters: {'iterations': 1426, 'depth': 10, 'learning_rate': 0.2144582301062219, 'random_strength': 96, 'bagging_temperature': 0.33942956038889577, 'l2_leaf_reg': 3.65755993046359e-05, 'border_count': 185, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:53,221] Trial 190 finished with value: 0.7226443299484647 and parameters: {'iterations': 829, 'depth': 12, 'learning_rate': 0.20176552939331455, 'random_strength': 68, 'bagging_temperature': 0.12375209176794771, 'l2_leaf_reg': 0.003763541774409078, 'border_count': 109, 'grow_policy': 'Depthwise'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:24:58,771] Trial 191 finished with value: 0.6751410158841856 and parameters: {'iterations': 697, 'depth': 9, 'learning_rate': 0.178986297056689, 'random_strength': 56, 'bagging_temperature': 0.022197977939871043, 'l2_leaf_reg': 1.9633036227454545e-05, 'border_count': 154, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:03,531] Trial 192 finished with value: 0.7012661396005181 and parameters: {'iterations': 719, 'depth': 9, 'learning_rate': 0.18158010461090038, 'random_strength': 55, 'bagging_temperature': 0.03530701699161181, 'l2_leaf_reg': 1.490313927119281e-05, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:08,292] Trial 193 finished with value: 0.6998738388942572 and parameters: {'iterations': 714, 'depth': 9, 'learning_rate': 0.1877896447919286, 'random_strength': 57, 'bagging_temperature': 0.204148502200141, 'l2_leaf_reg': 1.2912161731827054e-05, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:13,223] Trial 194 finished with value: 0.7214140551374347 and parameters: {'iterations': 800, 'depth': 9, 'learning_rate': 0.2625890190307942, 'random_strength': 51, 'bagging_temperature': 0.161904795110732, 'l2_leaf_reg': 6.862284486643614e-05, 'border_count': 86, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:17,192] Trial 195 finished with value: 0.7351397317002525 and parameters: {'iterations': 759, 'depth': 9, 'learning_rate': 0.27035385777387544, 'random_strength': 60, 'bagging_temperature': 0.0758083114765585, 'l2_leaf_reg': 2.7423489580259828e-05, 'border_count': 48, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:23,369] Trial 196 finished with value: 0.6961871706987004 and parameters: {'iterations': 857, 'depth': 12, 'learning_rate': 0.19558879459133863, 'random_strength': 48, 'bagging_temperature': 0.0017009993912970867, 'l2_leaf_reg': 0.0006688577756978477, 'border_count': 178, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:28,156] Trial 197 finished with value: 0.6887630784837319 and parameters: {'iterations': 641, 'depth': 9, 'learning_rate': 0.17123500140018902, 'random_strength': 61, 'bagging_temperature': 0.31136245569881216, 'l2_leaf_reg': 0.00010790420188859249, 'border_count': 167, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:33,916] Trial 198 finished with value: 0.6567328946893265 and parameters: {'iterations': 738, 'depth': 8, 'learning_rate': 0.18431185373075262, 'random_strength': 70, 'bagging_temperature': 0.3958915839937275, 'l2_leaf_reg': 0.01715943327017714, 'border_count': 29, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n",
      "[I 2023-12-07 21:25:38,578] Trial 199 finished with value: 0.6918041608393557 and parameters: {'iterations': 1062, 'depth': 6, 'learning_rate': 0.19191189022077548, 'random_strength': 71, 'bagging_temperature': 0.3845775823269435, 'l2_leaf_reg': 0.007013692391566551, 'border_count': 28, 'grow_policy': 'Lossguide'}. Best is trial 70 with value: 0.6328066892412928.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'iterations': 1037, 'depth': 9, 'learning_rate': 0.1903445793891251, 'random_strength': 67, 'bagging_temperature': 0.0031143876397643697, 'l2_leaf_reg': 0.000547250777618118, 'border_count': 65, 'grow_policy': 'Lossguide'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1500),\n",
    "        'depth': trial.suggest_int('depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def optimize(X_train, y_train, X_test, y_test, n_trials=200):\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=n_trials)\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "# Load your datasets and run optimization\n",
    "best_params_w = optimize(X_train_w, y_train_w, X_test_w, y_test_w)\n",
    "print(\"Best parameters for working days:\", best_params_w)\n",
    "\n",
    "best_params_nw = optimize(X_train_nw, y_train_nw, X_test_nw, y_test_nw)\n",
    "print(\"Best parameters for non-working days:\", best_params_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6274522411975406\n",
      "RMSE for non-working days: 0.681707564937524\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from Optuna study\n",
    "params_w = {'iterations': 327,\n",
    "            'depth': 5,\n",
    "            'learning_rate': 0.22959914137522078,\n",
    "            'random_strength': 0,\n",
    "            'bagging_temperature': 0.9998170501649718,\n",
    "            'l2_leaf_reg': 1.6823816623838656e-07,\n",
    "            'border_count': 249,\n",
    "            'grow_policy': 'SymmetricTree'}\n",
    "\n",
    "params_nw = {'iterations': 1037,\n",
    "             'depth': 9,\n",
    "             'learning_rate': 0.1903445793891251,\n",
    "             'random_strength': 67,\n",
    "             'bagging_temperature': 0.0031143876397643697,\n",
    "             'l2_leaf_reg': 0.000547250777618118,\n",
    "             'border_count': 65,\n",
    "             'grow_policy': 'Lossguide'}\n",
    "\n",
    "# Create and train the model for working days\n",
    "model_w = cb.CatBoostRegressor(**params_w)\n",
    "model_w.fit(X_train_w, y_train_w, eval_set=[(X_test_w, y_test_w)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for working days\n",
    "predictions_w = model_w.predict(X_test_w)\n",
    "rmse_w = mean_squared_error(y_test_w, predictions_w, squared=False)\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "\n",
    "# Create and train the model for non-working days\n",
    "model_nw = cb.CatBoostRegressor(**params_nw)\n",
    "model_nw.fit(X_train_nw, y_train_nw, eval_set=[(X_test_nw, y_test_nw)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for non-working days\n",
    "predictions_nw = model_nw.predict(X_test_nw)\n",
    "rmse_nw = mean_squared_error(y_test_nw, predictions_nw, squared=False)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our third CatBoost tuning study with Optuna, we'll refine our approach based on insights from previous iterations:\n",
    "\n",
    "- Iterations: We'll focus on a narrower range around the best-performing values\n",
    "- Depth: Aiming for a middle range to balance model complexity and generalization\n",
    "- Learning Rate: Concentrating on a tighter range around higher values\n",
    "- Random Strength: Including both moderate and extreme values based on prior findings\n",
    "- Bagging Temperature: Exploring a broader range, given the varied optimal values\n",
    "- L2 Leaf Regularization: Focusing more on smaller values, aligning with recent trends\n",
    "- Border Count: Expanding the range to capture higher values suggested by the second study\n",
    "- Grow Policy: Keeping 'SymmetricTree' and 'Lossguide' options based on their previous effectiveness\n",
    "\n",
    "This strategy is designed to enhance prediction accuracy and improve RMSE scores for different types of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 21:45:46,104] A new study created in memory with name: no-name-7237ce25-11e3-48a2-b754-fe513f658b0d\n",
      "[I 2023-12-07 21:45:54,857] Trial 0 finished with value: 0.661701797904094 and parameters: {'iterations': 503, 'depth': 9, 'learning_rate': 0.23532489967153777, 'random_strength': 24, 'bagging_temperature': 0.4278621596216796, 'l2_leaf_reg': 3.161019546196481e-05, 'border_count': 162, 'grow_policy': 'Lossguide'}. Best is trial 0 with value: 0.661701797904094.\n",
      "[I 2023-12-07 21:46:08,668] Trial 1 finished with value: 0.6786828625745213 and parameters: {'iterations': 568, 'depth': 10, 'learning_rate': 0.11404278526682399, 'random_strength': 43, 'bagging_temperature': 0.5906964823671997, 'l2_leaf_reg': 2.9682687684057663e-05, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 0 with value: 0.661701797904094.\n",
      "[I 2023-12-07 21:46:12,924] Trial 2 finished with value: 0.6492238619353742 and parameters: {'iterations': 928, 'depth': 8, 'learning_rate': 0.132033731303642, 'random_strength': 39, 'bagging_temperature': 0.14820446444562152, 'l2_leaf_reg': 5.415126756147001e-05, 'border_count': 247, 'grow_policy': 'SymmetricTree'}. Best is trial 2 with value: 0.6492238619353742.\n",
      "[I 2023-12-07 21:46:21,644] Trial 3 finished with value: 0.6555054479489886 and parameters: {'iterations': 797, 'depth': 9, 'learning_rate': 0.24681455491102272, 'random_strength': 38, 'bagging_temperature': 0.47263945282661024, 'l2_leaf_reg': 1.3099108320716633e-06, 'border_count': 185, 'grow_policy': 'Lossguide'}. Best is trial 2 with value: 0.6492238619353742.\n",
      "[I 2023-12-07 21:46:24,431] Trial 4 finished with value: 0.6697984320737752 and parameters: {'iterations': 539, 'depth': 5, 'learning_rate': 0.10954673936770207, 'random_strength': 4, 'bagging_temperature': 0.6064982981050588, 'l2_leaf_reg': 7.098162328372016e-05, 'border_count': 147, 'grow_policy': 'SymmetricTree'}. Best is trial 2 with value: 0.6492238619353742.\n",
      "[I 2023-12-07 21:46:34,606] Trial 5 finished with value: 0.6710491347012615 and parameters: {'iterations': 1144, 'depth': 8, 'learning_rate': 0.19986244402677866, 'random_strength': 44, 'bagging_temperature': 0.28397002604096255, 'l2_leaf_reg': 9.646389070432128e-05, 'border_count': 234, 'grow_policy': 'Lossguide'}. Best is trial 2 with value: 0.6492238619353742.\n",
      "[I 2023-12-07 21:46:42,957] Trial 6 finished with value: 0.6477134105993292 and parameters: {'iterations': 534, 'depth': 4, 'learning_rate': 0.10082078878397863, 'random_strength': 17, 'bagging_temperature': 0.32046815221329317, 'l2_leaf_reg': 8.309264073732298e-05, 'border_count': 84, 'grow_policy': 'Lossguide'}. Best is trial 6 with value: 0.6477134105993292.\n",
      "[I 2023-12-07 21:46:47,985] Trial 7 finished with value: 0.6691656307012057 and parameters: {'iterations': 738, 'depth': 7, 'learning_rate': 0.14542002017146155, 'random_strength': 3, 'bagging_temperature': 0.9175164919438199, 'l2_leaf_reg': 8.193004762793729e-05, 'border_count': 245, 'grow_policy': 'SymmetricTree'}. Best is trial 6 with value: 0.6477134105993292.\n",
      "[I 2023-12-07 21:46:58,517] Trial 8 finished with value: 0.6099831940749727 and parameters: {'iterations': 861, 'depth': 10, 'learning_rate': 0.20033669406535876, 'random_strength': 3, 'bagging_temperature': 0.0738359051350348, 'l2_leaf_reg': 1.326216547673465e-05, 'border_count': 81, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:01,398] Trial 9 finished with value: 0.6250664724899055 and parameters: {'iterations': 317, 'depth': 7, 'learning_rate': 0.2273334236866943, 'random_strength': 31, 'bagging_temperature': 0.6063936182470726, 'l2_leaf_reg': 8.494025758832078e-07, 'border_count': 120, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:14,212] Trial 10 finished with value: 0.6494063589840182 and parameters: {'iterations': 1195, 'depth': 10, 'learning_rate': 0.17715621237837853, 'random_strength': 15, 'bagging_temperature': 0.07008230848362948, 'l2_leaf_reg': 1.370703176489675e-07, 'border_count': 52, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:16,628] Trial 11 finished with value: 0.6682547833212256 and parameters: {'iterations': 302, 'depth': 6, 'learning_rate': 0.2084867059679687, 'random_strength': 31, 'bagging_temperature': 0.02077063559535408, 'l2_leaf_reg': 6.151247982626091e-06, 'border_count': 100, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:19,264] Trial 12 finished with value: 0.6171264850262811 and parameters: {'iterations': 971, 'depth': 7, 'learning_rate': 0.21828352568167247, 'random_strength': 24, 'bagging_temperature': 0.7615626369255386, 'l2_leaf_reg': 2.982207844928417e-06, 'border_count': 104, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:22,520] Trial 13 finished with value: 0.6430483850606571 and parameters: {'iterations': 982, 'depth': 6, 'learning_rate': 0.2017846457611603, 'random_strength': 12, 'bagging_temperature': 0.8039591247981273, 'l2_leaf_reg': 9.28643503737292e-06, 'border_count': 63, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:34,527] Trial 14 finished with value: 0.6282738897964738 and parameters: {'iterations': 997, 'depth': 8, 'learning_rate': 0.18015522452989505, 'random_strength': 9, 'bagging_temperature': 0.7193562619299707, 'l2_leaf_reg': 8.705918244414945e-06, 'border_count': 95, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:38,605] Trial 15 finished with value: 0.6624315005872374 and parameters: {'iterations': 772, 'depth': 6, 'learning_rate': 0.22032539786095504, 'random_strength': 50, 'bagging_temperature': 0.1742015345035508, 'l2_leaf_reg': 2.9544447382031637e-06, 'border_count': 117, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:41,350] Trial 16 finished with value: 0.6734462238485106 and parameters: {'iterations': 884, 'depth': 9, 'learning_rate': 0.2484872715866932, 'random_strength': 24, 'bagging_temperature': 0.9831271320394467, 'l2_leaf_reg': 1.7260266458990015e-05, 'border_count': 74, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:50,509] Trial 17 finished with value: 0.6441393520737018 and parameters: {'iterations': 669, 'depth': 4, 'learning_rate': 0.18816742039725934, 'random_strength': 20, 'bagging_temperature': 0.35262613664864806, 'l2_leaf_reg': 3.4660827310230527e-06, 'border_count': 185, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:47:59,027] Trial 18 finished with value: 0.6160140822235436 and parameters: {'iterations': 1082, 'depth': 7, 'learning_rate': 0.16213520930696151, 'random_strength': 1, 'bagging_temperature': 0.22587615290050866, 'l2_leaf_reg': 1.8814059843653185e-05, 'border_count': 114, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:48:07,906] Trial 19 finished with value: 0.6461163656109487 and parameters: {'iterations': 1040, 'depth': 5, 'learning_rate': 0.1598168843069982, 'random_strength': 1, 'bagging_temperature': 0.18558087457395847, 'l2_leaf_reg': 1.8219599904558087e-05, 'border_count': 131, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:48:18,524] Trial 20 finished with value: 0.6570627331571557 and parameters: {'iterations': 874, 'depth': 10, 'learning_rate': 0.1513900399418271, 'random_strength': 8, 'bagging_temperature': 0.07087704123293395, 'l2_leaf_reg': 2.8365913399615326e-05, 'border_count': 167, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:48:34,631] Trial 21 finished with value: 0.6564371938352591 and parameters: {'iterations': 1073, 'depth': 7, 'learning_rate': 0.16399528024820814, 'random_strength': 6, 'bagging_temperature': 0.004254139516983724, 'l2_leaf_reg': 1.2677847260428903e-05, 'border_count': 107, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:48:44,768] Trial 22 finished with value: 0.6412998444113968 and parameters: {'iterations': 1117, 'depth': 8, 'learning_rate': 0.1906686130676589, 'random_strength': 0, 'bagging_temperature': 0.2071748684573962, 'l2_leaf_reg': 5.7644585860755e-06, 'border_count': 85, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:48:47,083] Trial 23 finished with value: 0.6811626008432221 and parameters: {'iterations': 957, 'depth': 7, 'learning_rate': 0.21349874533343086, 'random_strength': 12, 'bagging_temperature': 0.26511632056813167, 'l2_leaf_reg': 1.667731397441394e-05, 'border_count': 67, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:02,723] Trial 24 finished with value: 0.6440279211790678 and parameters: {'iterations': 842, 'depth': 6, 'learning_rate': 0.19327298203261672, 'random_strength': 28, 'bagging_temperature': 0.42727323303365344, 'l2_leaf_reg': 4.320233634042548e-05, 'border_count': 117, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:19,725] Trial 25 finished with value: 0.6444813990807204 and parameters: {'iterations': 1059, 'depth': 7, 'learning_rate': 0.21489365153544987, 'random_strength': 21, 'bagging_temperature': 0.11210732375369534, 'l2_leaf_reg': 2.4414473168086723e-05, 'border_count': 83, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:23,139] Trial 26 finished with value: 0.6665568444661932 and parameters: {'iterations': 703, 'depth': 5, 'learning_rate': 0.17349617307822185, 'random_strength': 13, 'bagging_temperature': 0.376453137753776, 'l2_leaf_reg': 1.0528133795345103e-05, 'border_count': 50, 'grow_policy': 'SymmetricTree'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:35,025] Trial 27 finished with value: 0.6139335518716389 and parameters: {'iterations': 1159, 'depth': 8, 'learning_rate': 0.20430153272584825, 'random_strength': 8, 'bagging_temperature': 0.24766617499579754, 'l2_leaf_reg': 4.899014316704899e-05, 'border_count': 100, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:45,093] Trial 28 finished with value: 0.6121976714868598 and parameters: {'iterations': 1132, 'depth': 9, 'learning_rate': 0.20507712961540592, 'random_strength': 7, 'bagging_temperature': 0.23489825130555322, 'l2_leaf_reg': 4.1110773047968525e-05, 'border_count': 133, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:49:53,372] Trial 29 finished with value: 0.6182392761749261 and parameters: {'iterations': 1190, 'depth': 9, 'learning_rate': 0.23346216559404318, 'random_strength': 9, 'bagging_temperature': 0.25098538178248414, 'l2_leaf_reg': 5.255245080020627e-05, 'border_count': 172, 'grow_policy': 'Lossguide'}. Best is trial 8 with value: 0.6099831940749727.\n",
      "[I 2023-12-07 21:50:05,544] Trial 30 finished with value: 0.6081846257422295 and parameters: {'iterations': 435, 'depth': 10, 'learning_rate': 0.20541421670770693, 'random_strength': 5, 'bagging_temperature': 0.12140170291834806, 'l2_leaf_reg': 4.025452268134428e-05, 'border_count': 131, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:50:16,988] Trial 31 finished with value: 0.6534317420458825 and parameters: {'iterations': 407, 'depth': 10, 'learning_rate': 0.2028789800048337, 'random_strength': 6, 'bagging_temperature': 0.12245944462790395, 'l2_leaf_reg': 3.879890603907294e-05, 'border_count': 152, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:50:31,748] Trial 32 finished with value: 0.6193627662848235 and parameters: {'iterations': 468, 'depth': 9, 'learning_rate': 0.20677183483149233, 'random_strength': 5, 'bagging_temperature': 0.15599785016188644, 'l2_leaf_reg': 3.0903234345208934e-05, 'border_count': 132, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:50:40,844] Trial 33 finished with value: 0.6673650066056689 and parameters: {'iterations': 633, 'depth': 10, 'learning_rate': 0.19746744008343217, 'random_strength': 10, 'bagging_temperature': 0.08249112380078785, 'l2_leaf_reg': 4.735977432403251e-05, 'border_count': 137, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:51:02,798] Trial 34 finished with value: 0.6248064515897181 and parameters: {'iterations': 620, 'depth': 9, 'learning_rate': 0.22422663082918765, 'random_strength': 16, 'bagging_temperature': 0.21493641652966347, 'l2_leaf_reg': 3.303196457024348e-05, 'border_count': 91, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:51:14,110] Trial 35 finished with value: 0.6347715362127482 and parameters: {'iterations': 436, 'depth': 10, 'learning_rate': 0.21042858266942627, 'random_strength': 3, 'bagging_temperature': 0.14575696854195871, 'l2_leaf_reg': 6.134086310047653e-05, 'border_count': 145, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:51:28,072] Trial 36 finished with value: 0.6314820964401895 and parameters: {'iterations': 1139, 'depth': 9, 'learning_rate': 0.18704667897790905, 'random_strength': 6, 'bagging_temperature': 0.28473654997922715, 'l2_leaf_reg': 5.9302537027949395e-05, 'border_count': 214, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:51:37,107] Trial 37 finished with value: 0.6667743401840202 and parameters: {'iterations': 380, 'depth': 8, 'learning_rate': 0.22957834776859187, 'random_strength': 19, 'bagging_temperature': 0.31538861148471053, 'l2_leaf_reg': 9.087961101776677e-05, 'border_count': 158, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:51:44,323] Trial 38 finished with value: 0.6239247972780332 and parameters: {'iterations': 815, 'depth': 10, 'learning_rate': 0.2373878093356131, 'random_strength': 3, 'bagging_temperature': 0.054041989663202825, 'l2_leaf_reg': 2.367724142314001e-05, 'border_count': 125, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:01,663] Trial 39 finished with value: 0.6241570887990873 and parameters: {'iterations': 580, 'depth': 8, 'learning_rate': 0.20224172477397134, 'random_strength': 13, 'bagging_temperature': 0.0037060085069305915, 'l2_leaf_reg': 4.0469913185635144e-05, 'border_count': 143, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:11,368] Trial 40 finished with value: 0.6433868833086506 and parameters: {'iterations': 1023, 'depth': 9, 'learning_rate': 0.1955201645449835, 'random_strength': 7, 'bagging_temperature': 0.12963108422870084, 'l2_leaf_reg': 7.100090399219122e-05, 'border_count': 109, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:19,877] Trial 41 finished with value: 0.6680785014644474 and parameters: {'iterations': 1099, 'depth': 8, 'learning_rate': 0.1824043332335434, 'random_strength': 0, 'bagging_temperature': 0.21292829748766368, 'l2_leaf_reg': 2.4696017955840582e-05, 'border_count': 116, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:30,182] Trial 42 finished with value: 0.6647214061514877 and parameters: {'iterations': 1178, 'depth': 10, 'learning_rate': 0.20865860799385538, 'random_strength': 2, 'bagging_temperature': 0.2460245247795661, 'l2_leaf_reg': 4.447740582243844e-05, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:39,373] Trial 43 finished with value: 0.6140569306581118 and parameters: {'iterations': 918, 'depth': 9, 'learning_rate': 0.19489487826301868, 'random_strength': 4, 'bagging_temperature': 0.17040258298081407, 'l2_leaf_reg': 1.844401078946048e-05, 'border_count': 95, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:52:48,127] Trial 44 finished with value: 0.6364319796233088 and parameters: {'iterations': 916, 'depth': 9, 'learning_rate': 0.19641467237573765, 'random_strength': 10, 'bagging_temperature': 0.09890623553548339, 'l2_leaf_reg': 9.9558789269636e-05, 'border_count': 101, 'grow_policy': 'Lossguide'}. Best is trial 30 with value: 0.6081846257422295.\n",
      "[I 2023-12-07 21:53:04,361] Trial 45 finished with value: 0.5989115975753266 and parameters: {'iterations': 925, 'depth': 9, 'learning_rate': 0.21359394240857074, 'random_strength': 5, 'bagging_temperature': 0.16884932996382926, 'l2_leaf_reg': 6.32939449867399e-05, 'border_count': 92, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:53:12,986] Trial 46 finished with value: 0.6692659000227641 and parameters: {'iterations': 718, 'depth': 10, 'learning_rate': 0.2208243938166972, 'random_strength': 37, 'bagging_temperature': 0.04713570153608804, 'l2_leaf_reg': 5.569100408103869e-05, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:53:22,545] Trial 47 finished with value: 0.6237961609720164 and parameters: {'iterations': 783, 'depth': 10, 'learning_rate': 0.21529607598768008, 'random_strength': 11, 'bagging_temperature': 0.10193220416641144, 'l2_leaf_reg': 7.045237117462632e-05, 'border_count': 126, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:53:37,932] Trial 48 finished with value: 0.642562847854665 and parameters: {'iterations': 1012, 'depth': 9, 'learning_rate': 0.20569598102413206, 'random_strength': 15, 'bagging_temperature': 0.3001929142910796, 'l2_leaf_reg': 3.749813288594756e-05, 'border_count': 58, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:53:48,866] Trial 49 finished with value: 0.6221332042926023 and parameters: {'iterations': 509, 'depth': 8, 'learning_rate': 0.22284595797763757, 'random_strength': 8, 'bagging_temperature': 0.1724503448919813, 'l2_leaf_reg': 7.193680305343904e-05, 'border_count': 89, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:54:00,575] Trial 50 finished with value: 0.6125018982452458 and parameters: {'iterations': 1151, 'depth': 9, 'learning_rate': 0.21259253906787254, 'random_strength': 4, 'bagging_temperature': 0.3475971631251554, 'l2_leaf_reg': 3.2826531784318173e-05, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:54:11,260] Trial 51 finished with value: 0.6282399166046028 and parameters: {'iterations': 1117, 'depth': 9, 'learning_rate': 0.21244521475037087, 'random_strength': 4, 'bagging_temperature': 0.2586406157264517, 'l2_leaf_reg': 4.799234713668816e-05, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:54:24,520] Trial 52 finished with value: 0.6254661431304605 and parameters: {'iterations': 1158, 'depth': 10, 'learning_rate': 0.2035232401539416, 'random_strength': 7, 'bagging_temperature': 0.3425144007274991, 'l2_leaf_reg': 3.026536445941923e-05, 'border_count': 99, 'grow_policy': 'Lossguide'}. Best is trial 45 with value: 0.5989115975753266.\n",
      "[I 2023-12-07 21:54:33,601] Trial 53 finished with value: 0.5984675506421627 and parameters: {'iterations': 1200, 'depth': 8, 'learning_rate': 0.2205847463803754, 'random_strength': 2, 'bagging_temperature': 0.1897234755099855, 'l2_leaf_reg': 3.489763815948794e-05, 'border_count': 84, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:54:42,883] Trial 54 finished with value: 0.6356566293158219 and parameters: {'iterations': 951, 'depth': 9, 'learning_rate': 0.2210595319956116, 'random_strength': 2, 'bagging_temperature': 0.19756033502963355, 'l2_leaf_reg': 3.540507572940002e-05, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:54:55,088] Trial 55 finished with value: 0.6014820926102196 and parameters: {'iterations': 1199, 'depth': 9, 'learning_rate': 0.2173148705642619, 'random_strength': 5, 'bagging_temperature': 0.14402466958098636, 'l2_leaf_reg': 2.3037805265880202e-05, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:02,645] Trial 56 finished with value: 0.6173131666152044 and parameters: {'iterations': 851, 'depth': 10, 'learning_rate': 0.22839712405457777, 'random_strength': 0, 'bagging_temperature': 0.042867328085469406, 'l2_leaf_reg': 1.371612445162524e-05, 'border_count': 195, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:05,044] Trial 57 finished with value: 0.6521268481624567 and parameters: {'iterations': 1198, 'depth': 8, 'learning_rate': 0.23770550607708482, 'random_strength': 5, 'bagging_temperature': 0.13801117697273846, 'l2_leaf_reg': 2.203062497887292e-05, 'border_count': 83, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:11,233] Trial 58 finished with value: 0.6489950783605322 and parameters: {'iterations': 1066, 'depth': 9, 'learning_rate': 0.21707253080303293, 'random_strength': 2, 'bagging_temperature': 0.08548332219131875, 'l2_leaf_reg': 2.6085627977350308e-05, 'border_count': 89, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:25,654] Trial 59 finished with value: 0.6634993798606676 and parameters: {'iterations': 349, 'depth': 10, 'learning_rate': 0.200218308553665, 'random_strength': 18, 'bagging_temperature': 0.03449523341876211, 'l2_leaf_reg': 1.4912648813182244e-05, 'border_count': 109, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:28,282] Trial 60 finished with value: 0.6671654931101868 and parameters: {'iterations': 1125, 'depth': 8, 'learning_rate': 0.21760288974115666, 'random_strength': 14, 'bagging_temperature': 0.17543779229314638, 'l2_leaf_reg': 1.9217268146155812e-05, 'border_count': 54, 'grow_policy': 'SymmetricTree'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:36,490] Trial 61 finished with value: 0.6444165788732193 and parameters: {'iterations': 1160, 'depth': 9, 'learning_rate': 0.20947346312325812, 'random_strength': 4, 'bagging_temperature': 0.13086108302334212, 'l2_leaf_reg': 3.0630829818255515e-05, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:43,377] Trial 62 finished with value: 0.6611715533692211 and parameters: {'iterations': 1035, 'depth': 9, 'learning_rate': 0.21210673614072376, 'random_strength': 5, 'bagging_temperature': 0.21343222762363911, 'l2_leaf_reg': 3.685327807375947e-05, 'border_count': 76, 'grow_policy': 'Lossguide'}. Best is trial 53 with value: 0.5984675506421627.\n",
      "[I 2023-12-07 21:55:52,288] Trial 63 finished with value: 0.592534282064036 and parameters: {'iterations': 1096, 'depth': 9, 'learning_rate': 0.22603548878280666, 'random_strength': 2, 'bagging_temperature': 0.1867337573932248, 'l2_leaf_reg': 2.304593084966779e-05, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:55:58,360] Trial 64 finished with value: 0.6409739288276434 and parameters: {'iterations': 1089, 'depth': 10, 'learning_rate': 0.2261182635784916, 'random_strength': 0, 'bagging_temperature': 0.0757688344863871, 'l2_leaf_reg': 1.2180137982546496e-05, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:56:11,806] Trial 65 finished with value: 0.5988189268882347 and parameters: {'iterations': 998, 'depth': 9, 'learning_rate': 0.23280751654166926, 'random_strength': 2, 'bagging_temperature': 0.1536482394304556, 'l2_leaf_reg': 1.9642539991559242e-05, 'border_count': 81, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:56:24,703] Trial 66 finished with value: 0.6413820367508176 and parameters: {'iterations': 997, 'depth': 8, 'learning_rate': 0.2324567183279701, 'random_strength': 2, 'bagging_temperature': 0.11021314481433742, 'l2_leaf_reg': 2.119498458764101e-05, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:56:38,482] Trial 67 finished with value: 0.6300224891854268 and parameters: {'iterations': 894, 'depth': 10, 'learning_rate': 0.24259007520435005, 'random_strength': 48, 'bagging_temperature': 0.15485876851014477, 'l2_leaf_reg': 8.39350755161264e-06, 'border_count': 70, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:56:47,428] Trial 68 finished with value: 0.6647201517205136 and parameters: {'iterations': 970, 'depth': 9, 'learning_rate': 0.22678119472132843, 'random_strength': 9, 'bagging_temperature': 0.1862753228434796, 'l2_leaf_reg': 1.5558196708675955e-05, 'border_count': 93, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:56:56,798] Trial 69 finished with value: 0.6344794189783557 and parameters: {'iterations': 755, 'depth': 8, 'learning_rate': 0.22225450121555923, 'random_strength': 1, 'bagging_temperature': 0.0654853689539148, 'l2_leaf_reg': 2.1093468641731222e-05, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:57:02,676] Trial 70 finished with value: 0.706473199087072 and parameters: {'iterations': 943, 'depth': 10, 'learning_rate': 0.23115625727768208, 'random_strength': 6, 'bagging_temperature': 0.02141829504627879, 'l2_leaf_reg': 2.4610075400823717e-05, 'border_count': 80, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:57:21,475] Trial 71 finished with value: 0.6175028813390712 and parameters: {'iterations': 1051, 'depth': 9, 'learning_rate': 0.21811103180398717, 'random_strength': 7, 'bagging_temperature': 0.23859181080130587, 'l2_leaf_reg': 2.754467581920765e-05, 'border_count': 123, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:57:31,444] Trial 72 finished with value: 0.6487216241085282 and parameters: {'iterations': 811, 'depth': 9, 'learning_rate': 0.2258060939302553, 'random_strength': 2, 'bagging_temperature': 0.1475401394036481, 'l2_leaf_reg': 5.345211875072751e-05, 'border_count': 86, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:57:45,435] Trial 73 finished with value: 0.6090789085026037 and parameters: {'iterations': 1114, 'depth': 9, 'learning_rate': 0.2072846003962051, 'random_strength': 35, 'bagging_temperature': 0.28466181666992796, 'l2_leaf_reg': 4.3233827793595136e-05, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:57:53,377] Trial 74 finished with value: 0.6613985623234997 and parameters: {'iterations': 1098, 'depth': 8, 'learning_rate': 0.2352074536907377, 'random_strength': 41, 'bagging_temperature': 0.2799699076305139, 'l2_leaf_reg': 1.61910326364631e-05, 'border_count': 105, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:58:01,473] Trial 75 finished with value: 0.6638271921593978 and parameters: {'iterations': 1184, 'depth': 9, 'learning_rate': 0.21584329076166364, 'random_strength': 35, 'bagging_temperature': 0.19805778791196, 'l2_leaf_reg': 7.934606609110084e-05, 'border_count': 55, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:58:19,978] Trial 76 finished with value: 0.6419449793522833 and parameters: {'iterations': 996, 'depth': 9, 'learning_rate': 0.2196173388621386, 'random_strength': 28, 'bagging_temperature': 0.11055084662599199, 'l2_leaf_reg': 4.264254137693198e-05, 'border_count': 153, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:58:41,446] Trial 77 finished with value: 0.7194188589828577 and parameters: {'iterations': 875, 'depth': 10, 'learning_rate': 0.20750649486808415, 'random_strength': 33, 'bagging_temperature': 0.16253233394045435, 'l2_leaf_reg': 6.230845260569203e-05, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:58:49,897] Trial 78 finished with value: 0.6519761074242065 and parameters: {'iterations': 842, 'depth': 7, 'learning_rate': 0.2423718666209619, 'random_strength': 21, 'bagging_temperature': 0.23110250413506978, 'l2_leaf_reg': 2.8421441988160926e-05, 'border_count': 172, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:05,750] Trial 79 finished with value: 0.6177504027988524 and parameters: {'iterations': 1108, 'depth': 10, 'learning_rate': 0.20018944370634234, 'random_strength': 3, 'bagging_temperature': 0.07678725173452408, 'l2_leaf_reg': 1.8530728618310404e-05, 'border_count': 112, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:13,649] Trial 80 finished with value: 0.6653734658150855 and parameters: {'iterations': 929, 'depth': 9, 'learning_rate': 0.22965619041681037, 'random_strength': 28, 'bagging_temperature': 0.12246944856392461, 'l2_leaf_reg': 3.5164773861561573e-05, 'border_count': 136, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:24,396] Trial 81 finished with value: 0.6194236756387039 and parameters: {'iterations': 1140, 'depth': 9, 'learning_rate': 0.20752043064490866, 'random_strength': 5, 'bagging_temperature': 0.22547926455494566, 'l2_leaf_reg': 4.384337991187462e-05, 'border_count': 139, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:40,555] Trial 82 finished with value: 0.626817304311687 and parameters: {'iterations': 1059, 'depth': 9, 'learning_rate': 0.21113317405892626, 'random_strength': 10, 'bagging_temperature': 0.195087682654158, 'l2_leaf_reg': 5.2336586842254975e-05, 'border_count': 151, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:48,321] Trial 83 finished with value: 0.6485211455782174 and parameters: {'iterations': 1165, 'depth': 8, 'learning_rate': 0.19157043798711118, 'random_strength': 1, 'bagging_temperature': 0.2632888358226132, 'l2_leaf_reg': 6.503322824969646e-05, 'border_count': 98, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 21:59:56,697] Trial 84 finished with value: 0.6425850663984599 and parameters: {'iterations': 1199, 'depth': 9, 'learning_rate': 0.22334848217871156, 'random_strength': 8, 'bagging_temperature': 0.13931617690925213, 'l2_leaf_reg': 4.0845651948147716e-05, 'border_count': 132, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:00:05,636] Trial 85 finished with value: 0.6477907493070942 and parameters: {'iterations': 1029, 'depth': 9, 'learning_rate': 0.20493653757412744, 'random_strength': 26, 'bagging_temperature': 0.17628972068645582, 'l2_leaf_reg': 8.541759266232277e-05, 'border_count': 120, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:00:21,735] Trial 86 finished with value: 0.6098360625607983 and parameters: {'iterations': 1121, 'depth': 10, 'learning_rate': 0.19994229668543181, 'random_strength': 45, 'bagging_temperature': 0.0966566799366114, 'l2_leaf_reg': 2.2493134921119656e-05, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:00:34,606] Trial 87 finished with value: 0.6677483024684189 and parameters: {'iterations': 1076, 'depth': 10, 'learning_rate': 0.21365795474586824, 'random_strength': 46, 'bagging_temperature': 0.11497277652492807, 'l2_leaf_reg': 2.403579584492412e-05, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:00:48,822] Trial 88 finished with value: 0.6425399872996923 and parameters: {'iterations': 1122, 'depth': 10, 'learning_rate': 0.1883171435881451, 'random_strength': 40, 'bagging_temperature': 0.0903874492463913, 'l2_leaf_reg': 1.182534221636958e-05, 'border_count': 252, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:00:57,357] Trial 89 finished with value: 0.6670411290092448 and parameters: {'iterations': 1172, 'depth': 10, 'learning_rate': 0.20221767316984254, 'random_strength': 31, 'bagging_temperature': 0.15420827987983216, 'l2_leaf_reg': 1.560998560630171e-05, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:02,861] Trial 90 finished with value: 0.6827071719391321 and parameters: {'iterations': 905, 'depth': 10, 'learning_rate': 0.19908028687050044, 'random_strength': 36, 'bagging_temperature': 0.0605361080458056, 'l2_leaf_reg': 2.7018210417939963e-05, 'border_count': 93, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:19,427] Trial 91 finished with value: 0.6433611423535639 and parameters: {'iterations': 1140, 'depth': 9, 'learning_rate': 0.19668606996342494, 'random_strength': 45, 'bagging_temperature': 0.202326757597886, 'l2_leaf_reg': 3.37035879670885e-05, 'border_count': 88, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:29,841] Trial 92 finished with value: 0.6156926224386465 and parameters: {'iterations': 1131, 'depth': 10, 'learning_rate': 0.20907441915807798, 'random_strength': 3, 'bagging_temperature': 0.2389582596271279, 'l2_leaf_reg': 2.085016686815022e-05, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:40,509] Trial 93 finished with value: 0.6582143461183563 and parameters: {'iterations': 1081, 'depth': 9, 'learning_rate': 0.21537220645439725, 'random_strength': 42, 'bagging_temperature': 0.09233907406412235, 'l2_leaf_reg': 4.9779269513598476e-05, 'border_count': 84, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:46,538] Trial 94 finished with value: 0.651340676031918 and parameters: {'iterations': 974, 'depth': 4, 'learning_rate': 0.20504413809513658, 'random_strength': 6, 'bagging_temperature': 0.1643035145024353, 'l2_leaf_reg': 2.963065080696607e-05, 'border_count': 231, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:01:58,005] Trial 95 finished with value: 0.5950063553805628 and parameters: {'iterations': 1171, 'depth': 10, 'learning_rate': 0.21836321718505547, 'random_strength': 4, 'bagging_temperature': 0.12637526657343098, 'l2_leaf_reg': 5.88618693856304e-05, 'border_count': 165, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:02:18,285] Trial 96 finished with value: 0.6400409402667488 and parameters: {'iterations': 1178, 'depth': 10, 'learning_rate': 0.2192572135720418, 'random_strength': 38, 'bagging_temperature': 0.03233613346924358, 'l2_leaf_reg': 5.83474842506603e-05, 'border_count': 162, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:02:24,620] Trial 97 finished with value: 0.6270576338129294 and parameters: {'iterations': 1104, 'depth': 10, 'learning_rate': 0.22426954208164052, 'random_strength': 0, 'bagging_temperature': 0.13713921990176003, 'l2_leaf_reg': 7.765823844888078e-05, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:02:35,084] Trial 98 finished with value: 0.6485058222425221 and parameters: {'iterations': 1152, 'depth': 10, 'learning_rate': 0.22774122075096953, 'random_strength': 50, 'bagging_temperature': 0.10266507295208763, 'l2_leaf_reg': 3.824228328802702e-05, 'border_count': 63, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:02:42,915] Trial 99 finished with value: 0.6559740735104507 and parameters: {'iterations': 684, 'depth': 6, 'learning_rate': 0.210671787240925, 'random_strength': 4, 'bagging_temperature': 0.04978440176359429, 'l2_leaf_reg': 4.888302351225674e-05, 'border_count': 181, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:02:48,127] Trial 100 finished with value: 0.6559803560128521 and parameters: {'iterations': 859, 'depth': 10, 'learning_rate': 0.21978986697621594, 'random_strength': 1, 'bagging_temperature': 0.12769271270251698, 'l2_leaf_reg': 9.715312584886361e-05, 'border_count': 194, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:10,845] Trial 101 finished with value: 0.6145517356285093 and parameters: {'iterations': 1114, 'depth': 9, 'learning_rate': 0.2135236572882232, 'random_strength': 5, 'bagging_temperature': 0.1875091789563316, 'l2_leaf_reg': 3.2613560294716806e-05, 'border_count': 141, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:20,605] Trial 102 finished with value: 0.6487564292816443 and parameters: {'iterations': 1177, 'depth': 7, 'learning_rate': 0.1942189419968815, 'random_strength': 4, 'bagging_temperature': 0.2262010714627178, 'l2_leaf_reg': 4.2158514417534494e-05, 'border_count': 147, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:29,512] Trial 103 finished with value: 0.6601429815423954 and parameters: {'iterations': 1017, 'depth': 9, 'learning_rate': 0.20138948000220858, 'random_strength': 3, 'bagging_temperature': 0.14680782844222562, 'l2_leaf_reg': 2.289650207554666e-05, 'border_count': 128, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:38,353] Trial 104 finished with value: 0.6106679614664938 and parameters: {'iterations': 1146, 'depth': 9, 'learning_rate': 0.21680307145451957, 'random_strength': 7, 'bagging_temperature': 0.17591343403646426, 'l2_leaf_reg': 6.136997036902737e-05, 'border_count': 169, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:46,992] Trial 105 finished with value: 0.6259995296168529 and parameters: {'iterations': 1044, 'depth': 9, 'learning_rate': 0.2167855223099738, 'random_strength': 7, 'bagging_temperature': 0.18106292579536737, 'l2_leaf_reg': 6.073036985643974e-05, 'border_count': 171, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:03:57,036] Trial 106 finished with value: 0.6306427938226086 and parameters: {'iterations': 1146, 'depth': 10, 'learning_rate': 0.22170897598748615, 'random_strength': 6, 'bagging_temperature': 0.06892182850635395, 'l2_leaf_reg': 6.745178003766562e-05, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:04:07,960] Trial 107 finished with value: 0.6275323247168176 and parameters: {'iterations': 1200, 'depth': 8, 'learning_rate': 0.22531242184510775, 'random_strength': 2, 'bagging_temperature': 0.10779000226158825, 'l2_leaf_reg': 1.8849412885123245e-05, 'border_count': 180, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:04:17,236] Trial 108 finished with value: 0.6193504858781314 and parameters: {'iterations': 582, 'depth': 5, 'learning_rate': 0.23245789975063533, 'random_strength': 9, 'bagging_temperature': 0.16244581311024076, 'l2_leaf_reg': 2.7057779124641813e-05, 'border_count': 158, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:04:27,417] Trial 109 finished with value: 0.6344081218359167 and parameters: {'iterations': 1091, 'depth': 9, 'learning_rate': 0.2078529898099588, 'random_strength': 1, 'bagging_temperature': 0.08837027974177876, 'l2_leaf_reg': 7.519937871941994e-05, 'border_count': 167, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:04:48,585] Trial 110 finished with value: 0.6691992057732269 and parameters: {'iterations': 1168, 'depth': 10, 'learning_rate': 0.2175875163497531, 'random_strength': 11, 'bagging_temperature': 0.20840059550525214, 'l2_leaf_reg': 4.7595659314062636e-05, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:04:57,369] Trial 111 finished with value: 0.6210678339090653 and parameters: {'iterations': 1133, 'depth': 9, 'learning_rate': 0.20471210779022714, 'random_strength': 8, 'bagging_temperature': 0.120861361335013, 'l2_leaf_reg': 3.682101105896711e-05, 'border_count': 72, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:05:06,490] Trial 112 finished with value: 0.640390787217961 and parameters: {'iterations': 1183, 'depth': 9, 'learning_rate': 0.21130568877285197, 'random_strength': 5, 'bagging_temperature': 0.27792045970300144, 'l2_leaf_reg': 3.045728256194096e-05, 'border_count': 151, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:05:18,518] Trial 113 finished with value: 0.6503178735726788 and parameters: {'iterations': 1120, 'depth': 8, 'learning_rate': 0.1980870304371408, 'random_strength': 3, 'bagging_temperature': 0.2175597219248716, 'l2_leaf_reg': 5.626103438017485e-05, 'border_count': 163, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:05:26,917] Trial 114 finished with value: 0.6514714659974103 and parameters: {'iterations': 1155, 'depth': 9, 'learning_rate': 0.21406840009664557, 'random_strength': 7, 'bagging_temperature': 0.1849074048464959, 'l2_leaf_reg': 4.3694976998001725e-05, 'border_count': 135, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:05:40,814] Trial 115 finished with value: 0.654176075278251 and parameters: {'iterations': 999, 'depth': 10, 'learning_rate': 0.20677180427214784, 'random_strength': 6, 'bagging_temperature': 0.2576915417746127, 'l2_leaf_reg': 3.890694269379527e-05, 'border_count': 146, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:05:47,660] Trial 116 finished with value: 0.6288563165904347 and parameters: {'iterations': 1073, 'depth': 9, 'learning_rate': 0.22164781791188737, 'random_strength': 2, 'bagging_temperature': 0.14397958944290626, 'l2_leaf_reg': 1.7446389907689308e-05, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:06:02,914] Trial 117 finished with value: 0.6342505026574525 and parameters: {'iterations': 817, 'depth': 9, 'learning_rate': 0.2095832363465017, 'random_strength': 47, 'bagging_temperature': 0.1707386279461831, 'l2_leaf_reg': 2.091874235778271e-05, 'border_count': 97, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:06:10,759] Trial 118 finished with value: 0.6495481434449315 and parameters: {'iterations': 1093, 'depth': 10, 'learning_rate': 0.22898355044919777, 'random_strength': 5, 'bagging_temperature': 0.017442611190413557, 'l2_leaf_reg': 5.388159610852358e-05, 'border_count': 102, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:06:21,758] Trial 119 finished with value: 0.631318883657688 and parameters: {'iterations': 478, 'depth': 8, 'learning_rate': 0.20212914136740712, 'random_strength': 0, 'bagging_temperature': 0.12972842415570082, 'l2_leaf_reg': 2.512666629734843e-05, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:06:24,718] Trial 120 finished with value: 0.6710624261321501 and parameters: {'iterations': 941, 'depth': 9, 'learning_rate': 0.21610695420444742, 'random_strength': 23, 'bagging_temperature': 0.30091925766236416, 'l2_leaf_reg': 8.725609327305613e-05, 'border_count': 176, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:06:50,327] Trial 121 finished with value: 0.6319211418175635 and parameters: {'iterations': 1158, 'depth': 9, 'learning_rate': 0.21245385395417696, 'random_strength': 4, 'bagging_temperature': 0.20371042556052546, 'l2_leaf_reg': 3.298176254504719e-05, 'border_count': 87, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:06,284] Trial 122 finished with value: 0.6367618868002692 and parameters: {'iterations': 1140, 'depth': 9, 'learning_rate': 0.2192677511752416, 'random_strength': 43, 'bagging_temperature': 0.23582841101239863, 'l2_leaf_reg': 1.409844320245202e-05, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:16,373] Trial 123 finished with value: 0.6151691980105476 and parameters: {'iterations': 1108, 'depth': 9, 'learning_rate': 0.22366690267284364, 'random_strength': 3, 'bagging_temperature': 0.269476210464945, 'l2_leaf_reg': 3.532219068118584e-05, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:28,076] Trial 124 finished with value: 0.6081753341006313 and parameters: {'iterations': 1200, 'depth': 10, 'learning_rate': 0.21389587349185485, 'random_strength': 1, 'bagging_temperature': 0.2471011744795898, 'l2_leaf_reg': 6.594380852549547e-05, 'border_count': 157, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:35,660] Trial 125 finished with value: 0.6111912129013896 and parameters: {'iterations': 1189, 'depth': 10, 'learning_rate': 0.20467956638176069, 'random_strength': 1, 'bagging_temperature': 0.2544703978063113, 'l2_leaf_reg': 6.053667181299673e-05, 'border_count': 169, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:43,417] Trial 126 finished with value: 0.6499814821476735 and parameters: {'iterations': 1195, 'depth': 10, 'learning_rate': 0.21475912139946052, 'random_strength': 1, 'bagging_temperature': 0.2519361516034515, 'l2_leaf_reg': 6.793199326094636e-05, 'border_count': 157, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:07:51,683] Trial 127 finished with value: 0.6246737290665935 and parameters: {'iterations': 1183, 'depth': 10, 'learning_rate': 0.20643512437807257, 'random_strength': 2, 'bagging_temperature': 0.15662622810191157, 'l2_leaf_reg': 8.15086362649286e-05, 'border_count': 190, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:08:03,304] Trial 128 finished with value: 0.6345134571760361 and parameters: {'iterations': 1199, 'depth': 10, 'learning_rate': 0.19958006295569625, 'random_strength': 0, 'bagging_temperature': 0.19242709772439992, 'l2_leaf_reg': 6.378622016597238e-05, 'border_count': 165, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:08:16,123] Trial 129 finished with value: 0.6232589746169963 and parameters: {'iterations': 1174, 'depth': 10, 'learning_rate': 0.2099070928301354, 'random_strength': 4, 'bagging_temperature': 0.3244789175243742, 'l2_leaf_reg': 5.3165938112919964e-05, 'border_count': 170, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:08:31,423] Trial 130 finished with value: 0.6396499645558084 and parameters: {'iterations': 1150, 'depth': 10, 'learning_rate': 0.2039420717948147, 'random_strength': 34, 'bagging_temperature': 0.09698336748059548, 'l2_leaf_reg': 4.540482068263836e-05, 'border_count': 157, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:08:55,989] Trial 131 finished with value: 0.6184228781274038 and parameters: {'iterations': 1126, 'depth': 10, 'learning_rate': 0.19643598941097856, 'random_strength': 1, 'bagging_temperature': 0.22312324698830568, 'l2_leaf_reg': 6.924426348241441e-05, 'border_count': 177, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:09:08,829] Trial 132 finished with value: 0.6267015746226763 and parameters: {'iterations': 1173, 'depth': 10, 'learning_rate': 0.2117761616562233, 'random_strength': 3, 'bagging_temperature': 0.29248508999781386, 'l2_leaf_reg': 5.8316378108450246e-05, 'border_count': 160, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:09:30,647] Trial 133 finished with value: 0.6284594342586675 and parameters: {'iterations': 1161, 'depth': 10, 'learning_rate': 0.218487360227293, 'random_strength': 2, 'bagging_temperature': 0.1780381605228631, 'l2_leaf_reg': 4.812073992303334e-05, 'border_count': 91, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:09:39,536] Trial 134 finished with value: 0.5926145335957165 and parameters: {'iterations': 1057, 'depth': 10, 'learning_rate': 0.2273931938535443, 'random_strength': 6, 'bagging_temperature': 0.24633695649498366, 'l2_leaf_reg': 4.117516031111716e-05, 'border_count': 168, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:09:48,216] Trial 135 finished with value: 0.6402180405374396 and parameters: {'iterations': 1060, 'depth': 10, 'learning_rate': 0.22679764021378496, 'random_strength': 5, 'bagging_temperature': 0.21155336218285437, 'l2_leaf_reg': 2.7972045730937933e-05, 'border_count': 186, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:05,295] Trial 136 finished with value: 0.6153689244941607 and parameters: {'iterations': 1036, 'depth': 10, 'learning_rate': 0.23243596427312513, 'random_strength': 30, 'bagging_temperature': 0.24829771477127022, 'l2_leaf_reg': 9.761759534831914e-05, 'border_count': 175, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:13,186] Trial 137 finished with value: 0.6513435462960387 and parameters: {'iterations': 1095, 'depth': 10, 'learning_rate': 0.23556435957491814, 'random_strength': 7, 'bagging_temperature': 0.12302564337676358, 'l2_leaf_reg': 7.578532765066344e-05, 'border_count': 153, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:21,533] Trial 138 finished with value: 0.6228459127457396 and parameters: {'iterations': 1077, 'depth': 10, 'learning_rate': 0.22258465180065237, 'random_strength': 4, 'bagging_temperature': 0.15472365840304175, 'l2_leaf_reg': 2.3627778122145587e-05, 'border_count': 166, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:37,363] Trial 139 finished with value: 0.6165646237138903 and parameters: {'iterations': 1124, 'depth': 10, 'learning_rate': 0.2254663197173293, 'random_strength': 0, 'bagging_temperature': 0.07558253974568079, 'l2_leaf_reg': 3.9912621895803145e-05, 'border_count': 168, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:49,829] Trial 140 finished with value: 0.609535280506151 and parameters: {'iterations': 981, 'depth': 10, 'learning_rate': 0.23052628830437197, 'random_strength': 3, 'bagging_temperature': 0.2754656840859008, 'l2_leaf_reg': 3.122256108282606e-05, 'border_count': 61, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:10:57,395] Trial 141 finished with value: 0.6418837663940735 and parameters: {'iterations': 988, 'depth': 10, 'learning_rate': 0.2304200324584468, 'random_strength': 6, 'bagging_temperature': 0.27089551852233096, 'l2_leaf_reg': 3.141596702250053e-05, 'border_count': 77, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:11:05,187] Trial 142 finished with value: 0.6537817860539421 and parameters: {'iterations': 957, 'depth': 10, 'learning_rate': 0.22095948395325643, 'random_strength': 3, 'bagging_temperature': 0.28954259542416244, 'l2_leaf_reg': 5.130066917705882e-05, 'border_count': 60, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:11:13,662] Trial 143 finished with value: 0.6192597392605861 and parameters: {'iterations': 1012, 'depth': 10, 'learning_rate': 0.22796988736222645, 'random_strength': 2, 'bagging_temperature': 0.3145008585688184, 'l2_leaf_reg': 2.0098985313976927e-05, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:11:30,390] Trial 144 finished with value: 0.617389863018766 and parameters: {'iterations': 894, 'depth': 10, 'learning_rate': 0.21598343194003175, 'random_strength': 5, 'bagging_temperature': 0.22717116142214142, 'l2_leaf_reg': 3.704824214913189e-05, 'border_count': 162, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:11:47,809] Trial 145 finished with value: 0.621762257443278 and parameters: {'iterations': 1200, 'depth': 10, 'learning_rate': 0.22981054919634064, 'random_strength': 4, 'bagging_temperature': 0.1957007032787332, 'l2_leaf_reg': 4.51979878423281e-05, 'border_count': 70, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:11:52,652] Trial 146 finished with value: 0.6613218289351899 and parameters: {'iterations': 540, 'depth': 10, 'learning_rate': 0.23800278708600886, 'random_strength': 2, 'bagging_temperature': 0.13886398593519342, 'l2_leaf_reg': 5.879346818255886e-05, 'border_count': 72, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:07,374] Trial 147 finished with value: 0.5988060267217604 and parameters: {'iterations': 316, 'depth': 10, 'learning_rate': 0.1922958594084245, 'random_strength': 1, 'bagging_temperature': 0.24900984422106584, 'l2_leaf_reg': 2.711907731872256e-05, 'border_count': 173, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:16,990] Trial 148 finished with value: 0.6447686618071659 and parameters: {'iterations': 353, 'depth': 9, 'learning_rate': 0.19102242813824466, 'random_strength': 9, 'bagging_temperature': 0.37476177378426456, 'l2_leaf_reg': 2.680993330572803e-05, 'border_count': 180, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:25,211] Trial 149 finished with value: 0.6492775854754025 and parameters: {'iterations': 310, 'depth': 10, 'learning_rate': 0.22446296378443942, 'random_strength': 6, 'bagging_temperature': 0.17354599322864261, 'l2_leaf_reg': 1.631491766325844e-05, 'border_count': 85, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:38,676] Trial 150 finished with value: 0.6193618440650926 and parameters: {'iterations': 336, 'depth': 9, 'learning_rate': 0.18572204157795444, 'random_strength': 3, 'bagging_temperature': 0.11124175053637024, 'l2_leaf_reg': 2.1704476562307487e-05, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:47,562] Trial 151 finished with value: 0.6401449830955755 and parameters: {'iterations': 964, 'depth': 10, 'learning_rate': 0.20090012940845733, 'random_strength': 1, 'bagging_temperature': 0.25268900154150103, 'l2_leaf_reg': 3.075885256908438e-05, 'border_count': 174, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:12:55,794] Trial 152 finished with value: 0.6284862140909507 and parameters: {'iterations': 1145, 'depth': 10, 'learning_rate': 0.20835627112010857, 'random_strength': 0, 'bagging_temperature': 0.27201478750690355, 'l2_leaf_reg': 3.9955593855388766e-05, 'border_count': 185, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:13:11,227] Trial 153 finished with value: 0.6052400551367895 and parameters: {'iterations': 382, 'depth': 10, 'learning_rate': 0.19439561521402757, 'random_strength': 1, 'bagging_temperature': 0.23219453228380796, 'l2_leaf_reg': 2.4498585746170258e-05, 'border_count': 202, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:13:19,443] Trial 154 finished with value: 0.650702152764501 and parameters: {'iterations': 433, 'depth': 7, 'learning_rate': 0.19575510956891518, 'random_strength': 3, 'bagging_temperature': 0.20481567158170275, 'l2_leaf_reg': 2.448988671212088e-05, 'border_count': 222, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:13:30,586] Trial 155 finished with value: 0.6483070256180626 and parameters: {'iterations': 417, 'depth': 10, 'learning_rate': 0.19006095464680162, 'random_strength': 4, 'bagging_temperature': 0.1659832676837536, 'l2_leaf_reg': 2.744744825753114e-05, 'border_count': 212, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:13:38,770] Trial 156 finished with value: 0.6750331597696634 and parameters: {'iterations': 386, 'depth': 10, 'learning_rate': 0.19495965866139273, 'random_strength': 5, 'bagging_temperature': 0.2346930940301259, 'l2_leaf_reg': 1.742187321334631e-05, 'border_count': 198, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:13:46,447] Trial 157 finished with value: 0.6384227310427533 and parameters: {'iterations': 337, 'depth': 10, 'learning_rate': 0.19829340518816535, 'random_strength': 2, 'bagging_temperature': 0.05717087060770798, 'l2_leaf_reg': 2.2176555189110765e-05, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:01,804] Trial 158 finished with value: 0.6587444578868074 and parameters: {'iterations': 373, 'depth': 9, 'learning_rate': 0.19262301843767843, 'random_strength': 39, 'bagging_temperature': 0.5387152958048393, 'l2_leaf_reg': 3.5385174525297074e-05, 'border_count': 53, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:09,966] Trial 159 finished with value: 0.6187335105200509 and parameters: {'iterations': 918, 'depth': 10, 'learning_rate': 0.21813447714088777, 'random_strength': 1, 'bagging_temperature': 0.138988127299788, 'l2_leaf_reg': 3.1195409683559906e-05, 'border_count': 204, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:19,676] Trial 160 finished with value: 0.6888701489049054 and parameters: {'iterations': 464, 'depth': 9, 'learning_rate': 0.21348110706408954, 'random_strength': 8, 'bagging_temperature': 0.20876033756379805, 'l2_leaf_reg': 1.9184895533912805e-05, 'border_count': 155, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:34,843] Trial 161 finished with value: 0.5990161065087113 and parameters: {'iterations': 391, 'depth': 10, 'learning_rate': 0.2086385094494031, 'random_strength': 1, 'bagging_temperature': 0.24510835668545433, 'l2_leaf_reg': 6.34168864182577e-05, 'border_count': 164, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:46,031] Trial 162 finished with value: 0.6396007300098172 and parameters: {'iterations': 369, 'depth': 10, 'learning_rate': 0.20254854143185386, 'random_strength': 1, 'bagging_temperature': 0.30143157882999944, 'l2_leaf_reg': 1.4253330941061526e-05, 'border_count': 148, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:14:59,467] Trial 163 finished with value: 0.6116825569526587 and parameters: {'iterations': 390, 'depth': 10, 'learning_rate': 0.2082822070959721, 'random_strength': 49, 'bagging_temperature': 0.23694435559186605, 'l2_leaf_reg': 4.391393786877822e-05, 'border_count': 240, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:07,195] Trial 164 finished with value: 0.6147530087114652 and parameters: {'iterations': 407, 'depth': 10, 'learning_rate': 0.21991426255406035, 'random_strength': 0, 'bagging_temperature': 0.2769494930578234, 'l2_leaf_reg': 2.4675312004786512e-05, 'border_count': 61, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:15,712] Trial 165 finished with value: 0.6359499276363056 and parameters: {'iterations': 436, 'depth': 10, 'learning_rate': 0.21206668257506145, 'random_strength': 2, 'bagging_temperature': 0.17923103725275003, 'l2_leaf_reg': 1.0357928658618143e-05, 'border_count': 162, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:24,896] Trial 166 finished with value: 0.6281222563336997 and parameters: {'iterations': 313, 'depth': 9, 'learning_rate': 0.17592217227878082, 'random_strength': 4, 'bagging_temperature': 0.22556828126989092, 'l2_leaf_reg': 7.248867189872608e-05, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:36,501] Trial 167 finished with value: 0.6435515998310248 and parameters: {'iterations': 336, 'depth': 10, 'learning_rate': 0.20346992183952867, 'random_strength': 3, 'bagging_temperature': 0.19137184275092636, 'l2_leaf_reg': 3.4296769800782436e-05, 'border_count': 164, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:47,072] Trial 168 finished with value: 0.6103795058599101 and parameters: {'iterations': 733, 'depth': 9, 'learning_rate': 0.21544641574573017, 'random_strength': 6, 'bagging_temperature': 0.09923556112508444, 'l2_leaf_reg': 5.294064329704315e-05, 'border_count': 140, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:15:52,724] Trial 169 finished with value: 0.6255418616718196 and parameters: {'iterations': 648, 'depth': 10, 'learning_rate': 0.1845487145436729, 'random_strength': 5, 'bagging_temperature': 0.08121962304721035, 'l2_leaf_reg': 5.149094557254055e-05, 'border_count': 150, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:00,238] Trial 170 finished with value: 0.6250532686546372 and parameters: {'iterations': 732, 'depth': 8, 'learning_rate': 0.1813889964805637, 'random_strength': 3, 'bagging_temperature': 0.10992747289050608, 'l2_leaf_reg': 2.8704330641620465e-05, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:09,731] Trial 171 finished with value: 0.6430167606268352 and parameters: {'iterations': 411, 'depth': 9, 'learning_rate': 0.21595275399901337, 'random_strength': 26, 'bagging_temperature': 0.1511628831788005, 'l2_leaf_reg': 6.433580784742261e-05, 'border_count': 120, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:15,959] Trial 172 finished with value: 0.6595208310659132 and parameters: {'iterations': 785, 'depth': 9, 'learning_rate': 0.21002217054538844, 'random_strength': 2, 'bagging_temperature': 0.0969170070501907, 'l2_leaf_reg': 8.202776268760317e-05, 'border_count': 141, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:26,904] Trial 173 finished with value: 0.6448077452326314 and parameters: {'iterations': 355, 'depth': 9, 'learning_rate': 0.22184456858349474, 'random_strength': 6, 'bagging_temperature': 0.4166768020514189, 'l2_leaf_reg': 4.117939768623825e-05, 'border_count': 132, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:35,564] Trial 174 finished with value: 0.6231728048523518 and parameters: {'iterations': 612, 'depth': 9, 'learning_rate': 0.20637749796178015, 'random_strength': 7, 'bagging_temperature': 0.13438595560363756, 'l2_leaf_reg': 5.509680675306498e-05, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:16:46,371] Trial 175 finished with value: 0.6290392490683894 and parameters: {'iterations': 928, 'depth': 9, 'learning_rate': 0.21416407405796034, 'random_strength': 4, 'bagging_temperature': 0.2549331369156488, 'l2_leaf_reg': 4.579467522135669e-05, 'border_count': 128, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:01,138] Trial 176 finished with value: 0.6269032370209907 and parameters: {'iterations': 977, 'depth': 10, 'learning_rate': 0.1986782583683764, 'random_strength': 0, 'bagging_temperature': 0.04511788676989345, 'l2_leaf_reg': 2.1858898216294487e-05, 'border_count': 144, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:10,041] Trial 177 finished with value: 0.6710588027200985 and parameters: {'iterations': 1052, 'depth': 10, 'learning_rate': 0.21758637394259503, 'random_strength': 8, 'bagging_temperature': 0.16068480055834525, 'l2_leaf_reg': 1.83373839268154e-05, 'border_count': 171, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:20,310] Trial 178 finished with value: 0.6419232042917713 and parameters: {'iterations': 1110, 'depth': 9, 'learning_rate': 0.22618497434737975, 'random_strength': 3, 'bagging_temperature': 0.21577005316210446, 'l2_leaf_reg': 7.333495023982877e-06, 'border_count': 159, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:34,471] Trial 179 finished with value: 0.6850777644955336 and parameters: {'iterations': 1166, 'depth': 10, 'learning_rate': 0.22342643231369366, 'random_strength': 6, 'bagging_temperature': 0.32756579633472804, 'l2_leaf_reg': 1.2592786189263907e-05, 'border_count': 91, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:42,699] Trial 180 finished with value: 0.6324584817765366 and parameters: {'iterations': 831, 'depth': 10, 'learning_rate': 0.23395573106339104, 'random_strength': 5, 'bagging_temperature': 0.1151319634271093, 'l2_leaf_reg': 6.615642817402408e-05, 'border_count': 87, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:17:50,610] Trial 181 finished with value: 0.6581834885406239 and parameters: {'iterations': 1183, 'depth': 10, 'learning_rate': 0.20616899254518523, 'random_strength': 1, 'bagging_temperature': 0.25209319950954073, 'l2_leaf_reg': 5.96466663732227e-05, 'border_count': 170, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:01,299] Trial 182 finished with value: 0.6203526160654843 and parameters: {'iterations': 1139, 'depth': 10, 'learning_rate': 0.21090241798541737, 'random_strength': 1, 'bagging_temperature': 0.29003859209441196, 'l2_leaf_reg': 5.160932335790324e-05, 'border_count': 165, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:07,827] Trial 183 finished with value: 0.6403531333515747 and parameters: {'iterations': 1186, 'depth': 10, 'learning_rate': 0.20417770172294392, 'random_strength': 2, 'bagging_temperature': 0.2676845550746201, 'l2_leaf_reg': 8.994542894177516e-05, 'border_count': 179, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:15,316] Trial 184 finished with value: 0.6729762217282239 and parameters: {'iterations': 874, 'depth': 10, 'learning_rate': 0.2018090572341388, 'random_strength': 1, 'bagging_temperature': 0.24034497760174778, 'l2_leaf_reg': 7.334509572232068e-05, 'border_count': 172, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:30,056] Trial 185 finished with value: 0.6372649139890689 and parameters: {'iterations': 1167, 'depth': 10, 'learning_rate': 0.19272066874816973, 'random_strength': 17, 'bagging_temperature': 0.1868355563197382, 'l2_leaf_reg': 3.733605457611445e-05, 'border_count': 155, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:39,277] Trial 186 finished with value: 0.6436870271322822 and parameters: {'iterations': 1199, 'depth': 9, 'learning_rate': 0.213516780659944, 'random_strength': 4, 'bagging_temperature': 0.2057137452021813, 'l2_leaf_reg': 2.6309185993868363e-05, 'border_count': 166, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:45,708] Trial 187 finished with value: 0.6471537404349093 and parameters: {'iterations': 1030, 'depth': 10, 'learning_rate': 0.20886133080416838, 'random_strength': 0, 'bagging_temperature': 0.07375228099895392, 'l2_leaf_reg': 5.972818847571573e-05, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:18:53,271] Trial 188 finished with value: 0.6564482425501815 and parameters: {'iterations': 1156, 'depth': 9, 'learning_rate': 0.21955443650062045, 'random_strength': 3, 'bagging_temperature': 0.16224239143274116, 'l2_leaf_reg': 4.674975426939504e-05, 'border_count': 159, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:19:02,776] Trial 189 finished with value: 0.6455428619301555 and parameters: {'iterations': 1004, 'depth': 10, 'learning_rate': 0.1998604496217944, 'random_strength': 2, 'bagging_temperature': 0.3071446098932146, 'l2_leaf_reg': 3.403159093618244e-05, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:19:57,696] Trial 190 finished with value: 0.6713659064012469 and parameters: {'iterations': 1129, 'depth': 10, 'learning_rate': 0.22893782401397392, 'random_strength': 5, 'bagging_temperature': 0.28431981264434936, 'l2_leaf_reg': 2.9285571580926065e-05, 'border_count': 169, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:20:24,796] Trial 191 finished with value: 0.6139407683374473 and parameters: {'iterations': 359, 'depth': 10, 'learning_rate': 0.20899499503581465, 'random_strength': 3, 'bagging_temperature': 0.22917246440829217, 'l2_leaf_reg': 4.1966923873607484e-05, 'border_count': 249, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:20:39,490] Trial 192 finished with value: 0.683472566827778 and parameters: {'iterations': 404, 'depth': 10, 'learning_rate': 0.20519577748114726, 'random_strength': 42, 'bagging_temperature': 0.2430586624357775, 'l2_leaf_reg': 4.804948141866306e-05, 'border_count': 240, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:20:53,059] Trial 193 finished with value: 0.6150983362503835 and parameters: {'iterations': 397, 'depth': 10, 'learning_rate': 0.2160506498255555, 'random_strength': 44, 'bagging_temperature': 0.26755607424707745, 'l2_leaf_reg': 3.104573603019346e-06, 'border_count': 176, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:11,221] Trial 194 finished with value: 0.6133561113286539 and parameters: {'iterations': 467, 'depth': 10, 'learning_rate': 0.20721158135270196, 'random_strength': 50, 'bagging_temperature': 0.2259010123679616, 'l2_leaf_reg': 5.8707841551975586e-05, 'border_count': 213, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:21,260] Trial 195 finished with value: 0.6013570335643812 and parameters: {'iterations': 371, 'depth': 10, 'learning_rate': 0.21325893673621998, 'random_strength': 0, 'bagging_temperature': 0.1978350941772542, 'l2_leaf_reg': 4.402133480644276e-05, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:27,559] Trial 196 finished with value: 0.6493898399522406 and parameters: {'iterations': 303, 'depth': 10, 'learning_rate': 0.21192363113658608, 'random_strength': 0, 'bagging_temperature': 0.19127141933854813, 'l2_leaf_reg': 2.4433014123030112e-05, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:36,603] Trial 197 finished with value: 0.6030944384638084 and parameters: {'iterations': 375, 'depth': 9, 'learning_rate': 0.22067081434006325, 'random_strength': 1, 'bagging_temperature': 0.12736166451572922, 'l2_leaf_reg': 3.783178238379718e-05, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:44,106] Trial 198 finished with value: 0.6423850209512314 and parameters: {'iterations': 364, 'depth': 9, 'learning_rate': 0.22001938698253018, 'random_strength': 1, 'bagging_temperature': 0.13381967942881468, 'l2_leaf_reg': 3.9147135422078915e-05, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:46,245] Trial 199 finished with value: 0.6631738452210884 and parameters: {'iterations': 324, 'depth': 9, 'learning_rate': 0.22338120669967226, 'random_strength': 2, 'bagging_temperature': 0.1006514944375799, 'l2_leaf_reg': 3.139844184884592e-05, 'border_count': 84, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.592534282064036.\n",
      "[I 2023-12-07 22:21:46,247] A new study created in memory with name: no-name-b044ec1b-bda6-4c8f-8b83-c87f87e722d1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'iterations': 1096, 'depth': 9, 'learning_rate': 0.22603548878280666, 'random_strength': 2, 'bagging_temperature': 0.1867337573932248, 'l2_leaf_reg': 2.304593084966779e-05, 'border_count': 66, 'grow_policy': 'Lossguide'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 22:21:47,955] Trial 0 finished with value: 0.7038790795618295 and parameters: {'iterations': 578, 'depth': 9, 'learning_rate': 0.23485463581306498, 'random_strength': 50, 'bagging_temperature': 0.38032227032012167, 'l2_leaf_reg': 1.1960995156277105e-07, 'border_count': 155, 'grow_policy': 'SymmetricTree'}. Best is trial 0 with value: 0.7038790795618295.\n",
      "[I 2023-12-07 22:21:52,385] Trial 1 finished with value: 0.6779976698454548 and parameters: {'iterations': 541, 'depth': 7, 'learning_rate': 0.2446599507975211, 'random_strength': 34, 'bagging_temperature': 0.8441074836095279, 'l2_leaf_reg': 6.852265066865515e-06, 'border_count': 58, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:21:57,238] Trial 2 finished with value: 0.6954029042882701 and parameters: {'iterations': 927, 'depth': 7, 'learning_rate': 0.13170120420473286, 'random_strength': 44, 'bagging_temperature': 0.9584477472787345, 'l2_leaf_reg': 1.9781301046902822e-05, 'border_count': 89, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:21:58,698] Trial 3 finished with value: 0.6984051648323222 and parameters: {'iterations': 1033, 'depth': 7, 'learning_rate': 0.2363748170853878, 'random_strength': 13, 'bagging_temperature': 0.6950577642868271, 'l2_leaf_reg': 8.712265482308234e-05, 'border_count': 158, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:22:00,964] Trial 4 finished with value: 0.6997520105764956 and parameters: {'iterations': 502, 'depth': 10, 'learning_rate': 0.23183855194403635, 'random_strength': 2, 'bagging_temperature': 0.5283279714833908, 'l2_leaf_reg': 1.447590274609178e-06, 'border_count': 123, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:22:02,139] Trial 5 finished with value: 0.6989536229429686 and parameters: {'iterations': 480, 'depth': 4, 'learning_rate': 0.1386140256491002, 'random_strength': 28, 'bagging_temperature': 0.08079248665411476, 'l2_leaf_reg': 3.0993428547580017e-06, 'border_count': 250, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:22:05,477] Trial 6 finished with value: 0.6899782512088609 and parameters: {'iterations': 421, 'depth': 6, 'learning_rate': 0.23786732707281372, 'random_strength': 9, 'bagging_temperature': 0.03982894063359921, 'l2_leaf_reg': 1.7140884999297437e-07, 'border_count': 140, 'grow_policy': 'Lossguide'}. Best is trial 1 with value: 0.6779976698454548.\n",
      "[I 2023-12-07 22:22:09,245] Trial 7 finished with value: 0.6716387941639014 and parameters: {'iterations': 866, 'depth': 4, 'learning_rate': 0.1664971250872358, 'random_strength': 49, 'bagging_temperature': 0.8292910859770268, 'l2_leaf_reg': 1.7564336700825152e-07, 'border_count': 211, 'grow_policy': 'Lossguide'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:10,528] Trial 8 finished with value: 0.6791223791064724 and parameters: {'iterations': 572, 'depth': 7, 'learning_rate': 0.20342767316506732, 'random_strength': 24, 'bagging_temperature': 0.784238799693573, 'l2_leaf_reg': 4.1612319585416915e-05, 'border_count': 99, 'grow_policy': 'SymmetricTree'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:13,341] Trial 9 finished with value: 0.7135864850626249 and parameters: {'iterations': 307, 'depth': 10, 'learning_rate': 0.14734713016250497, 'random_strength': 21, 'bagging_temperature': 0.37362070972843764, 'l2_leaf_reg': 2.0927343756644043e-06, 'border_count': 85, 'grow_policy': 'SymmetricTree'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:16,540] Trial 10 finished with value: 0.6775240357137507 and parameters: {'iterations': 1198, 'depth': 4, 'learning_rate': 0.1721682130159398, 'random_strength': 39, 'bagging_temperature': 0.9973058055677871, 'l2_leaf_reg': 4.170868568132561e-07, 'border_count': 221, 'grow_policy': 'Lossguide'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:20,433] Trial 11 finished with value: 0.6824948533439246 and parameters: {'iterations': 1119, 'depth': 4, 'learning_rate': 0.16984428747220917, 'random_strength': 41, 'bagging_temperature': 0.9871570413661901, 'l2_leaf_reg': 3.4997130998588694e-07, 'border_count': 223, 'grow_policy': 'Lossguide'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:25,373] Trial 12 finished with value: 0.6731539732199394 and parameters: {'iterations': 842, 'depth': 5, 'learning_rate': 0.10622682538580298, 'random_strength': 50, 'bagging_temperature': 0.9867580584823419, 'l2_leaf_reg': 6.217407998414841e-07, 'border_count': 201, 'grow_policy': 'Lossguide'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:30,772] Trial 13 finished with value: 0.6743015798929319 and parameters: {'iterations': 786, 'depth': 5, 'learning_rate': 0.10732607824685227, 'random_strength': 50, 'bagging_temperature': 0.811842920325922, 'l2_leaf_reg': 7.293411784755857e-07, 'border_count': 190, 'grow_policy': 'Lossguide'}. Best is trial 7 with value: 0.6716387941639014.\n",
      "[I 2023-12-07 22:22:35,491] Trial 14 finished with value: 0.6568234085979129 and parameters: {'iterations': 793, 'depth': 5, 'learning_rate': 0.10464928167566688, 'random_strength': 33, 'bagging_temperature': 0.6590321074053476, 'l2_leaf_reg': 1.0162004476170724e-07, 'border_count': 192, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:22:38,664] Trial 15 finished with value: 0.6790885862761988 and parameters: {'iterations': 685, 'depth': 5, 'learning_rate': 0.18753644945227868, 'random_strength': 32, 'bagging_temperature': 0.6232343796528178, 'l2_leaf_reg': 1.4629083804693186e-07, 'border_count': 183, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:22:43,474] Trial 16 finished with value: 0.6703653562348609 and parameters: {'iterations': 936, 'depth': 6, 'learning_rate': 0.12402839809996324, 'random_strength': 18, 'bagging_temperature': 0.6645819276279834, 'l2_leaf_reg': 2.3213233421564246e-07, 'border_count': 249, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:22:48,957] Trial 17 finished with value: 0.6694443921263522 and parameters: {'iterations': 995, 'depth': 6, 'learning_rate': 0.10111280171333888, 'random_strength': 18, 'bagging_temperature': 0.6307772188755764, 'l2_leaf_reg': 2.9933507823172494e-07, 'border_count': 243, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:22:54,609] Trial 18 finished with value: 0.6726135081002392 and parameters: {'iterations': 714, 'depth': 8, 'learning_rate': 0.10136406271013235, 'random_strength': 16, 'bagging_temperature': 0.5306266199124431, 'l2_leaf_reg': 1.1205996533759717e-07, 'border_count': 180, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:22:59,179] Trial 19 finished with value: 0.6767367581298915 and parameters: {'iterations': 1030, 'depth': 6, 'learning_rate': 0.12753489911394378, 'random_strength': 28, 'bagging_temperature': 0.4432383737029304, 'l2_leaf_reg': 8.943386829204133e-07, 'border_count': 235, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:23:03,589] Trial 20 finished with value: 0.6630500590940722 and parameters: {'iterations': 1019, 'depth': 8, 'learning_rate': 0.11398700062345787, 'random_strength': 7, 'bagging_temperature': 0.6033815493502822, 'l2_leaf_reg': 3.1882648791095897e-07, 'border_count': 170, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:23:07,352] Trial 21 finished with value: 0.6906734829322084 and parameters: {'iterations': 1025, 'depth': 8, 'learning_rate': 0.1146534303361593, 'random_strength': 5, 'bagging_temperature': 0.5992838313335062, 'l2_leaf_reg': 2.698139017625817e-07, 'border_count': 159, 'grow_policy': 'Lossguide'}. Best is trial 14 with value: 0.6568234085979129.\n",
      "[I 2023-12-07 22:23:12,759] Trial 22 finished with value: 0.6482963252852505 and parameters: {'iterations': 948, 'depth': 8, 'learning_rate': 0.11810735473472185, 'random_strength': 11, 'bagging_temperature': 0.7174426771017643, 'l2_leaf_reg': 3.978715196464701e-07, 'border_count': 177, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:18,324] Trial 23 finished with value: 0.6580451015070998 and parameters: {'iterations': 803, 'depth': 8, 'learning_rate': 0.11866804892946947, 'random_strength': 9, 'bagging_temperature': 0.7084023120446455, 'l2_leaf_reg': 5.199810341303698e-07, 'border_count': 176, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:22,518] Trial 24 finished with value: 0.6494680163267945 and parameters: {'iterations': 642, 'depth': 9, 'learning_rate': 0.14585339949169832, 'random_strength': 0, 'bagging_temperature': 0.7134061761563725, 'l2_leaf_reg': 1.0366833961403121e-07, 'border_count': 136, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:25,979] Trial 25 finished with value: 0.695323373855761 and parameters: {'iterations': 646, 'depth': 9, 'learning_rate': 0.14422340024763813, 'random_strength': 0, 'bagging_temperature': 0.7796666133126663, 'l2_leaf_reg': 1.1084718914693646e-07, 'border_count': 130, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:30,796] Trial 26 finished with value: 0.6907035226032021 and parameters: {'iterations': 748, 'depth': 9, 'learning_rate': 0.15131519778790933, 'random_strength': 12, 'bagging_temperature': 0.7326760840497866, 'l2_leaf_reg': 1.0616753490042206e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:35,685] Trial 27 finished with value: 0.6559966842264948 and parameters: {'iterations': 905, 'depth': 9, 'learning_rate': 0.13235876910555058, 'random_strength': 4, 'bagging_temperature': 0.7307993150038903, 'l2_leaf_reg': 2.1851093781148896e-07, 'border_count': 200, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:40,089] Trial 28 finished with value: 0.7105706852443346 and parameters: {'iterations': 911, 'depth': 9, 'learning_rate': 0.13535642976892345, 'random_strength': 4, 'bagging_temperature': 0.8881645408848965, 'l2_leaf_reg': 1.9790157350820945e-07, 'border_count': 143, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:42,373] Trial 29 finished with value: 0.67539585266463 and parameters: {'iterations': 629, 'depth': 10, 'learning_rate': 0.1581258211023083, 'random_strength': 1, 'bagging_temperature': 0.8911337524858323, 'l2_leaf_reg': 4.5498814888472245e-07, 'border_count': 109, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:48,181] Trial 30 finished with value: 0.6900872197505857 and parameters: {'iterations': 875, 'depth': 9, 'learning_rate': 0.1251517728407316, 'random_strength': 13, 'bagging_temperature': 0.7345012370191404, 'l2_leaf_reg': 1.139554878650206e-06, 'border_count': 164, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:52,432] Trial 31 finished with value: 0.6738522143776094 and parameters: {'iterations': 801, 'depth': 8, 'learning_rate': 0.13466056921146516, 'random_strength': 5, 'bagging_temperature': 0.7240951742278285, 'l2_leaf_reg': 1.8094691499553433e-07, 'border_count': 199, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:23:58,967] Trial 32 finished with value: 0.6692226957697064 and parameters: {'iterations': 958, 'depth': 9, 'learning_rate': 0.11699771203011926, 'random_strength': 36, 'bagging_temperature': 0.7743808633735826, 'l2_leaf_reg': 1.020142085284734e-07, 'border_count': 193, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:03,576] Trial 33 finished with value: 0.6901671643206378 and parameters: {'iterations': 1094, 'depth': 10, 'learning_rate': 0.12551923179931812, 'random_strength': 9, 'bagging_temperature': 0.8714012408496444, 'l2_leaf_reg': 2.046760743325252e-07, 'border_count': 143, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:08,425] Trial 34 finished with value: 0.6916893820804487 and parameters: {'iterations': 739, 'depth': 8, 'learning_rate': 0.1400457236447964, 'random_strength': 31, 'bagging_temperature': 0.6678757140358798, 'l2_leaf_reg': 2.9933227382211076e-07, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:13,228] Trial 35 finished with value: 0.7032707112965748 and parameters: {'iterations': 831, 'depth': 9, 'learning_rate': 0.13161878415973852, 'random_strength': 3, 'bagging_temperature': 0.5766166198696869, 'l2_leaf_reg': 1.4838937619103026e-07, 'border_count': 209, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:14,685] Trial 36 finished with value: 0.6884535592791416 and parameters: {'iterations': 633, 'depth': 7, 'learning_rate': 0.15279100760148653, 'random_strength': 0, 'bagging_temperature': 0.6784505817267092, 'l2_leaf_reg': 4.721505179365792e-07, 'border_count': 151, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:20,071] Trial 37 finished with value: 0.6711782155241949 and parameters: {'iterations': 887, 'depth': 7, 'learning_rate': 0.11368492007074171, 'random_strength': 12, 'bagging_temperature': 0.8624905038447128, 'l2_leaf_reg': 6.246233560297752e-06, 'border_count': 170, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:25,254] Trial 38 finished with value: 0.7008376529380297 and parameters: {'iterations': 971, 'depth': 10, 'learning_rate': 0.1436432402417224, 'random_strength': 26, 'bagging_temperature': 0.920702296109381, 'l2_leaf_reg': 1.4227264625749892e-07, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:26,847] Trial 39 finished with value: 0.6622573031550824 and parameters: {'iterations': 513, 'depth': 8, 'learning_rate': 0.13214425021689277, 'random_strength': 7, 'bagging_temperature': 0.8180770588141039, 'l2_leaf_reg': 2.4554455521852875e-07, 'border_count': 214, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:32,709] Trial 40 finished with value: 0.6734253210937664 and parameters: {'iterations': 434, 'depth': 9, 'learning_rate': 0.12114897714460512, 'random_strength': 23, 'bagging_temperature': 0.7717383041170349, 'l2_leaf_reg': 7.218678225861774e-07, 'border_count': 227, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:37,985] Trial 41 finished with value: 0.6518058505474209 and parameters: {'iterations': 807, 'depth': 8, 'learning_rate': 0.1191914593568764, 'random_strength': 9, 'bagging_temperature': 0.6966037564109745, 'l2_leaf_reg': 5.151777966578392e-07, 'border_count': 178, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:43,389] Trial 42 finished with value: 0.660865291444202 and parameters: {'iterations': 772, 'depth': 7, 'learning_rate': 0.11088236806354593, 'random_strength': 15, 'bagging_temperature': 0.6651580986828654, 'l2_leaf_reg': 3.940057351786417e-07, 'border_count': 189, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:48,611] Trial 43 finished with value: 0.6567952100057667 and parameters: {'iterations': 678, 'depth': 8, 'learning_rate': 0.11941193551599998, 'random_strength': 7, 'bagging_temperature': 0.7455139661449168, 'l2_leaf_reg': 1.5251281573771437e-07, 'border_count': 153, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:53,898] Trial 44 finished with value: 0.6965960385419753 and parameters: {'iterations': 579, 'depth': 8, 'learning_rate': 0.1382606739573044, 'random_strength': 7, 'bagging_temperature': 0.8321054446475957, 'l2_leaf_reg': 2.113913123373671e-07, 'border_count': 153, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:24:55,574] Trial 45 finished with value: 0.7045178947914451 and parameters: {'iterations': 672, 'depth': 8, 'learning_rate': 0.12086691504109297, 'random_strength': 10, 'bagging_temperature': 0.7379335593646583, 'l2_leaf_reg': 1.5443473562607915e-07, 'border_count': 130, 'grow_policy': 'SymmetricTree'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:25:00,552] Trial 46 finished with value: 0.657497283078427 and parameters: {'iterations': 709, 'depth': 9, 'learning_rate': 0.1285409090122937, 'random_strength': 3, 'bagging_temperature': 0.5585709439307242, 'l2_leaf_reg': 3.8569782907108e-07, 'border_count': 166, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:25:04,258] Trial 47 finished with value: 0.6731509683165593 and parameters: {'iterations': 578, 'depth': 7, 'learning_rate': 0.11230992799993833, 'random_strength': 6, 'bagging_temperature': 0.7083810402310613, 'l2_leaf_reg': 1.0517279991954006e-06, 'border_count': 133, 'grow_policy': 'Lossguide'}. Best is trial 22 with value: 0.6482963252852505.\n",
      "[I 2023-12-07 22:25:08,863] Trial 48 finished with value: 0.6378064978427013 and parameters: {'iterations': 914, 'depth': 9, 'learning_rate': 0.13939416258078766, 'random_strength': 2, 'bagging_temperature': 0.9451553733981317, 'l2_leaf_reg': 2.622092167993516e-07, 'border_count': 116, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:12,472] Trial 49 finished with value: 0.7093641691923049 and parameters: {'iterations': 1084, 'depth': 10, 'learning_rate': 0.15959922586757785, 'random_strength': 2, 'bagging_temperature': 0.9323695670542446, 'l2_leaf_reg': 6.02802806080124e-07, 'border_count': 92, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:14,994] Trial 50 finished with value: 0.699913874355989 and parameters: {'iterations': 914, 'depth': 9, 'learning_rate': 0.14008859940071722, 'random_strength': 10, 'bagging_temperature': 0.9585287456450193, 'l2_leaf_reg': 1.6379049605964126e-06, 'border_count': 112, 'grow_policy': 'SymmetricTree'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:19,856] Trial 51 finished with value: 0.640563113740546 and parameters: {'iterations': 843, 'depth': 8, 'learning_rate': 0.12932086572019685, 'random_strength': 2, 'bagging_temperature': 0.8080209596484279, 'l2_leaf_reg': 2.6605603416449126e-07, 'border_count': 139, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:28,269] Trial 52 finished with value: 0.6746792942064733 and parameters: {'iterations': 852, 'depth': 9, 'learning_rate': 0.12979481866567885, 'random_strength': 2, 'bagging_temperature': 0.818474520278915, 'l2_leaf_reg': 2.573928068829035e-07, 'border_count': 103, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:35,017] Trial 53 finished with value: 0.6688848680675659 and parameters: {'iterations': 945, 'depth': 9, 'learning_rate': 0.1436163770914185, 'random_strength': 0, 'bagging_temperature': 0.8499972222716229, 'l2_leaf_reg': 3.3854675889225134e-07, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:40,314] Trial 54 finished with value: 0.6726286195394273 and parameters: {'iterations': 824, 'depth': 8, 'learning_rate': 0.10822338177083367, 'random_strength': 4, 'bagging_temperature': 0.7967410049051349, 'l2_leaf_reg': 5.508887265393341e-07, 'border_count': 120, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:45,902] Trial 55 finished with value: 0.6473312693923513 and parameters: {'iterations': 898, 'depth': 7, 'learning_rate': 0.13399293047357036, 'random_strength': 2, 'bagging_temperature': 0.630835390179174, 'l2_leaf_reg': 1.9322092234405725e-07, 'border_count': 177, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:51,348] Trial 56 finished with value: 0.668283994936902 and parameters: {'iterations': 984, 'depth': 7, 'learning_rate': 0.12503551872753, 'random_strength': 15, 'bagging_temperature': 0.6294970597596982, 'l2_leaf_reg': 3.6237302512929735e-07, 'border_count': 180, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:25:57,498] Trial 57 finished with value: 0.6733659762937685 and parameters: {'iterations': 875, 'depth': 7, 'learning_rate': 0.14783089398289767, 'random_strength': 20, 'bagging_temperature': 0.6340270862242333, 'l2_leaf_reg': 1.338908191463088e-07, 'border_count': 146, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:01,494] Trial 58 finished with value: 0.6793056914230657 and parameters: {'iterations': 1067, 'depth': 6, 'learning_rate': 0.13629754450627235, 'random_strength': 2, 'bagging_temperature': 0.6850660801377626, 'l2_leaf_reg': 2.683345582622607e-07, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:08,653] Trial 59 finished with value: 0.6574201102870264 and parameters: {'iterations': 764, 'depth': 7, 'learning_rate': 0.10001617423127032, 'random_strength': 47, 'bagging_temperature': 0.7604576869655801, 'l2_leaf_reg': 1.7751503575531924e-07, 'border_count': 158, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:13,513] Trial 60 finished with value: 0.6869747944707543 and parameters: {'iterations': 835, 'depth': 8, 'learning_rate': 0.1062295453495832, 'random_strength': 8, 'bagging_temperature': 0.7992889314018958, 'l2_leaf_reg': 4.5647990848666093e-07, 'border_count': 174, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:19,764] Trial 61 finished with value: 0.6826589558608396 and parameters: {'iterations': 903, 'depth': 9, 'learning_rate': 0.13056836071669226, 'random_strength': 5, 'bagging_temperature': 0.6997410992721995, 'l2_leaf_reg': 2.3162868821685054e-07, 'border_count': 199, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:24,735] Trial 62 finished with value: 0.6624912319049827 and parameters: {'iterations': 928, 'depth': 8, 'learning_rate': 0.13386481777677112, 'random_strength': 4, 'bagging_temperature': 0.7698155121640986, 'l2_leaf_reg': 1.25733273679373e-07, 'border_count': 187, 'grow_policy': 'Lossguide'}. Best is trial 48 with value: 0.6378064978427013.\n",
      "[I 2023-12-07 22:26:29,864] Trial 63 finished with value: 0.6242893415293588 and parameters: {'iterations': 1002, 'depth': 10, 'learning_rate': 0.12296237125377069, 'random_strength': 0, 'bagging_temperature': 0.7056556153368084, 'l2_leaf_reg': 2.995883039377535e-07, 'border_count': 125, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:35,297] Trial 64 finished with value: 0.6543126948431314 and parameters: {'iterations': 1056, 'depth': 10, 'learning_rate': 0.12293658369828525, 'random_strength': 1, 'bagging_temperature': 0.6505015341481573, 'l2_leaf_reg': 6.809541670322675e-07, 'border_count': 124, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:39,567] Trial 65 finished with value: 0.6482495018172246 and parameters: {'iterations': 988, 'depth': 10, 'learning_rate': 0.11524751644470686, 'random_strength': 0, 'bagging_temperature': 0.6962783354327186, 'l2_leaf_reg': 3.1485912948091086e-07, 'border_count': 114, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:43,453] Trial 66 finished with value: 0.677599874502746 and parameters: {'iterations': 1132, 'depth': 10, 'learning_rate': 0.11748261559085026, 'random_strength': 0, 'bagging_temperature': 0.5956799231535587, 'l2_leaf_reg': 2.9778412611004075e-07, 'border_count': 115, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:48,896] Trial 67 finished with value: 0.6274019483335708 and parameters: {'iterations': 981, 'depth': 10, 'learning_rate': 0.12678464615854323, 'random_strength': 2, 'bagging_temperature': 0.8399121772710543, 'l2_leaf_reg': 1.907616903888917e-07, 'border_count': 124, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:53,407] Trial 68 finished with value: 0.6589619961090442 and parameters: {'iterations': 1003, 'depth': 10, 'learning_rate': 0.11157235194232946, 'random_strength': 3, 'bagging_temperature': 0.8510822918373498, 'l2_leaf_reg': 1.8184030163319215e-07, 'border_count': 103, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:26:55,789] Trial 69 finished with value: 0.7037610446009558 and parameters: {'iterations': 959, 'depth': 10, 'learning_rate': 0.12483723114670169, 'random_strength': 2, 'bagging_temperature': 0.9161575114181582, 'l2_leaf_reg': 3.5651634900317204e-07, 'border_count': 127, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:01,758] Trial 70 finished with value: 0.6555380747893099 and parameters: {'iterations': 1003, 'depth': 10, 'learning_rate': 0.11536883056608613, 'random_strength': 6, 'bagging_temperature': 0.8948550798599856, 'l2_leaf_reg': 2.8454903246441046e-07, 'border_count': 95, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:06,304] Trial 71 finished with value: 0.6438505488879818 and parameters: {'iterations': 1050, 'depth': 10, 'learning_rate': 0.12819977870992613, 'random_strength': 0, 'bagging_temperature': 0.809119424407054, 'l2_leaf_reg': 1.901376074296609e-07, 'border_count': 140, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:11,251] Trial 72 finished with value: 0.6573344128702275 and parameters: {'iterations': 1044, 'depth': 10, 'learning_rate': 0.12836268255326405, 'random_strength': 1, 'bagging_temperature': 0.8340075239843114, 'l2_leaf_reg': 2.1041245054287288e-07, 'border_count': 116, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:16,625] Trial 73 finished with value: 0.6746840310101576 and parameters: {'iterations': 1151, 'depth': 10, 'learning_rate': 0.1245463259715288, 'random_strength': 5, 'bagging_temperature': 0.7991415245273978, 'l2_leaf_reg': 4.1091225927239e-07, 'border_count': 108, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:22,002] Trial 74 finished with value: 0.6644028081764521 and parameters: {'iterations': 1022, 'depth': 10, 'learning_rate': 0.10476845642634333, 'random_strength': 3, 'bagging_temperature': 0.7548330993149226, 'l2_leaf_reg': 1.7730013883530424e-07, 'border_count': 148, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:26,337] Trial 75 finished with value: 0.6747137737485159 and parameters: {'iterations': 981, 'depth': 10, 'learning_rate': 0.11628402435760878, 'random_strength': 0, 'bagging_temperature': 0.7921627122665401, 'l2_leaf_reg': 2.447522668602795e-07, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:31,147] Trial 76 finished with value: 0.7062275796242543 and parameters: {'iterations': 927, 'depth': 10, 'learning_rate': 0.1372730279822411, 'random_strength': 2, 'bagging_temperature': 0.8871201729761208, 'l2_leaf_reg': 1.189393233567414e-07, 'border_count': 122, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:37,523] Trial 77 finished with value: 0.6579046521838294 and parameters: {'iterations': 889, 'depth': 10, 'learning_rate': 0.12118230115688507, 'random_strength': 6, 'bagging_temperature': 0.8592292149537769, 'l2_leaf_reg': 3.32781402408651e-07, 'border_count': 84, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:43,666] Trial 78 finished with value: 0.6751346890338569 and parameters: {'iterations': 956, 'depth': 10, 'learning_rate': 0.10885158159940851, 'random_strength': 11, 'bagging_temperature': 0.7281305367887959, 'l2_leaf_reg': 2.1126854695595353e-07, 'border_count': 134, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:47,755] Trial 79 finished with value: 0.6515188755920167 and parameters: {'iterations': 1081, 'depth': 9, 'learning_rate': 0.1280889943421752, 'random_strength': 4, 'bagging_temperature': 0.819107857370768, 'l2_leaf_reg': 2.856719683754089e-07, 'border_count': 127, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:51,686] Trial 80 finished with value: 0.675087015904145 and parameters: {'iterations': 1194, 'depth': 9, 'learning_rate': 0.13404235881803533, 'random_strength': 1, 'bagging_temperature': 0.7575579769167833, 'l2_leaf_reg': 1.6611375360234493e-07, 'border_count': 161, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:27:55,252] Trial 81 finished with value: 0.655575203558102 and parameters: {'iterations': 858, 'depth': 6, 'learning_rate': 0.13942632310398903, 'random_strength': 0, 'bagging_temperature': 0.7151404935496385, 'l2_leaf_reg': 1.019599455766048e-07, 'border_count': 139, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:00,074] Trial 82 finished with value: 0.637285869814281 and parameters: {'iterations': 1112, 'depth': 9, 'learning_rate': 0.130304945354861, 'random_strength': 3, 'bagging_temperature': 0.690519884741365, 'l2_leaf_reg': 1.2489262793491484e-07, 'border_count': 108, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:04,686] Trial 83 finished with value: 0.6581055836635801 and parameters: {'iterations': 1120, 'depth': 10, 'learning_rate': 0.12272799188448846, 'random_strength': 3, 'bagging_temperature': 0.6828845786692194, 'l2_leaf_reg': 1.2947355426877783e-07, 'border_count': 108, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:09,856] Trial 84 finished with value: 0.6701288586969987 and parameters: {'iterations': 1039, 'depth': 10, 'learning_rate': 0.12889785863090672, 'random_strength': 6, 'bagging_temperature': 0.6588813576943631, 'l2_leaf_reg': 1.4652952895233316e-07, 'border_count': 101, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:15,965] Trial 85 finished with value: 0.675385529628759 and parameters: {'iterations': 1164, 'depth': 9, 'learning_rate': 0.11447772541522837, 'random_strength': 4, 'bagging_temperature': 0.7798218466635519, 'l2_leaf_reg': 2.3450564822366235e-07, 'border_count': 118, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:17,678] Trial 86 finished with value: 0.7007046827161679 and parameters: {'iterations': 1096, 'depth': 7, 'learning_rate': 0.11909976841645584, 'random_strength': 8, 'bagging_temperature': 0.7000958830673301, 'l2_leaf_reg': 1.986305261578394e-07, 'border_count': 128, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:21,555] Trial 87 finished with value: 0.699968380163425 and parameters: {'iterations': 1007, 'depth': 9, 'learning_rate': 0.1344798740378183, 'random_strength': 1, 'bagging_temperature': 0.747453462045176, 'l2_leaf_reg': 4.0666034365924976e-07, 'border_count': 112, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:26,665] Trial 88 finished with value: 0.6515509554627884 and parameters: {'iterations': 970, 'depth': 10, 'learning_rate': 0.12565504609849287, 'random_strength': 5, 'bagging_temperature': 0.9618692248665992, 'l2_leaf_reg': 1.6430350643320668e-07, 'border_count': 143, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:31,243] Trial 89 finished with value: 0.6446975383225748 and parameters: {'iterations': 1058, 'depth': 9, 'learning_rate': 0.13140226167151695, 'random_strength': 3, 'bagging_temperature': 0.8352968348050747, 'l2_leaf_reg': 1.235692259906787e-07, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:35,141] Trial 90 finished with value: 0.6491805183164896 and parameters: {'iterations': 1101, 'depth': 9, 'learning_rate': 0.1415877990096084, 'random_strength': 3, 'bagging_temperature': 0.8481934332503872, 'l2_leaf_reg': 1.2363278350630485e-07, 'border_count': 90, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:39,146] Trial 91 finished with value: 0.6745866483946563 and parameters: {'iterations': 1058, 'depth': 9, 'learning_rate': 0.13204094037707106, 'random_strength': 1, 'bagging_temperature': 0.8193899159322895, 'l2_leaf_reg': 3.0382819662672413e-07, 'border_count': 134, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:44,047] Trial 92 finished with value: 0.6269179794132739 and parameters: {'iterations': 310, 'depth': 10, 'learning_rate': 0.12749763504084438, 'random_strength': 0, 'bagging_temperature': 0.8743444254672265, 'l2_leaf_reg': 1.8981302464453399e-07, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:47,892] Trial 93 finished with value: 0.6663339488211037 and parameters: {'iterations': 1026, 'depth': 10, 'learning_rate': 0.13061619625707152, 'random_strength': 2, 'bagging_temperature': 0.872032325279177, 'l2_leaf_reg': 1.4417001872170324e-07, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:53,075] Trial 94 finished with value: 0.6949055346836012 and parameters: {'iterations': 933, 'depth': 10, 'learning_rate': 0.13687877053739927, 'random_strength': 39, 'bagging_temperature': 0.9051339878891144, 'l2_leaf_reg': 1.6787782256664197e-07, 'border_count': 71, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:28:57,318] Trial 95 finished with value: 0.633840631156941 and parameters: {'iterations': 443, 'depth': 10, 'learning_rate': 0.12677570997305848, 'random_strength': 0, 'bagging_temperature': 0.9403342283896884, 'l2_leaf_reg': 1.9747565588541826e-07, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:01,455] Trial 96 finished with value: 0.677470842425069 and parameters: {'iterations': 306, 'depth': 9, 'learning_rate': 0.1274198843894248, 'random_strength': 2, 'bagging_temperature': 0.9364553230859922, 'l2_leaf_reg': 1.943080257277394e-07, 'border_count': 52, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:06,816] Trial 97 finished with value: 0.6660708522640187 and parameters: {'iterations': 341, 'depth': 10, 'learning_rate': 0.12198958661956436, 'random_strength': 5, 'bagging_temperature': 0.975635145984356, 'l2_leaf_reg': 1.1654706234425677e-07, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:11,120] Trial 98 finished with value: 0.6822285440133635 and parameters: {'iterations': 381, 'depth': 10, 'learning_rate': 0.13265565389130643, 'random_strength': 0, 'bagging_temperature': 0.9451119919023881, 'l2_leaf_reg': 1.3842351055613935e-07, 'border_count': 76, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:12,559] Trial 99 finished with value: 0.6897982532943536 and parameters: {'iterations': 446, 'depth': 9, 'learning_rate': 0.13756011654478478, 'random_strength': 4, 'bagging_temperature': 0.8781166597061165, 'l2_leaf_reg': 2.643357637686798e-07, 'border_count': 59, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:17,855] Trial 100 finished with value: 0.6626796238684436 and parameters: {'iterations': 475, 'depth': 10, 'learning_rate': 0.1467495678713463, 'random_strength': 8, 'bagging_temperature': 0.9929958047065509, 'l2_leaf_reg': 2.3219606081785404e-07, 'border_count': 78, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:21,937] Trial 101 finished with value: 0.6299454717885826 and parameters: {'iterations': 340, 'depth': 10, 'learning_rate': 0.14078542624648663, 'random_strength': 0, 'bagging_temperature': 0.9133554686812361, 'l2_leaf_reg': 1.934847927630374e-07, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:25,702] Trial 102 finished with value: 0.6915631321843712 and parameters: {'iterations': 334, 'depth': 10, 'learning_rate': 0.1424691932439705, 'random_strength': 1, 'bagging_temperature': 0.9113831943294, 'l2_leaf_reg': 1.8903110886264868e-07, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:30,101] Trial 103 finished with value: 0.6440453088847498 and parameters: {'iterations': 379, 'depth': 10, 'learning_rate': 0.14023390025816326, 'random_strength': 3, 'bagging_temperature': 0.9270361315642339, 'l2_leaf_reg': 1.6006819671886159e-07, 'border_count': 86, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:34,620] Trial 104 finished with value: 0.6545926979228895 and parameters: {'iterations': 390, 'depth': 10, 'learning_rate': 0.14073241747592577, 'random_strength': 2, 'bagging_temperature': 0.9350202885705637, 'l2_leaf_reg': 1.607597086395958e-07, 'border_count': 66, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:38,413] Trial 105 finished with value: 0.7318938728458594 and parameters: {'iterations': 334, 'depth': 10, 'learning_rate': 0.12661980177190274, 'random_strength': 3, 'bagging_temperature': 0.9014108980034246, 'l2_leaf_reg': 1.194984166019276e-07, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:42,456] Trial 106 finished with value: 0.654149200851228 and parameters: {'iterations': 369, 'depth': 10, 'learning_rate': 0.14493705902933862, 'random_strength': 0, 'bagging_temperature': 0.8716350107934187, 'l2_leaf_reg': 2.4397446233527064e-07, 'border_count': 88, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:46,655] Trial 107 finished with value: 0.647058253381031 and parameters: {'iterations': 359, 'depth': 10, 'learning_rate': 0.13070750964847716, 'random_strength': 1, 'bagging_temperature': 0.8428902049614564, 'l2_leaf_reg': 1.3449038236884017e-07, 'border_count': 71, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:51,163] Trial 108 finished with value: 0.6887795785718458 and parameters: {'iterations': 301, 'depth': 9, 'learning_rate': 0.1365602761924048, 'random_strength': 3, 'bagging_temperature': 0.9678278371685971, 'l2_leaf_reg': 1.0207147540217685e-07, 'border_count': 87, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:55,757] Trial 109 finished with value: 0.6887530358015892 and parameters: {'iterations': 394, 'depth': 10, 'learning_rate': 0.12308314988891364, 'random_strength': 7, 'bagging_temperature': 0.9220568949484766, 'l2_leaf_reg': 2.1801321708127805e-07, 'border_count': 96, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:29:59,537] Trial 110 finished with value: 0.6696826733755732 and parameters: {'iterations': 328, 'depth': 10, 'learning_rate': 0.1492459275025782, 'random_strength': 4, 'bagging_temperature': 0.9513312031414946, 'l2_leaf_reg': 1.552734590816096e-07, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:03,642] Trial 111 finished with value: 0.6576839455601698 and parameters: {'iterations': 356, 'depth': 10, 'learning_rate': 0.12946602327314494, 'random_strength': 1, 'bagging_temperature': 0.8491102353547543, 'l2_leaf_reg': 1.3732490445087502e-07, 'border_count': 72, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:07,706] Trial 112 finished with value: 0.7014798195822508 and parameters: {'iterations': 431, 'depth': 10, 'learning_rate': 0.13953984077168036, 'random_strength': 1, 'bagging_temperature': 0.8046384770819276, 'l2_leaf_reg': 1.2961633470817074e-07, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:13,232] Trial 113 finished with value: 0.6657778746176679 and parameters: {'iterations': 414, 'depth': 10, 'learning_rate': 0.1312046528306665, 'random_strength': 5, 'bagging_temperature': 0.8325524539113562, 'l2_leaf_reg': 1.8110645912884213e-07, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:17,799] Trial 114 finished with value: 0.6709765762992967 and parameters: {'iterations': 370, 'depth': 10, 'learning_rate': 0.12688405083325763, 'random_strength': 0, 'bagging_temperature': 0.9027694680159217, 'l2_leaf_reg': 1.1304782857278526e-07, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:23,303] Trial 115 finished with value: 0.6911422638335657 and parameters: {'iterations': 319, 'depth': 9, 'learning_rate': 0.11930332053347847, 'random_strength': 30, 'bagging_temperature': 0.8853068726599357, 'l2_leaf_reg': 2.654358590858788e-07, 'border_count': 82, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:27,307] Trial 116 finished with value: 0.7096751431728532 and parameters: {'iterations': 361, 'depth': 10, 'learning_rate': 0.13418029485549923, 'random_strength': 3, 'bagging_temperature': 0.8646922711093621, 'l2_leaf_reg': 2.133489529845011e-07, 'border_count': 55, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:31,451] Trial 117 finished with value: 0.6913068813437612 and parameters: {'iterations': 407, 'depth': 10, 'learning_rate': 0.1242266673811237, 'random_strength': 1, 'bagging_temperature': 0.8448505844191027, 'l2_leaf_reg': 1.506142187846052e-07, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:35,462] Trial 118 finished with value: 0.6953504651253309 and parameters: {'iterations': 450, 'depth': 10, 'learning_rate': 0.1435961280220175, 'random_strength': 6, 'bagging_temperature': 0.9989072438994313, 'l2_leaf_reg': 1.6683714062104075e-07, 'border_count': 123, 'grow_policy': 'Lossguide'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:36,901] Trial 119 finished with value: 0.6923160056253007 and parameters: {'iterations': 345, 'depth': 9, 'learning_rate': 0.1305223293303435, 'random_strength': 2, 'bagging_temperature': 0.9217656070765295, 'l2_leaf_reg': 3.3370232861795946e-07, 'border_count': 70, 'grow_policy': 'SymmetricTree'}. Best is trial 63 with value: 0.6242893415293588.\n",
      "[I 2023-12-07 22:30:41,090] Trial 120 finished with value: 0.6220721099688813 and parameters: {'iterations': 1074, 'depth': 10, 'learning_rate': 0.13682421987984852, 'random_strength': 0, 'bagging_temperature': 0.8337678755830845, 'l2_leaf_reg': 1.916954546134245e-07, 'border_count': 51, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:30:44,715] Trial 121 finished with value: 0.6735952517197522 and parameters: {'iterations': 1067, 'depth': 10, 'learning_rate': 0.13658019792404327, 'random_strength': 0, 'bagging_temperature': 0.8302314212686733, 'l2_leaf_reg': 1.9406656846244127e-07, 'border_count': 52, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:30:49,597] Trial 122 finished with value: 0.6626922182851239 and parameters: {'iterations': 537, 'depth': 10, 'learning_rate': 0.1397929859887921, 'random_strength': 2, 'bagging_temperature': 0.8083735843436625, 'l2_leaf_reg': 2.3804040623675436e-07, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:30:54,036] Trial 123 finished with value: 0.6514880921057838 and parameters: {'iterations': 1118, 'depth': 10, 'learning_rate': 0.13375574567368695, 'random_strength': 0, 'bagging_temperature': 0.7835136406984929, 'l2_leaf_reg': 1.001591705144195e-07, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:30:58,484] Trial 124 finished with value: 0.6463077230338136 and parameters: {'iterations': 1076, 'depth': 10, 'learning_rate': 0.12710906568219604, 'random_strength': 4, 'bagging_temperature': 0.8846709888077228, 'l2_leaf_reg': 2.77639365533418e-07, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:03,285] Trial 125 finished with value: 0.6764689217333673 and parameters: {'iterations': 1045, 'depth': 10, 'learning_rate': 0.12175124210184024, 'random_strength': 4, 'bagging_temperature': 0.8949449338944668, 'l2_leaf_reg': 2.936575131601068e-07, 'border_count': 78, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:08,526] Trial 126 finished with value: 0.6704397561876259 and parameters: {'iterations': 1143, 'depth': 9, 'learning_rate': 0.12722502239690708, 'random_strength': 3, 'bagging_temperature': 0.9449318690519062, 'l2_leaf_reg': 2.6570023390096454e-07, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:13,932] Trial 127 finished with value: 0.6662637265328748 and parameters: {'iterations': 1076, 'depth': 10, 'learning_rate': 0.15045610248608732, 'random_strength': 5, 'bagging_temperature': 0.8685651868852671, 'l2_leaf_reg': 3.678847655754734e-07, 'border_count': 93, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:18,405] Trial 128 finished with value: 0.6695239352644687 and parameters: {'iterations': 1047, 'depth': 10, 'learning_rate': 0.11738778428923327, 'random_strength': 3, 'bagging_temperature': 0.8832388981989016, 'l2_leaf_reg': 4.614023639447294e-07, 'border_count': 104, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:22,427] Trial 129 finished with value: 0.7000049485560756 and parameters: {'iterations': 1016, 'depth': 9, 'learning_rate': 0.12469248234523646, 'random_strength': 2, 'bagging_temperature': 0.9679701100129436, 'l2_leaf_reg': 2.0690303939754146e-07, 'border_count': 142, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:27,193] Trial 130 finished with value: 0.6999002259204313 and parameters: {'iterations': 1111, 'depth': 10, 'learning_rate': 0.1528653137316906, 'random_strength': 6, 'bagging_temperature': 0.9269584289790547, 'l2_leaf_reg': 1.7680724080725202e-07, 'border_count': 131, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:31,601] Trial 131 finished with value: 0.6384908969791799 and parameters: {'iterations': 1083, 'depth': 10, 'learning_rate': 0.13128206990111393, 'random_strength': 1, 'bagging_temperature': 0.8373887059930181, 'l2_leaf_reg': 1.3783568479814124e-07, 'border_count': 73, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:35,359] Trial 132 finished with value: 0.6855997120433092 and parameters: {'iterations': 1087, 'depth': 10, 'learning_rate': 0.1355290343938627, 'random_strength': 0, 'bagging_temperature': 0.8191685374621432, 'l2_leaf_reg': 1.5102992387315148e-07, 'border_count': 148, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:39,576] Trial 133 finished with value: 0.6566600334346897 and parameters: {'iterations': 1066, 'depth': 10, 'learning_rate': 0.12966551595456657, 'random_strength': 1, 'bagging_temperature': 0.7928601823512897, 'l2_leaf_reg': 2.2119362095755406e-07, 'border_count': 85, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:42,825] Trial 134 finished with value: 0.6630795635741926 and parameters: {'iterations': 1165, 'depth': 4, 'learning_rate': 0.12032473760679702, 'random_strength': 4, 'bagging_temperature': 0.8596814956858431, 'l2_leaf_reg': 1.7985617854912233e-07, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:47,086] Trial 135 finished with value: 0.6400795928052884 and parameters: {'iterations': 1024, 'depth': 10, 'learning_rate': 0.13225086351242074, 'random_strength': 2, 'bagging_temperature': 0.9045852985874028, 'l2_leaf_reg': 3.153119782046483e-07, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:51,876] Trial 136 finished with value: 0.6694804919132896 and parameters: {'iterations': 986, 'depth': 10, 'learning_rate': 0.14136288360608842, 'random_strength': 2, 'bagging_temperature': 0.920859136282825, 'l2_leaf_reg': 1.2652740392549743e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:55,602] Trial 137 finished with value: 0.67783911863533 and parameters: {'iterations': 1014, 'depth': 8, 'learning_rate': 0.13291097844007035, 'random_strength': 0, 'bagging_temperature': 0.7745027732748997, 'l2_leaf_reg': 3.212729229619014e-07, 'border_count': 126, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:31:59,783] Trial 138 finished with value: 0.6482158779474997 and parameters: {'iterations': 1034, 'depth': 10, 'learning_rate': 0.14626586260415178, 'random_strength': 2, 'bagging_temperature': 0.8333965517534067, 'l2_leaf_reg': 1.1374950959274941e-07, 'border_count': 63, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:01,939] Trial 139 finished with value: 0.7039364987304406 and parameters: {'iterations': 968, 'depth': 10, 'learning_rate': 0.13685052368239478, 'random_strength': 1, 'bagging_temperature': 0.9467385100011153, 'l2_leaf_reg': 2.419685711540749e-07, 'border_count': 59, 'grow_policy': 'SymmetricTree'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:07,061] Trial 140 finished with value: 0.6775710560545316 and parameters: {'iterations': 994, 'depth': 9, 'learning_rate': 0.13852608718154658, 'random_strength': 3, 'bagging_temperature': 0.8099577423045345, 'l2_leaf_reg': 1.543666772859503e-07, 'border_count': 97, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:11,695] Trial 141 finished with value: 0.6905071488672055 and parameters: {'iterations': 1109, 'depth': 10, 'learning_rate': 0.12740238326508954, 'random_strength': 4, 'bagging_temperature': 0.8846250449842851, 'l2_leaf_reg': 2.747809142803431e-07, 'border_count': 80, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:15,660] Trial 142 finished with value: 0.6847465010538984 and parameters: {'iterations': 1135, 'depth': 10, 'learning_rate': 0.1318005490893262, 'random_strength': 1, 'bagging_temperature': 0.89977135875448, 'l2_leaf_reg': 2.1142283583637024e-07, 'border_count': 70, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:19,587] Trial 143 finished with value: 0.6553698830754197 and parameters: {'iterations': 1085, 'depth': 10, 'learning_rate': 0.12453247179873507, 'random_strength': 0, 'bagging_temperature': 0.8614334852730972, 'l2_leaf_reg': 3.5260191898695405e-07, 'border_count': 79, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:24,832] Trial 144 finished with value: 0.6613091979981415 and parameters: {'iterations': 1064, 'depth': 10, 'learning_rate': 0.12226082654974257, 'random_strength': 3, 'bagging_temperature': 0.9128149209240229, 'l2_leaf_reg': 1.8898063814495473e-07, 'border_count': 90, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:29,085] Trial 145 finished with value: 0.6468115671390062 and parameters: {'iterations': 1034, 'depth': 10, 'learning_rate': 0.12779438709985816, 'random_strength': 2, 'bagging_temperature': 0.982697383421456, 'l2_leaf_reg': 2.4994441294570783e-07, 'border_count': 74, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:34,602] Trial 146 finished with value: 0.6361441680509982 and parameters: {'iterations': 1098, 'depth': 10, 'learning_rate': 0.13493969327654168, 'random_strength': 5, 'bagging_temperature': 0.8425512633576049, 'l2_leaf_reg': 1.6613413572209375e-07, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:40,318] Trial 147 finished with value: 0.6666551392642407 and parameters: {'iterations': 1101, 'depth': 10, 'learning_rate': 0.13417994159716604, 'random_strength': 23, 'bagging_temperature': 0.7521166076176546, 'l2_leaf_reg': 1.375910177049923e-07, 'border_count': 67, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:44,480] Trial 148 finished with value: 0.6854422645104861 and parameters: {'iterations': 726, 'depth': 9, 'learning_rate': 0.14399854001679538, 'random_strength': 1, 'bagging_temperature': 0.845239174456285, 'l2_leaf_reg': 1.7041318841202094e-07, 'border_count': 110, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:48,023] Trial 149 finished with value: 0.6818873690215548 and parameters: {'iterations': 950, 'depth': 5, 'learning_rate': 0.14112579153780486, 'random_strength': 5, 'bagging_temperature': 0.7882169654861078, 'l2_leaf_reg': 1.5806909991286781e-07, 'border_count': 56, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:52,125] Trial 150 finished with value: 0.721070741554694 and parameters: {'iterations': 1051, 'depth': 10, 'learning_rate': 0.1303441317928385, 'random_strength': 0, 'bagging_temperature': 0.8229818743241849, 'l2_leaf_reg': 1.3372458911360568e-07, 'border_count': 138, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:32:56,953] Trial 151 finished with value: 0.6600347151378079 and parameters: {'iterations': 1125, 'depth': 10, 'learning_rate': 0.12548615212366895, 'random_strength': 3, 'bagging_temperature': 0.8784819120000611, 'l2_leaf_reg': 2.9420778158922453e-07, 'border_count': 75, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:01,317] Trial 152 finished with value: 0.6473340765509096 and parameters: {'iterations': 1077, 'depth': 10, 'learning_rate': 0.13474992437328034, 'random_strength': 4, 'bagging_temperature': 0.9027694992706335, 'l2_leaf_reg': 2.155924708663942e-07, 'border_count': 85, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:06,181] Trial 153 finished with value: 0.6245301552470462 and parameters: {'iterations': 1022, 'depth': 10, 'learning_rate': 0.12935358713929343, 'random_strength': 1, 'bagging_temperature': 0.8662712704699426, 'l2_leaf_reg': 1.8266804275541837e-07, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:10,250] Trial 154 finished with value: 0.6639576174052305 and parameters: {'iterations': 1015, 'depth': 10, 'learning_rate': 0.13730854562949038, 'random_strength': 1, 'bagging_temperature': 0.8420113820075261, 'l2_leaf_reg': 1.925484190991342e-07, 'border_count': 68, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:14,403] Trial 155 finished with value: 0.6665212851553515 and parameters: {'iterations': 813, 'depth': 10, 'learning_rate': 0.13198470648424993, 'random_strength': 2, 'bagging_temperature': 0.86494909066501, 'l2_leaf_reg': 1.1570174970992366e-07, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:19,953] Trial 156 finished with value: 0.6761384672037549 and parameters: {'iterations': 998, 'depth': 10, 'learning_rate': 0.12910881800309068, 'random_strength': 18, 'bagging_temperature': 0.936811011730444, 'l2_leaf_reg': 1.6672488128390366e-07, 'border_count': 63, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:26,495] Trial 157 finished with value: 0.6599142742164996 and parameters: {'iterations': 1036, 'depth': 8, 'learning_rate': 0.13922383009353514, 'random_strength': 35, 'bagging_temperature': 0.8034676401904695, 'l2_leaf_reg': 1.4755699120367275e-07, 'border_count': 122, 'grow_policy': 'Lossguide'}. Best is trial 120 with value: 0.6220721099688813.\n",
      "[I 2023-12-07 22:33:31,115] Trial 158 finished with value: 0.6195655802833077 and parameters: {'iterations': 916, 'depth': 10, 'learning_rate': 0.12002762445811731, 'random_strength': 0, 'bagging_temperature': 0.7679563961566029, 'l2_leaf_reg': 1.992909034956101e-07, 'border_count': 106, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:35,300] Trial 159 finished with value: 0.6754153011802645 and parameters: {'iterations': 919, 'depth': 10, 'learning_rate': 0.11846752722428569, 'random_strength': 0, 'bagging_temperature': 0.7714076703148868, 'l2_leaf_reg': 2.3373842555155123e-07, 'border_count': 106, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:40,461] Trial 160 finished with value: 0.6624233431336402 and parameters: {'iterations': 599, 'depth': 10, 'learning_rate': 0.11484334135428095, 'random_strength': 2, 'bagging_temperature': 0.734073322510492, 'l2_leaf_reg': 8.266815899271895e-07, 'border_count': 100, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:45,330] Trial 161 finished with value: 0.6456784074563421 and parameters: {'iterations': 879, 'depth': 10, 'learning_rate': 0.12316018183506373, 'random_strength': 0, 'bagging_temperature': 0.8149468762769685, 'l2_leaf_reg': 1.834507411475068e-07, 'border_count': 113, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:49,757] Trial 162 finished with value: 0.6799917155855757 and parameters: {'iterations': 318, 'depth': 10, 'learning_rate': 0.12119480836742635, 'random_strength': 1, 'bagging_temperature': 0.8301634727082662, 'l2_leaf_reg': 2.0526304488593715e-07, 'border_count': 72, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:54,186] Trial 163 finished with value: 0.6592074909233868 and parameters: {'iterations': 862, 'depth': 10, 'learning_rate': 0.1332581814341876, 'random_strength': 3, 'bagging_temperature': 0.8467272825238719, 'l2_leaf_reg': 2.5774765661173846e-06, 'border_count': 131, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:33:58,336] Trial 164 finished with value: 0.6445602656357784 and parameters: {'iterations': 978, 'depth': 10, 'learning_rate': 0.1287643304150878, 'random_strength': 1, 'bagging_temperature': 0.7626322150310393, 'l2_leaf_reg': 1.2918523395978635e-07, 'border_count': 117, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:02,593] Trial 165 finished with value: 0.6705349649894923 and parameters: {'iterations': 975, 'depth': 10, 'learning_rate': 0.12570459118347144, 'random_strength': 1, 'bagging_temperature': 0.7681159474873694, 'l2_leaf_reg': 1.6097656045849996e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:06,664] Trial 166 finished with value: 0.630953915992589 and parameters: {'iterations': 938, 'depth': 10, 'learning_rate': 0.1287178836717578, 'random_strength': 0, 'bagging_temperature': 0.7421747819176379, 'l2_leaf_reg': 2.3067211972689477e-07, 'border_count': 115, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:10,876] Trial 167 finished with value: 0.6710224730466294 and parameters: {'iterations': 948, 'depth': 10, 'learning_rate': 0.11263528650504552, 'random_strength': 0, 'bagging_temperature': 0.7194627081821755, 'l2_leaf_reg': 2.48282572729367e-07, 'border_count': 112, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:14,300] Trial 168 finished with value: 0.6622806221356259 and parameters: {'iterations': 942, 'depth': 10, 'learning_rate': 0.11735513194570564, 'random_strength': 45, 'bagging_temperature': 0.9596094802048999, 'l2_leaf_reg': 3.02888808588036e-07, 'border_count': 125, 'grow_policy': 'SymmetricTree'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:18,615] Trial 169 finished with value: 0.6877397113483182 and parameters: {'iterations': 910, 'depth': 10, 'learning_rate': 0.12326449600114578, 'random_strength': 2, 'bagging_temperature': 0.7930822365620102, 'l2_leaf_reg': 4.0942613540144575e-07, 'border_count': 107, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:22,556] Trial 170 finished with value: 0.6868497474417032 and parameters: {'iterations': 894, 'depth': 10, 'learning_rate': 0.13559607050998548, 'random_strength': 0, 'bagging_temperature': 0.6741408481132907, 'l2_leaf_reg': 1.9477598577539455e-07, 'border_count': 114, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:26,933] Trial 171 finished with value: 0.6741507377766852 and parameters: {'iterations': 973, 'depth': 10, 'learning_rate': 0.12897245440085958, 'random_strength': 1, 'bagging_temperature': 0.7486384896258184, 'l2_leaf_reg': 1.4017482546716437e-07, 'border_count': 115, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:31,385] Trial 172 finished with value: 0.6833469261529915 and parameters: {'iterations': 934, 'depth': 10, 'learning_rate': 0.12909893075122472, 'random_strength': 2, 'bagging_temperature': 0.736480007021458, 'l2_leaf_reg': 2.2668832317055816e-07, 'border_count': 136, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:35,805] Trial 173 finished with value: 0.6300813990085348 and parameters: {'iterations': 988, 'depth': 10, 'learning_rate': 0.12680443060838772, 'random_strength': 0, 'bagging_temperature': 0.7132228752166356, 'l2_leaf_reg': 1.7464763359806705e-07, 'border_count': 118, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:39,770] Trial 174 finished with value: 0.6306999238195085 and parameters: {'iterations': 1024, 'depth': 10, 'learning_rate': 0.1259698241233283, 'random_strength': 0, 'bagging_temperature': 0.7158618449128374, 'l2_leaf_reg': 1.715242959453743e-07, 'border_count': 121, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:43,837] Trial 175 finished with value: 0.669249897737463 and parameters: {'iterations': 1000, 'depth': 10, 'learning_rate': 0.11999728712731288, 'random_strength': 0, 'bagging_temperature': 0.6944619214741345, 'l2_leaf_reg': 2.582383592067047e-07, 'border_count': 124, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:47,912] Trial 176 finished with value: 0.6848325046914022 and parameters: {'iterations': 1023, 'depth': 10, 'learning_rate': 0.12552446469222342, 'random_strength': 0, 'bagging_temperature': 0.7476140807034437, 'l2_leaf_reg': 1.846449611197798e-07, 'border_count': 120, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:51,992] Trial 177 finished with value: 0.7079198918112072 and parameters: {'iterations': 776, 'depth': 10, 'learning_rate': 0.13200291837170436, 'random_strength': 2, 'bagging_temperature': 0.7322182400442148, 'l2_leaf_reg': 3.373765961857553e-07, 'border_count': 130, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:34:56,088] Trial 178 finished with value: 0.6606123490222361 and parameters: {'iterations': 1007, 'depth': 10, 'learning_rate': 0.12578475371992157, 'random_strength': 0, 'bagging_temperature': 0.6980833270004579, 'l2_leaf_reg': 2.12567929800609e-07, 'border_count': 110, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:01,339] Trial 179 finished with value: 0.6317319338065637 and parameters: {'iterations': 956, 'depth': 10, 'learning_rate': 0.12287357571388564, 'random_strength': 1, 'bagging_temperature': 0.7264966255873418, 'l2_leaf_reg': 4.25738847436287e-06, 'border_count': 117, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:06,644] Trial 180 finished with value: 0.6751925728316834 and parameters: {'iterations': 916, 'depth': 10, 'learning_rate': 0.12054378772086467, 'random_strength': 1, 'bagging_temperature': 0.7245665452526909, 'l2_leaf_reg': 3.18048079250616e-06, 'border_count': 116, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:10,820] Trial 181 finished with value: 0.6660886214420558 and parameters: {'iterations': 959, 'depth': 10, 'learning_rate': 0.12436362863932764, 'random_strength': 1, 'bagging_temperature': 0.7074113416940537, 'l2_leaf_reg': 1.7478900060317872e-07, 'border_count': 122, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:15,701] Trial 182 finished with value: 0.7028105191336617 and parameters: {'iterations': 992, 'depth': 10, 'learning_rate': 0.12760811693696952, 'random_strength': 2, 'bagging_temperature': 0.6800078043339641, 'l2_leaf_reg': 5.583111173427933e-07, 'border_count': 128, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:20,015] Trial 183 finished with value: 0.6515494439819342 and parameters: {'iterations': 1047, 'depth': 10, 'learning_rate': 0.12202844106570468, 'random_strength': 0, 'bagging_temperature': 0.6598711171866465, 'l2_leaf_reg': 2.2708712168995806e-07, 'border_count': 106, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:23,734] Trial 184 finished with value: 0.6736345234381708 and parameters: {'iterations': 846, 'depth': 10, 'learning_rate': 0.17900501892263063, 'random_strength': 2, 'bagging_temperature': 0.777700465537887, 'l2_leaf_reg': 1.9432729794753617e-07, 'border_count': 156, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:28,084] Trial 185 finished with value: 0.6649945764988056 and parameters: {'iterations': 955, 'depth': 10, 'learning_rate': 0.13139155385290288, 'random_strength': 1, 'bagging_temperature': 0.7157164124266997, 'l2_leaf_reg': 2.6673248896253005e-07, 'border_count': 119, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:31,863] Trial 186 finished with value: 0.6827391751813882 and parameters: {'iterations': 1013, 'depth': 10, 'learning_rate': 0.13350955538894, 'random_strength': 0, 'bagging_temperature': 0.7863643310586124, 'l2_leaf_reg': 4.5615775098125334e-06, 'border_count': 65, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:36,803] Trial 187 finished with value: 0.6401875692680334 and parameters: {'iterations': 493, 'depth': 10, 'learning_rate': 0.11633638026145826, 'random_strength': 3, 'bagging_temperature': 0.8706513089841263, 'l2_leaf_reg': 1.417602307327614e-07, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:42,980] Trial 188 finished with value: 0.6896750866110373 and parameters: {'iterations': 938, 'depth': 10, 'learning_rate': 0.11684340042616044, 'random_strength': 4, 'bagging_temperature': 0.8694113688798127, 'l2_leaf_reg': 1.5923038747596815e-07, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:47,783] Trial 189 finished with value: 0.6597075640299594 and parameters: {'iterations': 965, 'depth': 10, 'learning_rate': 0.10978968066051038, 'random_strength': 3, 'bagging_temperature': 0.9016840749152569, 'l2_leaf_reg': 1.4599610281846397e-05, 'border_count': 57, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:52,117] Trial 190 finished with value: 0.6318831993177906 and parameters: {'iterations': 511, 'depth': 10, 'learning_rate': 0.11932898644954168, 'random_strength': 2, 'bagging_temperature': 0.5025381330447349, 'l2_leaf_reg': 1.3982700800608853e-07, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:35:57,110] Trial 191 finished with value: 0.6722269802857471 and parameters: {'iterations': 545, 'depth': 10, 'learning_rate': 0.11435845370183481, 'random_strength': 2, 'bagging_temperature': 0.5373968952415709, 'l2_leaf_reg': 1.4182725522090036e-07, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:03,137] Trial 192 finished with value: 0.6606883749630384 and parameters: {'iterations': 507, 'depth': 10, 'learning_rate': 0.11747254779694827, 'random_strength': 3, 'bagging_temperature': 0.3815246361862823, 'l2_leaf_reg': 1.2995728195573652e-06, 'border_count': 50, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:07,403] Trial 193 finished with value: 0.6575794413519463 and parameters: {'iterations': 480, 'depth': 10, 'learning_rate': 0.1201787851342064, 'random_strength': 1, 'bagging_temperature': 0.6899166644259671, 'l2_leaf_reg': 1.0786166460686312e-07, 'border_count': 59, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:12,803] Trial 194 finished with value: 0.6785626380040322 and parameters: {'iterations': 476, 'depth': 10, 'learning_rate': 0.11216789411227293, 'random_strength': 2, 'bagging_temperature': 0.4722123233850815, 'l2_leaf_reg': 1.2317896724107718e-07, 'border_count': 54, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:17,101] Trial 195 finished with value: 0.6572730169223351 and parameters: {'iterations': 532, 'depth': 10, 'learning_rate': 0.12292204916065742, 'random_strength': 1, 'bagging_temperature': 0.5151528858769606, 'l2_leaf_reg': 1.7021354038200118e-07, 'border_count': 64, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:21,243] Trial 196 finished with value: 0.6724289929576092 and parameters: {'iterations': 495, 'depth': 10, 'learning_rate': 0.1261753641586711, 'random_strength': 5, 'bagging_temperature': 0.6070733832523671, 'l2_leaf_reg': 1.3990652397692336e-07, 'border_count': 69, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:25,852] Trial 197 finished with value: 0.6674099014991383 and parameters: {'iterations': 447, 'depth': 10, 'learning_rate': 0.13622086939353492, 'random_strength': 3, 'bagging_temperature': 0.6698340826834355, 'l2_leaf_reg': 2.1729734983071405e-07, 'border_count': 62, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:28,049] Trial 198 finished with value: 0.7082739493096994 and parameters: {'iterations': 1099, 'depth': 10, 'learning_rate': 0.1296572292859179, 'random_strength': 0, 'bagging_temperature': 0.6261809888798039, 'l2_leaf_reg': 1.508213453437177e-07, 'border_count': 55, 'grow_policy': 'SymmetricTree'}. Best is trial 158 with value: 0.6195655802833077.\n",
      "[I 2023-12-07 22:36:35,484] Trial 199 finished with value: 0.6817844050308675 and parameters: {'iterations': 559, 'depth': 10, 'learning_rate': 0.11857716188058354, 'random_strength': 27, 'bagging_temperature': 0.6474490488354661, 'l2_leaf_reg': 1.7663900533474773e-07, 'border_count': 110, 'grow_policy': 'Lossguide'}. Best is trial 158 with value: 0.6195655802833077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'iterations': 916, 'depth': 10, 'learning_rate': 0.12002762445811731, 'random_strength': 0, 'bagging_temperature': 0.7679563961566029, 'l2_leaf_reg': 1.992909034956101e-07, 'border_count': 106, 'grow_policy': 'Lossguide'}\n"
     ]
    }
   ],
   "source": [
    "# third study\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 300, 1200),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.25),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 50),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-7, 1e-4, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 50, 255),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Lossguide']),\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def optimize(X_train, y_train, X_test, y_test, n_trials=200):\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=n_trials)\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "# Load your datasets and run optimization\n",
    "best_params_w = optimize(X_train_w, y_train_w, X_test_w, y_test_w)\n",
    "print(\"Best parameters for working days:\", best_params_w)\n",
    "\n",
    "best_params_nw = optimize(X_train_nw, y_train_nw, X_test_nw, y_test_nw)\n",
    "print(\"Best parameters for non-working days:\", best_params_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.5254528342\n",
      "bestIteration = 445\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.5262171727\n",
      "bestIteration = 498\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.5287631179\n",
      "bestIteration = 378\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.5277772754\n",
      "bestIteration = 484\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.5298155314\n",
      "bestIteration = 375\n",
      "\n",
      "Average RMSE for working days (CV): 0.5520736295644594\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.5481581292\n",
      "bestIteration = 407\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.5428681118\n",
      "bestIteration = 456\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.5396602631\n",
      "bestIteration = 486\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.5429897692\n",
      "bestIteration = 436\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.5474430976\n",
      "bestIteration = 336\n",
      "\n",
      "Average RMSE for non-working days (CV): 0.579036925933108\n"
     ]
    }
   ],
   "source": [
    "def perform_cv(X_train, y_train, params, n_folds=5):\n",
    "    pool = Pool(X_train, y_train)\n",
    "    # Ensure that 'loss_function' is included in the params dictionary\n",
    "    updated_params = params.copy()\n",
    "    updated_params['loss_function'] = 'RMSE'\n",
    "\n",
    "    cv_results = cv(\n",
    "        pool=pool, \n",
    "        params=updated_params, \n",
    "        fold_count=n_folds, \n",
    "        seed=42, \n",
    "        shuffle=True, \n",
    "        stratified=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    avg_rmse = np.mean(cv_results['test-RMSE-mean'])\n",
    "    return avg_rmse\n",
    "\n",
    "# Best parameters from Optuna study\n",
    "params_w = {'iterations': 1096, 'depth': 9,\n",
    " 'learning_rate': 0.22603548878280666,\n",
    " 'random_strength': 2,\n",
    " 'bagging_temperature': 0.1867337573932248,\n",
    " 'l2_leaf_reg': 2.304593084966779e-05,\n",
    " 'border_count': 66,\n",
    " 'grow_policy': 'Lossguide'}\n",
    "\n",
    "params_nw = {'iterations': 916,\n",
    " 'depth': 10,\n",
    " 'learning_rate': 0.12002762445811731,\n",
    " 'random_strength': 0,\n",
    " 'bagging_temperature': 0.7679563961566029,\n",
    " 'l2_leaf_reg': 1.992909034956101e-07,\n",
    " 'border_count': 106,\n",
    " 'grow_policy': 'Lossguide'}\n",
    "\n",
    "# Perform cross-validation and get average RMSE for working days\n",
    "avg_rmse_w = perform_cv(X_train_w, y_train_w, params_w)\n",
    "print(\"Average RMSE for working days (CV):\", avg_rmse_w)\n",
    "\n",
    "# Perform cross-validation and get average RMSE for non-working days\n",
    "avg_rmse_nw = perform_cv(X_train_nw, y_train_nw, params_nw)\n",
    "print(\"Average RMSE for non-working days (CV):\", avg_rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 22:43:58,543] A new study created in memory with name: no-name-7534a8a9-d428-4547-b1e1-fd59d8b5201f\n",
      "[I 2023-12-07 22:44:06,328] Trial 0 finished with value: 0.6120389261009053 and parameters: {'iterations': 1058, 'depth': 8, 'learning_rate': 0.18847500863268535, 'random_strength': 8, 'bagging_temperature': 0.5898929017182961, 'l2_leaf_reg': 8.138438860705015e-06, 'border_count': 51}. Best is trial 0 with value: 0.6120389261009053.\n",
      "[I 2023-12-07 22:44:12,919] Trial 1 finished with value: 0.6770303797496238 and parameters: {'iterations': 1051, 'depth': 8, 'learning_rate': 0.24150937654417956, 'random_strength': 1, 'bagging_temperature': 0.8593676039544788, 'l2_leaf_reg': 1.997713285930957e-06, 'border_count': 56}. Best is trial 0 with value: 0.6120389261009053.\n",
      "[I 2023-12-07 22:44:19,859] Trial 2 finished with value: 0.6443832916204862 and parameters: {'iterations': 1193, 'depth': 10, 'learning_rate': 0.16684649436340163, 'random_strength': 3, 'bagging_temperature': 0.5969780559032498, 'l2_leaf_reg': 1.0633058534120789e-05, 'border_count': 119}. Best is trial 0 with value: 0.6120389261009053.\n",
      "[I 2023-12-07 22:44:36,985] Trial 3 finished with value: 0.6037999020902801 and parameters: {'iterations': 1125, 'depth': 9, 'learning_rate': 0.11503710806747815, 'random_strength': 5, 'bagging_temperature': 0.3960870332645078, 'l2_leaf_reg': 1.0201216124921486e-06, 'border_count': 89}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:44:42,875] Trial 4 finished with value: 0.6493195879496235 and parameters: {'iterations': 1064, 'depth': 9, 'learning_rate': 0.14175909232802394, 'random_strength': 3, 'bagging_temperature': 0.7844435896444248, 'l2_leaf_reg': 2.7680085744176647e-05, 'border_count': 65}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:44:48,198] Trial 5 finished with value: 0.6255197022797555 and parameters: {'iterations': 1175, 'depth': 10, 'learning_rate': 0.19732356895268896, 'random_strength': 1, 'bagging_temperature': 0.954982092829246, 'l2_leaf_reg': 1.792078247798657e-05, 'border_count': 103}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:44:58,375] Trial 6 finished with value: 0.605006734233847 and parameters: {'iterations': 956, 'depth': 10, 'learning_rate': 0.1686862576898338, 'random_strength': 5, 'bagging_temperature': 0.16650274465469403, 'l2_leaf_reg': 1.193669108494894e-06, 'border_count': 113}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:04,650] Trial 7 finished with value: 0.6738799170838565 and parameters: {'iterations': 939, 'depth': 8, 'learning_rate': 0.22130687465320023, 'random_strength': 9, 'bagging_temperature': 0.5259890857736512, 'l2_leaf_reg': 2.7900773107178662e-05, 'border_count': 128}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:11,369] Trial 8 finished with value: 0.6475950865050393 and parameters: {'iterations': 1165, 'depth': 9, 'learning_rate': 0.19294937395693273, 'random_strength': 7, 'bagging_temperature': 0.9216497579907499, 'l2_leaf_reg': 4.02666080740959e-06, 'border_count': 68}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:16,481] Trial 9 finished with value: 0.6567163577516963 and parameters: {'iterations': 1117, 'depth': 9, 'learning_rate': 0.22410224133096956, 'random_strength': 4, 'bagging_temperature': 0.47277431490255617, 'l2_leaf_reg': 6.055697557361048e-06, 'border_count': 132}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:27,456] Trial 10 finished with value: 0.6437639250651439 and parameters: {'iterations': 977, 'depth': 9, 'learning_rate': 0.10011670347720374, 'random_strength': 6, 'bagging_temperature': 0.2703227878970749, 'l2_leaf_reg': 8.094357281022017e-05, 'border_count': 84}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:35,126] Trial 11 finished with value: 0.639551330892352 and parameters: {'iterations': 990, 'depth': 10, 'learning_rate': 0.12739498292963924, 'random_strength': 5, 'bagging_temperature': 0.17592878372656873, 'l2_leaf_reg': 1.0628668181029943e-06, 'border_count': 97}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:43,092] Trial 12 finished with value: 0.6775685737687506 and parameters: {'iterations': 1126, 'depth': 10, 'learning_rate': 0.15610667340514078, 'random_strength': 10, 'bagging_temperature': 0.10228778855822561, 'l2_leaf_reg': 1.1977916232051308e-06, 'border_count': 147}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:49,643] Trial 13 finished with value: 0.6412043514747265 and parameters: {'iterations': 900, 'depth': 9, 'learning_rate': 0.11962972335297234, 'random_strength': 6, 'bagging_temperature': 0.3095672105723595, 'l2_leaf_reg': 2.394901681126327e-06, 'border_count': 104}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:45:58,840] Trial 14 finished with value: 0.6141338791178828 and parameters: {'iterations': 1011, 'depth': 10, 'learning_rate': 0.15305241691247862, 'random_strength': 4, 'bagging_temperature': 0.36704201204703246, 'l2_leaf_reg': 2.2274007911658622e-06, 'border_count': 83}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:05,697] Trial 15 finished with value: 0.6251089974412003 and parameters: {'iterations': 1105, 'depth': 9, 'learning_rate': 0.1736971915092784, 'random_strength': 7, 'bagging_temperature': 0.2092682026312187, 'l2_leaf_reg': 1.0072727871087287e-06, 'border_count': 115}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:14,905] Trial 16 finished with value: 0.641591113081691 and parameters: {'iterations': 942, 'depth': 10, 'learning_rate': 0.1350599299503191, 'random_strength': 2, 'bagging_temperature': 0.372334083013773, 'l2_leaf_reg': 3.5277297736962395e-06, 'border_count': 85}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:25,179] Trial 17 finished with value: 0.6448566259755129 and parameters: {'iterations': 1092, 'depth': 8, 'learning_rate': 0.10403761568533443, 'random_strength': 5, 'bagging_temperature': 0.10234936049480164, 'l2_leaf_reg': 1.6374855695108344e-06, 'border_count': 94}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:31,778] Trial 18 finished with value: 0.6421055951730943 and parameters: {'iterations': 1020, 'depth': 9, 'learning_rate': 0.12032273128106755, 'random_strength': 0, 'bagging_temperature': 0.4037887949433565, 'l2_leaf_reg': 3.4158268273520565e-06, 'border_count': 113}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:40,396] Trial 19 finished with value: 0.6879286640655995 and parameters: {'iterations': 1134, 'depth': 10, 'learning_rate': 0.14482427504082668, 'random_strength': 6, 'bagging_temperature': 0.24780267806889433, 'l2_leaf_reg': 1.5073363213850204e-06, 'border_count': 143}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:48,699] Trial 20 finished with value: 0.6751268196909328 and parameters: {'iterations': 916, 'depth': 9, 'learning_rate': 0.15741237083637433, 'random_strength': 4, 'bagging_temperature': 0.3033666475494847, 'l2_leaf_reg': 1.9051120445827348e-06, 'border_count': 133}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:46:55,197] Trial 21 finished with value: 0.6217083118174008 and parameters: {'iterations': 1076, 'depth': 8, 'learning_rate': 0.18457536063707913, 'random_strength': 8, 'bagging_temperature': 0.629811757263455, 'l2_leaf_reg': 5.550535016641014e-06, 'border_count': 55}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:02,754] Trial 22 finished with value: 0.6286159213378237 and parameters: {'iterations': 1030, 'depth': 8, 'learning_rate': 0.17212096343701874, 'random_strength': 8, 'bagging_temperature': 0.668604844448289, 'l2_leaf_reg': 1.3390814814181036e-06, 'border_count': 69}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:09,206] Trial 23 finished with value: 0.6571299195316888 and parameters: {'iterations': 980, 'depth': 8, 'learning_rate': 0.18517598502123508, 'random_strength': 10, 'bagging_temperature': 0.4673473194411307, 'l2_leaf_reg': 2.4821015128694877e-06, 'border_count': 123}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:16,838] Trial 24 finished with value: 0.6431103682206224 and parameters: {'iterations': 1146, 'depth': 8, 'learning_rate': 0.19931932610738815, 'random_strength': 5, 'bagging_temperature': 0.7011965335092353, 'l2_leaf_reg': 1.3987063733570138e-06, 'border_count': 50}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:27,084] Trial 25 finished with value: 0.610563981945321 and parameters: {'iterations': 1086, 'depth': 9, 'learning_rate': 0.16312053396011988, 'random_strength': 7, 'bagging_temperature': 0.553010676115898, 'l2_leaf_reg': 7.107839429998233e-06, 'border_count': 110}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:37,679] Trial 26 finished with value: 0.6062735252059066 and parameters: {'iterations': 1098, 'depth': 9, 'learning_rate': 0.16378936067366887, 'random_strength': 7, 'bagging_temperature': 0.5241366882188377, 'l2_leaf_reg': 3.0728941631055923e-06, 'border_count': 105}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:49,947] Trial 27 finished with value: 0.6286280298046872 and parameters: {'iterations': 1150, 'depth': 9, 'learning_rate': 0.14469344811683227, 'random_strength': 6, 'bagging_temperature': 0.4427056515184461, 'l2_leaf_reg': 2.86571107485684e-06, 'border_count': 92}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:47:58,330] Trial 28 finished with value: 0.6259773525730989 and parameters: {'iterations': 1099, 'depth': 9, 'learning_rate': 0.17636733438541807, 'random_strength': 3, 'bagging_temperature': 0.34312281992709825, 'l2_leaf_reg': 1.0617924974804243e-06, 'border_count': 105}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:08,602] Trial 29 finished with value: 0.6568000285599954 and parameters: {'iterations': 1042, 'depth': 10, 'learning_rate': 0.11051295871114915, 'random_strength': 9, 'bagging_temperature': 0.5217556489778463, 'l2_leaf_reg': 1.7276619049818923e-06, 'border_count': 90}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:17,874] Trial 30 finished with value: 0.6424675247520595 and parameters: {'iterations': 1200, 'depth': 9, 'learning_rate': 0.13423525711719828, 'random_strength': 5, 'bagging_temperature': 0.4045545344068337, 'l2_leaf_reg': 1.6042289331133775e-06, 'border_count': 80}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:25,474] Trial 31 finished with value: 0.612212034866982 and parameters: {'iterations': 1080, 'depth': 9, 'learning_rate': 0.163521089150601, 'random_strength': 7, 'bagging_temperature': 0.537311325154152, 'l2_leaf_reg': 4.433693282812443e-06, 'border_count': 110}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:38,015] Trial 32 finished with value: 0.6390687160582045 and parameters: {'iterations': 1115, 'depth': 9, 'learning_rate': 0.15215196370091086, 'random_strength': 7, 'bagging_temperature': 0.5871991848656716, 'l2_leaf_reg': 2.857126831538741e-06, 'border_count': 111}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:45,413] Trial 33 finished with value: 0.6851054440574388 and parameters: {'iterations': 1062, 'depth': 9, 'learning_rate': 0.1606077993079297, 'random_strength': 8, 'bagging_temperature': 0.4857236519751873, 'l2_leaf_reg': 2.179211783349069e-06, 'border_count': 98}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:48:54,151] Trial 34 finished with value: 0.6376123386107443 and parameters: {'iterations': 1084, 'depth': 9, 'learning_rate': 0.16688967601102617, 'random_strength': 6, 'bagging_temperature': 0.4178836944402389, 'l2_leaf_reg': 7.226623529501762e-06, 'border_count': 120}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:02,033] Trial 35 finished with value: 0.6409273600431747 and parameters: {'iterations': 1042, 'depth': 9, 'learning_rate': 0.14879314887026826, 'random_strength': 9, 'bagging_temperature': 0.7404377787738488, 'l2_leaf_reg': 9.257245122075293e-06, 'border_count': 75}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:13,506] Trial 36 finished with value: 0.6410746925548598 and parameters: {'iterations': 1175, 'depth': 10, 'learning_rate': 0.13798589805035447, 'random_strength': 4, 'bagging_temperature': 0.5850441675913698, 'l2_leaf_reg': 4.787234226510515e-06, 'border_count': 108}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:20,420] Trial 37 finished with value: 0.6526420807264791 and parameters: {'iterations': 1057, 'depth': 9, 'learning_rate': 0.16782546785621852, 'random_strength': 7, 'bagging_temperature': 0.5046766584948853, 'l2_leaf_reg': 1.887247335939656e-06, 'border_count': 101}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:28,551] Trial 38 finished with value: 0.6306598308158328 and parameters: {'iterations': 1141, 'depth': 9, 'learning_rate': 0.1434888207957294, 'random_strength': 3, 'bagging_temperature': 0.600542595420106, 'l2_leaf_reg': 3.1687047260903283e-06, 'border_count': 126}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:35,697] Trial 39 finished with value: 0.6355920638205934 and parameters: {'iterations': 951, 'depth': 9, 'learning_rate': 0.1770849132758964, 'random_strength': 5, 'bagging_temperature': 0.4415466133692604, 'l2_leaf_reg': 1.2838103477418974e-06, 'border_count': 118}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:43,512] Trial 40 finished with value: 0.683794110910871 and parameters: {'iterations': 1159, 'depth': 10, 'learning_rate': 0.16071146804227385, 'random_strength': 7, 'bagging_temperature': 0.5516206184905307, 'l2_leaf_reg': 1.1955898506731892e-05, 'border_count': 90}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:50,700] Trial 41 finished with value: 0.6729827115274081 and parameters: {'iterations': 1068, 'depth': 8, 'learning_rate': 0.1958245389357731, 'random_strength': 8, 'bagging_temperature': 0.6486232128349738, 'l2_leaf_reg': 4.057401301561594e-06, 'border_count': 62}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:49:58,298] Trial 42 finished with value: 0.6466197749935945 and parameters: {'iterations': 1117, 'depth': 8, 'learning_rate': 0.18460590791371742, 'random_strength': 9, 'bagging_temperature': 0.5539998215026914, 'l2_leaf_reg': 7.012181266801817e-06, 'border_count': 138}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:07,213] Trial 43 finished with value: 0.6187365341424922 and parameters: {'iterations': 998, 'depth': 9, 'learning_rate': 0.20288889839554416, 'random_strength': 6, 'bagging_temperature': 0.49204409165795215, 'l2_leaf_reg': 4.811425006107727e-06, 'border_count': 107}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:13,711] Trial 44 finished with value: 0.650665669225906 and parameters: {'iterations': 1099, 'depth': 8, 'learning_rate': 0.20750876396785722, 'random_strength': 8, 'bagging_temperature': 0.600237419334501, 'l2_leaf_reg': 1.2701118972056568e-06, 'border_count': 116}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:21,909] Trial 45 finished with value: 0.6499680574377387 and parameters: {'iterations': 1046, 'depth': 10, 'learning_rate': 0.15208008278561735, 'random_strength': 5, 'bagging_temperature': 0.8460841742753342, 'l2_leaf_reg': 2.517238576716526e-06, 'border_count': 74}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:29,484] Trial 46 finished with value: 0.6356987038612251 and parameters: {'iterations': 1113, 'depth': 9, 'learning_rate': 0.16796033210767158, 'random_strength': 6, 'bagging_temperature': 0.34172414047712435, 'l2_leaf_reg': 1.0218275705430122e-06, 'border_count': 99}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:38,019] Trial 47 finished with value: 0.6401415727652433 and parameters: {'iterations': 961, 'depth': 10, 'learning_rate': 0.12696514891883168, 'random_strength': 7, 'bagging_temperature': 0.1716008083575859, 'l2_leaf_reg': 1.9113088106330146e-06, 'border_count': 128}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:47,014] Trial 48 finished with value: 0.6793848288506689 and parameters: {'iterations': 1124, 'depth': 9, 'learning_rate': 0.19106918096231196, 'random_strength': 4, 'bagging_temperature': 0.44672977930375457, 'l2_leaf_reg': 1.4976894067680256e-05, 'border_count': 59}. Best is trial 3 with value: 0.6037999020902801.\n",
      "[I 2023-12-07 22:50:56,127] Trial 49 finished with value: 0.6037555982770327 and parameters: {'iterations': 1091, 'depth': 8, 'learning_rate': 0.15516935800364315, 'random_strength': 9, 'bagging_temperature': 0.5150304472560162, 'l2_leaf_reg': 8.922181244616424e-06, 'border_count': 102}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:06,456] Trial 50 finished with value: 0.6576318508478547 and parameters: {'iterations': 1087, 'depth': 8, 'learning_rate': 0.15734978895907112, 'random_strength': 10, 'bagging_temperature': 0.4904520196666236, 'l2_leaf_reg': 8.76251594703047e-06, 'border_count': 95}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:12,721] Trial 51 finished with value: 0.6610927224506672 and parameters: {'iterations': 1070, 'depth': 8, 'learning_rate': 0.17818784146158098, 'random_strength': 9, 'bagging_temperature': 0.550243902431453, 'l2_leaf_reg': 5.7013221944117975e-06, 'border_count': 103}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:25,945] Trial 52 finished with value: 0.6532750214699838 and parameters: {'iterations': 1105, 'depth': 8, 'learning_rate': 0.16919947044491512, 'random_strength': 8, 'bagging_temperature': 0.38090311847410585, 'l2_leaf_reg': 1.0592380513324766e-05, 'border_count': 113}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:37,811] Trial 53 finished with value: 0.619929916162056 and parameters: {'iterations': 1032, 'depth': 8, 'learning_rate': 0.1624079627080009, 'random_strength': 9, 'bagging_temperature': 0.5209423484556288, 'l2_leaf_reg': 3.8043071272683293e-06, 'border_count': 121}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:49,164] Trial 54 finished with value: 0.6398294305445847 and parameters: {'iterations': 1133, 'depth': 8, 'learning_rate': 0.15173332332485082, 'random_strength': 7, 'bagging_temperature': 0.4683547772766133, 'l2_leaf_reg': 7.727621841440152e-06, 'border_count': 102}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:51:55,709] Trial 55 finished with value: 0.6495747733615773 and parameters: {'iterations': 1093, 'depth': 9, 'learning_rate': 0.17420600412432508, 'random_strength': 5, 'bagging_temperature': 0.6297896709646753, 'l2_leaf_reg': 6.3993554561367605e-06, 'border_count': 106}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:52:02,982] Trial 56 finished with value: 0.6299820139837299 and parameters: {'iterations': 1012, 'depth': 9, 'learning_rate': 0.15649646026206276, 'random_strength': 2, 'bagging_temperature': 0.26244048904337214, 'l2_leaf_reg': 5.363594828463557e-06, 'border_count': 88}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:52:16,305] Trial 57 finished with value: 0.6545945274216018 and parameters: {'iterations': 1077, 'depth': 8, 'learning_rate': 0.18102451537538194, 'random_strength': 10, 'bagging_temperature': 0.30396721873508775, 'l2_leaf_reg': 1.5275295653579104e-06, 'border_count': 111}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:52:23,653] Trial 58 finished with value: 0.6422677585694733 and parameters: {'iterations': 919, 'depth': 10, 'learning_rate': 0.17030545048792756, 'random_strength': 6, 'bagging_temperature': 0.5675566224663022, 'l2_leaf_reg': 1.1730837640528672e-06, 'border_count': 50}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:52:31,853] Trial 59 finished with value: 0.6461193334180728 and parameters: {'iterations': 1173, 'depth': 8, 'learning_rate': 0.147410581929004, 'random_strength': 8, 'bagging_temperature': 0.5267650623440474, 'l2_leaf_reg': 7.895856359770934e-06, 'border_count': 132}. Best is trial 49 with value: 0.6037555982770327.\n",
      "[I 2023-12-07 22:52:40,934] Trial 60 finished with value: 0.6028622878532418 and parameters: {'iterations': 1052, 'depth': 9, 'learning_rate': 0.13876779594922165, 'random_strength': 4, 'bagging_temperature': 0.6249322029803629, 'l2_leaf_reg': 1.2130404203068322e-05, 'border_count': 125}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:52:46,458] Trial 61 finished with value: 0.6374173017708095 and parameters: {'iterations': 1055, 'depth': 9, 'learning_rate': 0.1400361944823537, 'random_strength': 4, 'bagging_temperature': 0.685656998082883, 'l2_leaf_reg': 1.2071667838413413e-05, 'border_count': 125}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:52:54,368] Trial 62 finished with value: 0.6609690911396998 and parameters: {'iterations': 1067, 'depth': 9, 'learning_rate': 0.13361713435288677, 'random_strength': 3, 'bagging_temperature': 0.6116838468200687, 'l2_leaf_reg': 1.7824037287697504e-05, 'border_count': 115}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:08,723] Trial 63 finished with value: 0.6509693848260537 and parameters: {'iterations': 1030, 'depth': 9, 'learning_rate': 0.1622583937938363, 'random_strength': 4, 'bagging_temperature': 0.5688188672899411, 'l2_leaf_reg': 1.0352543813067128e-05, 'border_count': 119}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:22,394] Trial 64 finished with value: 0.6197681946199115 and parameters: {'iterations': 1107, 'depth': 9, 'learning_rate': 0.11327789140635308, 'random_strength': 5, 'bagging_temperature': 0.6546290984180879, 'l2_leaf_reg': 6.213298712691778e-06, 'border_count': 96}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:28,208] Trial 65 finished with value: 0.6396866960532953 and parameters: {'iterations': 1093, 'depth': 9, 'learning_rate': 0.1556856022039488, 'random_strength': 2, 'bagging_temperature': 0.5039140203931763, 'l2_leaf_reg': 8.42249336744868e-06, 'border_count': 67}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:35,738] Trial 66 finished with value: 0.6302584256905664 and parameters: {'iterations': 1127, 'depth': 9, 'learning_rate': 0.1478591998594578, 'random_strength': 6, 'bagging_temperature': 0.5775413574977176, 'l2_leaf_reg': 1.1641551662921667e-06, 'border_count': 136}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:43,864] Trial 67 finished with value: 0.6358595666405907 and parameters: {'iterations': 1074, 'depth': 9, 'learning_rate': 0.14165330660865502, 'random_strength': 8, 'bagging_temperature': 0.6174667378802238, 'l2_leaf_reg': 9.270197653836585e-06, 'border_count': 108}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:53:51,193] Trial 68 finished with value: 0.6348562465554743 and parameters: {'iterations': 1052, 'depth': 9, 'learning_rate': 0.1718174865789872, 'random_strength': 4, 'bagging_temperature': 0.5324307433709657, 'l2_leaf_reg': 1.723864961775174e-06, 'border_count': 80}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:00,975] Trial 69 finished with value: 0.6247267957150623 and parameters: {'iterations': 1019, 'depth': 10, 'learning_rate': 0.13005512040493, 'random_strength': 9, 'bagging_temperature': 0.4270732037062599, 'l2_leaf_reg': 1.4437446155398725e-06, 'border_count': 146}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:12,771] Trial 70 finished with value: 0.6172069796480687 and parameters: {'iterations': 997, 'depth': 9, 'learning_rate': 0.16402258534855735, 'random_strength': 5, 'bagging_temperature': 0.4601685821514031, 'l2_leaf_reg': 7.011838331145864e-06, 'border_count': 122}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:20,048] Trial 71 finished with value: 0.6316264425525079 and parameters: {'iterations': 1085, 'depth': 9, 'learning_rate': 0.16288987875284147, 'random_strength': 7, 'bagging_temperature': 0.5385457516973097, 'l2_leaf_reg': 5.131517368954998e-06, 'border_count': 112}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:27,056] Trial 72 finished with value: 0.6872604800038971 and parameters: {'iterations': 1081, 'depth': 9, 'learning_rate': 0.1648137663190446, 'random_strength': 7, 'bagging_temperature': 0.6434512752941505, 'l2_leaf_reg': 2.262788185110405e-06, 'border_count': 109}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:38,712] Trial 73 finished with value: 0.6864400254906466 and parameters: {'iterations': 1058, 'depth': 9, 'learning_rate': 0.15892909288644097, 'random_strength': 6, 'bagging_temperature': 0.4730184709133101, 'l2_leaf_reg': 4.413721775083285e-06, 'border_count': 105}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:54:47,990] Trial 74 finished with value: 0.635405987967566 and parameters: {'iterations': 1041, 'depth': 9, 'learning_rate': 0.15446213977498108, 'random_strength': 8, 'bagging_temperature': 0.5840507576574897, 'l2_leaf_reg': 3.4339940319933453e-06, 'border_count': 100}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:01,181] Trial 75 finished with value: 0.6241005023175319 and parameters: {'iterations': 1101, 'depth': 9, 'learning_rate': 0.1723289005234158, 'random_strength': 6, 'bagging_temperature': 0.5147523391399487, 'l2_leaf_reg': 6.425240060765289e-06, 'border_count': 116}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:08,594] Trial 76 finished with value: 0.6541492830083618 and parameters: {'iterations': 1111, 'depth': 9, 'learning_rate': 0.1494653875394662, 'random_strength': 7, 'bagging_temperature': 0.40445493478483674, 'l2_leaf_reg': 4.04950054231402e-06, 'border_count': 109}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:16,189] Trial 77 finished with value: 0.6285671199402609 and parameters: {'iterations': 1092, 'depth': 8, 'learning_rate': 0.16594251939134141, 'random_strength': 5, 'bagging_temperature': 0.6078504988312267, 'l2_leaf_reg': 2.9052743439353753e-06, 'border_count': 93}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:28,607] Trial 78 finished with value: 0.6337570555041959 and parameters: {'iterations': 1063, 'depth': 10, 'learning_rate': 0.18056970732048605, 'random_strength': 7, 'bagging_temperature': 0.546883124430994, 'l2_leaf_reg': 4.380254957424562e-06, 'border_count': 103}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:35,745] Trial 79 finished with value: 0.6329435411857535 and parameters: {'iterations': 1121, 'depth': 9, 'learning_rate': 0.15843785770194121, 'random_strength': 8, 'bagging_temperature': 0.48644644723679575, 'l2_leaf_reg': 2.067183926517043e-06, 'border_count': 55}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:43,896] Trial 80 finished with value: 0.6523470228284263 and parameters: {'iterations': 1154, 'depth': 8, 'learning_rate': 0.14582087824649068, 'random_strength': 9, 'bagging_temperature': 0.6727804740589995, 'l2_leaf_reg': 5.916058838059005e-06, 'border_count': 98}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:55:52,769] Trial 81 finished with value: 0.6208474829951036 and parameters: {'iterations': 973, 'depth': 10, 'learning_rate': 0.15130610788951354, 'random_strength': 4, 'bagging_temperature': 0.37196207072211773, 'l2_leaf_reg': 2.487091965344865e-06, 'border_count': 81}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:01,071] Trial 82 finished with value: 0.6101577877378823 and parameters: {'iterations': 931, 'depth': 10, 'learning_rate': 0.15401496141737214, 'random_strength': 4, 'bagging_temperature': 0.42982597757112145, 'l2_leaf_reg': 1.1150361260359359e-06, 'border_count': 86}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:16,163] Trial 83 finished with value: 0.622138844977169 and parameters: {'iterations': 948, 'depth': 10, 'learning_rate': 0.13745222792583897, 'random_strength': 3, 'bagging_temperature': 0.5081311158501705, 'l2_leaf_reg': 1.3626919925595223e-06, 'border_count': 87}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:22,941] Trial 84 finished with value: 0.6808287568450371 and parameters: {'iterations': 940, 'depth': 10, 'learning_rate': 0.14394004242997743, 'random_strength': 3, 'bagging_temperature': 0.43037397465642635, 'l2_leaf_reg': 1.0211690745136479e-06, 'border_count': 77}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:30,809] Trial 85 finished with value: 0.6328742837824028 and parameters: {'iterations': 913, 'depth': 10, 'learning_rate': 0.15343776238129744, 'random_strength': 4, 'bagging_temperature': 0.5720414152309625, 'l2_leaf_reg': 1.2732908614844318e-06, 'border_count': 91}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:37,836] Trial 86 finished with value: 0.6504736812280713 and parameters: {'iterations': 901, 'depth': 9, 'learning_rate': 0.1595837518180777, 'random_strength': 5, 'bagging_temperature': 0.46059230544551066, 'l2_leaf_reg': 1.69743293924875e-06, 'border_count': 73}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:46,322] Trial 87 finished with value: 0.6460175827007064 and parameters: {'iterations': 921, 'depth': 10, 'learning_rate': 0.16828542736187874, 'random_strength': 5, 'bagging_temperature': 0.3946972451736911, 'l2_leaf_reg': 1.3785547641831237e-06, 'border_count': 117}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:56:51,649] Trial 88 finished with value: 0.6436161112687405 and parameters: {'iterations': 1139, 'depth': 9, 'learning_rate': 0.17633765987522684, 'random_strength': 0, 'bagging_temperature': 0.3275931634793764, 'l2_leaf_reg': 1.0989727409046295e-06, 'border_count': 85}. Best is trial 60 with value: 0.6028622878532418.\n",
      "[I 2023-12-07 22:57:00,558] Trial 89 finished with value: 0.5929091906852616 and parameters: {'iterations': 930, 'depth': 10, 'learning_rate': 0.15536135820926583, 'random_strength': 4, 'bagging_temperature': 0.5528719551202427, 'l2_leaf_reg': 1.5519730357537446e-06, 'border_count': 114}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:12,947] Trial 90 finished with value: 0.6664444411772952 and parameters: {'iterations': 956, 'depth': 10, 'learning_rate': 0.15452635391885983, 'random_strength': 4, 'bagging_temperature': 0.28456406669884854, 'l2_leaf_reg': 1.5491785590553652e-06, 'border_count': 130}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:18,792] Trial 91 finished with value: 0.6356753949771231 and parameters: {'iterations': 964, 'depth': 10, 'learning_rate': 0.1665533535897991, 'random_strength': 3, 'bagging_temperature': 0.5467623428617653, 'l2_leaf_reg': 1.1061723479619148e-06, 'border_count': 111}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:26,129] Trial 92 finished with value: 0.6351579798478643 and parameters: {'iterations': 927, 'depth': 10, 'learning_rate': 0.1595038560903107, 'random_strength': 4, 'bagging_temperature': 0.49878242246645665, 'l2_leaf_reg': 1.2008374937570107e-06, 'border_count': 115}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:35,408] Trial 93 finished with value: 0.6690107384446456 and parameters: {'iterations': 1076, 'depth': 10, 'learning_rate': 0.14798836978876928, 'random_strength': 5, 'bagging_temperature': 0.5296916212297477, 'l2_leaf_reg': 1.9018949672669895e-06, 'border_count': 124}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:42,938] Trial 94 finished with value: 0.6743185180367642 and parameters: {'iterations': 936, 'depth': 9, 'learning_rate': 0.16298698584673987, 'random_strength': 8, 'bagging_temperature': 0.5614397774571918, 'l2_leaf_reg': 1.451059228025224e-06, 'border_count': 105}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:53,786] Trial 95 finished with value: 0.6458811293963681 and parameters: {'iterations': 932, 'depth': 10, 'learning_rate': 0.17179888785120342, 'random_strength': 6, 'bagging_temperature': 0.5857554210357843, 'l2_leaf_reg': 1.0138544216176218e-06, 'border_count': 101}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:57:57,998] Trial 96 finished with value: 0.6902106341633811 and parameters: {'iterations': 1089, 'depth': 8, 'learning_rate': 0.15065658390891548, 'random_strength': 4, 'bagging_temperature': 0.5995278829246069, 'l2_leaf_reg': 1.2826775859851776e-06, 'border_count': 114}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:08,010] Trial 97 finished with value: 0.6348218122902597 and parameters: {'iterations': 909, 'depth': 10, 'learning_rate': 0.15678007882445696, 'random_strength': 10, 'bagging_temperature': 0.6299854882049563, 'l2_leaf_reg': 1.1227062996276735e-05, 'border_count': 120}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:20,476] Trial 98 finished with value: 0.623057517445273 and parameters: {'iterations': 1071, 'depth': 9, 'learning_rate': 0.1416031519957038, 'random_strength': 7, 'bagging_temperature': 0.48402267755114076, 'l2_leaf_reg': 1.7303769464029564e-06, 'border_count': 110}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:27,653] Trial 99 finished with value: 0.599336052858688 and parameters: {'iterations': 1048, 'depth': 9, 'learning_rate': 0.17444495932742157, 'random_strength': 5, 'bagging_temperature': 0.4531018845563993, 'l2_leaf_reg': 9.473891872163613e-06, 'border_count': 107}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:36,574] Trial 100 finished with value: 0.6194325721205849 and parameters: {'iterations': 983, 'depth': 9, 'learning_rate': 0.17560109701870377, 'random_strength': 5, 'bagging_temperature': 0.4416552996560131, 'l2_leaf_reg': 1.3207528211829786e-05, 'border_count': 95}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:45,747] Trial 101 finished with value: 0.6215580083345776 and parameters: {'iterations': 1035, 'depth': 9, 'learning_rate': 0.1700913118675489, 'random_strength': 4, 'bagging_temperature': 0.4222484984764705, 'l2_leaf_reg': 7.819399749785985e-06, 'border_count': 107}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:58:53,286] Trial 102 finished with value: 0.623779470606634 and parameters: {'iterations': 1098, 'depth': 9, 'learning_rate': 0.16571091058232543, 'random_strength': 5, 'bagging_temperature': 0.5124239923956257, 'l2_leaf_reg': 9.126578547319122e-06, 'border_count': 70}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:00,603] Trial 103 finished with value: 0.6553196365791547 and parameters: {'iterations': 945, 'depth': 9, 'learning_rate': 0.16197190812416085, 'random_strength': 6, 'bagging_temperature': 0.534971493855732, 'l2_leaf_reg': 9.441913521249975e-06, 'border_count': 113}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:12,790] Trial 104 finished with value: 0.5964316124214318 and parameters: {'iterations': 926, 'depth': 9, 'learning_rate': 0.15708371925315748, 'random_strength': 3, 'bagging_temperature': 0.5623999761718675, 'l2_leaf_reg': 1.0202712009647296e-05, 'border_count': 103}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:21,176] Trial 105 finished with value: 0.6330575818073227 and parameters: {'iterations': 906, 'depth': 9, 'learning_rate': 0.1539887074138485, 'random_strength': 3, 'bagging_temperature': 0.5627919840676286, 'l2_leaf_reg': 1.0548536866985302e-05, 'border_count': 59}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:32,967] Trial 106 finished with value: 0.6327872156985891 and parameters: {'iterations': 935, 'depth': 9, 'learning_rate': 0.14459457865346123, 'random_strength': 2, 'bagging_temperature': 0.3552395427845678, 'l2_leaf_reg': 9.914340870554461e-06, 'border_count': 97}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:39,848] Trial 107 finished with value: 0.6717475080263204 and parameters: {'iterations': 927, 'depth': 8, 'learning_rate': 0.17409332660227003, 'random_strength': 4, 'bagging_temperature': 0.45878193354527375, 'l2_leaf_reg': 1.2523024372322474e-05, 'border_count': 102}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:45,404] Trial 108 finished with value: 0.6088667317406516 and parameters: {'iterations': 1047, 'depth': 9, 'learning_rate': 0.15772031230825678, 'random_strength': 2, 'bagging_temperature': 0.4788325722811274, 'l2_leaf_reg': 8.40127966552737e-06, 'border_count': 106}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:51,521] Trial 109 finished with value: 0.6258415952901883 and parameters: {'iterations': 1049, 'depth': 9, 'learning_rate': 0.15750630036567584, 'random_strength': 1, 'bagging_temperature': 0.4783777626961406, 'l2_leaf_reg': 1.3908677347647939e-05, 'border_count': 104}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 22:59:59,609] Trial 110 finished with value: 0.6190150121049139 and parameters: {'iterations': 1021, 'depth': 9, 'learning_rate': 0.16036899365380275, 'random_strength': 2, 'bagging_temperature': 0.39162770226277893, 'l2_leaf_reg': 1.1585349020236669e-05, 'border_count': 99}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:09,919] Trial 111 finished with value: 0.6308701049833465 and parameters: {'iterations': 1038, 'depth': 9, 'learning_rate': 0.16782780896350372, 'random_strength': 1, 'bagging_temperature': 0.5031993731594658, 'l2_leaf_reg': 8.587154816426585e-06, 'border_count': 107}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:17,632] Trial 112 finished with value: 0.628616825593001 and parameters: {'iterations': 1061, 'depth': 9, 'learning_rate': 0.14992643318857307, 'random_strength': 2, 'bagging_temperature': 0.23739317857928105, 'l2_leaf_reg': 9.980249615715007e-06, 'border_count': 106}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:25,080] Trial 113 finished with value: 0.6463108367191618 and parameters: {'iterations': 929, 'depth': 9, 'learning_rate': 0.15538412925903292, 'random_strength': 3, 'bagging_temperature': 0.4507589440837574, 'l2_leaf_reg': 7.385978659771491e-06, 'border_count': 127}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:32,886] Trial 114 finished with value: 0.6469003939690338 and parameters: {'iterations': 1186, 'depth': 9, 'learning_rate': 0.17021036024286504, 'random_strength': 5, 'bagging_temperature': 0.552858235823652, 'l2_leaf_reg': 6.5801779546783146e-06, 'border_count': 100}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:40,004] Trial 115 finished with value: 0.6214790353607578 and parameters: {'iterations': 1045, 'depth': 9, 'learning_rate': 0.1632716971708347, 'random_strength': 3, 'bagging_temperature': 0.5907853164528211, 'l2_leaf_reg': 8.139467234994924e-06, 'border_count': 118}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:47,658] Trial 116 finished with value: 0.6101561469185034 and parameters: {'iterations': 924, 'depth': 8, 'learning_rate': 0.14595030128217246, 'random_strength': 4, 'bagging_temperature': 0.5218118503644573, 'l2_leaf_reg': 6.862359075849234e-06, 'border_count': 104}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:00:55,553] Trial 117 finished with value: 0.6083554098008949 and parameters: {'iterations': 922, 'depth': 9, 'learning_rate': 0.1529377112190442, 'random_strength': 4, 'bagging_temperature': 0.42013088845245883, 'l2_leaf_reg': 6.950608674404027e-06, 'border_count': 103}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:03,921] Trial 118 finished with value: 0.6215214585399518 and parameters: {'iterations': 924, 'depth': 8, 'learning_rate': 0.15237773514827577, 'random_strength': 4, 'bagging_temperature': 0.4185772417024144, 'l2_leaf_reg': 1.115925179660543e-06, 'border_count': 88}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:15,148] Trial 119 finished with value: 0.6229885902449763 and parameters: {'iterations': 918, 'depth': 10, 'learning_rate': 0.14753354001424795, 'random_strength': 4, 'bagging_temperature': 0.4662507719935486, 'l2_leaf_reg': 8.281504349849157e-06, 'border_count': 94}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:23,292] Trial 120 finished with value: 0.6152667532879509 and parameters: {'iterations': 910, 'depth': 9, 'learning_rate': 0.13849360665391924, 'random_strength': 4, 'bagging_temperature': 0.4386878157133758, 'l2_leaf_reg': 1.1289876157673494e-05, 'border_count': 103}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:32,215] Trial 121 finished with value: 0.6263395872788048 and parameters: {'iterations': 951, 'depth': 9, 'learning_rate': 0.1572168294507799, 'random_strength': 5, 'bagging_temperature': 0.5228659281382096, 'l2_leaf_reg': 7.057451956053086e-06, 'border_count': 109}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:44,613] Trial 122 finished with value: 0.6212103554689915 and parameters: {'iterations': 942, 'depth': 9, 'learning_rate': 0.1431799203306295, 'random_strength': 3, 'bagging_temperature': 0.4940644893926798, 'l2_leaf_reg': 5.783096887022196e-06, 'border_count': 105}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:50,490] Trial 123 finished with value: 0.6569195962515154 and parameters: {'iterations': 918, 'depth': 9, 'learning_rate': 0.14604610409975305, 'random_strength': 4, 'bagging_temperature': 0.40721091842451546, 'l2_leaf_reg': 8.886644561525533e-06, 'border_count': 112}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:01:59,271] Trial 124 finished with value: 0.6330324043735929 and parameters: {'iterations': 902, 'depth': 9, 'learning_rate': 0.15025740747203234, 'random_strength': 5, 'bagging_temperature': 0.3777256490370936, 'l2_leaf_reg': 5.118718157720172e-06, 'border_count': 101}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:02:09,547] Trial 125 finished with value: 0.6168461267875305 and parameters: {'iterations': 969, 'depth': 9, 'learning_rate': 0.1604802556355845, 'random_strength': 4, 'bagging_temperature': 0.48020347429307964, 'l2_leaf_reg': 7.571400155927851e-06, 'border_count': 97}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:02:16,536] Trial 126 finished with value: 0.6340062612619213 and parameters: {'iterations': 1129, 'depth': 9, 'learning_rate': 0.15349851507876194, 'random_strength': 3, 'bagging_temperature': 0.45252794197596075, 'l2_leaf_reg': 6.6204429886373566e-06, 'border_count': 107}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:02:24,006] Trial 127 finished with value: 0.6363932463363207 and parameters: {'iterations': 937, 'depth': 10, 'learning_rate': 0.16428370681566618, 'random_strength': 5, 'bagging_temperature': 0.5296047347739907, 'l2_leaf_reg': 1.2079126217176837e-06, 'border_count': 104}. Best is trial 89 with value: 0.5929091906852616.\n",
      "[I 2023-12-07 23:02:33,187] Trial 128 finished with value: 0.5894744535516588 and parameters: {'iterations': 956, 'depth': 9, 'learning_rate': 0.1263016745448219, 'random_strength': 4, 'bagging_temperature': 0.11022353495377599, 'l2_leaf_reg': 9.918169510819463e-06, 'border_count': 109}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:02:42,391] Trial 129 finished with value: 0.6272316460930362 and parameters: {'iterations': 1002, 'depth': 8, 'learning_rate': 0.11670563867342826, 'random_strength': 4, 'bagging_temperature': 0.12511257465203302, 'l2_leaf_reg': 1.0321216665267004e-05, 'border_count': 82}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:02:50,964] Trial 130 finished with value: 0.6235278156714422 and parameters: {'iterations': 959, 'depth': 9, 'learning_rate': 0.12735943131928926, 'random_strength': 3, 'bagging_temperature': 0.14935959928362424, 'l2_leaf_reg': 1.4775825536275199e-05, 'border_count': 109}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:06,199] Trial 131 finished with value: 0.6427802079038883 and parameters: {'iterations': 953, 'depth': 9, 'learning_rate': 0.12105872039604762, 'random_strength': 4, 'bagging_temperature': 0.16305865711420575, 'l2_leaf_reg': 9.455231689452071e-06, 'border_count': 111}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:13,463] Trial 132 finished with value: 0.6277570766412987 and parameters: {'iterations': 923, 'depth': 9, 'learning_rate': 0.13373898547897214, 'random_strength': 1, 'bagging_temperature': 0.5736609958285056, 'l2_leaf_reg': 8.27283195656364e-06, 'border_count': 102}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:19,945] Trial 133 finished with value: 0.6678022295816934 and parameters: {'iterations': 986, 'depth': 9, 'learning_rate': 0.15610574835508, 'random_strength': 5, 'bagging_temperature': 0.2025986587029815, 'l2_leaf_reg': 7.098231401555444e-06, 'border_count': 114}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:28,072] Trial 134 finished with value: 0.6216512679667278 and parameters: {'iterations': 1109, 'depth': 9, 'learning_rate': 0.15958115400587267, 'random_strength': 4, 'bagging_temperature': 0.10886667299408756, 'l2_leaf_reg': 5.975289370286406e-06, 'border_count': 99}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:36,122] Trial 135 finished with value: 0.6482601327483409 and parameters: {'iterations': 932, 'depth': 9, 'learning_rate': 0.14983073958670948, 'random_strength': 4, 'bagging_temperature': 0.5120035254722156, 'l2_leaf_reg': 1.0846371169608602e-05, 'border_count': 108}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:45,821] Trial 136 finished with value: 0.6272564651735151 and parameters: {'iterations': 943, 'depth': 9, 'learning_rate': 0.14176453256890184, 'random_strength': 6, 'bagging_temperature': 0.3596574521786161, 'l2_leaf_reg': 1.5082165633735444e-06, 'border_count': 105}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:03:56,243] Trial 137 finished with value: 0.6329791048226963 and parameters: {'iterations': 1118, 'depth': 10, 'learning_rate': 0.10471322540662066, 'random_strength': 5, 'bagging_temperature': 0.42215002343657626, 'l2_leaf_reg': 8.900019397759686e-06, 'border_count': 111}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:05,792] Trial 138 finished with value: 0.6217173467047993 and parameters: {'iterations': 1023, 'depth': 9, 'learning_rate': 0.13732445303792035, 'random_strength': 4, 'bagging_temperature': 0.4937336578464826, 'l2_leaf_reg': 1.296373031067848e-06, 'border_count': 116}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:13,842] Trial 139 finished with value: 0.6291586279913023 and parameters: {'iterations': 912, 'depth': 9, 'learning_rate': 0.16640183766010777, 'random_strength': 2, 'bagging_temperature': 0.3231955251433982, 'l2_leaf_reg': 1.223729844056146e-05, 'border_count': 78}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:27,484] Trial 140 finished with value: 0.635136445368052 and parameters: {'iterations': 1083, 'depth': 8, 'learning_rate': 0.14654569174958373, 'random_strength': 3, 'bagging_temperature': 0.47000626507091703, 'l2_leaf_reg': 3.7384655962308745e-06, 'border_count': 107}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:42,238] Trial 141 finished with value: 0.633104518170473 and parameters: {'iterations': 1050, 'depth': 8, 'learning_rate': 0.13073887645683874, 'random_strength': 9, 'bagging_temperature': 0.606369743597299, 'l2_leaf_reg': 7.716078647087012e-06, 'border_count': 140}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:49,418] Trial 142 finished with value: 0.6395324015107445 and parameters: {'iterations': 1054, 'depth': 8, 'learning_rate': 0.18748057108795205, 'random_strength': 5, 'bagging_temperature': 0.5457312366781759, 'l2_leaf_reg': 1.0183230178540737e-05, 'border_count': 104}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:04:57,807] Trial 143 finished with value: 0.6308991105843527 and parameters: {'iterations': 1101, 'depth': 8, 'learning_rate': 0.1527471658391145, 'random_strength': 6, 'bagging_temperature': 0.5604134747027159, 'l2_leaf_reg': 6.641678916191582e-06, 'border_count': 102}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:04,797] Trial 144 finished with value: 0.6339608580560531 and parameters: {'iterations': 1067, 'depth': 8, 'learning_rate': 0.1619916455986047, 'random_strength': 8, 'bagging_temperature': 0.5196409254077609, 'l2_leaf_reg': 9.377167084322276e-06, 'border_count': 109}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:14,511] Trial 145 finished with value: 0.6443804117422598 and parameters: {'iterations': 1166, 'depth': 8, 'learning_rate': 0.12476489575206647, 'random_strength': 9, 'bagging_temperature': 0.6246489056884106, 'l2_leaf_reg': 2.6177329775697716e-06, 'border_count': 63}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:22,726] Trial 146 finished with value: 0.608146645447148 and parameters: {'iterations': 1146, 'depth': 9, 'learning_rate': 0.1581425395994382, 'random_strength': 4, 'bagging_temperature': 0.5803073445704479, 'l2_leaf_reg': 1.013568789382926e-06, 'border_count': 100}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:30,165] Trial 147 finished with value: 0.6696560902068702 and parameters: {'iterations': 1141, 'depth': 9, 'learning_rate': 0.1569660262140039, 'random_strength': 4, 'bagging_temperature': 0.3870849477519446, 'l2_leaf_reg': 1.0830711510262052e-06, 'border_count': 87}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:37,923] Trial 148 finished with value: 0.6591049605979209 and parameters: {'iterations': 1154, 'depth': 9, 'learning_rate': 0.15920127150319396, 'random_strength': 4, 'bagging_temperature': 0.5779121056339198, 'l2_leaf_reg': 1.1804500908101707e-06, 'border_count': 96}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:44,346] Trial 149 finished with value: 0.6275797349265253 and parameters: {'iterations': 931, 'depth': 9, 'learning_rate': 0.15484682280449852, 'random_strength': 3, 'bagging_temperature': 0.5410595393383552, 'l2_leaf_reg': 1.0857525808786533e-06, 'border_count': 100}. Best is trial 128 with value: 0.5894744535516588.\n",
      "[I 2023-12-07 23:05:44,347] A new study created in memory with name: no-name-98d5231c-07d5-4a79-9f59-fcc83d9b2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'iterations': 956, 'depth': 9, 'learning_rate': 0.1263016745448219, 'random_strength': 4, 'bagging_temperature': 0.11022353495377599, 'l2_leaf_reg': 9.918169510819463e-06, 'border_count': 109}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 23:05:47,260] Trial 0 finished with value: 0.7094670832810533 and parameters: {'iterations': 927, 'depth': 8, 'learning_rate': 0.2246578830201884, 'random_strength': 10, 'bagging_temperature': 0.48883262933009486, 'l2_leaf_reg': 5.202728475579945e-05, 'border_count': 148}. Best is trial 0 with value: 0.7094670832810533.\n",
      "[I 2023-12-07 23:05:52,609] Trial 1 finished with value: 0.6801659870650618 and parameters: {'iterations': 999, 'depth': 8, 'learning_rate': 0.10533692487472691, 'random_strength': 9, 'bagging_temperature': 0.6038811739352704, 'l2_leaf_reg': 1.4333907920984423e-05, 'border_count': 98}. Best is trial 1 with value: 0.6801659870650618.\n",
      "[I 2023-12-07 23:05:55,280] Trial 2 finished with value: 0.6922838269198185 and parameters: {'iterations': 931, 'depth': 10, 'learning_rate': 0.23533132497839834, 'random_strength': 9, 'bagging_temperature': 0.7802716976635609, 'l2_leaf_reg': 2.713644706624146e-05, 'border_count': 100}. Best is trial 1 with value: 0.6801659870650618.\n",
      "[I 2023-12-07 23:05:57,159] Trial 3 finished with value: 0.6604802669647039 and parameters: {'iterations': 928, 'depth': 8, 'learning_rate': 0.2464557243907714, 'random_strength': 1, 'bagging_temperature': 0.3838157276583598, 'l2_leaf_reg': 7.842263246508976e-06, 'border_count': 83}. Best is trial 3 with value: 0.6604802669647039.\n",
      "[I 2023-12-07 23:06:01,035] Trial 4 finished with value: 0.7035244696615031 and parameters: {'iterations': 1069, 'depth': 10, 'learning_rate': 0.20486061769453479, 'random_strength': 6, 'bagging_temperature': 0.24558284965131702, 'l2_leaf_reg': 5.5714720819592764e-06, 'border_count': 121}. Best is trial 3 with value: 0.6604802669647039.\n",
      "[I 2023-12-07 23:06:04,050] Trial 5 finished with value: 0.6347512046700396 and parameters: {'iterations': 1035, 'depth': 10, 'learning_rate': 0.1563790913422753, 'random_strength': 0, 'bagging_temperature': 0.6308305005551773, 'l2_leaf_reg': 5.325638966628733e-06, 'border_count': 65}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:07,358] Trial 6 finished with value: 0.6731758752320899 and parameters: {'iterations': 1095, 'depth': 8, 'learning_rate': 0.17112434852356978, 'random_strength': 7, 'bagging_temperature': 0.7861701629323856, 'l2_leaf_reg': 7.62785825947592e-06, 'border_count': 146}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:11,387] Trial 7 finished with value: 0.6791070112961427 and parameters: {'iterations': 905, 'depth': 8, 'learning_rate': 0.10322061470584742, 'random_strength': 7, 'bagging_temperature': 0.5972427137996144, 'l2_leaf_reg': 1.8016384193685283e-05, 'border_count': 55}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:14,456] Trial 8 finished with value: 0.7081276706611954 and parameters: {'iterations': 950, 'depth': 8, 'learning_rate': 0.19009337634251305, 'random_strength': 7, 'bagging_temperature': 0.4950064167143252, 'l2_leaf_reg': 1.6738236947507197e-06, 'border_count': 68}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:18,550] Trial 9 finished with value: 0.6650549854288674 and parameters: {'iterations': 976, 'depth': 8, 'learning_rate': 0.12965729039898374, 'random_strength': 9, 'bagging_temperature': 0.34643951862993005, 'l2_leaf_reg': 7.427051646828373e-06, 'border_count': 107}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:21,180] Trial 10 finished with value: 0.6546004351878368 and parameters: {'iterations': 1178, 'depth': 9, 'learning_rate': 0.16061372057915452, 'random_strength': 0, 'bagging_temperature': 0.9787573855931218, 'l2_leaf_reg': 9.577671792336873e-05, 'border_count': 53}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:23,644] Trial 11 finished with value: 0.6730141884471065 and parameters: {'iterations': 1175, 'depth': 9, 'learning_rate': 0.15848199614649808, 'random_strength': 0, 'bagging_temperature': 0.9426640990955106, 'l2_leaf_reg': 8.006663835022664e-05, 'border_count': 52}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:25,908] Trial 12 finished with value: 0.6782530596009136 and parameters: {'iterations': 1197, 'depth': 9, 'learning_rate': 0.15245669566085956, 'random_strength': 3, 'bagging_temperature': 0.9845123838508295, 'l2_leaf_reg': 3.527220404028742e-05, 'border_count': 73}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:28,688] Trial 13 finished with value: 0.6852896804031932 and parameters: {'iterations': 1128, 'depth': 10, 'learning_rate': 0.14258118712202636, 'random_strength': 3, 'bagging_temperature': 0.7378936059628851, 'l2_leaf_reg': 9.900885618919895e-05, 'border_count': 67}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:31,337] Trial 14 finished with value: 0.6839317899979546 and parameters: {'iterations': 1018, 'depth': 9, 'learning_rate': 0.1816141047755283, 'random_strength': 2, 'bagging_temperature': 0.11690531707619145, 'l2_leaf_reg': 3.451957473624801e-06, 'border_count': 50}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:33,918] Trial 15 finished with value: 0.6415833134895017 and parameters: {'iterations': 1140, 'depth': 10, 'learning_rate': 0.1674970708544554, 'random_strength': 0, 'bagging_temperature': 0.8897697967076639, 'l2_leaf_reg': 1.544526587275099e-05, 'border_count': 84}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:36,547] Trial 16 finished with value: 0.6552223977602072 and parameters: {'iterations': 1121, 'depth': 10, 'learning_rate': 0.19603317745252205, 'random_strength': 3, 'bagging_temperature': 0.703405088436186, 'l2_leaf_reg': 1.4078735953227078e-05, 'border_count': 88}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:39,215] Trial 17 finished with value: 0.6549752394161594 and parameters: {'iterations': 1044, 'depth': 10, 'learning_rate': 0.17579911317818764, 'random_strength': 1, 'bagging_temperature': 0.8916260498879691, 'l2_leaf_reg': 3.6674677060787753e-06, 'border_count': 80}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:43,448] Trial 18 finished with value: 0.6703228300055001 and parameters: {'iterations': 1132, 'depth': 10, 'learning_rate': 0.12914837998325943, 'random_strength': 4, 'bagging_temperature': 0.8487407882657856, 'l2_leaf_reg': 1.1491670376459618e-06, 'border_count': 117}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:45,695] Trial 19 finished with value: 0.6428052392226238 and parameters: {'iterations': 1056, 'depth': 10, 'learning_rate': 0.20699306060995737, 'random_strength': 1, 'bagging_temperature': 0.6616021230624813, 'l2_leaf_reg': 1.169913262660664e-05, 'border_count': 90}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:48,520] Trial 20 finished with value: 0.6560025340278018 and parameters: {'iterations': 1092, 'depth': 9, 'learning_rate': 0.1794461534979706, 'random_strength': 5, 'bagging_temperature': 0.8194861931593419, 'l2_leaf_reg': 2.277498314969263e-05, 'border_count': 66}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:50,645] Trial 21 finished with value: 0.6659913314534212 and parameters: {'iterations': 1037, 'depth': 10, 'learning_rate': 0.20914367902135023, 'random_strength': 1, 'bagging_temperature': 0.6842151511724142, 'l2_leaf_reg': 1.1402122174428072e-05, 'border_count': 93}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:52,935] Trial 22 finished with value: 0.6468312867026413 and parameters: {'iterations': 1065, 'depth': 10, 'learning_rate': 0.21404378598774754, 'random_strength': 0, 'bagging_temperature': 0.6465926165355692, 'l2_leaf_reg': 1.0766728567614677e-05, 'border_count': 78}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:55,571] Trial 23 finished with value: 0.6463815733079604 and parameters: {'iterations': 996, 'depth': 10, 'learning_rate': 0.19123788883262674, 'random_strength': 2, 'bagging_temperature': 0.8824751395813611, 'l2_leaf_reg': 1.9360973736904738e-05, 'border_count': 108}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:06:58,708] Trial 24 finished with value: 0.6420437132828737 and parameters: {'iterations': 1154, 'depth': 10, 'learning_rate': 0.1666282160202781, 'random_strength': 2, 'bagging_temperature': 0.7207534229927768, 'l2_leaf_reg': 5.480604296182879e-06, 'border_count': 89}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:07:02,390] Trial 25 finished with value: 0.7117327608442742 and parameters: {'iterations': 1156, 'depth': 10, 'learning_rate': 0.16983624096140088, 'random_strength': 2, 'bagging_temperature': 0.7253886843850108, 'l2_leaf_reg': 5.108872064977319e-06, 'border_count': 61}. Best is trial 5 with value: 0.6347512046700396.\n",
      "[I 2023-12-07 23:07:04,696] Trial 26 finished with value: 0.6328446874206756 and parameters: {'iterations': 1094, 'depth': 9, 'learning_rate': 0.165136899871376, 'random_strength': 0, 'bagging_temperature': 0.8977907984147008, 'l2_leaf_reg': 3.0714547481458674e-06, 'border_count': 77}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:07,444] Trial 27 finished with value: 0.6439006785081242 and parameters: {'iterations': 1095, 'depth': 9, 'learning_rate': 0.14755225270079272, 'random_strength': 0, 'bagging_temperature': 0.9083883018302286, 'l2_leaf_reg': 2.425556642445472e-06, 'border_count': 76}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:10,004] Trial 28 finished with value: 0.6747802752118663 and parameters: {'iterations': 1109, 'depth': 9, 'learning_rate': 0.16013616468072303, 'random_strength': 0, 'bagging_temperature': 0.8468302339703792, 'l2_leaf_reg': 2.7110720627257055e-06, 'border_count': 59}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:13,099] Trial 29 finished with value: 0.6696218626507471 and parameters: {'iterations': 1080, 'depth': 9, 'learning_rate': 0.1402354481142743, 'random_strength': 1, 'bagging_temperature': 0.9421478819210855, 'l2_leaf_reg': 4.3307352680753604e-05, 'border_count': 72}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:16,139] Trial 30 finished with value: 0.7042043335859561 and parameters: {'iterations': 1144, 'depth': 9, 'learning_rate': 0.18308317402064145, 'random_strength': 4, 'bagging_temperature': 0.7944795255407368, 'l2_leaf_reg': 3.842385185926536e-06, 'border_count': 83}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:19,627] Trial 31 finished with value: 0.6598037950719724 and parameters: {'iterations': 1160, 'depth': 10, 'learning_rate': 0.1698344211699683, 'random_strength': 2, 'bagging_temperature': 0.5577611504189721, 'l2_leaf_reg': 5.720765902742081e-06, 'border_count': 85}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:21,844] Trial 32 finished with value: 0.6743477515145561 and parameters: {'iterations': 1029, 'depth': 10, 'learning_rate': 0.16314494949150854, 'random_strength': 0, 'bagging_temperature': 0.7571987462065279, 'l2_leaf_reg': 4.510792428253052e-06, 'border_count': 95}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:25,489] Trial 33 finished with value: 0.6470904372143078 and parameters: {'iterations': 1111, 'depth': 10, 'learning_rate': 0.1538577072037723, 'random_strength': 1, 'bagging_temperature': 0.8228204167008929, 'l2_leaf_reg': 8.386750195245926e-06, 'border_count': 104}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:27,752] Trial 34 finished with value: 0.6990974426316472 and parameters: {'iterations': 1148, 'depth': 9, 'learning_rate': 0.16785112571415012, 'random_strength': 2, 'bagging_temperature': 0.6134499304646086, 'l2_leaf_reg': 6.2523156243561335e-06, 'border_count': 99}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:31,063] Trial 35 finished with value: 0.6412170414231969 and parameters: {'iterations': 1190, 'depth': 10, 'learning_rate': 0.15086573615264834, 'random_strength': 1, 'bagging_temperature': 0.7449495735534369, 'l2_leaf_reg': 1.0109452579632571e-05, 'border_count': 63}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:33,406] Trial 36 finished with value: 0.6693542874454482 and parameters: {'iterations': 1194, 'depth': 10, 'learning_rate': 0.13660270539984593, 'random_strength': 1, 'bagging_temperature': 0.7819248122791064, 'l2_leaf_reg': 9.003804281921082e-06, 'border_count': 62}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:38,571] Trial 37 finished with value: 0.6680849499527093 and parameters: {'iterations': 1174, 'depth': 9, 'learning_rate': 0.14955598150453187, 'random_strength': 10, 'bagging_temperature': 0.8492627469294504, 'l2_leaf_reg': 1.5153773147245787e-05, 'border_count': 138}. Best is trial 26 with value: 0.6328446874206756.\n",
      "[I 2023-12-07 23:07:41,704] Trial 38 finished with value: 0.6303931540802252 and parameters: {'iterations': 1015, 'depth': 10, 'learning_rate': 0.11368520615791583, 'random_strength': 0, 'bagging_temperature': 0.7716297776743714, 'l2_leaf_reg': 6.80979932781304e-06, 'border_count': 72}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:44,630] Trial 39 finished with value: 0.6740934766950236 and parameters: {'iterations': 980, 'depth': 10, 'learning_rate': 0.11803583085737654, 'random_strength': 1, 'bagging_temperature': 0.6404763627043606, 'l2_leaf_reg': 7.794659731511786e-06, 'border_count': 59}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:47,133] Trial 40 finished with value: 0.6541313867174252 and parameters: {'iterations': 1011, 'depth': 9, 'learning_rate': 0.11653249112982457, 'random_strength': 0, 'bagging_temperature': 0.7604324534514368, 'l2_leaf_reg': 6.519988466942229e-06, 'border_count': 71}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:49,599] Trial 41 finished with value: 0.6696279863463139 and parameters: {'iterations': 1082, 'depth': 10, 'learning_rate': 0.15580578282320173, 'random_strength': 0, 'bagging_temperature': 0.6948139714401438, 'l2_leaf_reg': 9.378825966000924e-06, 'border_count': 65}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:52,033] Trial 42 finished with value: 0.6559326198562399 and parameters: {'iterations': 992, 'depth': 10, 'learning_rate': 0.14501571778174435, 'random_strength': 0, 'bagging_temperature': 0.801982380663333, 'l2_leaf_reg': 1.3083867864306688e-05, 'border_count': 77}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:54,864] Trial 43 finished with value: 0.6558875258107469 and parameters: {'iterations': 1053, 'depth': 10, 'learning_rate': 0.17538856374798403, 'random_strength': 1, 'bagging_temperature': 0.9060123644486245, 'l2_leaf_reg': 9.849865272714171e-06, 'border_count': 71}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:07:58,505] Trial 44 finished with value: 0.7040146055349257 and parameters: {'iterations': 1018, 'depth': 10, 'learning_rate': 0.10301169250638464, 'random_strength': 0, 'bagging_temperature': 0.7594757650505716, 'l2_leaf_reg': 6.924310704444487e-06, 'border_count': 56}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:01,827] Trial 45 finished with value: 0.668801271392359 and parameters: {'iterations': 973, 'depth': 8, 'learning_rate': 0.16221556733197692, 'random_strength': 6, 'bagging_temperature': 0.5701953686376755, 'l2_leaf_reg': 4.367662178080765e-06, 'border_count': 82}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:04,017] Trial 46 finished with value: 0.6570187300524698 and parameters: {'iterations': 941, 'depth': 10, 'learning_rate': 0.15340188565827284, 'random_strength': 1, 'bagging_temperature': 0.962073889151665, 'l2_leaf_reg': 1.7597866469618607e-05, 'border_count': 75}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:06,753] Trial 47 finished with value: 0.6637874781726332 and parameters: {'iterations': 1185, 'depth': 10, 'learning_rate': 0.1363097649384278, 'random_strength': 0, 'bagging_temperature': 0.9953135789893486, 'l2_leaf_reg': 7.212121943309541e-06, 'border_count': 68}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:09,314] Trial 48 finished with value: 0.6977491711301281 and parameters: {'iterations': 1166, 'depth': 9, 'learning_rate': 0.1582807627778717, 'random_strength': 3, 'bagging_temperature': 0.5338816965661958, 'l2_leaf_reg': 2.4956569506099648e-05, 'border_count': 55}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:12,023] Trial 49 finished with value: 0.6313742075259147 and parameters: {'iterations': 1113, 'depth': 10, 'learning_rate': 0.14740997995204522, 'random_strength': 0, 'bagging_temperature': 0.8674726232293001, 'l2_leaf_reg': 2.949148221551814e-06, 'border_count': 64}. Best is trial 38 with value: 0.6303931540802252.\n",
      "[I 2023-12-07 23:08:15,023] Trial 50 finished with value: 0.6248152459394875 and parameters: {'iterations': 1066, 'depth': 9, 'learning_rate': 0.13006722764987766, 'random_strength': 1, 'bagging_temperature': 0.732318757678134, 'l2_leaf_reg': 2.8675355465607892e-06, 'border_count': 65}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:18,526] Trial 51 finished with value: 0.6642362772683935 and parameters: {'iterations': 1036, 'depth': 9, 'learning_rate': 0.14540457071700175, 'random_strength': 1, 'bagging_temperature': 0.7303031816706463, 'l2_leaf_reg': 2.888799137434339e-06, 'border_count': 63}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:21,887] Trial 52 finished with value: 0.6651416306769927 and parameters: {'iterations': 1064, 'depth': 9, 'learning_rate': 0.1319615489002958, 'random_strength': 0, 'bagging_temperature': 0.7946646870476062, 'l2_leaf_reg': 2.1329623959324183e-06, 'border_count': 57}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:25,418] Trial 53 finished with value: 0.6730753637044301 and parameters: {'iterations': 1076, 'depth': 9, 'learning_rate': 0.1230821239265288, 'random_strength': 1, 'bagging_temperature': 0.6867167510114524, 'l2_leaf_reg': 3.239147678878479e-06, 'border_count': 68}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:28,525] Trial 54 finished with value: 0.6827035350564283 and parameters: {'iterations': 1107, 'depth': 8, 'learning_rate': 0.11137650008006726, 'random_strength': 2, 'bagging_temperature': 0.7599653680866619, 'l2_leaf_reg': 4.512152444476477e-06, 'border_count': 50}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:32,273] Trial 55 finished with value: 0.670240205843523 and parameters: {'iterations': 1028, 'depth': 9, 'learning_rate': 0.14073581938450705, 'random_strength': 8, 'bagging_temperature': 0.6655973981146287, 'l2_leaf_reg': 1.8264480570583821e-06, 'border_count': 64}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:34,663] Trial 56 finished with value: 0.6792781898750226 and parameters: {'iterations': 1050, 'depth': 10, 'learning_rate': 0.12901359847847357, 'random_strength': 0, 'bagging_temperature': 0.833691174016437, 'l2_leaf_reg': 3.2939070585690476e-06, 'border_count': 70}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:39,023] Trial 57 finished with value: 0.6582940119626755 and parameters: {'iterations': 1095, 'depth': 9, 'learning_rate': 0.15044369672144317, 'random_strength': 4, 'bagging_temperature': 0.8543839068199799, 'l2_leaf_reg': 3.7624242480845585e-06, 'border_count': 53}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:42,792] Trial 58 finished with value: 0.6556152811186574 and parameters: {'iterations': 1010, 'depth': 10, 'learning_rate': 0.10737199014478857, 'random_strength': 2, 'bagging_temperature': 0.6162373131066785, 'l2_leaf_reg': 5.0724658429077395e-06, 'border_count': 74}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:45,717] Trial 59 finished with value: 0.6994194930461727 and parameters: {'iterations': 1128, 'depth': 10, 'learning_rate': 0.12366146465688808, 'random_strength': 3, 'bagging_temperature': 0.7150288248668567, 'l2_leaf_reg': 2.3465692498132184e-06, 'border_count': 62}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:48,279] Trial 60 finished with value: 0.6591885579234507 and parameters: {'iterations': 1070, 'depth': 9, 'learning_rate': 0.14717797539082741, 'random_strength': 1, 'bagging_temperature': 0.8050669500579777, 'l2_leaf_reg': 3.0714168867892856e-06, 'border_count': 80}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:50,609] Trial 61 finished with value: 0.6484143892838228 and parameters: {'iterations': 1138, 'depth': 10, 'learning_rate': 0.16473085607319662, 'random_strength': 0, 'bagging_temperature': 0.8759378493777642, 'l2_leaf_reg': 2.7329642331272155e-06, 'border_count': 86}. Best is trial 50 with value: 0.6248152459394875.\n",
      "[I 2023-12-07 23:08:53,160] Trial 62 finished with value: 0.6234453601583366 and parameters: {'iterations': 1121, 'depth': 10, 'learning_rate': 0.1574614315151278, 'random_strength': 0, 'bagging_temperature': 0.9265950035942817, 'l2_leaf_reg': 4.021100263977743e-06, 'border_count': 79}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:08:55,549] Trial 63 finished with value: 0.6583501550995557 and parameters: {'iterations': 1119, 'depth': 10, 'learning_rate': 0.15666403399034776, 'random_strength': 0, 'bagging_temperature': 0.9296748855135685, 'l2_leaf_reg': 3.9058050278888404e-06, 'border_count': 68}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:08:58,177] Trial 64 finished with value: 0.6567269575141743 and parameters: {'iterations': 1085, 'depth': 10, 'learning_rate': 0.15337366414670292, 'random_strength': 1, 'bagging_temperature': 0.9224456047741878, 'l2_leaf_reg': 5.670132230789367e-06, 'border_count': 79}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:00,741] Trial 65 finished with value: 0.6367380441729854 and parameters: {'iterations': 1060, 'depth': 10, 'learning_rate': 0.1418343264831292, 'random_strength': 1, 'bagging_temperature': 0.9753121293433203, 'l2_leaf_reg': 4.467570281567233e-06, 'border_count': 59}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:03,902] Trial 66 finished with value: 0.6237393298682739 and parameters: {'iterations': 1103, 'depth': 10, 'learning_rate': 0.14142554086619066, 'random_strength': 0, 'bagging_temperature': 0.9635489125387366, 'l2_leaf_reg': 4.377560256103958e-06, 'border_count': 59}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:06,542] Trial 67 finished with value: 0.6712645849246657 and parameters: {'iterations': 1100, 'depth': 10, 'learning_rate': 0.1363180871296587, 'random_strength': 0, 'bagging_temperature': 0.9512052593574505, 'l2_leaf_reg': 3.3605060705879265e-06, 'border_count': 66}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:08,873] Trial 68 finished with value: 0.642273115076747 and parameters: {'iterations': 1116, 'depth': 10, 'learning_rate': 0.15967681325324032, 'random_strength': 0, 'bagging_temperature': 0.8781909367528646, 'l2_leaf_reg': 3.891252286155193e-06, 'border_count': 74}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:11,563] Trial 69 finished with value: 0.7029137183635558 and parameters: {'iterations': 1045, 'depth': 9, 'learning_rate': 0.14589960025061932, 'random_strength': 0, 'bagging_temperature': 0.9991093563629803, 'l2_leaf_reg': 5.0802902760546685e-06, 'border_count': 91}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:14,157] Trial 70 finished with value: 0.660407535007001 and parameters: {'iterations': 1089, 'depth': 10, 'learning_rate': 0.17171064618550125, 'random_strength': 0, 'bagging_temperature': 0.9307500615705255, 'l2_leaf_reg': 2.887967431687251e-06, 'border_count': 131}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:17,022] Trial 71 finished with value: 0.6587977342429067 and parameters: {'iterations': 1103, 'depth': 10, 'learning_rate': 0.13949312273911404, 'random_strength': 1, 'bagging_temperature': 0.9752582296759124, 'l2_leaf_reg': 4.353124682557084e-06, 'border_count': 60}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:20,185] Trial 72 finished with value: 0.6941835994923071 and parameters: {'iterations': 1059, 'depth': 10, 'learning_rate': 0.14310664802885964, 'random_strength': 1, 'bagging_temperature': 0.9644130278110346, 'l2_leaf_reg': 6.165820317441824e-06, 'border_count': 60}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:23,163] Trial 73 finished with value: 0.6675800573009772 and parameters: {'iterations': 1125, 'depth': 10, 'learning_rate': 0.13222958609171748, 'random_strength': 0, 'bagging_temperature': 0.9128170807081688, 'l2_leaf_reg': 4.814836823301822e-06, 'border_count': 58}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:26,462] Trial 74 finished with value: 0.6518119108364837 and parameters: {'iterations': 1038, 'depth': 10, 'learning_rate': 0.1506508594279187, 'random_strength': 0, 'bagging_temperature': 0.8946832917706078, 'l2_leaf_reg': 3.4454342992220184e-06, 'border_count': 53}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:29,189] Trial 75 finished with value: 0.7145822437192756 and parameters: {'iterations': 1059, 'depth': 10, 'learning_rate': 0.16331373660688506, 'random_strength': 2, 'bagging_temperature': 0.9507379641393997, 'l2_leaf_reg': 5.583974000527936e-06, 'border_count': 70}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:32,058] Trial 76 finished with value: 0.6427423868426424 and parameters: {'iterations': 1073, 'depth': 10, 'learning_rate': 0.14279188952804622, 'random_strength': 1, 'bagging_temperature': 0.8695092532158899, 'l2_leaf_reg': 4.238908118129175e-06, 'border_count': 66}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:34,481] Trial 77 finished with value: 0.6654036417147865 and parameters: {'iterations': 1136, 'depth': 9, 'learning_rate': 0.15792673955384326, 'random_strength': 0, 'bagging_temperature': 0.9742398699758918, 'l2_leaf_reg': 2.481566508622863e-06, 'border_count': 56}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:37,258] Trial 78 finished with value: 0.634986852296828 and parameters: {'iterations': 1024, 'depth': 10, 'learning_rate': 0.14839083140284312, 'random_strength': 1, 'bagging_temperature': 0.9358614672440521, 'l2_leaf_reg': 3.711377845282458e-06, 'border_count': 77}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:39,870] Trial 79 finished with value: 0.6456477953646952 and parameters: {'iterations': 904, 'depth': 10, 'learning_rate': 0.15286760162605895, 'random_strength': 0, 'bagging_temperature': 0.8174390517212451, 'l2_leaf_reg': 3.751275018926658e-06, 'border_count': 82}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:43,303] Trial 80 finished with value: 0.689484288808538 and parameters: {'iterations': 1007, 'depth': 9, 'learning_rate': 0.10026097365468775, 'random_strength': 6, 'bagging_temperature': 0.9029499835238053, 'l2_leaf_reg': 2.972277884358672e-06, 'border_count': 78}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:46,900] Trial 81 finished with value: 0.6721390713644507 and parameters: {'iterations': 987, 'depth': 10, 'learning_rate': 0.14819922027816732, 'random_strength': 1, 'bagging_temperature': 0.9357475121966837, 'l2_leaf_reg': 4.756150033030115e-06, 'border_count': 73}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:50,905] Trial 82 finished with value: 0.7110858669963427 and parameters: {'iterations': 1022, 'depth': 10, 'learning_rate': 0.13829633325157653, 'random_strength': 2, 'bagging_temperature': 0.8690833022296609, 'l2_leaf_reg': 4.065991183516465e-06, 'border_count': 69}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:53,700] Trial 83 finished with value: 0.6639905212871386 and parameters: {'iterations': 1032, 'depth': 10, 'learning_rate': 0.1429552582799786, 'random_strength': 1, 'bagging_temperature': 0.8358611052442867, 'l2_leaf_reg': 6.246543075355785e-06, 'border_count': 76}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:56,595] Trial 84 finished with value: 0.6633631441784661 and parameters: {'iterations': 1043, 'depth': 10, 'learning_rate': 0.14911179014769796, 'random_strength': 1, 'bagging_temperature': 0.9839211301726177, 'l2_leaf_reg': 3.5317887914304095e-06, 'border_count': 64}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:09:59,487] Trial 85 finished with value: 0.6734628345696938 and parameters: {'iterations': 1002, 'depth': 10, 'learning_rate': 0.16072390365364211, 'random_strength': 0, 'bagging_temperature': 0.9165774377768839, 'l2_leaf_reg': 7.056691368567702e-06, 'border_count': 116}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:10:01,720] Trial 86 finished with value: 0.6764036952743251 and parameters: {'iterations': 1114, 'depth': 10, 'learning_rate': 0.16502340154314007, 'random_strength': 5, 'bagging_temperature': 0.947201421614446, 'l2_leaf_reg': 4.9780891786691714e-06, 'border_count': 87}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:10:03,970] Trial 87 finished with value: 0.6879923813356672 and parameters: {'iterations': 1023, 'depth': 10, 'learning_rate': 0.1566073140447035, 'random_strength': 2, 'bagging_temperature': 0.8568399009458634, 'l2_leaf_reg': 8.105541784486821e-06, 'border_count': 72}. Best is trial 62 with value: 0.6234453601583366.\n",
      "[I 2023-12-07 23:10:06,899] Trial 88 finished with value: 0.6220824993943405 and parameters: {'iterations': 1084, 'depth': 10, 'learning_rate': 0.13423849820881487, 'random_strength': 0, 'bagging_temperature': 0.9638357334127471, 'l2_leaf_reg': 3.157131219199917e-06, 'border_count': 62}. Best is trial 88 with value: 0.6220824993943405.\n",
      "[I 2023-12-07 23:10:09,993] Trial 89 finished with value: 0.6952050368823525 and parameters: {'iterations': 1089, 'depth': 10, 'learning_rate': 0.13261248658882785, 'random_strength': 0, 'bagging_temperature': 0.8877034301546942, 'l2_leaf_reg': 2.6652133785935375e-06, 'border_count': 66}. Best is trial 88 with value: 0.6220824993943405.\n",
      "[I 2023-12-07 23:10:12,270] Trial 90 finished with value: 0.6701520460871055 and parameters: {'iterations': 1081, 'depth': 9, 'learning_rate': 0.13507649537518326, 'random_strength': 0, 'bagging_temperature': 0.7763402523759737, 'l2_leaf_reg': 3.2867264669011663e-06, 'border_count': 81}. Best is trial 88 with value: 0.6220824993943405.\n",
      "[I 2023-12-07 23:10:14,874] Trial 91 finished with value: 0.6477467984843813 and parameters: {'iterations': 1063, 'depth': 10, 'learning_rate': 0.14078868163559982, 'random_strength': 1, 'bagging_temperature': 0.9989084533435987, 'l2_leaf_reg': 4.132683183263885e-06, 'border_count': 61}. Best is trial 88 with value: 0.6220824993943405.\n",
      "[I 2023-12-07 23:10:18,381] Trial 92 finished with value: 0.6159020690452929 and parameters: {'iterations': 1050, 'depth': 10, 'learning_rate': 0.14374245859390913, 'random_strength': 0, 'bagging_temperature': 0.9652054833669892, 'l2_leaf_reg': 3.0337119972706364e-06, 'border_count': 55}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:20,916] Trial 93 finished with value: 0.6489063300008977 and parameters: {'iterations': 1101, 'depth': 10, 'learning_rate': 0.12924680560144589, 'random_strength': 0, 'bagging_temperature': 0.9054961629367267, 'l2_leaf_reg': 2.189619646546774e-06, 'border_count': 64}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:23,801] Trial 94 finished with value: 0.6300514565427126 and parameters: {'iterations': 1052, 'depth': 10, 'learning_rate': 0.14582304658864734, 'random_strength': 0, 'bagging_temperature': 0.9496420743914084, 'l2_leaf_reg': 3.1108558367043753e-06, 'border_count': 55}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:26,156] Trial 95 finished with value: 0.6386188485668235 and parameters: {'iterations': 1076, 'depth': 10, 'learning_rate': 0.15464872557895842, 'random_strength': 0, 'bagging_temperature': 0.9534537860155304, 'l2_leaf_reg': 3.0188056182067748e-06, 'border_count': 50}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:28,724] Trial 96 finished with value: 0.6414368652377654 and parameters: {'iterations': 1051, 'depth': 10, 'learning_rate': 0.1450305460877095, 'random_strength': 0, 'bagging_temperature': 0.9637369207755293, 'l2_leaf_reg': 2.5784696413899315e-06, 'border_count': 54}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:31,020] Trial 97 finished with value: 0.6825609430910625 and parameters: {'iterations': 1068, 'depth': 8, 'learning_rate': 0.13687396064597024, 'random_strength': 0, 'bagging_temperature': 0.9172128755391379, 'l2_leaf_reg': 3.1253047147762497e-06, 'border_count': 52}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:33,647] Trial 98 finished with value: 0.6535973632180389 and parameters: {'iterations': 1096, 'depth': 10, 'learning_rate': 0.12504022692324193, 'random_strength': 0, 'bagging_temperature': 0.8863851940065985, 'l2_leaf_reg': 2.4290722228112543e-06, 'border_count': 57}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:36,856] Trial 99 finished with value: 0.6450412186343383 and parameters: {'iterations': 1107, 'depth': 9, 'learning_rate': 0.12685523913562596, 'random_strength': 0, 'bagging_temperature': 0.8317797434632034, 'l2_leaf_reg': 1.9331460231749834e-06, 'border_count': 62}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:40,141] Trial 100 finished with value: 0.6286078443070406 and parameters: {'iterations': 965, 'depth': 10, 'learning_rate': 0.13331057379635572, 'random_strength': 0, 'bagging_temperature': 0.8614844687795359, 'l2_leaf_reg': 2.8365638334158424e-06, 'border_count': 150}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:43,003] Trial 101 finished with value: 0.6523131867190793 and parameters: {'iterations': 1123, 'depth': 10, 'learning_rate': 0.133467352036219, 'random_strength': 0, 'bagging_temperature': 0.8601560161514616, 'l2_leaf_reg': 2.773847420294797e-06, 'border_count': 123}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:45,216] Trial 102 finished with value: 0.7192342742196404 and parameters: {'iterations': 916, 'depth': 10, 'learning_rate': 0.13765646309269788, 'random_strength': 0, 'bagging_temperature': 0.9318335517803294, 'l2_leaf_reg': 2.255830707917847e-06, 'border_count': 142}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:47,558] Trial 103 finished with value: 0.6438788513893454 and parameters: {'iterations': 975, 'depth': 10, 'learning_rate': 0.13964195548099737, 'random_strength': 0, 'bagging_temperature': 0.9032801833721634, 'l2_leaf_reg': 3.4566056592748706e-06, 'border_count': 150}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:50,945] Trial 104 finished with value: 0.6386312732910275 and parameters: {'iterations': 967, 'depth': 10, 'learning_rate': 0.12118118130010047, 'random_strength': 0, 'bagging_temperature': 0.8433472321826453, 'l2_leaf_reg': 2.6910553773018116e-06, 'border_count': 96}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:53,834] Trial 105 finished with value: 0.6302367373322886 and parameters: {'iterations': 942, 'depth': 10, 'learning_rate': 0.12778529706167657, 'random_strength': 1, 'bagging_temperature': 0.9828006247141633, 'l2_leaf_reg': 3.165125370091725e-06, 'border_count': 104}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:56,782] Trial 106 finished with value: 0.6661087850557856 and parameters: {'iterations': 955, 'depth': 10, 'learning_rate': 0.13014936021583454, 'random_strength': 1, 'bagging_temperature': 0.9828270103137811, 'l2_leaf_reg': 3.0532056583579157e-06, 'border_count': 126}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:10:59,590] Trial 107 finished with value: 0.6426961533448993 and parameters: {'iterations': 931, 'depth': 10, 'learning_rate': 0.126899063865214, 'random_strength': 0, 'bagging_temperature': 0.9661266082361436, 'l2_leaf_reg': 2.043483695462704e-06, 'border_count': 102}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:02,167] Trial 108 finished with value: 0.6615522495699652 and parameters: {'iterations': 948, 'depth': 10, 'learning_rate': 0.11836550389124206, 'random_strength': 1, 'bagging_temperature': 0.9456698993684886, 'l2_leaf_reg': 2.496141040212101e-06, 'border_count': 115}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:04,890] Trial 109 finished with value: 0.6436033963248422 and parameters: {'iterations': 963, 'depth': 9, 'learning_rate': 0.13556758756175383, 'random_strength': 0, 'bagging_temperature': 0.9284551433083112, 'l2_leaf_reg': 3.563375389302823e-06, 'border_count': 113}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:07,381] Trial 110 finished with value: 0.68565110647547 and parameters: {'iterations': 936, 'depth': 10, 'learning_rate': 0.13352723222392646, 'random_strength': 8, 'bagging_temperature': 0.8798401186890266, 'l2_leaf_reg': 2.8852282512082024e-06, 'border_count': 145}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:10,413] Trial 111 finished with value: 0.6437525387137284 and parameters: {'iterations': 1043, 'depth': 10, 'learning_rate': 0.1455803414810869, 'random_strength': 0, 'bagging_temperature': 0.9565099085216747, 'l2_leaf_reg': 3.909188201971051e-06, 'border_count': 131}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:12,714] Trial 112 finished with value: 0.674609214708522 and parameters: {'iterations': 1049, 'depth': 10, 'learning_rate': 0.15145699343839272, 'random_strength': 0, 'bagging_temperature': 0.817706429845617, 'l2_leaf_reg': 3.2033481419744796e-06, 'border_count': 58}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:16,077] Trial 113 finished with value: 0.6494420982002465 and parameters: {'iterations': 916, 'depth': 10, 'learning_rate': 0.13074560867496723, 'random_strength': 1, 'bagging_temperature': 0.9854892815616454, 'l2_leaf_reg': 2.4130388759682693e-06, 'border_count': 110}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:18,655] Trial 114 finished with value: 0.6558361642556517 and parameters: {'iterations': 1084, 'depth': 10, 'learning_rate': 0.13897341642992284, 'random_strength': 1, 'bagging_temperature': 0.9017387102272597, 'l2_leaf_reg': 4.502873915477226e-06, 'border_count': 55}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:21,499] Trial 115 finished with value: 0.6426052516470717 and parameters: {'iterations': 1071, 'depth': 10, 'learning_rate': 0.14357916337206755, 'random_strength': 0, 'bagging_temperature': 0.9993127834578592, 'l2_leaf_reg': 4.145605837518934e-06, 'border_count': 67}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:24,492] Trial 116 finished with value: 0.6695346447703221 and parameters: {'iterations': 1114, 'depth': 10, 'learning_rate': 0.11336844231108457, 'random_strength': 0, 'bagging_temperature': 0.9419839456122638, 'l2_leaf_reg': 3.5765733214395947e-06, 'border_count': 63}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:27,193] Trial 117 finished with value: 0.7262952200886443 and parameters: {'iterations': 1090, 'depth': 10, 'learning_rate': 0.12211083379247648, 'random_strength': 1, 'bagging_temperature': 0.7123277990374993, 'l2_leaf_reg': 2.2355566063878714e-06, 'border_count': 70}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:30,004] Trial 118 finished with value: 0.6349481741549378 and parameters: {'iterations': 921, 'depth': 9, 'learning_rate': 0.14662311421278706, 'random_strength': 0, 'bagging_temperature': 0.8632801255667347, 'l2_leaf_reg': 5.508489272786494e-06, 'border_count': 60}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:32,664] Trial 119 finished with value: 0.6760859910181828 and parameters: {'iterations': 1016, 'depth': 10, 'learning_rate': 0.1551736625229857, 'random_strength': 0, 'bagging_temperature': 0.919117667799842, 'l2_leaf_reg': 3.2814411270820854e-06, 'border_count': 51}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:35,463] Trial 120 finished with value: 0.6677706412373944 and parameters: {'iterations': 1131, 'depth': 9, 'learning_rate': 0.16135091732652931, 'random_strength': 1, 'bagging_temperature': 0.9702776573605807, 'l2_leaf_reg': 1.6834151249265796e-06, 'border_count': 65}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:38,443] Trial 121 finished with value: 0.6450544668068937 and parameters: {'iterations': 919, 'depth': 9, 'learning_rate': 0.14742895012696217, 'random_strength': 0, 'bagging_temperature': 0.8637525443770038, 'l2_leaf_reg': 4.518300171828182e-06, 'border_count': 59}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:41,271] Trial 122 finished with value: 0.6724193076026609 and parameters: {'iterations': 910, 'depth': 9, 'learning_rate': 0.1415040981383143, 'random_strength': 0, 'bagging_temperature': 0.7771326221107124, 'l2_leaf_reg': 5.49226605600782e-06, 'border_count': 61}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:43,716] Trial 123 finished with value: 0.6426397808151416 and parameters: {'iterations': 924, 'depth': 9, 'learning_rate': 0.15065138634294886, 'random_strength': 0, 'bagging_temperature': 0.8887230703156385, 'l2_leaf_reg': 2.804222715019728e-06, 'border_count': 56}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:46,587] Trial 124 finished with value: 0.6269194249644452 and parameters: {'iterations': 1036, 'depth': 9, 'learning_rate': 0.12688261033580456, 'random_strength': 0, 'bagging_temperature': 0.793565301998862, 'l2_leaf_reg': 3.9032493616126945e-06, 'border_count': 68}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:49,394] Trial 125 finished with value: 0.6678841708383252 and parameters: {'iterations': 1055, 'depth': 9, 'learning_rate': 0.1265598954439661, 'random_strength': 0, 'bagging_temperature': 0.8022091530650034, 'l2_leaf_reg': 3.92694567791597e-06, 'border_count': 68}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:52,440] Trial 126 finished with value: 0.6540861025841506 and parameters: {'iterations': 1038, 'depth': 10, 'learning_rate': 0.12873261855880588, 'random_strength': 1, 'bagging_temperature': 0.7266966649913756, 'l2_leaf_reg': 3.6502027511193966e-06, 'border_count': 72}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:55,143] Trial 127 finished with value: 0.654370245004692 and parameters: {'iterations': 1106, 'depth': 9, 'learning_rate': 0.13427092142450095, 'random_strength': 0, 'bagging_temperature': 0.7497635975447865, 'l2_leaf_reg': 4.935064980636691e-06, 'border_count': 75}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:11:57,901] Trial 128 finished with value: 0.675087730135628 and parameters: {'iterations': 1034, 'depth': 10, 'learning_rate': 0.1250429603063157, 'random_strength': 1, 'bagging_temperature': 0.7372260266027852, 'l2_leaf_reg': 3.1435535416291013e-06, 'border_count': 54}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:00,986] Trial 129 finished with value: 0.6426190290290276 and parameters: {'iterations': 1027, 'depth': 10, 'learning_rate': 0.1206139621802435, 'random_strength': 0, 'bagging_temperature': 0.7835409617765268, 'l2_leaf_reg': 4.183304217460253e-06, 'border_count': 65}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:03,966] Trial 130 finished with value: 0.6855680081663351 and parameters: {'iterations': 1099, 'depth': 10, 'learning_rate': 0.13162133790605898, 'random_strength': 3, 'bagging_temperature': 0.6860688670421667, 'l2_leaf_reg': 2.6806692386441406e-06, 'border_count': 70}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:06,564] Trial 131 finished with value: 0.6308222014211499 and parameters: {'iterations': 943, 'depth': 9, 'learning_rate': 0.14651812359755864, 'random_strength': 0, 'bagging_temperature': 0.8182784046881592, 'l2_leaf_reg': 5.356608553765791e-06, 'border_count': 61}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:08,800] Trial 132 finished with value: 0.6860506287705034 and parameters: {'iterations': 951, 'depth': 9, 'learning_rate': 0.13826129880902577, 'random_strength': 0, 'bagging_temperature': 0.8114083154908974, 'l2_leaf_reg': 5.907074766358087e-06, 'border_count': 62}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:11,184] Trial 133 finished with value: 0.6546429634843026 and parameters: {'iterations': 937, 'depth': 9, 'learning_rate': 0.1584990884060474, 'random_strength': 0, 'bagging_temperature': 0.8418784891584425, 'l2_leaf_reg': 5.26445967451259e-06, 'border_count': 84}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:13,966] Trial 134 finished with value: 0.6232097254987721 and parameters: {'iterations': 1078, 'depth': 9, 'learning_rate': 0.15229457106001457, 'random_strength': 0, 'bagging_temperature': 0.8248532130534193, 'l2_leaf_reg': 6.687585393075183e-06, 'border_count': 58}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:16,546] Trial 135 finished with value: 0.6443930246238568 and parameters: {'iterations': 1065, 'depth': 9, 'learning_rate': 0.1436554234693368, 'random_strength': 0, 'bagging_temperature': 0.8209159083440176, 'l2_leaf_reg': 7.5111881620412524e-06, 'border_count': 56}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:19,140] Trial 136 finished with value: 0.6372402888770141 and parameters: {'iterations': 945, 'depth': 9, 'learning_rate': 0.15188288702168504, 'random_strength': 0, 'bagging_temperature': 0.8338569922091386, 'l2_leaf_reg': 2.9767886035289775e-06, 'border_count': 59}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:22,364] Trial 137 finished with value: 0.6239425043313449 and parameters: {'iterations': 1075, 'depth': 9, 'learning_rate': 0.14776434551664894, 'random_strength': 0, 'bagging_temperature': 0.8461316994111087, 'l2_leaf_reg': 6.9326494471160975e-06, 'border_count': 53}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:24,748] Trial 138 finished with value: 0.6559484203700872 and parameters: {'iterations': 1081, 'depth': 9, 'learning_rate': 0.1414005106122633, 'random_strength': 0, 'bagging_temperature': 0.7985296846592872, 'l2_leaf_reg': 7.057236391151723e-06, 'border_count': 54}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:27,474] Trial 139 finished with value: 0.6541451899090317 and parameters: {'iterations': 1075, 'depth': 9, 'learning_rate': 0.13657371354460013, 'random_strength': 1, 'bagging_temperature': 0.772460331518667, 'l2_leaf_reg': 6.546190360761974e-06, 'border_count': 52}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:29,904] Trial 140 finished with value: 0.6659014102385279 and parameters: {'iterations': 964, 'depth': 9, 'learning_rate': 0.14826192800230636, 'random_strength': 0, 'bagging_temperature': 0.7881318714395729, 'l2_leaf_reg': 6.094088476524481e-06, 'border_count': 58}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:32,274] Trial 141 finished with value: 0.6847753276079687 and parameters: {'iterations': 1091, 'depth': 9, 'learning_rate': 0.1552838232031532, 'random_strength': 0, 'bagging_temperature': 0.8741888396215037, 'l2_leaf_reg': 8.389109420607792e-06, 'border_count': 63}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:34,844] Trial 142 finished with value: 0.6614220549410604 and parameters: {'iterations': 1058, 'depth': 9, 'learning_rate': 0.1449984413444914, 'random_strength': 0, 'bagging_temperature': 0.84758277544826, 'l2_leaf_reg': 3.401035458937135e-06, 'border_count': 57}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:37,438] Trial 143 finished with value: 0.6394614655942508 and parameters: {'iterations': 956, 'depth': 9, 'learning_rate': 0.14977969305067754, 'random_strength': 0, 'bagging_temperature': 0.9126903432044626, 'l2_leaf_reg': 4.9522404058932705e-06, 'border_count': 67}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:40,538] Trial 144 finished with value: 0.7153704341598784 and parameters: {'iterations': 1068, 'depth': 9, 'learning_rate': 0.13463750476705566, 'random_strength': 4, 'bagging_temperature': 0.8230996551987962, 'l2_leaf_reg': 3.846427439486431e-06, 'border_count': 60}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:43,271] Trial 145 finished with value: 0.6720100563552458 and parameters: {'iterations': 1120, 'depth': 9, 'learning_rate': 0.1283812586879285, 'random_strength': 0, 'bagging_temperature': 0.898198557199594, 'l2_leaf_reg': 6.595240282486599e-06, 'border_count': 50}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:46,320] Trial 146 finished with value: 0.6636512714105266 and parameters: {'iterations': 1085, 'depth': 9, 'learning_rate': 0.12375515204245675, 'random_strength': 1, 'bagging_temperature': 0.9599796517574829, 'l2_leaf_reg': 2.6173129093396624e-06, 'border_count': 55}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:50,184] Trial 147 finished with value: 0.6632676010218993 and parameters: {'iterations': 1077, 'depth': 9, 'learning_rate': 0.15322511242175463, 'random_strength': 10, 'bagging_temperature': 0.9392060817812004, 'l2_leaf_reg': 4.536978902509025e-06, 'border_count': 53}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:52,614] Trial 148 finished with value: 0.6646955894512728 and parameters: {'iterations': 983, 'depth': 9, 'learning_rate': 0.14018018880436509, 'random_strength': 0, 'bagging_temperature': 0.8463308029402387, 'l2_leaf_reg': 2.939887788282439e-06, 'border_count': 106}. Best is trial 92 with value: 0.6159020690452929.\n",
      "[I 2023-12-07 23:12:55,403] Trial 149 finished with value: 0.6473774922669288 and parameters: {'iterations': 1048, 'depth': 9, 'learning_rate': 0.11756234203870598, 'random_strength': 0, 'bagging_temperature': 0.884129051457648, 'l2_leaf_reg': 3.4367404350819304e-06, 'border_count': 64}. Best is trial 92 with value: 0.6159020690452929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'iterations': 1050, 'depth': 10, 'learning_rate': 0.14374245859390913, 'random_strength': 0, 'bagging_temperature': 0.9652054833669892, 'l2_leaf_reg': 3.0337119972706364e-06, 'border_count': 55}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 900, 1200),\n",
    "        'depth': trial.suggest_int('depth', 8, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.25),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 10),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-6, 1e-4, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 50, 150),\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def optimize(X_train, y_train, X_test, y_test, n_trials=150):\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), n_trials=n_trials)\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "# Load your datasets and run optimization\n",
    "best_params_w = optimize(X_train_w, y_train_w, X_test_w, y_test_w)\n",
    "print(\"Best parameters for working days:\", best_params_w)\n",
    "\n",
    "best_params_nw = optimize(X_train_nw, y_train_nw, X_test_nw, y_test_nw)\n",
    "print(\"Best parameters for non-working days:\", best_params_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.5200795961\n",
      "bestIteration = 606\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.525530426\n",
      "bestIteration = 599\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.5244924405\n",
      "bestIteration = 640\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.5273229829\n",
      "bestIteration = 660\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.5241769934\n",
      "bestIteration = 615\n",
      "\n",
      "Average RMSE for working days (CV): 0.5745018950449374\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.5483396177\n",
      "bestIteration = 258\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.543124221\n",
      "bestIteration = 247\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.53780695\n",
      "bestIteration = 273\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.542019295\n",
      "bestIteration = 241\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.544657972\n",
      "bestIteration = 218\n",
      "\n",
      "Average RMSE for non-working days (CV): 0.5893193493624388\n"
     ]
    }
   ],
   "source": [
    "def perform_cv(X_train, y_train, params, n_folds=5):\n",
    "    pool = Pool(X_train, y_train)\n",
    "    # Ensure that 'loss_function' is included in the params dictionary\n",
    "    updated_params = params.copy()\n",
    "    updated_params['loss_function'] = 'RMSE'\n",
    "\n",
    "    cv_results = cv(\n",
    "        pool=pool, \n",
    "        params=updated_params, \n",
    "        fold_count=n_folds, \n",
    "        seed=42, \n",
    "        shuffle=True, \n",
    "        stratified=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    avg_rmse = np.mean(cv_results['test-RMSE-mean'])\n",
    "    return avg_rmse\n",
    "\n",
    "# Best parameters from Optuna study\n",
    "params_w = {'iterations': 956,\n",
    " 'depth': 9,\n",
    " 'learning_rate': 0.1263016745448219,\n",
    " 'random_strength': 4,\n",
    " 'bagging_temperature': 0.11022353495377599,\n",
    " 'l2_leaf_reg': 9.918169510819463e-06,\n",
    " 'border_count': 109}\n",
    "\n",
    "params_nw = {'iterations': 1050,\n",
    " 'depth': 10,\n",
    " 'learning_rate': 0.14374245859390913,\n",
    " 'random_strength': 0,\n",
    " 'bagging_temperature': 0.9652054833669892,\n",
    " 'l2_leaf_reg': 3.0337119972706364e-06,\n",
    " 'border_count': 55}\n",
    "\n",
    "# Perform cross-validation and get average RMSE for working days\n",
    "avg_rmse_w = perform_cv(X_train_w, y_train_w, params_w)\n",
    "print(\"Average RMSE for working days (CV):\", avg_rmse_w)\n",
    "\n",
    "# Perform cross-validation and get average RMSE for non-working days\n",
    "avg_rmse_nw = perform_cv(X_train_nw, y_train_nw, params_nw)\n",
    "print(\"Average RMSE for non-working days (CV):\", avg_rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6537497213786495\n",
      "RMSE for non-working days: 0.6898826460575969\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from all Optuna studies\n",
    "params_w = { 'iterations': 1096, \n",
    " 'depth': 9, \n",
    " 'learning_rate': 0.22603548878280666, \n",
    " 'random_strength': 2, \n",
    " 'bagging_temperature': 0.1867337573932248, \n",
    " 'l2_leaf_reg': 2.304593084966779e-05, \n",
    " 'border_count': 66, \n",
    " 'grow_policy': 'Lossguide',\n",
    " 'loss_function': 'RMSE',\n",
    " 'verbose': False\n",
    "    }\n",
    "\n",
    "params_nw = {\n",
    "    'iterations': 366,\n",
    "    'depth': 9,\n",
    "    'learning_rate': 0.13516379949083754,\n",
    "    'random_strength': 10,\n",
    "    'bagging_temperature': 0.27795134630855506,\n",
    "    'l2_leaf_reg': 0.10661335848192686,\n",
    "    'border_count': 1,\n",
    "    'loss_function': 'RMSE',\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "# Create and train the model for working days\n",
    "model_w = cb.CatBoostRegressor(**params_w)\n",
    "model_w.fit(X_train_w, y_train_w, eval_set=[(X_test_w, y_test_w)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for working days\n",
    "predictions_w = model_w.predict(X_test_w)\n",
    "rmse_w = mean_squared_error(y_test_w, predictions_w, squared=False)\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "\n",
    "# Create and train the model for non-working days\n",
    "model_nw = cb.CatBoostRegressor(**params_nw)\n",
    "model_nw.fit(X_train_nw, y_train_nw, eval_set=[(X_test_nw, y_test_nw)], verbose=False)\n",
    "\n",
    "# Predict and calculate RMSE for non-working days\n",
    "predictions_nw = model_nw.predict(X_test_nw)\n",
    "rmse_nw = mean_squared_error(y_test_nw, predictions_nw, squared=False)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importances for Working Days Model:\n",
      "                             Feature  Importance\n",
      "48                 time_of_day_Night   41.656714\n",
      "70               time_of_day_Evening   13.246301\n",
      "49                            hour_5    5.515536\n",
      "27  site_name_Face au 40 quai D'Issy    4.160831\n",
      "38                              temp    3.107443\n",
      "..                               ...         ...\n",
      "13    site_name_Totem Cours la Reine    0.000000\n",
      "11                           hour_11    0.000000\n",
      "81      site_name_6 rue Julia Bartet    0.000000\n",
      "65                           hour_10    0.000000\n",
      "64                           hour_14    0.000000\n",
      "\n",
      "[86 rows x 2 columns]\n",
      "\n",
      "Importances for Non-Working Days Model:\n",
      "                                       Feature  Importance\n",
      "48                           time_of_day_Night   33.798313\n",
      "70                         time_of_day_Evening   14.181672\n",
      "80               site_name_20 Avenue de Clichy    4.445850\n",
      "27            site_name_Face au 40 quai D'Issy    3.486923\n",
      "25  site_name_Totem 73 boulevard de Sbastopol    2.958814\n",
      "..                                         ...         ...\n",
      "81                site_name_6 rue Julia Bartet    0.024588\n",
      "15                                   rush_hour    0.018177\n",
      "55                                     hour_12    0.011208\n",
      "0                                weather_Snowy    0.005001\n",
      "28                                 working_day    0.000000\n",
      "\n",
      "[86 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances_w = model_w.get_feature_importance()\n",
    "feature_importances_nw = model_nw.get_feature_importance()\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train_w.columns\n",
    "\n",
    "# Combine names and importances into a DataFrame\n",
    "importances_w = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_w})\n",
    "importances_nw = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_nw})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importances_w.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "importances_nw.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Display the sorted importances\n",
    "print(\"Importances for Working Days Model:\")\n",
    "print(importances_w)\n",
    "print(\"\\nImportances for Non-Working Days Model:\")\n",
    "print(importances_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor (Light Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's integrate LightGBM - a framework celebrated for its efficiency with large datasets. LightGBM stands out with its swift training speed, minimal memory usage, and robust accuracy, making it a solid choice for our data\n",
    "\n",
    "**Advantages of LightGBM**\n",
    "\n",
    "- Efficient and Fast: Exceptional at processing large volumes of data quickly and efficiently\n",
    "- Handles Categorical Features: Automatically manages categorical features, streamlining data processing\n",
    "- Outperforms XGBoost in Speed: Typically faster than XGBoost, especially beneficial for large datasets\n",
    "\n",
    "We start from a baseline model and progressively enhance it using the Optuna framework for precise hyperparameter tuning. This strategy aims to craft a model adept at accurately predicting bike traffic under various conditions in Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1281\n",
      "[LightGBM] [Info] Number of data points in the train set: 325137, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 3.136118\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 130026, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 2.829719\n",
      "RMSE for working days: 0.6352286356285236\n",
      "RMSE for non-working days: 0.6658435178643521\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "# Initialize LightGBM models\n",
    "lgbm_model_w = lgb.LGBMRegressor()\n",
    "lgbm_model_nw = lgb.LGBMRegressor()\n",
    "\n",
    "# Fit the models\n",
    "lgbm_model_w.fit(X_train_w, y_train_w)\n",
    "lgbm_model_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_w = lgbm_model_w.predict(X_test_w)\n",
    "y_pred_nw = lgbm_model_nw.predict(X_test_nw)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch\n",
    "def preprocess_features(df):\n",
    "    \"\"\" Preprocess the feature names to remove whitespaces \"\"\"\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "# Load and preprocess datasets\n",
    "train_processed_w = preprocess_features(pd.read_parquet(Path(\"data\") / \"train_processed_working_day.parquet\"))\n",
    "train_processed_nw = preprocess_features(pd.read_parquet(Path(\"data\") / \"train_processed_non_working_day.parquet\"))\n",
    "test_processed_w = preprocess_features(pd.read_parquet(Path(\"data\") / \"test_processed_working_day.parquet\"))\n",
    "test_processed_nw = preprocess_features(pd.read_parquet(Path(\"data\") / \"test_processed_non_working_day.parquet\"))\n",
    "\n",
    "# Separate features and target\n",
    "X_train_w, y_train_w = train_processed_w.drop(columns=[\"log_bike_count\"]), train_processed_w[\"log_bike_count\"]\n",
    "X_train_nw, y_train_nw = train_processed_nw.drop(columns=[\"log_bike_count\"]), train_processed_nw[\"log_bike_count\"]\n",
    "X_test_w, y_test_w = test_processed_w.drop(columns=[\"log_bike_count\"]), test_processed_w[\"log_bike_count\"]\n",
    "X_test_nw, y_test_nw = test_processed_nw.drop(columns=[\"log_bike_count\"]), test_processed_nw[\"log_bike_count\"]\n",
    "\n",
    "# Parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 40],  # Ensure it's less than 2^max_depth\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_child_samples': [20, 30, 40]  # Control overfitting\n",
    "}\n",
    "\n",
    "# Function for hyperparameter tuning and model training\n",
    "def train_and_optimize(X_train, y_train):\n",
    "    model = lgb.LGBMRegressor(random_state=42, force_row_wise=True)  # Set force_row_wise to True\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, -grid_search.best_score_\n",
    "\n",
    "# Train and optimize models\n",
    "model_w, best_score_w = train_and_optimize(X_train_w, y_train_w)\n",
    "model_nw, best_score_nw = train_and_optimize(X_train_nw, y_train_nw)\n",
    "\n",
    "# Output results\n",
    "print(f\"Best RMSE score for working days: {np.sqrt(best_score_w)}\")\n",
    "print(f\"Best RMSE score for non-working days: {np.sqrt(best_score_nw)}\")\n",
    "\n",
    "# Evaluate RMSE\n",
    "y_pred_w = model_w.predict(X_test_w)\n",
    "y_pred_nw = model_nw.predict(X_test_nw)\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "print(f\"Test RMSE for working days: {rmse_w}\")\n",
    "print(f\"Test RMSE for non-working days: {rmse_nw}\")\n",
    "\n",
    "# Feature Importance Analysis\n",
    "print(f\"Feature importances for working days model:\\n{model_w.feature_importances_}\")\n",
    "print(f\"Feature importances for non-working days model:\\n{model_nw.feature_importances_}\")\n",
    "\n",
    "# Save Models\n",
    "model_w.booster_.save_model('lgbm_model_working_days.txt')\n",
    "model_nw.booster_.save_model('lgbm_model_non_working_days.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 17:06:05,518] A new study created in memory with name: no-name-89d72900-8d21-4b83-8582-81a03c720ef1\n",
      "[I 2023-12-06 17:06:07,849] Trial 0 finished with value: 0.6745907489530569 and parameters: {'lambda_l1': 0.0006663588230952027, 'lambda_l2': 0.0011494865393059884, 'num_leaves': 39, 'feature_fraction': 0.9900840173857927, 'bagging_fraction': 0.9236635825308717, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 0 with value: 0.6745907489530569.\n",
      "[I 2023-12-06 17:06:12,570] Trial 1 finished with value: 0.6445538484307667 and parameters: {'lambda_l1': 0.0001844075620451729, 'lambda_l2': 2.5834423472021055e-06, 'num_leaves': 193, 'feature_fraction': 0.4687093801046808, 'bagging_fraction': 0.47881531358886553, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 1 with value: 0.6445538484307667.\n",
      "[I 2023-12-06 17:06:16,207] Trial 2 finished with value: 0.6675082168929467 and parameters: {'lambda_l1': 1.152446926470397e-06, 'lambda_l2': 4.35134527253791e-07, 'num_leaves': 113, 'feature_fraction': 0.48783995356270626, 'bagging_fraction': 0.5701914034730908, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 1 with value: 0.6445538484307667.\n",
      "[I 2023-12-06 17:06:21,629] Trial 3 finished with value: 0.6909088182597206 and parameters: {'lambda_l1': 0.8955888535830486, 'lambda_l2': 0.20238952421767684, 'num_leaves': 250, 'feature_fraction': 0.6284788198619112, 'bagging_fraction': 0.5587817712078409, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 1 with value: 0.6445538484307667.\n",
      "[I 2023-12-06 17:06:26,774] Trial 4 finished with value: 0.6325312135378189 and parameters: {'lambda_l1': 1.2968077913852304e-06, 'lambda_l2': 6.253399281278596e-07, 'num_leaves': 204, 'feature_fraction': 0.7796362896768261, 'bagging_fraction': 0.9341334912256465, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:28,310] Trial 5 finished with value: 0.6714087192580412 and parameters: {'lambda_l1': 0.0010967973821068002, 'lambda_l2': 0.006409553169297914, 'num_leaves': 16, 'feature_fraction': 0.7074417193409073, 'bagging_fraction': 0.9151800315592117, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:32,472] Trial 6 finished with value: 0.6559464178869084 and parameters: {'lambda_l1': 1.3591285398951443, 'lambda_l2': 1.6264319568063943e-06, 'num_leaves': 145, 'feature_fraction': 0.5282366741798795, 'bagging_fraction': 0.5701068562893997, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:34,568] Trial 7 finished with value: 0.6707275317279165 and parameters: {'lambda_l1': 6.693896211605246e-08, 'lambda_l2': 5.629085669845822, 'num_leaves': 38, 'feature_fraction': 0.4424544972106215, 'bagging_fraction': 0.5329004250165916, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:39,228] Trial 8 finished with value: 0.639986952907419 and parameters: {'lambda_l1': 0.005259637957494805, 'lambda_l2': 0.01788024529326979, 'num_leaves': 168, 'feature_fraction': 0.9508912628664299, 'bagging_fraction': 0.8588241518799944, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:41,414] Trial 9 finished with value: 0.6715324967651917 and parameters: {'lambda_l1': 0.006516644369116315, 'lambda_l2': 1.1253698541445947, 'num_leaves': 41, 'feature_fraction': 0.5768733006232593, 'bagging_fraction': 0.7333204715085628, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 4 with value: 0.6325312135378189.\n",
      "[I 2023-12-06 17:06:46,436] Trial 10 finished with value: 0.614255302195596 and parameters: {'lambda_l1': 1.1193261410565932e-08, 'lambda_l2': 1.1800532434780942e-08, 'num_leaves': 255, 'feature_fraction': 0.8383649277591473, 'bagging_fraction': 0.9918931783895347, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:06:50,787] Trial 11 finished with value: 0.6222166860337782 and parameters: {'lambda_l1': 1.0139218076269038e-08, 'lambda_l2': 1.5417048307534105e-08, 'num_leaves': 256, 'feature_fraction': 0.8072637954001116, 'bagging_fraction': 0.9943226194867717, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:06:54,933] Trial 12 finished with value: 0.6286424017669492 and parameters: {'lambda_l1': 2.1769922708810843e-08, 'lambda_l2': 1.0918504164905202e-08, 'num_leaves': 240, 'feature_fraction': 0.8357260745644601, 'bagging_fraction': 0.9786016410085538, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:06:59,258] Trial 13 finished with value: 0.6213962612255244 and parameters: {'lambda_l1': 1.1763550082997413e-08, 'lambda_l2': 1.2544198453951831e-08, 'num_leaves': 255, 'feature_fraction': 0.8692807356580367, 'bagging_fraction': 0.8202776593048324, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:01,823] Trial 14 finished with value: 0.6321415699499671 and parameters: {'lambda_l1': 2.3545131677490623e-07, 'lambda_l2': 4.227246829291971e-05, 'num_leaves': 101, 'feature_fraction': 0.8980239497935144, 'bagging_fraction': 0.8118422195574263, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:07,154] Trial 15 finished with value: 0.6362200351893152 and parameters: {'lambda_l1': 6.7822843047437e-06, 'lambda_l2': 6.330064317353504e-08, 'num_leaves': 210, 'feature_fraction': 0.8914350346533472, 'bagging_fraction': 0.8003126113277214, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:12,546] Trial 16 finished with value: 0.6541149408803343 and parameters: {'lambda_l1': 1.722652833287832e-08, 'lambda_l2': 3.841197207938974e-05, 'num_leaves': 225, 'feature_fraction': 0.740271358681263, 'bagging_fraction': 0.7402155558159539, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:17,350] Trial 17 finished with value: 0.6440581563131182 and parameters: {'lambda_l1': 1.7989503047016677e-07, 'lambda_l2': 8.113931589546784e-08, 'num_leaves': 176, 'feature_fraction': 0.8618032268539969, 'bagging_fraction': 0.8531216798439923, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:19,711] Trial 18 finished with value: 0.6561941774371458 and parameters: {'lambda_l1': 2.1337952752438757e-05, 'lambda_l2': 1.0021604681605212e-08, 'num_leaves': 81, 'feature_fraction': 0.7531311564027354, 'bagging_fraction': 0.6950771878881814, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:25,285] Trial 19 finished with value: 0.6649704869294049 and parameters: {'lambda_l1': 1.0107022074486912e-08, 'lambda_l2': 1.1116137704909097e-05, 'num_leaves': 225, 'feature_fraction': 0.6481362406120398, 'bagging_fraction': 0.9993113124700294, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:29,690] Trial 20 finished with value: 0.6324992928336013 and parameters: {'lambda_l1': 2.1081855281671263e-07, 'lambda_l2': 1.0702315673086965e-07, 'num_leaves': 148, 'feature_fraction': 0.8100734527457052, 'bagging_fraction': 0.8733727279861637, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:33,949] Trial 21 finished with value: 0.6310119686450835 and parameters: {'lambda_l1': 1.0350456023497845e-08, 'lambda_l2': 1.789102050570648e-08, 'num_leaves': 254, 'feature_fraction': 0.8170572769904081, 'bagging_fraction': 0.9964126434216358, 'bagging_freq': 1, 'min_child_samples': 83}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:38,149] Trial 22 finished with value: 0.6343131516836019 and parameters: {'lambda_l1': 7.658809352588712e-08, 'lambda_l2': 2.317524927443436e-07, 'num_leaves': 256, 'feature_fraction': 0.8965569913492895, 'bagging_fraction': 0.9435404023420411, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:43,738] Trial 23 finished with value: 0.6340157781470702 and parameters: {'lambda_l1': 5.848114043600378e-07, 'lambda_l2': 5.018354327272987e-08, 'num_leaves': 221, 'feature_fraction': 0.7884705557669541, 'bagging_fraction': 0.9481685797024529, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:47,120] Trial 24 finished with value: 0.6402864359488408 and parameters: {'lambda_l1': 5.501871936434538e-08, 'lambda_l2': 2.936913065775281e-07, 'num_leaves': 184, 'feature_fraction': 0.8503067263525929, 'bagging_fraction': 0.9074706356896588, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:52,803] Trial 25 finished with value: 0.6186704068019868 and parameters: {'lambda_l1': 5.128958909149176e-08, 'lambda_l2': 1.009346947503095e-08, 'num_leaves': 234, 'feature_fraction': 0.9328248391289456, 'bagging_fraction': 0.9645860189438737, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 10 with value: 0.614255302195596.\n",
      "[I 2023-12-06 17:07:58,437] Trial 26 finished with value: 0.6071302134016573 and parameters: {'lambda_l1': 3.155979321022697e-06, 'lambda_l2': 3.295148909219387e-06, 'num_leaves': 232, 'feature_fraction': 0.9500459295785518, 'bagging_fraction': 0.8940803854482313, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:04,953] Trial 27 finished with value: 0.6148110449285139 and parameters: {'lambda_l1': 3.2155507418997808e-06, 'lambda_l2': 3.868383433508994e-06, 'num_leaves': 231, 'feature_fraction': 0.9486925690425148, 'bagging_fraction': 0.8910496079372598, 'bagging_freq': 3, 'min_child_samples': 90}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:10,519] Trial 28 finished with value: 0.6153492073252212 and parameters: {'lambda_l1': 4.528820207004074e-06, 'lambda_l2': 5.105013396846543e-06, 'num_leaves': 204, 'feature_fraction': 0.9870734062422203, 'bagging_fraction': 0.8883971061357462, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:15,446] Trial 29 finished with value: 0.6402950704001454 and parameters: {'lambda_l1': 3.6720564747738e-05, 'lambda_l2': 0.00016198650909512487, 'num_leaves': 163, 'feature_fraction': 0.9737730784781378, 'bagging_fraction': 0.9152870795553525, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:20,568] Trial 30 finished with value: 0.6330738475944172 and parameters: {'lambda_l1': 3.6145927969772014e-06, 'lambda_l2': 1.653237221858664e-05, 'num_leaves': 194, 'feature_fraction': 0.9290472374597843, 'bagging_fraction': 0.9373733139643989, 'bagging_freq': 4, 'min_child_samples': 83}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:25,917] Trial 31 finished with value: 0.613231448598607 and parameters: {'lambda_l1': 5.2703714964902605e-06, 'lambda_l2': 2.487755232566201e-06, 'num_leaves': 210, 'feature_fraction': 0.9999121276947882, 'bagging_fraction': 0.8939894315168554, 'bagging_freq': 3, 'min_child_samples': 97}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:31,556] Trial 32 finished with value: 0.6145472195222169 and parameters: {'lambda_l1': 5.878911190705669e-07, 'lambda_l2': 1.5063707684908183e-06, 'num_leaves': 237, 'feature_fraction': 0.999397395866891, 'bagging_fraction': 0.8869875462361098, 'bagging_freq': 3, 'min_child_samples': 88}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:37,065] Trial 33 finished with value: 0.6190126215488646 and parameters: {'lambda_l1': 6.365538480972565e-07, 'lambda_l2': 9.987995997758246e-07, 'num_leaves': 214, 'feature_fraction': 0.9952720909293625, 'bagging_fraction': 0.9528679417606138, 'bagging_freq': 2, 'min_child_samples': 93}. Best is trial 26 with value: 0.6071302134016573.\n",
      "[I 2023-12-06 17:08:42,902] Trial 34 finished with value: 0.598882961154819 and parameters: {'lambda_l1': 5.357011380685383e-07, 'lambda_l2': 1.057193132189716e-06, 'num_leaves': 239, 'feature_fraction': 0.9961266527106151, 'bagging_fraction': 0.8455586491916388, 'bagging_freq': 3, 'min_child_samples': 94}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:08:47,945] Trial 35 finished with value: 0.6181118026086565 and parameters: {'lambda_l1': 2.394229903433665e-05, 'lambda_l2': 5.626191558503111e-07, 'num_leaves': 193, 'feature_fraction': 0.9563675039542836, 'bagging_fraction': 0.8434955753989226, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:08:53,960] Trial 36 finished with value: 0.6399573371453251 and parameters: {'lambda_l1': 1.5035432086265824e-06, 'lambda_l2': 4.066657965067805e-06, 'num_leaves': 243, 'feature_fraction': 0.9222188362995467, 'bagging_fraction': 0.9209881858695605, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:08:59,580] Trial 37 finished with value: 0.614173517716333 and parameters: {'lambda_l1': 3.7334432020170785e-07, 'lambda_l2': 2.8568174097657643e-07, 'num_leaves': 203, 'feature_fraction': 0.964421925516815, 'bagging_fraction': 0.9622332672887101, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:04,003] Trial 38 finished with value: 0.6297986354121096 and parameters: {'lambda_l1': 0.00018890528710563544, 'lambda_l2': 1.1902736828138954e-06, 'num_leaves': 148, 'feature_fraction': 0.9688877577906765, 'bagging_fraction': 0.8383332704970669, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:09,031] Trial 39 finished with value: 0.608171504511735 and parameters: {'lambda_l1': 1.1935184371265418e-05, 'lambda_l2': 2.5099969967208997e-07, 'num_leaves': 203, 'feature_fraction': 0.91472781231546, 'bagging_fraction': 0.7858712015067291, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:12,955] Trial 40 finished with value: 0.6440639382457095 and parameters: {'lambda_l1': 7.955993287317959e-05, 'lambda_l2': 0.0002601601807569314, 'num_leaves': 125, 'feature_fraction': 0.9152743833703362, 'bagging_fraction': 0.7880314513110346, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:18,310] Trial 41 finished with value: 0.6183749583286416 and parameters: {'lambda_l1': 9.692696732813804e-06, 'lambda_l2': 3.4305893816624384e-07, 'num_leaves': 200, 'feature_fraction': 0.969203404469184, 'bagging_fraction': 0.8748283176590345, 'bagging_freq': 6, 'min_child_samples': 94}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:23,255] Trial 42 finished with value: 0.6115750512110854 and parameters: {'lambda_l1': 2.07180565002968e-06, 'lambda_l2': 1.7085053333107902e-06, 'num_leaves': 185, 'feature_fraction': 0.995570034245574, 'bagging_fraction': 0.9236208311889009, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:28,097] Trial 43 finished with value: 0.6117743183898332 and parameters: {'lambda_l1': 1.975281994822264e-06, 'lambda_l2': 1.9028616732971036e-06, 'num_leaves': 177, 'feature_fraction': 0.9954543354078319, 'bagging_fraction': 0.91295018068535, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:32,921] Trial 44 finished with value: 0.6226061885196301 and parameters: {'lambda_l1': 1.3499045064975046e-06, 'lambda_l2': 1.4945926788632007e-06, 'num_leaves': 179, 'feature_fraction': 0.9401410793330174, 'bagging_fraction': 0.8559393807701765, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:37,328] Trial 45 finished with value: 0.627607946751968 and parameters: {'lambda_l1': 1.6809860052067627e-06, 'lambda_l2': 5.42293456409714e-07, 'num_leaves': 158, 'feature_fraction': 0.9163524991858587, 'bagging_fraction': 0.9231742304089475, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:41,242] Trial 46 finished with value: 0.6388757600117172 and parameters: {'lambda_l1': 1.8574074551864382e-05, 'lambda_l2': 8.539641435553807e-06, 'num_leaves': 134, 'feature_fraction': 0.8802579570576273, 'bagging_fraction': 0.7832036656859696, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:46,074] Trial 47 finished with value: 0.6090614063568806 and parameters: {'lambda_l1': 2.139155075779514e-06, 'lambda_l2': 2.218626303412942e-06, 'num_leaves': 186, 'feature_fraction': 0.9500330339724656, 'bagging_fraction': 0.8223847298938091, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:51,086] Trial 48 finished with value: 0.612056696423931 and parameters: {'lambda_l1': 1.0878233776151632e-05, 'lambda_l2': 7.398012463932105e-07, 'num_leaves': 188, 'feature_fraction': 0.9492288427609448, 'bagging_fraction': 0.7620604204080798, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:09:56,778] Trial 49 finished with value: 0.6224342028765063 and parameters: {'lambda_l1': 4.9058315511668255e-05, 'lambda_l2': 2.1494151917886956e-05, 'num_leaves': 243, 'feature_fraction': 0.9027186233742285, 'bagging_fraction': 0.8276256309605445, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:01,882] Trial 50 finished with value: 0.6573202038764133 and parameters: {'lambda_l1': 8.87147453180004e-05, 'lambda_l2': 1.4981320914859744e-07, 'num_leaves': 214, 'feature_fraction': 0.8717596114223817, 'bagging_fraction': 0.8253257209996692, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:06,603] Trial 51 finished with value: 0.6117561310199745 and parameters: {'lambda_l1': 2.167973906240013e-06, 'lambda_l2': 2.7940598745932708e-06, 'num_leaves': 172, 'feature_fraction': 0.9803567952987817, 'bagging_fraction': 0.8606994724817475, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:11,127] Trial 52 finished with value: 0.6184181188179808 and parameters: {'lambda_l1': 2.4401054181131015e-06, 'lambda_l2': 7.074123255568665e-06, 'num_leaves': 164, 'feature_fraction': 0.9714801803818774, 'bagging_fraction': 0.8579123299823039, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:16,537] Trial 53 finished with value: 0.6236495028388805 and parameters: {'lambda_l1': 9.371457944941948e-07, 'lambda_l2': 4.093409588222044e-06, 'num_leaves': 222, 'feature_fraction': 0.9401736734453028, 'bagging_fraction': 0.7980283187442634, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:21,449] Trial 54 finished with value: 0.6382337252324047 and parameters: {'lambda_l1': 6.855599581433775e-06, 'lambda_l2': 7.490096181352786e-07, 'num_leaves': 169, 'feature_fraction': 0.9127634786519612, 'bagging_fraction': 0.8634963176701934, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:26,564] Trial 55 finished with value: 0.6047278667694718 and parameters: {'lambda_l1': 1.44514034205668e-05, 'lambda_l2': 7.89495313202451e-05, 'num_leaves': 197, 'feature_fraction': 0.9802963578258947, 'bagging_fraction': 0.8373871498575883, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:29,719] Trial 56 finished with value: 0.6548377029723824 and parameters: {'lambda_l1': 0.00047732879802514543, 'lambda_l2': 0.0007553144720052223, 'num_leaves': 87, 'feature_fraction': 0.8893836999322132, 'bagging_fraction': 0.8105823938455606, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:34,679] Trial 57 finished with value: 0.6155382893252742 and parameters: {'lambda_l1': 1.552163268900581e-05, 'lambda_l2': 4.058498886757114e-05, 'num_leaves': 192, 'feature_fraction': 0.9542115390828342, 'bagging_fraction': 0.8340491365420458, 'bagging_freq': 7, 'min_child_samples': 81}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:35,508] Trial 58 finished with value: 0.6903160735316475 and parameters: {'lambda_l1': 1.5684641433647827e-07, 'lambda_l2': 0.0001061877212021849, 'num_leaves': 6, 'feature_fraction': 0.9351134797623408, 'bagging_fraction': 0.7742414959283027, 'bagging_freq': 5, 'min_child_samples': 78}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:40,900] Trial 59 finished with value: 0.6341034405781087 and parameters: {'lambda_l1': 9.077633134285706e-06, 'lambda_l2': 1.3225570627887935e-05, 'num_leaves': 229, 'feature_fraction': 0.8501150629330153, 'bagging_fraction': 0.8110500994516134, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:46,709] Trial 60 finished with value: 0.6146818262970697 and parameters: {'lambda_l1': 6.851138150982243e-07, 'lambda_l2': 1.815210865549748e-07, 'num_leaves': 248, 'feature_fraction': 0.974767084786044, 'bagging_fraction': 0.7129831157247228, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:51,980] Trial 61 finished with value: 0.6087445416161686 and parameters: {'lambda_l1': 1.3101693064320666e-06, 'lambda_l2': 2.7596115094611196e-06, 'num_leaves': 200, 'feature_fraction': 0.9799004615789925, 'bagging_fraction': 0.8707541713866103, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:10:57,336] Trial 62 finished with value: 0.6170744576766869 and parameters: {'lambda_l1': 3.614719578311525e-07, 'lambda_l2': 8.043049177352505e-06, 'num_leaves': 215, 'feature_fraction': 0.9810754554565441, 'bagging_fraction': 0.8420488065969415, 'bagging_freq': 6, 'min_child_samples': 92}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:02,391] Trial 63 finished with value: 0.6110378467195277 and parameters: {'lambda_l1': 3.910503791663201e-06, 'lambda_l2': 1.8398520547155754e-06, 'num_leaves': 197, 'feature_fraction': 0.9558662958280763, 'bagging_fraction': 0.8961468764959785, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:07,398] Trial 64 finished with value: 0.624027150948314 and parameters: {'lambda_l1': 5.611954322477097e-06, 'lambda_l2': 3.825936360108958e-07, 'num_leaves': 198, 'feature_fraction': 0.9011290303563793, 'bagging_fraction': 0.8789688985069255, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:12,695] Trial 65 finished with value: 0.6202738411001206 and parameters: {'lambda_l1': 3.870140302059609e-06, 'lambda_l2': 2.3445119737397785e-05, 'num_leaves': 206, 'feature_fraction': 0.9467697402643064, 'bagging_fraction': 0.8146722162991792, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:18,213] Trial 66 finished with value: 0.6117721886854254 and parameters: {'lambda_l1': 1.0988605833535562e-05, 'lambda_l2': 5.401281250833645e-08, 'num_leaves': 221, 'feature_fraction': 0.9313649050963947, 'bagging_fraction': 0.9029861118974828, 'bagging_freq': 7, 'min_child_samples': 93}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:23,806] Trial 67 finished with value: 0.6179956689193415 and parameters: {'lambda_l1': 8.468843737611051e-07, 'lambda_l2': 2.9803137851945927e-06, 'num_leaves': 233, 'feature_fraction': 0.9580791294300791, 'bagging_fraction': 0.8744169836522296, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:29,419] Trial 68 finished with value: 0.6470955606030726 and parameters: {'lambda_l1': 2.6763039398274673e-05, 'lambda_l2': 5.973775031752635e-06, 'num_leaves': 218, 'feature_fraction': 0.9187666083642709, 'bagging_fraction': 0.9000328096754877, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:34,620] Trial 69 finished with value: 0.6232695313859046 and parameters: {'lambda_l1': 3.658265410965019e-06, 'lambda_l2': 7.275888970868991e-05, 'num_leaves': 208, 'feature_fraction': 0.8798296181332913, 'bagging_fraction': 0.7560380877627615, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:39,191] Trial 70 finished with value: 0.6119160819239841 and parameters: {'lambda_l1': 1.3740756339523426e-06, 'lambda_l2': 6.049758627131786e-07, 'num_leaves': 156, 'feature_fraction': 0.9571444097151299, 'bagging_fraction': 0.8388451913995065, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:44,321] Trial 71 finished with value: 0.6102027515392309 and parameters: {'lambda_l1': 2.601187915349042e-06, 'lambda_l2': 1.3625056198845093e-06, 'num_leaves': 187, 'feature_fraction': 0.9977652186603196, 'bagging_fraction': 0.9306227923513698, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:49,622] Trial 72 finished with value: 0.6154890812626461 and parameters: {'lambda_l1': 4.153623835965772e-07, 'lambda_l2': 1.2501467484172457e-06, 'num_leaves': 198, 'feature_fraction': 0.9824941425037105, 'bagging_fraction': 0.8868581488033669, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:54,504] Trial 73 finished with value: 0.6048093613285184 and parameters: {'lambda_l1': 6.0360354034443095e-06, 'lambda_l2': 9.862344611193368e-08, 'num_leaves': 181, 'feature_fraction': 0.9821414839791827, 'bagging_fraction': 0.9341386613423566, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:11:59,569] Trial 74 finished with value: 0.6056673609875671 and parameters: {'lambda_l1': 9.519141043841136e-07, 'lambda_l2': 9.840328798025927e-08, 'num_leaves': 187, 'feature_fraction': 0.9994376815871493, 'bagging_fraction': 0.934606873080854, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:04,743] Trial 75 finished with value: 0.6223967750919851 and parameters: {'lambda_l1': 1.1075361015554062e-06, 'lambda_l2': 1.1214429972067881e-07, 'num_leaves': 178, 'feature_fraction': 0.9791369009377106, 'bagging_fraction': 0.9426325636821147, 'bagging_freq': 6, 'min_child_samples': 94}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:07,345] Trial 76 finished with value: 0.6475489635315824 and parameters: {'lambda_l1': 2.418931360716838e-07, 'lambda_l2': 3.5002766655197995e-08, 'num_leaves': 51, 'feature_fraction': 0.935977777607353, 'bagging_fraction': 0.9656628315094768, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:13,291] Trial 77 finished with value: 0.6074158806781158 and parameters: {'lambda_l1': 1.647462034149556e-05, 'lambda_l2': 1.986887901248017e-07, 'num_leaves': 247, 'feature_fraction': 0.972052389850041, 'bagging_fraction': 0.8658969592849471, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:19,169] Trial 78 finished with value: 0.6301744731517677 and parameters: {'lambda_l1': 1.536097798731442e-05, 'lambda_l2': 1.8532521405886602e-07, 'num_leaves': 238, 'feature_fraction': 0.9647447994601673, 'bagging_fraction': 0.9805532002769708, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:25,122] Trial 79 finished with value: 0.613464323254542 and parameters: {'lambda_l1': 7.342260769539673e-06, 'lambda_l2': 2.6803972074854013e-08, 'num_leaves': 247, 'feature_fraction': 0.9822029368001497, 'bagging_fraction': 0.908119333514494, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:30,890] Trial 80 finished with value: 0.6266501162628594 and parameters: {'lambda_l1': 3.6797277964664815e-05, 'lambda_l2': 1.3739199700861505e-07, 'num_leaves': 226, 'feature_fraction': 0.9978154353458247, 'bagging_fraction': 0.8713255360762171, 'bagging_freq': 4, 'min_child_samples': 74}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:36,269] Trial 81 finished with value: 0.6134794683389664 and parameters: {'lambda_l1': 5.237427462329394e-06, 'lambda_l2': 3.1782047719410576e-07, 'num_leaves': 211, 'feature_fraction': 0.9659659851138939, 'bagging_fraction': 0.8539015400509256, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:42,278] Trial 82 finished with value: 0.6150876813386414 and parameters: {'lambda_l1': 1.0456984192517734e-06, 'lambda_l2': 1.0936497046461409e-07, 'num_leaves': 251, 'feature_fraction': 0.9260382100156196, 'bagging_fraction': 0.8467917702118425, 'bagging_freq': 5, 'min_child_samples': 87}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:47,207] Trial 83 finished with value: 0.6352813110539633 and parameters: {'lambda_l1': 1.397502177726554e-05, 'lambda_l2': 8.782244278830521e-08, 'num_leaves': 184, 'feature_fraction': 0.9450719934393695, 'bagging_fraction': 0.9367269303417749, 'bagging_freq': 3, 'min_child_samples': 78}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:52,909] Trial 84 finished with value: 0.6032119030934364 and parameters: {'lambda_l1': 2.5460429236943716e-06, 'lambda_l2': 2.679229680935505e-07, 'num_leaves': 232, 'feature_fraction': 0.9819573444021064, 'bagging_fraction': 0.8212005846810365, 'bagging_freq': 4, 'min_child_samples': 85}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:12:58,978] Trial 85 finished with value: 0.6192532778984735 and parameters: {'lambda_l1': 7.956415113787386e-06, 'lambda_l2': 5.11033387675375e-08, 'num_leaves': 242, 'feature_fraction': 0.9830784463268308, 'bagging_fraction': 0.8820163940995496, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:04,807] Trial 86 finished with value: 0.6266942027688291 and parameters: {'lambda_l1': 2.9529186489257494e-06, 'lambda_l2': 2.448514344653833e-07, 'num_leaves': 230, 'feature_fraction': 0.9692654410350928, 'bagging_fraction': 0.916985123276983, 'bagging_freq': 3, 'min_child_samples': 98}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:10,576] Trial 87 finished with value: 0.6029482699811417 and parameters: {'lambda_l1': 2.547707648321275e-05, 'lambda_l2': 4.2255315052885484e-07, 'num_leaves': 236, 'feature_fraction': 0.9866257963042778, 'bagging_fraction': 0.8021430713319049, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:16,574] Trial 88 finished with value: 0.6014719301499278 and parameters: {'lambda_l1': 2.2510857864112886e-05, 'lambda_l2': 7.475327821030536e-08, 'num_leaves': 245, 'feature_fraction': 0.988540644193945, 'bagging_fraction': 0.8002071566405026, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:22,465] Trial 89 finished with value: 0.6130122376434514 and parameters: {'lambda_l1': 1.871252426610486e-05, 'lambda_l2': 2.3627828192689794e-08, 'num_leaves': 235, 'feature_fraction': 0.9872822047780527, 'bagging_fraction': 0.8331524054829537, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:28,351] Trial 90 finished with value: 0.6188719211719534 and parameters: {'lambda_l1': 6.708244541021649e-05, 'lambda_l2': 5.682034641309261e-08, 'num_leaves': 242, 'feature_fraction': 0.9638534467137347, 'bagging_fraction': 0.8063061651053253, 'bagging_freq': 4, 'min_child_samples': 76}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:34,477] Trial 91 finished with value: 0.5993424990228567 and parameters: {'lambda_l1': 3.358597196393928e-05, 'lambda_l2': 5.076698896872533e-07, 'num_leaves': 249, 'feature_fraction': 0.9947872578886995, 'bagging_fraction': 0.7874566705007904, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:40,473] Trial 92 finished with value: 0.6125913767098812 and parameters: {'lambda_l1': 4.327396066835576e-05, 'lambda_l2': 3.9893265408333537e-07, 'num_leaves': 256, 'feature_fraction': 0.9993682141635146, 'bagging_fraction': 0.8164532760414119, 'bagging_freq': 4, 'min_child_samples': 80}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:46,487] Trial 93 finished with value: 0.6063963310201352 and parameters: {'lambda_l1': 2.8221117554945456e-05, 'lambda_l2': 8.674524619162291e-07, 'num_leaves': 251, 'feature_fraction': 0.9867763250752671, 'bagging_fraction': 0.8000123054402564, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:52,525] Trial 94 finished with value: 0.6027170211428898 and parameters: {'lambda_l1': 2.5724843900315872e-05, 'lambda_l2': 9.665692846825349e-07, 'num_leaves': 250, 'feature_fraction': 0.9879615889460569, 'bagging_fraction': 0.792879913331865, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:13:58,617] Trial 95 finished with value: 0.6062704903251801 and parameters: {'lambda_l1': 0.00013010922224745188, 'lambda_l2': 8.57919160274274e-07, 'num_leaves': 251, 'feature_fraction': 0.9871293316725333, 'bagging_fraction': 0.7702617053019958, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:14:04,382] Trial 96 finished with value: 0.6141794640955215 and parameters: {'lambda_l1': 6.826955764543308e-05, 'lambda_l2': 5.034872103283654e-07, 'num_leaves': 238, 'feature_fraction': 0.9991703752621959, 'bagging_fraction': 0.7725522291717812, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:14:10,347] Trial 97 finished with value: 0.6151637836131527 and parameters: {'lambda_l1': 0.00012875655968765055, 'lambda_l2': 9.298864767905805e-08, 'num_leaves': 247, 'feature_fraction': 0.9414201969172902, 'bagging_fraction': 0.7915494029586914, 'bagging_freq': 4, 'min_child_samples': 74}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:14:16,002] Trial 98 finished with value: 0.6176647977255865 and parameters: {'lambda_l1': 0.00029559967082748727, 'lambda_l2': 7.781635802269422e-08, 'num_leaves': 224, 'feature_fraction': 0.9870431101800198, 'bagging_fraction': 0.73886840105842, 'bagging_freq': 4, 'min_child_samples': 79}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:14:21,622] Trial 99 finished with value: 0.6272684586167527 and parameters: {'lambda_l1': 2.8162199835203112e-05, 'lambda_l2': 4.4292824370854e-07, 'num_leaves': 228, 'feature_fraction': 0.9601035936067651, 'bagging_fraction': 0.7594254886752235, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 34 with value: 0.598882961154819.\n",
      "[I 2023-12-06 17:14:21,624] A new study created in memory with name: no-name-237b4e3d-4944-4ff4-aab9-f5e87b14217a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'lambda_l1': 5.357011380685383e-07, 'lambda_l2': 1.057193132189716e-06, 'num_leaves': 239, 'feature_fraction': 0.9961266527106151, 'bagging_fraction': 0.8455586491916388, 'bagging_freq': 3, 'min_child_samples': 94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 17:14:24,252] Trial 0 finished with value: 0.7145079651547064 and parameters: {'lambda_l1': 0.008467024970266164, 'lambda_l2': 0.1015451249720472, 'num_leaves': 111, 'feature_fraction': 0.49320523260632987, 'bagging_fraction': 0.78755669041142, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 0 with value: 0.7145079651547064.\n",
      "[I 2023-12-06 17:14:26,495] Trial 1 finished with value: 0.6922953180840072 and parameters: {'lambda_l1': 3.968078203159748e-07, 'lambda_l2': 4.452620438311327e-08, 'num_leaves': 102, 'feature_fraction': 0.8887754117920019, 'bagging_fraction': 0.41900907776941565, 'bagging_freq': 5, 'min_child_samples': 82}. Best is trial 1 with value: 0.6922953180840072.\n",
      "[I 2023-12-06 17:14:30,176] Trial 2 finished with value: 0.7480068243326687 and parameters: {'lambda_l1': 0.044606830481967834, 'lambda_l2': 8.989031015785701e-07, 'num_leaves': 204, 'feature_fraction': 0.7198302256562537, 'bagging_fraction': 0.9523163661503516, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 1 with value: 0.6922953180840072.\n",
      "[I 2023-12-06 17:14:30,989] Trial 3 finished with value: 0.681359268090105 and parameters: {'lambda_l1': 0.0006334913740180084, 'lambda_l2': 9.864352359003164e-07, 'num_leaves': 19, 'feature_fraction': 0.46835650149237007, 'bagging_fraction': 0.40037439455037943, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:31,621] Trial 4 finished with value: 0.6879083810530382 and parameters: {'lambda_l1': 0.1144468797759091, 'lambda_l2': 1.1544764557682837e-05, 'num_leaves': 11, 'feature_fraction': 0.950636520199712, 'bagging_fraction': 0.9625606878684742, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:33,474] Trial 5 finished with value: 0.7272711614182548 and parameters: {'lambda_l1': 2.118002297663179, 'lambda_l2': 1.2856755222671526e-07, 'num_leaves': 60, 'feature_fraction': 0.621894284184555, 'bagging_fraction': 0.6911591386203404, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:36,158] Trial 6 finished with value: 0.6979064296612458 and parameters: {'lambda_l1': 2.8719404831485742e-06, 'lambda_l2': 0.0009571662576769477, 'num_leaves': 117, 'feature_fraction': 0.7289536587996095, 'bagging_fraction': 0.4223659439319093, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:38,249] Trial 7 finished with value: 0.7197075587418097 and parameters: {'lambda_l1': 0.0002710561318385919, 'lambda_l2': 0.0004092472240005989, 'num_leaves': 83, 'feature_fraction': 0.5155163891685778, 'bagging_fraction': 0.9348674431887142, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:42,038] Trial 8 finished with value: 0.737428670640443 and parameters: {'lambda_l1': 5.4460876600408075e-06, 'lambda_l2': 3.206098652066334e-08, 'num_leaves': 232, 'feature_fraction': 0.7459834124685081, 'bagging_fraction': 0.7005265258137066, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:46,168] Trial 9 finished with value: 0.7120989280738739 and parameters: {'lambda_l1': 5.242510889225639e-07, 'lambda_l2': 8.320177546491737e-07, 'num_leaves': 241, 'feature_fraction': 0.47284272037921876, 'bagging_fraction': 0.8790879362138322, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:49,290] Trial 10 finished with value: 0.718836259362109 and parameters: {'lambda_l1': 0.00040183921488261704, 'lambda_l2': 3.1161450783330684, 'num_leaves': 171, 'feature_fraction': 0.402975647994532, 'bagging_fraction': 0.5398580696170194, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:49,604] Trial 11 finished with value: 0.7687364260889193 and parameters: {'lambda_l1': 9.476101315620854, 'lambda_l2': 1.3610819743281776e-05, 'num_leaves': 3, 'feature_fraction': 0.9417593840758003, 'bagging_fraction': 0.5981063787405485, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:49,928] Trial 12 finished with value: 0.7718804946230318 and parameters: {'lambda_l1': 0.10006916733340285, 'lambda_l2': 1.5303029431029302e-05, 'num_leaves': 3, 'feature_fraction': 0.836130173471771, 'bagging_fraction': 0.8273863468879986, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:51,436] Trial 13 finished with value: 0.7199962847420569 and parameters: {'lambda_l1': 0.000979910653514773, 'lambda_l2': 1.7188646239474733e-05, 'num_leaves': 41, 'feature_fraction': 0.9827904767704791, 'bagging_fraction': 0.9932238995085358, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:52,738] Trial 14 finished with value: 0.7152834901869417 and parameters: {'lambda_l1': 0.3776794599560124, 'lambda_l2': 0.0038226504587455332, 'num_leaves': 37, 'feature_fraction': 0.5971971870535271, 'bagging_fraction': 0.7649328868355559, 'bagging_freq': 7, 'min_child_samples': 79}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:55,362] Trial 15 finished with value: 0.7120709409251151 and parameters: {'lambda_l1': 1.0282854829664252e-08, 'lambda_l2': 1.1336870691497142e-08, 'num_leaves': 155, 'feature_fraction': 0.8011084392108009, 'bagging_fraction': 0.8799178677865656, 'bagging_freq': 1, 'min_child_samples': 60}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:56,596] Trial 16 finished with value: 0.718237725349213 and parameters: {'lambda_l1': 0.006000056812740114, 'lambda_l2': 5.27622472569439e-05, 'num_leaves': 34, 'feature_fraction': 0.6423709392389425, 'bagging_fraction': 0.497836632043123, 'bagging_freq': 2, 'min_child_samples': 83}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:58,242] Trial 17 finished with value: 0.7421033787324727 and parameters: {'lambda_l1': 0.7411450697666973, 'lambda_l2': 2.029954655844344e-06, 'num_leaves': 66, 'feature_fraction': 0.8820282906566317, 'bagging_fraction': 0.6378895685122074, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 3 with value: 0.681359268090105.\n",
      "[I 2023-12-06 17:14:59,030] Trial 18 finished with value: 0.6787438269036795 and parameters: {'lambda_l1': 0.04917865984642189, 'lambda_l2': 3.6867236036257035e-07, 'num_leaves': 17, 'feature_fraction': 0.9903034561742232, 'bagging_fraction': 0.5147498603099145, 'bagging_freq': 4, 'min_child_samples': 69}. Best is trial 18 with value: 0.6787438269036795.\n",
      "[I 2023-12-06 17:15:01,005] Trial 19 finished with value: 0.7300602308459728 and parameters: {'lambda_l1': 7.22001384876451e-05, 'lambda_l2': 2.1679294682988214e-07, 'num_leaves': 82, 'feature_fraction': 0.6601268889532321, 'bagging_fraction': 0.48609663454998187, 'bagging_freq': 6, 'min_child_samples': 70}. Best is trial 18 with value: 0.6787438269036795.\n",
      "[I 2023-12-06 17:15:04,233] Trial 20 finished with value: 0.7137640893046585 and parameters: {'lambda_l1': 0.004573238182058192, 'lambda_l2': 2.649513638239678e-07, 'num_leaves': 163, 'feature_fraction': 0.5780698952595723, 'bagging_fraction': 0.4159968765213795, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 18 with value: 0.6787438269036795.\n",
      "[I 2023-12-06 17:15:05,200] Trial 21 finished with value: 0.660996490213059 and parameters: {'lambda_l1': 0.027666082094198144, 'lambda_l2': 1.640074735067235e-06, 'num_leaves': 22, 'feature_fraction': 0.9974098538217716, 'bagging_fraction': 0.5613477378583558, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:06,279] Trial 22 finished with value: 0.6812955525208173 and parameters: {'lambda_l1': 0.01910627289328449, 'lambda_l2': 9.907212011758485e-07, 'num_leaves': 28, 'feature_fraction': 0.9850099853043633, 'bagging_fraction': 0.5587509593545379, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:07,870] Trial 23 finished with value: 0.6962390164959361 and parameters: {'lambda_l1': 0.027466117645128192, 'lambda_l2': 2.3124669787957376e-06, 'num_leaves': 61, 'feature_fraction': 0.9996986377151567, 'bagging_fraction': 0.5746042053597165, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:09,062] Trial 24 finished with value: 0.7228331353949121 and parameters: {'lambda_l1': 0.02403793034987021, 'lambda_l2': 4.994277728134955e-08, 'num_leaves': 32, 'feature_fraction': 0.9995225082896168, 'bagging_fraction': 0.5268264849767008, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:11,916] Trial 25 finished with value: 0.711063254152011 and parameters: {'lambda_l1': 0.23217457474336858, 'lambda_l2': 2.313604049392107e-07, 'num_leaves': 137, 'feature_fraction': 0.9265384263658755, 'bagging_fraction': 0.6014804294423959, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:13,801] Trial 26 finished with value: 0.7040316623992358 and parameters: {'lambda_l1': 0.9186474070646918, 'lambda_l2': 1.0016768038403582e-08, 'num_leaves': 84, 'feature_fraction': 0.9041595569502295, 'bagging_fraction': 0.473531677792462, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:15,356] Trial 27 finished with value: 0.6726380869697794 and parameters: {'lambda_l1': 0.0039408732948380655, 'lambda_l2': 9.070668177508812e-05, 'num_leaves': 50, 'feature_fraction': 0.9577963211832267, 'bagging_fraction': 0.5664549635979281, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:16,793] Trial 28 finished with value: 0.6859506779851123 and parameters: {'lambda_l1': 0.0029983395585287216, 'lambda_l2': 8.441283790465968e-05, 'num_leaves': 52, 'feature_fraction': 0.8414947152144298, 'bagging_fraction': 0.637333642762577, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:18,797] Trial 29 finished with value: 0.6821484480081536 and parameters: {'lambda_l1': 0.009911797045698108, 'lambda_l2': 0.005394926236962661, 'num_leaves': 106, 'feature_fraction': 0.9368822495432773, 'bagging_fraction': 0.5382545929993301, 'bagging_freq': 1, 'min_child_samples': 88}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:20,284] Trial 30 finished with value: 0.6830134456416607 and parameters: {'lambda_l1': 0.051875734780970205, 'lambda_l2': 9.501064565756974e-05, 'num_leaves': 49, 'feature_fraction': 0.9691648587532354, 'bagging_fraction': 0.4618520289479237, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:21,166] Trial 31 finished with value: 0.7022599628722408 and parameters: {'lambda_l1': 0.013942329174327046, 'lambda_l2': 3.677745210902244e-06, 'num_leaves': 22, 'feature_fraction': 0.9646919532657084, 'bagging_fraction': 0.5600133870226742, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:22,146] Trial 32 finished with value: 0.6685808315736421 and parameters: {'lambda_l1': 0.0022585269267183256, 'lambda_l2': 3.7499070146792168e-06, 'num_leaves': 23, 'feature_fraction': 0.9092389517848777, 'bagging_fraction': 0.5052969881506315, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:22,889] Trial 33 finished with value: 0.6667267125096009 and parameters: {'lambda_l1': 0.002460932671410363, 'lambda_l2': 4.896174148597995e-06, 'num_leaves': 16, 'feature_fraction': 0.9036566050118482, 'bagging_fraction': 0.45760497260062805, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:24,617] Trial 34 finished with value: 0.6835869085717281 and parameters: {'lambda_l1': 0.0017943969879098247, 'lambda_l2': 4.99479557159901e-06, 'num_leaves': 72, 'feature_fraction': 0.8997769588891242, 'bagging_fraction': 0.45229935233274887, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 21 with value: 0.660996490213059.\n",
      "[I 2023-12-06 17:15:25,389] Trial 35 finished with value: 0.6579071197464706 and parameters: {'lambda_l1': 0.0017790833086020483, 'lambda_l2': 3.823810037248821e-05, 'num_leaves': 17, 'feature_fraction': 0.8771734873442082, 'bagging_fraction': 0.5029692567221024, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:26,227] Trial 36 finished with value: 0.6995706631767563 and parameters: {'lambda_l1': 0.00010591245161614423, 'lambda_l2': 7.634174262932396e-06, 'num_leaves': 20, 'feature_fraction': 0.8710252270018856, 'bagging_fraction': 0.5006804333171335, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:26,752] Trial 37 finished with value: 0.6783967182801566 and parameters: {'lambda_l1': 0.0013744512729871492, 'lambda_l2': 2.3053124166191317e-05, 'num_leaves': 9, 'feature_fraction': 0.9225763577354887, 'bagging_fraction': 0.450345525134053, 'bagging_freq': 3, 'min_child_samples': 90}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:28,840] Trial 38 finished with value: 0.6790067002680491 and parameters: {'lambda_l1': 0.0006243536318463682, 'lambda_l2': 2.993340511514624e-06, 'num_leaves': 93, 'feature_fraction': 0.8567949409755014, 'bagging_fraction': 0.43712394715867064, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:30,108] Trial 39 finished with value: 0.6777860967579948 and parameters: {'lambda_l1': 0.0001660310389610133, 'lambda_l2': 1.0780116042356944e-06, 'num_leaves': 43, 'feature_fraction': 0.8024697278441754, 'bagging_fraction': 0.48607713751987786, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:33,668] Trial 40 finished with value: 0.7254780830082993 and parameters: {'lambda_l1': 4.4688199174282986e-05, 'lambda_l2': 0.0002750302729303428, 'num_leaves': 204, 'feature_fraction': 0.9097713034963035, 'bagging_fraction': 0.4022435662596652, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:34,582] Trial 41 finished with value: 0.6853290593768379 and parameters: {'lambda_l1': 0.0012247180641177795, 'lambda_l2': 3.142643990923062e-05, 'num_leaves': 21, 'feature_fraction': 0.9568495978306526, 'bagging_fraction': 0.5187693164076653, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:36,182] Trial 42 finished with value: 0.6808001309901173 and parameters: {'lambda_l1': 0.006356432424166295, 'lambda_l2': 6.423168985869269e-06, 'num_leaves': 57, 'feature_fraction': 0.9431072251150754, 'bagging_fraction': 0.47202420892832975, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 35 with value: 0.6579071197464706.\n",
      "[I 2023-12-06 17:15:36,861] Trial 43 finished with value: 0.652280491729984 and parameters: {'lambda_l1': 0.003235652717441211, 'lambda_l2': 0.000158290156101458, 'num_leaves': 14, 'feature_fraction': 0.8790309745579921, 'bagging_fraction': 0.4337664401106475, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:37,438] Trial 44 finished with value: 0.6767706227734966 and parameters: {'lambda_l1': 0.00036079067606032864, 'lambda_l2': 8.698707621989466e-06, 'num_leaves': 10, 'feature_fraction': 0.887191813279754, 'bagging_fraction': 0.4397171041319972, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:37,808] Trial 45 finished with value: 0.705801357832893 and parameters: {'lambda_l1': 0.0027211071512698135, 'lambda_l2': 0.0001862324392028325, 'num_leaves': 5, 'feature_fraction': 0.915562156356386, 'bagging_fraction': 0.4002303504141862, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:38,876] Trial 46 finished with value: 0.7127620031058208 and parameters: {'lambda_l1': 0.00918444194948152, 'lambda_l2': 3.0057696035529516e-05, 'num_leaves': 29, 'feature_fraction': 0.8724937339091235, 'bagging_fraction': 0.4268844872494176, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:41,464] Trial 47 finished with value: 0.6915325128282469 and parameters: {'lambda_l1': 0.0007440379252859472, 'lambda_l2': 6.230165343891098e-07, 'num_leaves': 118, 'feature_fraction': 0.8134804293088108, 'bagging_fraction': 0.49862693779932493, 'bagging_freq': 4, 'min_child_samples': 86}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:42,675] Trial 48 finished with value: 0.7111045694576504 and parameters: {'lambda_l1': 0.08600943439451415, 'lambda_l2': 0.0009364967842762134, 'num_leaves': 41, 'feature_fraction': 0.7558318541930947, 'bagging_fraction': 0.45629828424512486, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:42,931] Trial 49 finished with value: 0.8479651529769018 and parameters: {'lambda_l1': 0.0020663398877577093, 'lambda_l2': 1.6865030417817352e-06, 'num_leaves': 2, 'feature_fraction': 0.8514883657424764, 'bagging_fraction': 0.5188974463419237, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:43,634] Trial 50 finished with value: 0.6948763784051493 and parameters: {'lambda_l1': 0.0003389139651349575, 'lambda_l2': 9.351755635883642e-06, 'num_leaves': 15, 'feature_fraction': 0.8266891614385884, 'bagging_fraction': 0.4687683949504193, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 43 with value: 0.652280491729984.\n",
      "[I 2023-12-06 17:15:44,725] Trial 51 finished with value: 0.6400186278969393 and parameters: {'lambda_l1': 0.005905151057726137, 'lambda_l2': 6.088235241045704e-05, 'num_leaves': 30, 'feature_fraction': 0.9502482563315988, 'bagging_fraction': 0.5369892798476114, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:45,692] Trial 52 finished with value: 0.7353933337937284 and parameters: {'lambda_l1': 0.010239860490541226, 'lambda_l2': 2.60098698094234e-05, 'num_leaves': 23, 'feature_fraction': 0.9270667283557965, 'bagging_fraction': 0.5394473582802884, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:46,884] Trial 53 finished with value: 0.6922397412156708 and parameters: {'lambda_l1': 0.030635175139720895, 'lambda_l2': 6.374574921987564e-05, 'num_leaves': 35, 'feature_fraction': 0.8911002193377203, 'bagging_fraction': 0.49437974057087314, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:47,570] Trial 54 finished with value: 0.6701660088877899 and parameters: {'lambda_l1': 0.004511118377566094, 'lambda_l2': 4.176484125042718e-06, 'num_leaves': 12, 'feature_fraction': 0.9442966662976767, 'bagging_fraction': 0.4830964600549629, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:48,809] Trial 55 finished with value: 0.6560741109828596 and parameters: {'lambda_l1': 0.0009643279371840236, 'lambda_l2': 1.1572223290022396e-05, 'num_leaves': 41, 'feature_fraction': 0.9739538496886253, 'bagging_fraction': 0.4324814803515746, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:50,584] Trial 56 finished with value: 0.7149272626132704 and parameters: {'lambda_l1': 0.01724199008071687, 'lambda_l2': 1.2318409841825802e-05, 'num_leaves': 73, 'feature_fraction': 0.9734839021513889, 'bagging_fraction': 0.43341719342788076, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:51,939] Trial 57 finished with value: 0.6708774642477042 and parameters: {'lambda_l1': 0.0008746457781261376, 'lambda_l2': 0.00020390953710786394, 'num_leaves': 47, 'feature_fraction': 0.9648715803339761, 'bagging_fraction': 0.4210235474526354, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:53,113] Trial 58 finished with value: 0.652978829291756 and parameters: {'lambda_l1': 0.1499490942129722, 'lambda_l2': 1.6775853240607215e-05, 'num_leaves': 34, 'feature_fraction': 0.9833043915034206, 'bagging_fraction': 0.4478321685522801, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:54,680] Trial 59 finished with value: 0.6839886919232919 and parameters: {'lambda_l1': 0.060584890243973455, 'lambda_l2': 0.0006646931441759227, 'num_leaves': 63, 'feature_fraction': 0.9838495374283892, 'bagging_fraction': 0.4212935862169119, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 51 with value: 0.6400186278969393.\n",
      "[I 2023-12-06 17:15:55,647] Trial 60 finished with value: 0.6350002014683076 and parameters: {'lambda_l1': 0.1913741158028011, 'lambda_l2': 1.5112608866438408e-05, 'num_leaves': 34, 'feature_fraction': 0.9996886681452227, 'bagging_fraction': 0.5292530249739991, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:15:56,538] Trial 61 finished with value: 0.674202958668417 and parameters: {'lambda_l1': 0.3086055520924818, 'lambda_l2': 3.70929923647032e-05, 'num_leaves': 32, 'feature_fraction': 0.9994743588172047, 'bagging_fraction': 0.5406226425462651, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:15:57,559] Trial 62 finished with value: 0.6538722111284402 and parameters: {'lambda_l1': 0.1194256446224034, 'lambda_l2': 0.00012164229354321548, 'num_leaves': 41, 'feature_fraction': 0.9449602672018211, 'bagging_fraction': 0.5170065377252199, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:15:58,820] Trial 63 finished with value: 0.7099412712407115 and parameters: {'lambda_l1': 3.3489152945867717, 'lambda_l2': 1.5201784703426595e-05, 'num_leaves': 39, 'feature_fraction': 0.9457734452558285, 'bagging_fraction': 0.48648804312738003, 'bagging_freq': 1, 'min_child_samples': 63}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:00,433] Trial 64 finished with value: 0.6805394383687035 and parameters: {'lambda_l1': 0.1513701898589607, 'lambda_l2': 5.406951452661909e-05, 'num_leaves': 55, 'feature_fraction': 0.9774000931348292, 'bagging_fraction': 0.44026580677763566, 'bagging_freq': 1, 'min_child_samples': 68}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:01,703] Trial 65 finished with value: 0.7561064876412437 and parameters: {'lambda_l1': 0.11686832604797781, 'lambda_l2': 0.00017069691693795652, 'num_leaves': 42, 'feature_fraction': 0.9272087194944041, 'bagging_fraction': 0.4749644897693244, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:03,271] Trial 66 finished with value: 0.7449771126379722 and parameters: {'lambda_l1': 0.46053998208972924, 'lambda_l2': 0.00044258537453995597, 'num_leaves': 74, 'feature_fraction': 0.9607483158611545, 'bagging_fraction': 0.505821955443979, 'bagging_freq': 1, 'min_child_samples': 56}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:04,179] Trial 67 finished with value: 0.6488405191859931 and parameters: {'lambda_l1': 0.15212967221717522, 'lambda_l2': 0.00012672478007513753, 'num_leaves': 31, 'feature_fraction': 0.9396195666130356, 'bagging_fraction': 0.5198652704553874, 'bagging_freq': 1, 'min_child_samples': 79}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:05,038] Trial 68 finished with value: 0.6915800567536976 and parameters: {'lambda_l1': 0.23579610320138833, 'lambda_l2': 0.00010695624776677578, 'num_leaves': 30, 'feature_fraction': 0.9469778074649279, 'bagging_fraction': 0.5887469587496805, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:08,600] Trial 69 finished with value: 0.7082098910482214 and parameters: {'lambda_l1': 0.04229980740629091, 'lambda_l2': 0.00012449944561256708, 'num_leaves': 252, 'feature_fraction': 0.9331953967530864, 'bagging_fraction': 0.5313616236786574, 'bagging_freq': 1, 'min_child_samples': 66}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:11,845] Trial 70 finished with value: 0.6965094196087208 and parameters: {'lambda_l1': 0.17097662657903973, 'lambda_l2': 0.0003712188505986492, 'num_leaves': 181, 'feature_fraction': 0.9821735709448814, 'bagging_fraction': 0.46116679605665095, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:12,796] Trial 71 finished with value: 0.7184189426227476 and parameters: {'lambda_l1': 0.08179538026371792, 'lambda_l2': 1.8392269917447174e-05, 'num_leaves': 27, 'feature_fraction': 0.9698745173333069, 'bagging_fraction': 0.5211245304533129, 'bagging_freq': 1, 'min_child_samples': 79}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:14,084] Trial 72 finished with value: 0.690411616240003 and parameters: {'lambda_l1': 0.6005807698390033, 'lambda_l2': 6.36313750025086e-05, 'num_leaves': 36, 'feature_fraction': 0.9182573907976812, 'bagging_fraction': 0.5471791987012683, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:15,499] Trial 73 finished with value: 0.698062685483571 and parameters: {'lambda_l1': 0.014069452217686582, 'lambda_l2': 4.002787270319225e-05, 'num_leaves': 49, 'feature_fraction': 0.9516106455732367, 'bagging_fraction': 0.4450900990006239, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:17,248] Trial 74 finished with value: 0.6885535002580973 and parameters: {'lambda_l1': 0.03966283394991084, 'lambda_l2': 5.0815556230666914e-05, 'num_leaves': 65, 'feature_fraction': 0.8903137614077468, 'bagging_fraction': 0.5170374139335647, 'bagging_freq': 2, 'min_child_samples': 64}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:17,959] Trial 75 finished with value: 0.6919819595879814 and parameters: {'lambda_l1': 0.006923179546614709, 'lambda_l2': 1.8693283184591864e-05, 'num_leaves': 13, 'feature_fraction': 0.9867955133772037, 'bagging_fraction': 0.48720215958999347, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:20,659] Trial 76 finished with value: 0.7291306452739333 and parameters: {'lambda_l1': 1.1015967157858506, 'lambda_l2': 0.00010332984142681788, 'num_leaves': 138, 'feature_fraction': 0.9344044760493905, 'bagging_fraction': 0.4117240583554945, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:22,251] Trial 77 finished with value: 0.7104044596036105 and parameters: {'lambda_l1': 0.2826588776138597, 'lambda_l2': 1.0466487971617037e-05, 'num_leaves': 56, 'feature_fraction': 0.9625661678348179, 'bagging_fraction': 0.5512258489940011, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:23,202] Trial 78 finished with value: 0.6747278311023205 and parameters: {'lambda_l1': 0.022034312521209798, 'lambda_l2': 0.00023885516081627477, 'num_leaves': 25, 'feature_fraction': 0.9983475548535649, 'bagging_fraction': 0.47086251203386353, 'bagging_freq': 2, 'min_child_samples': 83}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:24,301] Trial 79 finished with value: 0.7184429912256323 and parameters: {'lambda_l1': 0.08226875986235667, 'lambda_l2': 0.0016381931968364929, 'num_leaves': 46, 'feature_fraction': 0.9057160672111315, 'bagging_fraction': 0.5812316275733986, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:24,704] Trial 80 finished with value: 0.6862762571662543 and parameters: {'lambda_l1': 0.004667475247015607, 'lambda_l2': 2.5271627502372115e-05, 'num_leaves': 7, 'feature_fraction': 0.8749802373929787, 'bagging_fraction': 0.5043601018553593, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:25,505] Trial 81 finished with value: 0.6561698992154884 and parameters: {'lambda_l1': 0.14187512129968277, 'lambda_l2': 6.365006485301608e-06, 'num_leaves': 18, 'feature_fraction': 0.9778510112383718, 'bagging_fraction': 0.5279050996672534, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:26,379] Trial 82 finished with value: 0.6722030675375452 and parameters: {'lambda_l1': 0.19590475571144092, 'lambda_l2': 4.3886905282475136e-05, 'num_leaves': 16, 'feature_fraction': 0.9760157905955461, 'bagging_fraction': 0.5315607417166581, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:27,562] Trial 83 finished with value: 0.6862219334635878 and parameters: {'lambda_l1': 0.12437213398002418, 'lambda_l2': 6.2302300376854585e-06, 'num_leaves': 36, 'feature_fraction': 0.9526039539465933, 'bagging_fraction': 0.5089252238483262, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:28,819] Trial 84 finished with value: 0.6803429699739413 and parameters: {'lambda_l1': 0.5628717691745092, 'lambda_l2': 1.2016066021048418e-05, 'num_leaves': 28, 'feature_fraction': 0.9848566052244121, 'bagging_fraction': 0.5631941815008574, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:29,670] Trial 85 finished with value: 0.6647148722938139 and parameters: {'lambda_l1': 0.053710950305784856, 'lambda_l2': 0.00014855612527685965, 'num_leaves': 18, 'feature_fraction': 0.9173553652899846, 'bagging_fraction': 0.46432464485348757, 'bagging_freq': 1, 'min_child_samples': 64}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:30,223] Trial 86 finished with value: 0.6774155016169466 and parameters: {'lambda_l1': 0.37937781373308443, 'lambda_l2': 7.567254823247705e-05, 'num_leaves': 8, 'feature_fraction': 0.9409309803850576, 'bagging_fraction': 0.44260312346587655, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:31,620] Trial 87 finished with value: 0.6908428268446455 and parameters: {'lambda_l1': 0.02598943263863878, 'lambda_l2': 2.429641548252712e-06, 'num_leaves': 41, 'feature_fraction': 0.964111868316712, 'bagging_fraction': 0.5290861718380202, 'bagging_freq': 2, 'min_child_samples': 68}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:32,813] Trial 88 finished with value: 0.6725049896219736 and parameters: {'lambda_l1': 0.013581363976131548, 'lambda_l2': 2.174367035790886e-05, 'num_leaves': 34, 'feature_fraction': 0.9272660464096447, 'bagging_fraction': 0.4793305265314894, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:33,100] Trial 89 finished with value: 0.7673119092973403 and parameters: {'lambda_l1': 0.0014978865256785622, 'lambda_l2': 3.204598867422224e-05, 'num_leaves': 3, 'feature_fraction': 0.89601311058225, 'bagging_fraction': 0.4954476190382621, 'bagging_freq': 7, 'min_child_samples': 59}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:34,841] Trial 90 finished with value: 0.6873692651278314 and parameters: {'lambda_l1': 0.006616346791916777, 'lambda_l2': 8.469946153515536e-06, 'num_leaves': 88, 'feature_fraction': 0.8628655297805518, 'bagging_fraction': 0.5729998190764105, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:35,674] Trial 91 finished with value: 0.7342701968019457 and parameters: {'lambda_l1': 0.0033131876762080106, 'lambda_l2': 3.6558931671023312e-06, 'num_leaves': 19, 'feature_fraction': 0.9910674664465471, 'bagging_fraction': 0.5485316561636782, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:36,698] Trial 92 finished with value: 0.7218771120396237 and parameters: {'lambda_l1': 0.03127832372816841, 'lambda_l2': 1.5000802847567135e-05, 'num_leaves': 24, 'feature_fraction': 0.9730654023101959, 'bagging_fraction': 0.5581319117750076, 'bagging_freq': 3, 'min_child_samples': 65}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:37,398] Trial 93 finished with value: 0.6781899675876502 and parameters: {'lambda_l1': 0.1368774857990306, 'lambda_l2': 6.3202620857358e-06, 'num_leaves': 13, 'feature_fraction': 0.955568480227404, 'bagging_fraction': 0.5129314354687813, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:38,432] Trial 94 finished with value: 0.6857261220330634 and parameters: {'lambda_l1': 0.0810657067138377, 'lambda_l2': 1.315396962226234e-06, 'num_leaves': 30, 'feature_fraction': 0.9931208503177976, 'bagging_fraction': 0.42893697788214236, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:40,204] Trial 95 finished with value: 0.7228268816304619 and parameters: {'lambda_l1': 0.0006088279699072073, 'lambda_l2': 2.568258697803043e-06, 'num_leaves': 53, 'feature_fraction': 0.9729898249601466, 'bagging_fraction': 0.4556930044421056, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:41,687] Trial 96 finished with value: 0.7132941886296167 and parameters: {'lambda_l1': 0.016703340622628137, 'lambda_l2': 7.813442993807675e-05, 'num_leaves': 46, 'feature_fraction': 0.9537200197646867, 'bagging_fraction': 0.6144779798269449, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:42,713] Trial 97 finished with value: 0.6822904456874469 and parameters: {'lambda_l1': 0.009427104120562477, 'lambda_l2': 0.00012787159253170255, 'num_leaves': 25, 'feature_fraction': 0.9389479822770617, 'bagging_fraction': 0.5355719892461265, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:43,499] Trial 98 finished with value: 0.6610467774390572 and parameters: {'lambda_l1': 0.062402675479619835, 'lambda_l2': 0.00027726148327581916, 'num_leaves': 20, 'feature_fraction': 0.9994013499517834, 'bagging_fraction': 0.493553039695983, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 60 with value: 0.6350002014683076.\n",
      "[I 2023-12-06 17:16:45,192] Trial 99 finished with value: 0.6858694764380077 and parameters: {'lambda_l1': 0.18689374895676986, 'lambda_l2': 4.886802914213966e-05, 'num_leaves': 60, 'feature_fraction': 0.9128147243650385, 'bagging_fraction': 0.47958446895144746, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 60 with value: 0.6350002014683076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'lambda_l1': 0.1913741158028011, 'lambda_l2': 1.5112608866438408e-05, 'num_leaves': 34, 'feature_fraction': 0.9996886681452227, 'bagging_fraction': 0.5292530249739991, 'bagging_freq': 1, 'min_child_samples': 69}\n"
     ]
    }
   ],
   "source": [
    "#optuna study\n",
    "# Define the objective function for working days\n",
    "def objective_w(trial):\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "    model.fit(X_train_w, y_train_w)\n",
    "    y_pred = model.predict(X_test_w)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_w, y_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Define the objective function for non-working days\n",
    "def objective_nw(trial):\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "    model.fit(X_train_nw, y_train_nw)\n",
    "    y_pred = model.predict(X_test_nw)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_nw, y_pred))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Create and optimize the study for working days\n",
    "study_w = optuna.create_study(direction=\"minimize\")\n",
    "study_w.optimize(objective_w, n_trials=100)\n",
    "print(\"Best parameters for working days:\", study_w.best_params)\n",
    "\n",
    "# Create and optimize the study for non-working days\n",
    "study_nw = optuna.create_study(direction=\"minimize\")\n",
    "study_nw.optimize(objective_nw, n_trials=100)\n",
    "print(\"Best parameters for non-working days:\", study_nw.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Best parameters for working days: {'lambda_l1': 5.357011380685383e-07, 'lambda_l2': 1.057193132189716e-06, 'num_leaves': 239, 'feature_fraction': 0.9961266527106151, 'bagging_fraction': 0.8455586491916388, 'bagging_freq': 3, 'min_child_samples': 94}\n",
    "-> Best parameters for non-working days: {'lambda_l1': 0.1913741158028011, 'lambda_l2': 1.5112608866438408e-05, 'num_leaves': 34, 'feature_fraction': 0.9996886681452227, 'bagging_fraction': 0.5292530249739991, 'bagging_freq': 1, 'min_child_samples': 69}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 18:52:07,629] A new study created in memory with name: no-name-08ed0aa2-7d76-4955-861e-bfab82de71e1\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:52:21,085] Trial 0 finished with value: 0.764556919231036 and parameters: {'lambda_l1': 2.3693326203555176, 'lambda_l2': 0.014984610604775538, 'num_leaves': 74, 'feature_fraction': 0.5907072063277642, 'bagging_fraction': 0.48317865019933703, 'bagging_freq': 3, 'min_child_samples': 25, 'learning_rate': 0.019009334052452965, 'max_depth': 27, 'min_gain_to_split': 3.4676960332073445, 'min_sum_hessian_in_leaf': 2.008208846877515}. Best is trial 0 with value: 0.764556919231036.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:52:29,012] Trial 1 finished with value: 0.605680951055853 and parameters: {'lambda_l1': 0.004934283662330793, 'lambda_l2': 6.742608418021103e-07, 'num_leaves': 151, 'feature_fraction': 0.6713608446561619, 'bagging_fraction': 0.601675071625305, 'bagging_freq': 6, 'min_child_samples': 100, 'learning_rate': 0.1214119421226113, 'max_depth': 43, 'min_gain_to_split': 11.23544398067347, 'min_sum_hessian_in_leaf': 4.526705350057655}. Best is trial 1 with value: 0.605680951055853.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:52:42,577] Trial 2 finished with value: 0.8061899669012081 and parameters: {'lambda_l1': 0.0010235861348717613, 'lambda_l2': 0.21198116326442806, 'num_leaves': 124, 'feature_fraction': 0.9931495733104831, 'bagging_fraction': 0.4167965209122229, 'bagging_freq': 6, 'min_child_samples': 72, 'learning_rate': 0.016415743165493015, 'max_depth': 9, 'min_gain_to_split': 6.940789992460278, 'min_sum_hessian_in_leaf': 2.3008809519972306}. Best is trial 1 with value: 0.605680951055853.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:02,086] Trial 3 finished with value: 1.1910726672285967 and parameters: {'lambda_l1': 0.21923946559837584, 'lambda_l2': 1.0525786681105373e-07, 'num_leaves': 188, 'feature_fraction': 0.5378603910794084, 'bagging_fraction': 0.5349408596029849, 'bagging_freq': 4, 'min_child_samples': 91, 'learning_rate': 0.006113033409425791, 'max_depth': 14, 'min_gain_to_split': 12.0127097696814, 'min_sum_hessian_in_leaf': 7.793165054726574}. Best is trial 1 with value: 0.605680951055853.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:06,479] Trial 4 finished with value: 0.6513804551269046 and parameters: {'lambda_l1': 4.470686767928057e-06, 'lambda_l2': 6.321996171530872e-06, 'num_leaves': 236, 'feature_fraction': 0.4478177895735067, 'bagging_fraction': 0.4875785133925674, 'bagging_freq': 2, 'min_child_samples': 39, 'learning_rate': 0.44313947765612755, 'max_depth': 0, 'min_gain_to_split': 9.724042833353112, 'min_sum_hessian_in_leaf': 6.060651722716383}. Best is trial 1 with value: 0.605680951055853.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:19,892] Trial 5 finished with value: 0.6004240660947358 and parameters: {'lambda_l1': 0.009020141663766268, 'lambda_l2': 6.740080392078258e-08, 'num_leaves': 144, 'feature_fraction': 0.818581442635447, 'bagging_fraction': 0.44999724836547883, 'bagging_freq': 4, 'min_child_samples': 36, 'learning_rate': 0.059783625971296515, 'max_depth': 35, 'min_gain_to_split': 8.739563440508755, 'min_sum_hessian_in_leaf': 5.516174911007979}. Best is trial 5 with value: 0.6004240660947358.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:31,289] Trial 6 finished with value: 0.8166805858099077 and parameters: {'lambda_l1': 0.16392948974289356, 'lambda_l2': 7.934343053650552e-06, 'num_leaves': 56, 'feature_fraction': 0.6993127771214843, 'bagging_fraction': 0.49943074612159255, 'bagging_freq': 4, 'min_child_samples': 32, 'learning_rate': 0.015701248929857338, 'max_depth': 16, 'min_gain_to_split': 0.45085216399312733, 'min_sum_hessian_in_leaf': 2.772315864545497}. Best is trial 5 with value: 0.6004240660947358.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:35,680] Trial 7 finished with value: 0.6096217537871702 and parameters: {'lambda_l1': 1.4564432285815246e-07, 'lambda_l2': 0.009480916189236587, 'num_leaves': 100, 'feature_fraction': 0.5039117272254748, 'bagging_fraction': 0.8021436791931535, 'bagging_freq': 1, 'min_child_samples': 8, 'learning_rate': 0.33203292000871343, 'max_depth': 46, 'min_gain_to_split': 10.299685184288665, 'min_sum_hessian_in_leaf': 9.325446373199501}. Best is trial 5 with value: 0.6004240660947358.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:41,783] Trial 8 finished with value: 1.5769521987158712 and parameters: {'lambda_l1': 0.0005001666252867651, 'lambda_l2': 0.09170784215651952, 'num_leaves': 170, 'feature_fraction': 0.5098111754294203, 'bagging_fraction': 0.49988191348876304, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.0016379553436993946, 'max_depth': 5, 'min_gain_to_split': 13.283540940347494, 'min_sum_hessian_in_leaf': 9.947780894243197}. Best is trial 5 with value: 0.6004240660947358.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:49,876] Trial 9 finished with value: 0.5768714773296093 and parameters: {'lambda_l1': 1.3295125832016114e-06, 'lambda_l2': 0.0028706528719076355, 'num_leaves': 230, 'feature_fraction': 0.8198898040288317, 'bagging_fraction': 0.7958226343104069, 'bagging_freq': 5, 'min_child_samples': 10, 'learning_rate': 0.16652156149495453, 'max_depth': 48, 'min_gain_to_split': 7.845459885378604, 'min_sum_hessian_in_leaf': 2.1756536701993223}. Best is trial 9 with value: 0.5768714773296093.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:53:52,840] Trial 10 finished with value: 0.6752911074547091 and parameters: {'lambda_l1': 3.5547213705883925e-08, 'lambda_l2': 6.83557401315881, 'num_leaves': 12, 'feature_fraction': 0.8273934481684687, 'bagging_fraction': 0.9803642388312197, 'bagging_freq': 7, 'min_child_samples': 7, 'learning_rate': 0.6215086051375548, 'max_depth': 50, 'min_gain_to_split': 14.393415108316942, 'min_sum_hessian_in_leaf': 0.3478895713537087}. Best is trial 9 with value: 0.5768714773296093.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:08,386] Trial 11 finished with value: 0.578938679527363 and parameters: {'lambda_l1': 1.8646101683551906e-05, 'lambda_l2': 1.204829532013987e-08, 'num_leaves': 249, 'feature_fraction': 0.8128519120574563, 'bagging_fraction': 0.7119260440294124, 'bagging_freq': 5, 'min_child_samples': 48, 'learning_rate': 0.07662487740534131, 'max_depth': 35, 'min_gain_to_split': 7.680211532681022, 'min_sum_hessian_in_leaf': 4.0876644423179584}. Best is trial 9 with value: 0.5768714773296093.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:19,331] Trial 12 finished with value: 0.576885919086363 and parameters: {'lambda_l1': 7.238484570568066e-06, 'lambda_l2': 0.0002671254511476643, 'num_leaves': 256, 'feature_fraction': 0.8081056345868158, 'bagging_fraction': 0.7341504476258226, 'bagging_freq': 5, 'min_child_samples': 56, 'learning_rate': 0.11497259310002625, 'max_depth': 36, 'min_gain_to_split': 6.663410629142339, 'min_sum_hessian_in_leaf': 4.11455817099667}. Best is trial 9 with value: 0.5768714773296093.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:27,196] Trial 13 finished with value: 0.5743758887303165 and parameters: {'lambda_l1': 5.052963625902584e-06, 'lambda_l2': 0.00032826887941960045, 'num_leaves': 215, 'feature_fraction': 0.8914133612023307, 'bagging_fraction': 0.7969995221039704, 'bagging_freq': 6, 'min_child_samples': 67, 'learning_rate': 0.1764193074706687, 'max_depth': 38, 'min_gain_to_split': 6.211215171578413, 'min_sum_hessian_in_leaf': 0.523689840091675}. Best is trial 13 with value: 0.5743758887303165.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:34,718] Trial 14 finished with value: 0.5681911483305834 and parameters: {'lambda_l1': 4.0867369047020965e-07, 'lambda_l2': 0.0006825650135374653, 'num_leaves': 199, 'feature_fraction': 0.9319937876791172, 'bagging_fraction': 0.8484146578258911, 'bagging_freq': 7, 'min_child_samples': 66, 'learning_rate': 0.20219346014118958, 'max_depth': 26, 'min_gain_to_split': 5.2090766323557185, 'min_sum_hessian_in_leaf': 0.3999843059453212}. Best is trial 14 with value: 0.5681911483305834.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:37,936] Trial 15 finished with value: 0.6222666026922635 and parameters: {'lambda_l1': 3.6658111462631766e-07, 'lambda_l2': 0.00019152182224309175, 'num_leaves': 196, 'feature_fraction': 0.974339779159511, 'bagging_fraction': 0.8987822371094967, 'bagging_freq': 7, 'min_child_samples': 68, 'learning_rate': 0.9358885207553401, 'max_depth': 26, 'min_gain_to_split': 4.83233744720175, 'min_sum_hessian_in_leaf': 0.05823413910180991}. Best is trial 14 with value: 0.5681911483305834.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:43,867] Trial 16 finished with value: 0.5730762038757835 and parameters: {'lambda_l1': 1.272284998766052e-08, 'lambda_l2': 3.0317037624904685e-05, 'num_leaves': 208, 'feature_fraction': 0.9271945947531821, 'bagging_fraction': 0.8601600096528857, 'bagging_freq': 7, 'min_child_samples': 84, 'learning_rate': 0.2710246245927942, 'max_depth': 21, 'min_gain_to_split': 5.169204726792675, 'min_sum_hessian_in_leaf': 0.897852641142546}. Best is trial 14 with value: 0.5681911483305834.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:50,078] Trial 17 finished with value: 0.5666886925940426 and parameters: {'lambda_l1': 2.318955684418548e-08, 'lambda_l2': 1.659937581054521e-05, 'num_leaves': 201, 'feature_fraction': 0.933202334538208, 'bagging_fraction': 0.8869532325568935, 'bagging_freq': 7, 'min_child_samples': 84, 'learning_rate': 0.29512960947035977, 'max_depth': 19, 'min_gain_to_split': 3.762582603221026, 'min_sum_hessian_in_leaf': 1.170730975329345}. Best is trial 17 with value: 0.5666886925940426.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:53,589] Trial 18 finished with value: 0.6105796499760918 and parameters: {'lambda_l1': 8.588893971433131e-08, 'lambda_l2': 1.3009389021829237e-06, 'num_leaves': 172, 'feature_fraction': 0.9041311937172547, 'bagging_fraction': 0.9790573348851181, 'bagging_freq': 7, 'min_child_samples': 55, 'learning_rate': 0.9306221958185005, 'max_depth': 22, 'min_gain_to_split': 2.7664589050413406, 'min_sum_hessian_in_leaf': 1.5193596224715653}. Best is trial 17 with value: 0.5666886925940426.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:54:59,683] Trial 19 finished with value: 0.5663174158114302 and parameters: {'lambda_l1': 1.5903781209372298e-08, 'lambda_l2': 7.871004072278784e-05, 'num_leaves': 117, 'feature_fraction': 0.985004426001559, 'bagging_fraction': 0.9081402389619079, 'bagging_freq': 6, 'min_child_samples': 83, 'learning_rate': 0.28821500845031167, 'max_depth': 30, 'min_gain_to_split': 2.5286956313796525, 'min_sum_hessian_in_leaf': 3.2190935007044246}. Best is trial 19 with value: 0.5663174158114302.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:05,296] Trial 20 finished with value: 0.5627854285382089 and parameters: {'lambda_l1': 1.582850696679096e-08, 'lambda_l2': 5.490598069383533e-05, 'num_leaves': 111, 'feature_fraction': 0.9974939937501708, 'bagging_fraction': 0.9203716622762339, 'bagging_freq': 6, 'min_child_samples': 83, 'learning_rate': 0.40719756468078916, 'max_depth': 15, 'min_gain_to_split': 1.278793600404514, 'min_sum_hessian_in_leaf': 2.8493149972132947}. Best is trial 20 with value: 0.5627854285382089.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:11,964] Trial 21 finished with value: 0.5538268748547657 and parameters: {'lambda_l1': 1.247863326867823e-08, 'lambda_l2': 3.0103080257809377e-05, 'num_leaves': 111, 'feature_fraction': 0.9867641685957481, 'bagging_fraction': 0.9262904514771951, 'bagging_freq': 6, 'min_child_samples': 84, 'learning_rate': 0.4201761229431432, 'max_depth': 17, 'min_gain_to_split': 0.5188601422160044, 'min_sum_hessian_in_leaf': 3.2383686543984425}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:18,672] Trial 22 finished with value: 0.5623483318647273 and parameters: {'lambda_l1': 1.0958122059189807e-08, 'lambda_l2': 6.780140337807191e-05, 'num_leaves': 107, 'feature_fraction': 0.9877403889046339, 'bagging_fraction': 0.9353919933415215, 'bagging_freq': 6, 'min_child_samples': 83, 'learning_rate': 0.4281418783515212, 'max_depth': 9, 'min_gain_to_split': 0.5577137516604344, 'min_sum_hessian_in_leaf': 3.054475641257467}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:25,330] Trial 23 finished with value: 0.55954880138509 and parameters: {'lambda_l1': 1.0605277039325407e-08, 'lambda_l2': 4.195546722037364e-05, 'num_leaves': 89, 'feature_fraction': 0.986270460400167, 'bagging_fraction': 0.9474836097330559, 'bagging_freq': 6, 'min_child_samples': 97, 'learning_rate': 0.6072392350544561, 'max_depth': 10, 'min_gain_to_split': 0.3431080019390026, 'min_sum_hessian_in_leaf': 3.1824535663434546}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:31,695] Trial 24 finished with value: 0.5918025670577037 and parameters: {'lambda_l1': 1.5703775035113536e-07, 'lambda_l2': 3.327285939786289e-06, 'num_leaves': 84, 'feature_fraction': 0.875512006300089, 'bagging_fraction': 0.9900245246393243, 'bagging_freq': 5, 'min_child_samples': 100, 'learning_rate': 0.9975829895348592, 'max_depth': 8, 'min_gain_to_split': 0.43890950978277044, 'min_sum_hessian_in_leaf': 3.113198362582274}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:34,377] Trial 25 finished with value: 0.806321874059184 and parameters: {'lambda_l1': 8.713119197420854e-07, 'lambda_l2': 3.073634968387532e-05, 'num_leaves': 34, 'feature_fraction': 0.9580940195234364, 'bagging_fraction': 0.9497913642822458, 'bagging_freq': 6, 'min_child_samples': 93, 'learning_rate': 0.5097767930016387, 'max_depth': 1, 'min_gain_to_split': 1.8971176714476718, 'min_sum_hessian_in_leaf': 3.634632474518589}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:39,392] Trial 26 finished with value: 0.5786223104817283 and parameters: {'lambda_l1': 8.327396575105476e-08, 'lambda_l2': 0.0010060245607741336, 'num_leaves': 90, 'feature_fraction': 0.8777164492002367, 'bagging_fraction': 0.9476195994759982, 'bagging_freq': 3, 'min_child_samples': 91, 'learning_rate': 0.5450543990074493, 'max_depth': 9, 'min_gain_to_split': 1.280697386273145, 'min_sum_hessian_in_leaf': 4.587481128941224}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:52,275] Trial 27 finished with value: 0.5972655445325008 and parameters: {'lambda_l1': 3.4023078900923266e-05, 'lambda_l2': 9.486497816518166e-05, 'num_leaves': 62, 'feature_fraction': 0.947887697746932, 'bagging_fraction': 0.9374223069610467, 'bagging_freq': 6, 'min_child_samples': 76, 'learning_rate': 0.05252195049297939, 'max_depth': 13, 'min_gain_to_split': 0.37396065259341427, 'min_sum_hessian_in_leaf': 3.5803327927206063}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:55:57,060] Trial 28 finished with value: 0.5900226395306175 and parameters: {'lambda_l1': 1.1173875194947676e-08, 'lambda_l2': 2.1256776573613692e-06, 'num_leaves': 143, 'feature_fraction': 0.8547856575809669, 'bagging_fraction': 0.997308600797783, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.6170589795113811, 'max_depth': 4, 'min_gain_to_split': 0.0836942959431613, 'min_sum_hessian_in_leaf': 1.9931522244768416}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:04,031] Trial 29 finished with value: 0.5810176391865688 and parameters: {'lambda_l1': 6.282968722462803e-08, 'lambda_l2': 1.5987671213325194e-05, 'num_leaves': 69, 'feature_fraction': 0.910564208743914, 'bagging_fraction': 0.8573337758187074, 'bagging_freq': 3, 'min_child_samples': 77, 'learning_rate': 0.2066293774053234, 'max_depth': 11, 'min_gain_to_split': 3.4847860413792757, 'min_sum_hessian_in_leaf': 1.374482846551169}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:11,672] Trial 30 finished with value: 0.6165904155638166 and parameters: {'lambda_l1': 7.016443962336287e-07, 'lambda_l2': 0.0026485154326727216, 'num_leaves': 50, 'feature_fraction': 0.7717383476684593, 'bagging_fraction': 0.9373370050390453, 'bagging_freq': 5, 'min_child_samples': 93, 'learning_rate': 0.11652777449659453, 'max_depth': 6, 'min_gain_to_split': 1.5482990071796765, 'min_sum_hessian_in_leaf': 5.132076593008721}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:17,123] Trial 31 finished with value: 0.5660004149774253 and parameters: {'lambda_l1': 1.3229739828103441e-08, 'lambda_l2': 6.154093367216875e-05, 'num_leaves': 109, 'feature_fraction': 0.9941057084889044, 'bagging_fraction': 0.9104385190966355, 'bagging_freq': 6, 'min_child_samples': 82, 'learning_rate': 0.4136592464921419, 'max_depth': 18, 'min_gain_to_split': 1.4419451697348373, 'min_sum_hessian_in_leaf': 2.74209928605513}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:22,456] Trial 32 finished with value: 0.5720610557129551 and parameters: {'lambda_l1': 8.623366073418847e-08, 'lambda_l2': 5.528081247513122e-05, 'num_leaves': 95, 'feature_fraction': 0.9979984643138279, 'bagging_fraction': 0.9527483844671769, 'bagging_freq': 6, 'min_child_samples': 96, 'learning_rate': 0.36955537679616396, 'max_depth': 14, 'min_gain_to_split': 2.422130298158058, 'min_sum_hessian_in_leaf': 2.374189487475561}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:27,359] Trial 33 finished with value: 0.5759945423205762 and parameters: {'lambda_l1': 3.9461990865359104e-08, 'lambda_l2': 9.074411622522918e-06, 'num_leaves': 132, 'feature_fraction': 0.9513522049711618, 'bagging_fraction': 0.8876796827612297, 'bagging_freq': 6, 'min_child_samples': 88, 'learning_rate': 0.6609251056662475, 'max_depth': 11, 'min_gain_to_split': 1.0904855210595052, 'min_sum_hessian_in_leaf': 1.7362160144382273}. Best is trial 21 with value: 0.5538268748547657.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:38,700] Trial 34 finished with value: 0.5403767840163478 and parameters: {'lambda_l1': 2.179903162688404e-07, 'lambda_l2': 6.453265000649028e-07, 'num_leaves': 80, 'feature_fraction': 0.9617657902852735, 'bagging_fraction': 0.6226058036852815, 'bagging_freq': 5, 'min_child_samples': 78, 'learning_rate': 0.250270026562424, 'max_depth': 17, 'min_gain_to_split': 0.013042585316770938, 'min_sum_hessian_in_leaf': 2.714538180564537}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:56:50,277] Trial 35 finished with value: 0.54659684949073 and parameters: {'lambda_l1': 1.0016062724283029e-08, 'lambda_l2': 4.596717523929467e-07, 'num_leaves': 78, 'feature_fraction': 0.9537987194818498, 'bagging_fraction': 0.6200981396027009, 'bagging_freq': 5, 'min_child_samples': 99, 'learning_rate': 0.2456629549751694, 'max_depth': 30, 'min_gain_to_split': 0.15441787137208746, 'min_sum_hessian_in_leaf': 2.470718232781102}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:02,356] Trial 36 finished with value: 0.5458703653215559 and parameters: {'lambda_l1': 4.776043277130029e-08, 'lambda_l2': 4.078514929488964e-07, 'num_leaves': 79, 'feature_fraction': 0.9504882595109925, 'bagging_fraction': 0.6265372070743087, 'bagging_freq': 4, 'min_child_samples': 100, 'learning_rate': 0.23471568901483328, 'max_depth': 30, 'min_gain_to_split': 0.17285643441300935, 'min_sum_hessian_in_leaf': 2.3044522501507485}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:11,611] Trial 37 finished with value: 0.5670773871794557 and parameters: {'lambda_l1': 2.494522339293445e-07, 'lambda_l2': 1.8369351756104143e-07, 'num_leaves': 41, 'feature_fraction': 0.9532081747185792, 'bagging_fraction': 0.6214264867726481, 'bagging_freq': 4, 'min_child_samples': 99, 'learning_rate': 0.14201633001175534, 'max_depth': 30, 'min_gain_to_split': 0.042249727002098475, 'min_sum_hessian_in_leaf': 2.1941530460276057}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:18,095] Trial 38 finished with value: 0.5770975186510865 and parameters: {'lambda_l1': 4.736344832440643e-08, 'lambda_l2': 6.384935364241815e-07, 'num_leaves': 73, 'feature_fraction': 0.8970238029229863, 'bagging_fraction': 0.619275825565612, 'bagging_freq': 4, 'min_child_samples': 89, 'learning_rate': 0.2372504755170003, 'max_depth': 31, 'min_gain_to_split': 2.0713118263070536, 'min_sum_hessian_in_leaf': 2.4464162175829096}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:24,693] Trial 39 finished with value: 0.648621847335641 and parameters: {'lambda_l1': 1.7498734622621008e-06, 'lambda_l2': 4.978306413808359e-07, 'num_leaves': 16, 'feature_fraction': 0.6294218907954665, 'bagging_fraction': 0.581146560734974, 'bagging_freq': 2, 'min_child_samples': 77, 'learning_rate': 0.09616410148553216, 'max_depth': 41, 'min_gain_to_split': 2.861957318301793, 'min_sum_hessian_in_leaf': 1.0136740155722972}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:43,344] Trial 40 finished with value: 0.5918219839433503 and parameters: {'lambda_l1': 1.6866069660665425e-07, 'lambda_l2': 1.4030251379736486e-07, 'num_leaves': 125, 'feature_fraction': 0.910871195667162, 'bagging_fraction': 0.6602857707197904, 'bagging_freq': 5, 'min_child_samples': 46, 'learning_rate': 0.03809126136447779, 'max_depth': 24, 'min_gain_to_split': 1.1802351296258466, 'min_sum_hessian_in_leaf': 1.7107738893351956}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:57:56,030] Trial 41 finished with value: 0.5458988203710488 and parameters: {'lambda_l1': 4.101425852068329e-08, 'lambda_l2': 3.5839922220128803e-06, 'num_leaves': 84, 'feature_fraction': 0.9526708797829021, 'bagging_fraction': 0.5721110045141572, 'bagging_freq': 5, 'min_child_samples': 97, 'learning_rate': 0.15884055175381842, 'max_depth': 18, 'min_gain_to_split': 0.07922539522806366, 'min_sum_hessian_in_leaf': 3.6463484870199023}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:08,234] Trial 42 finished with value: 0.5596090450039972 and parameters: {'lambda_l1': 5.776908527528451e-08, 'lambda_l2': 3.2016711518648683e-06, 'num_leaves': 74, 'feature_fraction': 0.9521299448031794, 'bagging_fraction': 0.5443535148300699, 'bagging_freq': 4, 'min_child_samples': 95, 'learning_rate': 0.1440737990251362, 'max_depth': 18, 'min_gain_to_split': 0.9212571531061091, 'min_sum_hessian_in_leaf': 3.7351100060155256}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:15,284] Trial 43 finished with value: 0.5716785863865564 and parameters: {'lambda_l1': 2.9042989936163e-07, 'lambda_l2': 4.0921680140199474e-07, 'num_leaves': 84, 'feature_fraction': 0.9274543857037298, 'bagging_fraction': 0.6684209031287676, 'bagging_freq': 5, 'min_child_samples': 88, 'learning_rate': 0.2200113770800595, 'max_depth': 23, 'min_gain_to_split': 1.9208343029046424, 'min_sum_hessian_in_leaf': 2.572868397487415}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:26,684] Trial 44 finished with value: 0.5801594885032026 and parameters: {'lambda_l1': 3.3715924085684646e-08, 'lambda_l2': 1.1359668425666591e-06, 'num_leaves': 48, 'feature_fraction': 0.9622779495072052, 'bagging_fraction': 0.5740931905496175, 'bagging_freq': 5, 'min_child_samples': 99, 'learning_rate': 0.09144803830244186, 'max_depth': 28, 'min_gain_to_split': 0.6315008848811654, 'min_sum_hessian_in_leaf': 2.0178838892191853}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:33,912] Trial 45 finished with value: 0.5837735282401509 and parameters: {'lambda_l1': 1.2966617205536356e-07, 'lambda_l2': 4.934864209179131e-06, 'num_leaves': 26, 'feature_fraction': 0.8631903142348403, 'bagging_fraction': 0.658427098242886, 'bagging_freq': 4, 'min_child_samples': 88, 'learning_rate': 0.16809498564634856, 'max_depth': 20, 'min_gain_to_split': 0.08030274984144309, 'min_sum_hessian_in_leaf': 4.3688466422717624}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:39,137] Trial 46 finished with value: 0.5850355478627736 and parameters: {'lambda_l1': 3.457964045070847e-08, 'lambda_l2': 6.302944156959141e-08, 'num_leaves': 58, 'feature_fraction': 0.918122258478014, 'bagging_fraction': 0.533863581844158, 'bagging_freq': 3, 'min_child_samples': 93, 'learning_rate': 0.3323200295047428, 'max_depth': 33, 'min_gain_to_split': 2.00316856944416, 'min_sum_hessian_in_leaf': 3.4347617375922264}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:58:47,634] Trial 47 finished with value: 0.553215543745267 and parameters: {'lambda_l1': 6.135249517546944e-07, 'lambda_l2': 1.6967942178855476e-06, 'num_leaves': 101, 'feature_fraction': 0.8475074329293718, 'bagging_fraction': 0.6247421742725616, 'bagging_freq': 5, 'min_child_samples': 25, 'learning_rate': 0.24076254449039022, 'max_depth': 17, 'min_gain_to_split': 0.9661788518334995, 'min_sum_hessian_in_leaf': 3.9502317810435335}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:04,122] Trial 48 finished with value: 0.5574131233626456 and parameters: {'lambda_l1': 4.95756074367903e-07, 'lambda_l2': 4.094372230501153e-08, 'num_leaves': 98, 'feature_fraction': 0.8532874031716509, 'bagging_fraction': 0.6010762217010802, 'bagging_freq': 5, 'min_child_samples': 27, 'learning_rate': 0.07547519866902279, 'max_depth': 25, 'min_gain_to_split': 1.018159011042888, 'min_sum_hessian_in_leaf': 3.942056168690555}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:11,039] Trial 49 finished with value: 0.5657692879220084 and parameters: {'lambda_l1': 2.8437823524579997e-06, 'lambda_l2': 2.511388772604155e-07, 'num_leaves': 134, 'feature_fraction': 0.8874346488643817, 'bagging_fraction': 0.6307183991206587, 'bagging_freq': 4, 'min_child_samples': 21, 'learning_rate': 0.217202705951059, 'max_depth': 28, 'min_gain_to_split': 3.238646072376329, 'min_sum_hessian_in_leaf': 5.848967002616968}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:21,330] Trial 50 finished with value: 0.5636623497954518 and parameters: {'lambda_l1': 1.041385134314231e-06, 'lambda_l2': 1.110675301498862e-06, 'num_leaves': 75, 'feature_fraction': 0.7524153226737595, 'bagging_fraction': 0.6929047184322812, 'bagging_freq': 5, 'min_child_samples': 39, 'learning_rate': 0.14485628043270626, 'max_depth': 39, 'min_gain_to_split': 1.7256286039256281, 'min_sum_hessian_in_leaf': 4.838497059576909}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:29,586] Trial 51 finished with value: 0.5526447433059886 and parameters: {'lambda_l1': 1.7939576459011077e-07, 'lambda_l2': 6.818213008019382e-06, 'num_leaves': 104, 'feature_fraction': 0.9716085145128401, 'bagging_fraction': 0.728869166951377, 'bagging_freq': 5, 'min_child_samples': 72, 'learning_rate': 0.28149733332742455, 'max_depth': 16, 'min_gain_to_split': 0.6900614625055494, 'min_sum_hessian_in_leaf': 2.7477044031614635}. Best is trial 34 with value: 0.5403767840163478.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:40,420] Trial 52 finished with value: 0.5372249770293296 and parameters: {'lambda_l1': 2.460069649829253e-07, 'lambda_l2': 1.5180750938538445e-06, 'num_leaves': 79, 'feature_fraction': 0.966695020434156, 'bagging_fraction': 0.7288333211048011, 'bagging_freq': 5, 'min_child_samples': 59, 'learning_rate': 0.2746269568896338, 'max_depth': 20, 'min_gain_to_split': 0.02522886235044707, 'min_sum_hessian_in_leaf': 4.03679199722712}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 18:59:50,506] Trial 53 finished with value: 0.5417438496914945 and parameters: {'lambda_l1': 1.8487787987619813e-07, 'lambda_l2': 3.136711225391943e-07, 'num_leaves': 63, 'feature_fraction': 0.963189708932973, 'bagging_fraction': 0.7428102444624121, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.308105570660892, 'max_depth': 22, 'min_gain_to_split': 0.10425811416455932, 'min_sum_hessian_in_leaf': 2.7176599107212365}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:01,778] Trial 54 finished with value: 0.5470794839495928 and parameters: {'lambda_l1': 3.108379881707148e-07, 'lambda_l2': 3.145963778669992e-08, 'num_leaves': 63, 'feature_fraction': 0.941117928474889, 'bagging_fraction': 0.6960209121918739, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.17574404740689314, 'max_depth': 21, 'min_gain_to_split': 0.056656617278725896, 'min_sum_hessian_in_leaf': 2.4868514637642165}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:07,074] Trial 55 finished with value: 0.5750316731312901 and parameters: {'lambda_l1': 2.8516569955644397e-08, 'lambda_l2': 3.1125775682820484e-07, 'num_leaves': 78, 'feature_fraction': 0.9202793461627586, 'bagging_fraction': 0.7522632553301016, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.31685898371628873, 'max_depth': 23, 'min_gain_to_split': 2.3414891242157228, 'min_sum_hessian_in_leaf': 3.4789541857797825}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:17,817] Trial 56 finished with value: 0.5676259895013562 and parameters: {'lambda_l1': 2.1146421193759285e-06, 'lambda_l2': 1.2528999610114967e-07, 'num_leaves': 52, 'feature_fraction': 0.9725847940626569, 'bagging_fraction': 0.7567501784099862, 'bagging_freq': 3, 'min_child_samples': 50, 'learning_rate': 0.13658988784019144, 'max_depth': 33, 'min_gain_to_split': 1.524089010106843, 'min_sum_hessian_in_leaf': 2.874981530315847}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:26,310] Trial 57 finished with value: 0.5556865686906349 and parameters: {'lambda_l1': 8.747702582957023e-08, 'lambda_l2': 6.57502309682213e-07, 'num_leaves': 38, 'feature_fraction': 0.894159053068068, 'bagging_fraction': 0.674533889875953, 'bagging_freq': 4, 'min_child_samples': 45, 'learning_rate': 0.186794512583419, 'max_depth': 28, 'min_gain_to_split': 0.0004389672681308736, 'min_sum_hessian_in_leaf': 1.9582837170110658}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:34,626] Trial 58 finished with value: 0.5556511667055344 and parameters: {'lambda_l1': 2.630495239933622e-08, 'lambda_l2': 2.785704827117675e-07, 'num_leaves': 66, 'feature_fraction': 0.968360590837006, 'bagging_fraction': 0.6480870325414679, 'bagging_freq': 2, 'min_child_samples': 56, 'learning_rate': 0.3424718982509553, 'max_depth': 20, 'min_gain_to_split': 0.6925077043487378, 'min_sum_hessian_in_leaf': 4.1833897331131515}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:41,317] Trial 59 finished with value: 0.5594571161451457 and parameters: {'lambda_l1': 8.008370020293055e-06, 'lambda_l2': 9.163305323564107e-07, 'num_leaves': 119, 'feature_fraction': 0.9437586872855804, 'bagging_fraction': 0.6836227076674541, 'bagging_freq': 5, 'min_child_samples': 59, 'learning_rate': 0.2547999620074408, 'max_depth': 26, 'min_gain_to_split': 1.5125935531877395, 'min_sum_hessian_in_leaf': 2.9845688708653686}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:44,344] Trial 60 finished with value: 0.805512063883296 and parameters: {'lambda_l1': 4.1678725617636577e-07, 'lambda_l2': 8.195140548161239e-08, 'num_leaves': 4, 'feature_fraction': 0.9307917292357419, 'bagging_fraction': 0.6469905468796391, 'bagging_freq': 1, 'min_child_samples': 69, 'learning_rate': 0.11182302251644596, 'max_depth': 32, 'min_gain_to_split': 3.9671507684657383, 'min_sum_hessian_in_leaf': 2.281483072442006}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:00:55,177] Trial 61 finished with value: 0.5442495606683483 and parameters: {'lambda_l1': 1.9744195765498882e-07, 'lambda_l2': 2.471489747631966e-08, 'num_leaves': 63, 'feature_fraction': 0.9354463692402148, 'bagging_fraction': 0.7137597939686656, 'bagging_freq': 4, 'min_child_samples': 52, 'learning_rate': 0.18217515354496017, 'max_depth': 23, 'min_gain_to_split': 0.01318793709321, 'min_sum_hessian_in_leaf': 2.455189598690161}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:06,010] Trial 62 finished with value: 0.5505731386122574 and parameters: {'lambda_l1': 1.1741921350160422e-07, 'lambda_l2': 1.5627388087564085e-08, 'num_leaves': 83, 'feature_fraction': 0.9710535749550332, 'bagging_fraction': 0.7129987948275404, 'bagging_freq': 4, 'min_child_samples': 50, 'learning_rate': 0.18694000481764445, 'max_depth': 22, 'min_gain_to_split': 0.7845671999772121, 'min_sum_hessian_in_leaf': 3.2487782018760516}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:12,814] Trial 63 finished with value: 0.5723444056055937 and parameters: {'lambda_l1': 2.0163659380997494e-07, 'lambda_l2': 1.2151524340579744e-07, 'num_leaves': 30, 'feature_fraction': 0.9074617678661304, 'bagging_fraction': 0.6809792629844941, 'bagging_freq': 5, 'min_child_samples': 43, 'learning_rate': 0.28001131045560873, 'max_depth': 13, 'min_gain_to_split': 0.8170931674671215, 'min_sum_hessian_in_leaf': 1.4710214953301948}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:20,932] Trial 64 finished with value: 0.5556591843755262 and parameters: {'lambda_l1': 2.3956036158473854e-08, 'lambda_l2': 1.8953651273085037e-06, 'num_leaves': 89, 'feature_fraction': 0.9321328770808909, 'bagging_fraction': 0.7039861472408884, 'bagging_freq': 3, 'min_child_samples': 54, 'learning_rate': 0.4380566484850225, 'max_depth': 36, 'min_gain_to_split': 0.5364191276659747, 'min_sum_hessian_in_leaf': 2.5970703668420674}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:26,642] Trial 65 finished with value: 0.5785790971738962 and parameters: {'lambda_l1': 5.2584894273685434e-08, 'lambda_l2': 4.0175918928609574e-07, 'num_leaves': 43, 'feature_fraction': 0.8814825003247437, 'bagging_fraction': 0.773559533018749, 'bagging_freq': 4, 'min_child_samples': 59, 'learning_rate': 0.34535611391704235, 'max_depth': 27, 'min_gain_to_split': 1.3525792551445925, 'min_sum_hessian_in_leaf': 3.8481854228741215}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:30,942] Trial 66 finished with value: 0.5870156226012082 and parameters: {'lambda_l1': 1.0656381782453473e-06, 'lambda_l2': 2.3548698092194644e-08, 'num_leaves': 57, 'feature_fraction': 0.9799062236426851, 'bagging_fraction': 0.7102469100425179, 'bagging_freq': 5, 'min_child_samples': 79, 'learning_rate': 0.4746238176795612, 'max_depth': 24, 'min_gain_to_split': 2.155238753788255, 'min_sum_hessian_in_leaf': 3.4155260301333286}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:40,120] Trial 67 finished with value: 0.5626377356728265 and parameters: {'lambda_l1': 1.0400933077118397e-07, 'lambda_l2': 6.069127371052764e-08, 'num_leaves': 67, 'feature_fraction': 0.9612515533410287, 'bagging_fraction': 0.7237432918613503, 'bagging_freq': 5, 'min_child_samples': 72, 'learning_rate': 0.7302187343719518, 'max_depth': 19, 'min_gain_to_split': 0.05571843921606539, 'min_sum_hessian_in_leaf': 2.9253526352478434}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:47,828] Trial 68 finished with value: 0.5623205334187238 and parameters: {'lambda_l1': 4.385019193588902e-07, 'lambda_l2': 1.0050100015496469e-08, 'num_leaves': 158, 'feature_fraction': 0.9991728769647151, 'bagging_fraction': 0.6418959896038194, 'bagging_freq': 4, 'min_child_samples': 97, 'learning_rate': 0.2479030625444785, 'max_depth': 30, 'min_gain_to_split': 1.6604259191536994, 'min_sum_hessian_in_leaf': 1.868076121982323}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:01:51,773] Trial 69 finished with value: 0.5929375192223257 and parameters: {'lambda_l1': 2.329876890782533e-08, 'lambda_l2': 2.0032156505250296e-07, 'num_leaves': 93, 'feature_fraction': 0.9069545324689448, 'bagging_fraction': 0.6063424544384919, 'bagging_freq': 4, 'min_child_samples': 66, 'learning_rate': 0.5191671032480782, 'max_depth': 22, 'min_gain_to_split': 2.8679314588306197, 'min_sum_hessian_in_leaf': 2.217596626013093}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:02:04,647] Trial 70 finished with value: 0.5456630376804854 and parameters: {'lambda_l1': 5.197361953170638e-08, 'lambda_l2': 3.075642647433276e-06, 'num_leaves': 81, 'feature_fraction': 0.9369276950105117, 'bagging_fraction': 0.7400435211866625, 'bagging_freq': 5, 'min_child_samples': 51, 'learning_rate': 0.15855346070464324, 'max_depth': 16, 'min_gain_to_split': 0.39309782919982517, 'min_sum_hessian_in_leaf': 4.3122461686399305}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:02:17,113] Trial 71 finished with value: 0.5442026859139728 and parameters: {'lambda_l1': 5.805684675950531e-08, 'lambda_l2': 3.6556300321554414e-06, 'num_leaves': 79, 'feature_fraction': 0.9412091186599676, 'bagging_fraction': 0.7476362708595374, 'bagging_freq': 5, 'min_child_samples': 58, 'learning_rate': 0.16699238013084533, 'max_depth': 17, 'min_gain_to_split': 0.3960302270680854, 'min_sum_hessian_in_leaf': 4.20880035434891}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:02:29,771] Trial 72 finished with value: 0.5471193687572888 and parameters: {'lambda_l1': 2.3726757539405457e-07, 'lambda_l2': 4.785114416232678e-06, 'num_leaves': 80, 'feature_fraction': 0.9326174397719459, 'bagging_fraction': 0.7372119739595635, 'bagging_freq': 5, 'min_child_samples': 51, 'learning_rate': 0.15947352998032602, 'max_depth': 16, 'min_gain_to_split': 0.46323769776891877, 'min_sum_hessian_in_leaf': 4.436287831889492}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:02:43,314] Trial 73 finished with value: 0.5614663136458526 and parameters: {'lambda_l1': 6.573713792484645e-08, 'lambda_l2': 3.278405346158415e-06, 'num_leaves': 69, 'feature_fraction': 0.9778421297082105, 'bagging_fraction': 0.7801073197347572, 'bagging_freq': 4, 'min_child_samples': 58, 'learning_rate': 0.12518888962231972, 'max_depth': 14, 'min_gain_to_split': 1.1420371131629443, 'min_sum_hessian_in_leaf': 4.685376150538934}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:02:54,151] Trial 74 finished with value: 0.5551377379526763 and parameters: {'lambda_l1': 6.964817462509971e-07, 'lambda_l2': 1.0712656061124369e-05, 'num_leaves': 57, 'feature_fraction': 0.9409957566031294, 'bagging_fraction': 0.8205116855442285, 'bagging_freq': 5, 'min_child_samples': 52, 'learning_rate': 0.1806853600938493, 'max_depth': 18, 'min_gain_to_split': 0.5521117460230951, 'min_sum_hessian_in_leaf': 4.089022090236947}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:08,681] Trial 75 finished with value: 0.5604769258632933 and parameters: {'lambda_l1': 6.074037203293856e-08, 'lambda_l2': 7.804209450977073e-07, 'num_leaves': 90, 'feature_fraction': 0.9186805266358202, 'bagging_fraction': 0.7466124932931764, 'bagging_freq': 4, 'min_child_samples': 64, 'learning_rate': 0.10491180962806042, 'max_depth': 12, 'min_gain_to_split': 1.0432275029181972, 'min_sum_hessian_in_leaf': 3.6873104263657623}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:15,892] Trial 76 finished with value: 0.5755886586778486 and parameters: {'lambda_l1': 1.2958933401537e-07, 'lambda_l2': 2.3539048242045514e-06, 'num_leaves': 46, 'feature_fraction': 0.8946473881835971, 'bagging_fraction': 0.7232645228723104, 'bagging_freq': 5, 'min_child_samples': 38, 'learning_rate': 0.2147420892456904, 'max_depth': 19, 'min_gain_to_split': 1.7841926457478021, 'min_sum_hessian_in_leaf': 5.057957003824232}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:28,867] Trial 77 finished with value: 0.5473472804444188 and parameters: {'lambda_l1': 2.4215434488990924e-07, 'lambda_l2': 1.472955034217585e-06, 'num_leaves': 83, 'feature_fraction': 0.9582394767528237, 'bagging_fraction': 0.7623404134021283, 'bagging_freq': 5, 'min_child_samples': 47, 'learning_rate': 0.1292622364200256, 'max_depth': 15, 'min_gain_to_split': 0.3402825420803235, 'min_sum_hessian_in_leaf': 4.2844473093804405}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:35,312] Trial 78 finished with value: 0.5588692019453919 and parameters: {'lambda_l1': 1.869866030887722e-08, 'lambda_l2': 1.7837595895003394e-05, 'num_leaves': 116, 'feature_fraction': 0.8699230814624336, 'bagging_fraction': 0.6909966884917583, 'bagging_freq': 6, 'min_child_samples': 53, 'learning_rate': 0.3024281247871287, 'max_depth': 21, 'min_gain_to_split': 1.0793290225516259, 'min_sum_hessian_in_leaf': 3.101662297680615}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:44,814] Trial 79 finished with value: 0.5482964294981485 and parameters: {'lambda_l1': 4.447796268539818e-08, 'lambda_l2': 7.384392525731693e-07, 'num_leaves': 62, 'feature_fraction': 0.9980442398989656, 'bagging_fraction': 0.7408702799900673, 'bagging_freq': 3, 'min_child_samples': 56, 'learning_rate': 0.3864425373276144, 'max_depth': 17, 'min_gain_to_split': 0.3491383316262335, 'min_sum_hessian_in_leaf': 3.7601789919706796}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:03:57,923] Trial 80 finished with value: 0.5679870988267763 and parameters: {'lambda_l1': 1.541541607862055e-07, 'lambda_l2': 1.784533662589396e-07, 'num_leaves': 73, 'feature_fraction': 0.9438649056506945, 'bagging_fraction': 0.7137232884884274, 'bagging_freq': 4, 'min_child_samples': 42, 'learning_rate': 0.08143581580386648, 'max_depth': 15, 'min_gain_to_split': 1.3589843022848105, 'min_sum_hessian_in_leaf': 4.527094874422062}. Best is trial 52 with value: 0.5372249770293296.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:04:12,172] Trial 81 finished with value: 0.5368460148456566 and parameters: {'lambda_l1': 2.0338569548019702e-08, 'lambda_l2': 3.721774914057848e-07, 'num_leaves': 99, 'feature_fraction': 0.9605353474553334, 'bagging_fraction': 0.7344262276316799, 'bagging_freq': 5, 'min_child_samples': 69, 'learning_rate': 0.15665994745702908, 'max_depth': 25, 'min_gain_to_split': 0.037842679375101815, 'min_sum_hessian_in_leaf': 2.7002936251163696}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:04:22,549] Trial 82 finished with value: 0.5490175406768107 and parameters: {'lambda_l1': 2.0220001111192684e-08, 'lambda_l2': 4.090449485183108e-07, 'num_leaves': 98, 'feature_fraction': 0.9824170506662403, 'bagging_fraction': 0.7673417993850237, 'bagging_freq': 5, 'min_child_samples': 69, 'learning_rate': 0.18988455611830307, 'max_depth': 25, 'min_gain_to_split': 0.7433085801788938, 'min_sum_hessian_in_leaf': 3.3126789204168046}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:04:35,952] Trial 83 finished with value: 0.5441913029451995 and parameters: {'lambda_l1': 6.196141110369296e-08, 'lambda_l2': 9.55005135481305e-08, 'num_leaves': 89, 'feature_fraction': 0.9240976212035709, 'bagging_fraction': 0.7847969193095359, 'bagging_freq': 5, 'min_child_samples': 64, 'learning_rate': 0.14749073134375285, 'max_depth': 20, 'min_gain_to_split': 0.33234072561093553, 'min_sum_hessian_in_leaf': 2.765828770238381}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:04:50,652] Trial 84 finished with value: 0.5468732715171669 and parameters: {'lambda_l1': 8.41978325598737e-08, 'lambda_l2': 1.118037921267367e-07, 'num_leaves': 90, 'feature_fraction': 0.9173401393432723, 'bagging_fraction': 0.7977327550842839, 'bagging_freq': 6, 'min_child_samples': 65, 'learning_rate': 0.11121773671574682, 'max_depth': 20, 'min_gain_to_split': 0.38843816800414066, 'min_sum_hessian_in_leaf': 2.7440986206195466}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:02,881] Trial 85 finished with value: 0.5488207523315559 and parameters: {'lambda_l1': 4.0975131966006815e-07, 'lambda_l2': 4.9754626169518985e-08, 'num_leaves': 106, 'feature_fraction': 0.9639746714352558, 'bagging_fraction': 0.7849565081970431, 'bagging_freq': 5, 'min_child_samples': 58, 'learning_rate': 0.15560786527268644, 'max_depth': 21, 'min_gain_to_split': 0.8377563506187988, 'min_sum_hessian_in_leaf': 1.6647871461318435}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:13,596] Trial 86 finished with value: 0.5382535375939624 and parameters: {'lambda_l1': 1.6969244151567622e-08, 'lambda_l2': 2.427276950232313e-07, 'num_leaves': 71, 'feature_fraction': 0.9003903720411465, 'bagging_fraction': 0.7410906244522907, 'bagging_freq': 4, 'min_child_samples': 61, 'learning_rate': 0.2677106901197703, 'max_depth': 23, 'min_gain_to_split': 0.003725720183803502, 'min_sum_hessian_in_leaf': 2.0952813330696953}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:22,522] Trial 87 finished with value: 0.5412206011239036 and parameters: {'lambda_l1': 1.5077644928691374e-08, 'lambda_l2': 2.3254906532165652e-07, 'num_leaves': 52, 'feature_fraction': 0.8995674624713564, 'bagging_fraction': 0.7457898228775761, 'bagging_freq': 6, 'min_child_samples': 74, 'learning_rate': 0.2959537948438968, 'max_depth': 24, 'min_gain_to_split': 0.0005260448564524912, 'min_sum_hessian_in_leaf': 2.0723953135714783}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:30,898] Trial 88 finished with value: 0.542725224585071 and parameters: {'lambda_l1': 2.123786205010216e-08, 'lambda_l2': 9.414050760499406e-08, 'num_leaves': 52, 'feature_fraction': 0.8770653470633427, 'bagging_fraction': 0.7675157903337457, 'bagging_freq': 6, 'min_child_samples': 70, 'learning_rate': 0.37540410758021237, 'max_depth': 23, 'min_gain_to_split': 0.027291180141304678, 'min_sum_hessian_in_leaf': 2.2068433161144236}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:36,224] Trial 89 finished with value: 0.5785400249770893 and parameters: {'lambda_l1': 1.7435722732647757e-08, 'lambda_l2': 8.419292048374734e-08, 'num_leaves': 52, 'feature_fraction': 0.9007209884182709, 'bagging_fraction': 0.758894675238294, 'bagging_freq': 7, 'min_child_samples': 74, 'learning_rate': 0.38460785581778834, 'max_depth': 24, 'min_gain_to_split': 1.2919940378963983, 'min_sum_hessian_in_leaf': 2.1053080729412934}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:42,035] Trial 90 finished with value: 0.5758112504937775 and parameters: {'lambda_l1': 1.195153412449814e-08, 'lambda_l2': 1.9315152337823496e-07, 'num_leaves': 71, 'feature_fraction': 0.8839163560293941, 'bagging_fraction': 0.7844373029726724, 'bagging_freq': 6, 'min_child_samples': 80, 'learning_rate': 0.32068626769515696, 'max_depth': 27, 'min_gain_to_split': 1.8188004842965864, 'min_sum_hessian_in_leaf': 1.3085926876269103}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:49,553] Trial 91 finished with value: 0.5523226751394825 and parameters: {'lambda_l1': 2.687904987442009e-08, 'lambda_l2': 3.569917107873913e-08, 'num_leaves': 36, 'feature_fraction': 0.9237360033201818, 'bagging_fraction': 0.7508333964396179, 'bagging_freq': 6, 'min_child_samples': 70, 'learning_rate': 0.2787057702081999, 'max_depth': 23, 'min_gain_to_split': 0.01719799521676796, 'min_sum_hessian_in_leaf': 2.594350945138716}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:05:59,222] Trial 92 finished with value: 0.5572133761537208 and parameters: {'lambda_l1': 1.0306292331754988e-08, 'lambda_l2': 2.1612123296639407e-08, 'num_leaves': 63, 'feature_fraction': 0.9059804294709619, 'bagging_fraction': 0.7275150367749764, 'bagging_freq': 6, 'min_child_samples': 63, 'learning_rate': 0.20124629482776768, 'max_depth': 22, 'min_gain_to_split': 0.7674791028688063, 'min_sum_hessian_in_leaf': 1.9280294379405953}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:05,227] Trial 93 finished with value: 0.5702383126637374 and parameters: {'lambda_l1': 3.5138498761697706e-08, 'lambda_l2': 2.5325205653398806e-07, 'num_leaves': 25, 'feature_fraction': 0.8672021011087929, 'bagging_fraction': 0.7676263080115234, 'bagging_freq': 6, 'min_child_samples': 75, 'learning_rate': 0.4637787809303424, 'max_depth': 26, 'min_gain_to_split': 0.3660193618542595, 'min_sum_hessian_in_leaf': 2.346188725675858}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:13,558] Trial 94 finished with value: 0.5662176627888161 and parameters: {'lambda_l1': 8.756828790937295e-08, 'lambda_l2': 7.288158848056941e-08, 'num_leaves': 54, 'feature_fraction': 0.9848897048639305, 'bagging_fraction': 0.8140689862004851, 'bagging_freq': 6, 'min_child_samples': 68, 'learning_rate': 0.22118882747571988, 'max_depth': 25, 'min_gain_to_split': 1.0659240585440628, 'min_sum_hessian_in_leaf': 1.7046015117173212}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:21,530] Trial 95 finished with value: 0.5454598064575406 and parameters: {'lambda_l1': 1.7857755332974397e-08, 'lambda_l2': 1.2723319591418024e-07, 'num_leaves': 46, 'feature_fraction': 0.8939346839347186, 'bagging_fraction': 0.7355006069124328, 'bagging_freq': 7, 'min_child_samples': 61, 'learning_rate': 0.37514249391759386, 'max_depth': 19, 'min_gain_to_split': 0.030358495411724862, 'min_sum_hessian_in_leaf': 2.963264079208081}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:31,057] Trial 96 finished with value: 0.5562639481964405 and parameters: {'lambda_l1': 1.7103076409086722e-07, 'lambda_l2': 1.1296718165343296e-06, 'num_leaves': 60, 'feature_fraction': 0.8322566074353186, 'bagging_fraction': 0.7016926780928376, 'bagging_freq': 4, 'min_child_samples': 66, 'learning_rate': 0.25088889117772406, 'max_depth': 20, 'min_gain_to_split': 0.6234343290605953, 'min_sum_hessian_in_leaf': 2.0902666280296227}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:37,340] Trial 97 finished with value: 0.5684957903370782 and parameters: {'lambda_l1': 1.0529709457354173e-07, 'lambda_l2': 5.88591147947811e-07, 'num_leaves': 67, 'feature_fraction': 0.9233115971089016, 'bagging_fraction': 0.7500235067313806, 'bagging_freq': 4, 'min_child_samples': 71, 'learning_rate': 0.30799930512124885, 'max_depth': 23, 'min_gain_to_split': 1.4642917613964808, 'min_sum_hessian_in_leaf': 2.6478192774422578}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:50,184] Trial 98 finished with value: 0.5497318803859211 and parameters: {'lambda_l1': 3.697150715251408e-08, 'lambda_l2': 5.388064309644855e-08, 'num_leaves': 76, 'feature_fraction': 0.947618255556809, 'bagging_fraction': 0.7211701669401475, 'bagging_freq': 5, 'min_child_samples': 61, 'learning_rate': 0.13271697703689017, 'max_depth': 27, 'min_gain_to_split': 0.35436599517945927, 'min_sum_hessian_in_leaf': 2.4086475693739606}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:06:59,088] Trial 99 finished with value: 0.5471111630150058 and parameters: {'lambda_l1': 1.703782082287571e-08, 'lambda_l2': 2.9973032000936945e-07, 'num_leaves': 230, 'feature_fraction': 0.9653956159663297, 'bagging_fraction': 0.7748740121417321, 'bagging_freq': 3, 'min_child_samples': 67, 'learning_rate': 0.26699584362625334, 'max_depth': 22, 'min_gain_to_split': 0.9036418834072782, 'min_sum_hessian_in_leaf': 3.147731493208608}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:06,657] Trial 100 finished with value: 0.5678723181600223 and parameters: {'lambda_l1': 2.9053944851335863e-07, 'lambda_l2': 3.037013744757595e-08, 'num_leaves': 96, 'feature_fraction': 0.8813861631517266, 'bagging_fraction': 0.7612761025200809, 'bagging_freq': 7, 'min_child_samples': 79, 'learning_rate': 0.2056144216829612, 'max_depth': 24, 'min_gain_to_split': 2.230665422883237, 'min_sum_hessian_in_leaf': 2.844068860912907}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:14,567] Trial 101 finished with value: 0.5492310603244664 and parameters: {'lambda_l1': 1.6577297467723377e-08, 'lambda_l2': 1.1828670067498746e-07, 'num_leaves': 48, 'feature_fraction': 0.8965683842450238, 'bagging_fraction': 0.7337844742288198, 'bagging_freq': 7, 'min_child_samples': 64, 'learning_rate': 0.3649959709226546, 'max_depth': 19, 'min_gain_to_split': 0.0791588141360136, 'min_sum_hessian_in_leaf': 2.9700915570832898}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:20,863] Trial 102 finished with value: 0.5523594158875544 and parameters: {'lambda_l1': 5.8609809618748186e-08, 'lambda_l2': 1.5995354133126144e-07, 'num_leaves': 32, 'feature_fraction': 0.9109077602612438, 'bagging_fraction': 0.739104122338281, 'bagging_freq': 7, 'min_child_samples': 60, 'learning_rate': 0.5689486764707523, 'max_depth': 20, 'min_gain_to_split': 0.04560313651856522, 'min_sum_hessian_in_leaf': 2.21157612478568}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:27,132] Trial 103 finished with value: 0.5675918531212615 and parameters: {'lambda_l1': 2.6492205153644784e-08, 'lambda_l2': 9.744921103837557e-08, 'num_leaves': 46, 'feature_fraction': 0.9357110022409895, 'bagging_fraction': 0.709147833747388, 'bagging_freq': 7, 'min_child_samples': 57, 'learning_rate': 0.40043056764670015, 'max_depth': 17, 'min_gain_to_split': 0.7438173324330082, 'min_sum_hessian_in_leaf': 3.4813122885939807}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:35,654] Trial 104 finished with value: 0.5527687886249291 and parameters: {'lambda_l1': 1.5457578522435985e-08, 'lambda_l2': 3.0266615118648675e-07, 'num_leaves': 87, 'feature_fraction': 0.9241605846779113, 'bagging_fraction': 0.7897601109584949, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.45539171674258894, 'max_depth': 21, 'min_gain_to_split': 0.3152904444522939, 'min_sum_hessian_in_leaf': 2.5565840122904415}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:44,173] Trial 105 finished with value: 0.5545546038353983 and parameters: {'lambda_l1': 3.515682920776339e-08, 'lambda_l2': 5.964603203751368e-07, 'num_leaves': 54, 'feature_fraction': 0.9552825434287607, 'bagging_fraction': 0.7279767894008038, 'bagging_freq': 4, 'min_child_samples': 60, 'learning_rate': 0.2978941983996457, 'max_depth': 18, 'min_gain_to_split': 0.5993527835607917, 'min_sum_hessian_in_leaf': 2.824994303770898}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:51,616] Trial 106 finished with value: 0.5740483259401468 and parameters: {'lambda_l1': 7.25598026090457e-08, 'lambda_l2': 4.582110020451639e-08, 'num_leaves': 41, 'feature_fraction': 0.976346434702762, 'bagging_fraction': 0.7474338353141358, 'bagging_freq': 6, 'min_child_samples': 77, 'learning_rate': 0.23953017804084495, 'max_depth': 29, 'min_gain_to_split': 1.1403403002969774, 'min_sum_hessian_in_leaf': 3.276172001149734}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:07:56,547] Trial 107 finished with value: 0.5929821942376916 and parameters: {'lambda_l1': 1.0614692270430319e-08, 'lambda_l2': 1.7603635120020286e-07, 'num_leaves': 23, 'feature_fraction': 0.8936919921557827, 'bagging_fraction': 0.6941162700300111, 'bagging_freq': 5, 'min_child_samples': 54, 'learning_rate': 0.36743243541315757, 'max_depth': 26, 'min_gain_to_split': 1.6182717687183623, 'min_sum_hessian_in_leaf': 3.030499766253722}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:04,845] Trial 108 finished with value: 0.5528728526842045 and parameters: {'lambda_l1': 1.333713938556694e-07, 'lambda_l2': 1.7358039353805233e-08, 'num_leaves': 74, 'feature_fraction': 0.8721498469095436, 'bagging_fraction': 0.77606815922021, 'bagging_freq': 6, 'min_child_samples': 63, 'learning_rate': 0.5063623737935317, 'max_depth': 46, 'min_gain_to_split': 0.28291292043139943, 'min_sum_hessian_in_leaf': 1.8443448443200934}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:15,572] Trial 109 finished with value: 0.544270795861795 and parameters: {'lambda_l1': 4.913397580157751e-08, 'lambda_l2': 8.410211413402523e-08, 'num_leaves': 62, 'feature_fraction': 0.9450899425594009, 'bagging_fraction': 0.7165877827373401, 'bagging_freq': 4, 'min_child_samples': 49, 'learning_rate': 0.17903410853660467, 'max_depth': 23, 'min_gain_to_split': 0.010378987999681897, 'min_sum_hessian_in_leaf': 1.5914611968477983}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:26,686] Trial 110 finished with value: 0.5494149683146012 and parameters: {'lambda_l1': 6.091007267321089e-07, 'lambda_l2': 8.907766265001188e-07, 'num_leaves': 102, 'feature_fraction': 0.9895930035494355, 'bagging_fraction': 0.7174156995813512, 'bagging_freq': 4, 'min_child_samples': 48, 'learning_rate': 0.17554981793945307, 'max_depth': 23, 'min_gain_to_split': 0.9103577548486894, 'min_sum_hessian_in_leaf': 1.5583006661796257}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:37,844] Trial 111 finished with value: 0.5492640546732086 and parameters: {'lambda_l1': 2.408446247106672e-08, 'lambda_l2': 8.320814554078855e-08, 'num_leaves': 66, 'feature_fraction': 0.9352424988156733, 'bagging_fraction': 0.7333015811191802, 'bagging_freq': 4, 'min_child_samples': 56, 'learning_rate': 0.20627895257120527, 'max_depth': 19, 'min_gain_to_split': 0.5905317802105023, 'min_sum_hessian_in_leaf': 2.377053365404974}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:47,461] Trial 112 finished with value: 0.5399020724281673 and parameters: {'lambda_l1': 5.020817275220173e-08, 'lambda_l2': 4.815376627025265e-07, 'num_leaves': 59, 'feature_fraction': 0.9454059691684947, 'bagging_fraction': 0.7030243481096051, 'bagging_freq': 4, 'min_child_samples': 68, 'learning_rate': 0.2791501726941791, 'max_depth': 25, 'min_gain_to_split': 0.00014739031738067454, 'min_sum_hessian_in_leaf': 2.08375876891487}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:08:58,600] Trial 113 finished with value: 0.5524521118571053 and parameters: {'lambda_l1': 4.774559012346967e-08, 'lambda_l2': 4.0135867766461795e-07, 'num_leaves': 59, 'feature_fraction': 0.9660444855802098, 'bagging_fraction': 0.6857600035434113, 'bagging_freq': 4, 'min_child_samples': 68, 'learning_rate': 0.1555741922946073, 'max_depth': 25, 'min_gain_to_split': 0.2364489064812469, 'min_sum_hessian_in_leaf': 1.9276790593531188}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:09:05,785] Trial 114 finished with value: 0.5656222404288186 and parameters: {'lambda_l1': 8.24683740955343e-08, 'lambda_l2': 1.746542086570498e-06, 'num_leaves': 79, 'feature_fraction': 0.9471153192779345, 'bagging_fraction': 0.7019513986979141, 'bagging_freq': 4, 'min_child_samples': 70, 'learning_rate': 0.2687769649178181, 'max_depth': 23, 'min_gain_to_split': 1.308890904392841, 'min_sum_hessian_in_leaf': 2.048993017834539}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:09:15,033] Trial 115 finished with value: 0.5552566927964424 and parameters: {'lambda_l1': 2.1749167439872227e-07, 'lambda_l2': 2.3494034845259927e-07, 'num_leaves': 69, 'feature_fraction': 0.9159376459163792, 'bagging_fraction': 0.6680554704132665, 'bagging_freq': 4, 'min_child_samples': 74, 'learning_rate': 0.3290356465229126, 'max_depth': 21, 'min_gain_to_split': 0.5321527902917218, 'min_sum_hessian_in_leaf': 1.2116888064167277}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:09:23,823] Trial 116 finished with value: 0.5590971553048659 and parameters: {'lambda_l1': 1.2627361786462267e-07, 'lambda_l2': 4.951473019188226e-07, 'num_leaves': 61, 'feature_fraction': 0.9580817306688267, 'bagging_fraction': 0.7574874355051356, 'bagging_freq': 4, 'min_child_samples': 65, 'learning_rate': 0.22722964630475873, 'max_depth': 26, 'min_gain_to_split': 0.9099124331575298, 'min_sum_hessian_in_leaf': 1.4750438344944723}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:09:36,276] Trial 117 finished with value: 0.5368628144983588 and parameters: {'lambda_l1': 6.072672363310288e-08, 'lambda_l2': 1.2166975834339229e-06, 'num_leaves': 87, 'feature_fraction': 0.9435113529435057, 'bagging_fraction': 0.7115527446986178, 'bagging_freq': 5, 'min_child_samples': 49, 'learning_rate': 0.19170257071791497, 'max_depth': 24, 'min_gain_to_split': 0.02905189680715692, 'min_sum_hessian_in_leaf': 0.8679957278132273}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:09:49,616] Trial 118 finished with value: 0.5466800086931664 and parameters: {'lambda_l1': 3.0598073681829493e-07, 'lambda_l2': 1.2224360328521412e-06, 'num_leaves': 85, 'feature_fraction': 0.9765060208070407, 'bagging_fraction': 0.6787696165225444, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.1420131515939723, 'max_depth': 28, 'min_gain_to_split': 0.38047460452499826, 'min_sum_hessian_in_leaf': 0.7439907895575029}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:10:04,796] Trial 119 finished with value: 0.539098215220523 and parameters: {'lambda_l1': 3.097236372344855e-08, 'lambda_l2': 9.302840911247615e-07, 'num_leaves': 92, 'feature_fraction': 0.9320740262715294, 'bagging_fraction': 0.704532737409014, 'bagging_freq': 5, 'min_child_samples': 81, 'learning_rate': 0.12297847882559872, 'max_depth': 22, 'min_gain_to_split': 0.00029607707262997544, 'min_sum_hessian_in_leaf': 0.9807120431173018}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:10:19,127] Trial 120 finished with value: 0.5570245074378181 and parameters: {'lambda_l1': 2.9938340496334946e-08, 'lambda_l2': 9.101864936609177e-07, 'num_leaves': 92, 'feature_fraction': 0.9114677387325149, 'bagging_fraction': 0.7035411190887786, 'bagging_freq': 5, 'min_child_samples': 86, 'learning_rate': 0.11337543703613127, 'max_depth': 24, 'min_gain_to_split': 1.2211657095038946, 'min_sum_hessian_in_leaf': 1.0262328622284398}. Best is trial 81 with value: 0.5368460148456566.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:10:32,916] Trial 121 finished with value: 0.5355545364601616 and parameters: {'lambda_l1': 7.031739156431276e-08, 'lambda_l2': 2.0326348287056292e-06, 'num_leaves': 96, 'feature_fraction': 0.9314033569791667, 'bagging_fraction': 0.7143232546387456, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.19726927695720328, 'max_depth': 25, 'min_gain_to_split': 0.0055594602441733, 'min_sum_hessian_in_leaf': 0.5063371776576924}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:10:42,621] Trial 122 finished with value: 0.5491512476106106 and parameters: {'lambda_l1': 5.614973901533178e-08, 'lambda_l2': 2.139097886227233e-06, 'num_leaves': 113, 'feature_fraction': 0.9246863299179987, 'bagging_fraction': 0.7436659779574633, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.2499918938746878, 'max_depth': 22, 'min_gain_to_split': 0.6050438785104499, 'min_sum_hessian_in_leaf': 0.16065723429582357}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:10:58,210] Trial 123 finished with value: 0.5447588255607856 and parameters: {'lambda_l1': 7.461468804351755e-08, 'lambda_l2': 6.639243051547727e-07, 'num_leaves': 98, 'feature_fraction': 0.9494173606918331, 'bagging_fraction': 0.7678481163922631, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.12557031078933925, 'max_depth': 25, 'min_gain_to_split': 0.3129158654522661, 'min_sum_hessian_in_leaf': 0.5893639681172297}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:11:11,005] Trial 124 finished with value: 0.5355758988852316 and parameters: {'lambda_l1': 2.7994732657844046e-08, 'lambda_l2': 1.606182406042622e-06, 'num_leaves': 94, 'feature_fraction': 0.9654771598518288, 'bagging_fraction': 0.7272911073351485, 'bagging_freq': 5, 'min_child_samples': 79, 'learning_rate': 0.28906226233380405, 'max_depth': 21, 'min_gain_to_split': 0.003132815440335411, 'min_sum_hessian_in_leaf': 1.2060000644292739}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:11:24,972] Trial 125 finished with value: 0.537842747732004 and parameters: {'lambda_l1': 2.7547202378493804e-08, 'lambda_l2': 1.748467380620645e-06, 'num_leaves': 107, 'feature_fraction': 0.9885627308542461, 'bagging_fraction': 0.6945801619441136, 'bagging_freq': 5, 'min_child_samples': 76, 'learning_rate': 0.3029673999765641, 'max_depth': 21, 'min_gain_to_split': 0.0166455670327586, 'min_sum_hessian_in_leaf': 0.7804728063705164}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:11:32,845] Trial 126 finished with value: 0.5530424032325072 and parameters: {'lambda_l1': 3.315512973294781e-08, 'lambda_l2': 1.359571109475605e-06, 'num_leaves': 108, 'feature_fraction': 0.9911921774902606, 'bagging_fraction': 0.6945619057854521, 'bagging_freq': 5, 'min_child_samples': 80, 'learning_rate': 0.30549876241837376, 'max_depth': 27, 'min_gain_to_split': 0.7968614129437972, 'min_sum_hessian_in_leaf': 0.8067962923865036}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:11:45,422] Trial 127 finished with value: 0.5487071549395441 and parameters: {'lambda_l1': 2.0966095391774818e-08, 'lambda_l2': 4.8366365694331095e-06, 'num_leaves': 102, 'feature_fraction': 0.9643189094863994, 'bagging_fraction': 0.6642691335425238, 'bagging_freq': 5, 'min_child_samples': 77, 'learning_rate': 0.42538087839454203, 'max_depth': 24, 'min_gain_to_split': 0.010381623157811916, 'min_sum_hessian_in_leaf': 1.103527176832437}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:11:54,329] Trial 128 finished with value: 0.5493834392995961 and parameters: {'lambda_l1': 1.0153996729231704e-08, 'lambda_l2': 2.5780230619471326e-06, 'num_leaves': 122, 'feature_fraction': 0.9988895100083754, 'bagging_fraction': 0.6847602904864162, 'bagging_freq': 5, 'min_child_samples': 78, 'learning_rate': 0.2760330633846381, 'max_depth': 22, 'min_gain_to_split': 0.6622958551865983, 'min_sum_hessian_in_leaf': 0.48218112275865754}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:12:02,826] Trial 129 finished with value: 0.5550946279677317 and parameters: {'lambda_l1': 3.588705466924291e-08, 'lambda_l2': 1.4417230284535582e-06, 'num_leaves': 129, 'feature_fraction': 0.9779255293881726, 'bagging_fraction': 0.7223779089428422, 'bagging_freq': 5, 'min_child_samples': 81, 'learning_rate': 0.22532379646898915, 'max_depth': 21, 'min_gain_to_split': 1.1994665601381402, 'min_sum_hessian_in_leaf': 1.3675989173176346}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:12:09,472] Trial 130 finished with value: 0.5598440890040537 and parameters: {'lambda_l1': 1.4723861883910147e-08, 'lambda_l2': 4.0044111354842315e-07, 'num_leaves': 93, 'feature_fraction': 0.9845808022911824, 'bagging_fraction': 0.7102539349287789, 'bagging_freq': 5, 'min_child_samples': 75, 'learning_rate': 0.33667650690275513, 'max_depth': 29, 'min_gain_to_split': 0.9112168510637968, 'min_sum_hessian_in_leaf': 0.8487227041145572}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:12:24,151] Trial 131 finished with value: 0.5422900561980504 and parameters: {'lambda_l1': 1.1206406882565845e-07, 'lambda_l2': 8.192104870825111e-07, 'num_leaves': 110, 'feature_fraction': 0.95637544745368, 'bagging_fraction': 0.6772486031747385, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.20568232559591199, 'max_depth': 20, 'min_gain_to_split': 0.2858546039368145, 'min_sum_hessian_in_leaf': 1.2547381008168483}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:12:39,279] Trial 132 finished with value: 0.5402024598865622 and parameters: {'lambda_l1': 1.0874847985160233e-07, 'lambda_l2': 9.255402231437119e-07, 'num_leaves': 112, 'feature_fraction': 0.9708330129381615, 'bagging_fraction': 0.6752492648788422, 'bagging_freq': 5, 'min_child_samples': 75, 'learning_rate': 0.20199106713700912, 'max_depth': 26, 'min_gain_to_split': 0.269242299874514, 'min_sum_hessian_in_leaf': 1.1874266607552253}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:12:52,545] Trial 133 finished with value: 0.5445806278392782 and parameters: {'lambda_l1': 1.182476994955945e-07, 'lambda_l2': 9.096001193352932e-07, 'num_leaves': 115, 'feature_fraction': 0.9681559768413746, 'bagging_fraction': 0.6715183975054771, 'bagging_freq': 5, 'min_child_samples': 76, 'learning_rate': 0.19360090566681826, 'max_depth': 26, 'min_gain_to_split': 0.4990684040453338, 'min_sum_hessian_in_leaf': 1.0074186524735127}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:13:07,130] Trial 134 finished with value: 0.544594024629439 and parameters: {'lambda_l1': 1.759585091591651e-07, 'lambda_l2': 2.1008660054921697e-06, 'num_leaves': 108, 'feature_fraction': 0.9565939154353884, 'bagging_fraction': 0.652350345044289, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.22139891650433358, 'max_depth': 25, 'min_gain_to_split': 0.31167155535540775, 'min_sum_hessian_in_leaf': 0.6248591447262293}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:13:23,505] Trial 135 finished with value: 0.5407192964747276 and parameters: {'lambda_l1': 1.009720502037182e-07, 'lambda_l2': 1.5092432056542519e-06, 'num_leaves': 137, 'feature_fraction': 0.973940537917013, 'bagging_fraction': 0.6773270619010371, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.26975171334370546, 'max_depth': 22, 'min_gain_to_split': 0.017238832314271837, 'min_sum_hessian_in_leaf': 1.2982927000069837}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:13:38,548] Trial 136 finished with value: 0.5368850159056262 and parameters: {'lambda_l1': 8.821622578813015e-07, 'lambda_l2': 1.4049601834601066e-06, 'num_leaves': 122, 'feature_fraction': 0.9724921851565634, 'bagging_fraction': 0.6938744702832935, 'bagging_freq': 5, 'min_child_samples': 86, 'learning_rate': 0.2693984403887786, 'max_depth': 22, 'min_gain_to_split': 0.011520045142395099, 'min_sum_hessian_in_leaf': 0.24184294009924645}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:13:47,472] Trial 137 finished with value: 0.5501432633050136 and parameters: {'lambda_l1': 9.072331030303899e-07, 'lambda_l2': 6.280786817428659e-06, 'num_leaves': 137, 'feature_fraction': 0.9874635432845222, 'bagging_fraction': 0.689450663048104, 'bagging_freq': 5, 'min_child_samples': 86, 'learning_rate': 0.2651929548530077, 'max_depth': 26, 'min_gain_to_split': 0.6547451388178085, 'min_sum_hessian_in_leaf': 0.2229859699133043}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:13:55,110] Trial 138 finished with value: 0.5609011298190122 and parameters: {'lambda_l1': 8.698139801255148e-08, 'lambda_l2': 1.4588423746442858e-06, 'num_leaves': 152, 'feature_fraction': 0.9771131041897025, 'bagging_fraction': 0.7030604344035567, 'bagging_freq': 5, 'min_child_samples': 91, 'learning_rate': 0.2467618119658517, 'max_depth': 24, 'min_gain_to_split': 1.5439853757144761, 'min_sum_hessian_in_leaf': 0.25715993781744867}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:14:10,029] Trial 139 finished with value: 0.5417083046553228 and parameters: {'lambda_l1': 4.1605748420712175e-07, 'lambda_l2': 2.897783792772122e-06, 'num_leaves': 125, 'feature_fraction': 0.9725519696728172, 'bagging_fraction': 0.658221715020806, 'bagging_freq': 5, 'min_child_samples': 83, 'learning_rate': 0.2927768715551792, 'max_depth': 21, 'min_gain_to_split': 0.013465743911249557, 'min_sum_hessian_in_leaf': 0.43187673917563396}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:14:21,525] Trial 140 finished with value: 0.5525491855777426 and parameters: {'lambda_l1': 3.529138174666135e-08, 'lambda_l2': 5.583351491679511e-07, 'num_leaves': 144, 'feature_fraction': 0.9999829405964251, 'bagging_fraction': 0.643536983932182, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.16899244676331612, 'max_depth': 28, 'min_gain_to_split': 1.014009429264764, 'min_sum_hessian_in_leaf': 0.9275595286136822}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:14:36,282] Trial 141 finished with value: 0.5428392596587261 and parameters: {'lambda_l1': 2.617303919004752e-07, 'lambda_l2': 1.8577969550034609e-06, 'num_leaves': 120, 'feature_fraction': 0.9701672734801791, 'bagging_fraction': 0.6605047289305127, 'bagging_freq': 5, 'min_child_samples': 83, 'learning_rate': 0.2863433164294295, 'max_depth': 21, 'min_gain_to_split': 0.032883714851245006, 'min_sum_hessian_in_leaf': 0.3546895978354915}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:14:44,406] Trial 142 finished with value: 0.5507655651188379 and parameters: {'lambda_l1': 5.082740665067632e-07, 'lambda_l2': 4.3192948656606575e-06, 'num_leaves': 139, 'feature_fraction': 0.9376927020427847, 'bagging_fraction': 0.6710789992413538, 'bagging_freq': 5, 'min_child_samples': 81, 'learning_rate': 0.33955285106384053, 'max_depth': 22, 'min_gain_to_split': 0.526221810536546, 'min_sum_hessian_in_leaf': 0.6408829732084264}. Best is trial 121 with value: 0.5355545364601616.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:14:59,989] Trial 143 finished with value: 0.5342876835841576 and parameters: {'lambda_l1': 1.3502133048967148e-06, 'lambda_l2': 2.526392974206061e-06, 'num_leaves': 127, 'feature_fraction': 0.987137224313554, 'bagging_fraction': 0.6954375165264222, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.24054604944044397, 'max_depth': 24, 'min_gain_to_split': 0.00010084055482547462, 'min_sum_hessian_in_leaf': 0.4277009649857114}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:15:05,821] Trial 144 finished with value: 0.5875309005830435 and parameters: {'lambda_l1': 6.990665112038852e-07, 'lambda_l2': 9.230953433051368e-07, 'num_leaves': 124, 'feature_fraction': 0.9489732968114166, 'bagging_fraction': 0.6970980370248424, 'bagging_freq': 5, 'min_child_samples': 90, 'learning_rate': 0.23030114268643967, 'max_depth': 24, 'min_gain_to_split': 6.035879456746097, 'min_sum_hessian_in_leaf': 1.1735397418662497}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:15:20,429] Trial 145 finished with value: 0.5399507150678203 and parameters: {'lambda_l1': 2.4690898300148712e-08, 'lambda_l2': 8.490913333789173e-06, 'num_leaves': 105, 'feature_fraction': 0.9855076669315646, 'bagging_fraction': 0.7203334442422947, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.19824548375128664, 'max_depth': 27, 'min_gain_to_split': 0.26673249358391293, 'min_sum_hessian_in_leaf': 0.7323671710917088}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:15:26,463] Trial 146 finished with value: 0.5926017648126569 and parameters: {'lambda_l1': 1.1637523355581468e-06, 'lambda_l2': 2.609426562265415e-06, 'num_leaves': 104, 'feature_fraction': 0.9924577805363658, 'bagging_fraction': 0.7252058064523662, 'bagging_freq': 5, 'min_child_samples': 88, 'learning_rate': 0.2012370257635796, 'max_depth': 29, 'min_gain_to_split': 8.188167129410024, 'min_sum_hessian_in_leaf': 0.09543953479715211}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:15:37,693] Trial 147 finished with value: 0.5502849690277223 and parameters: {'lambda_l1': 4.6450002231357987e-08, 'lambda_l2': 8.732441276361182e-06, 'num_leaves': 131, 'feature_fraction': 0.9793841545755071, 'bagging_fraction': 0.6835952896834774, 'bagging_freq': 5, 'min_child_samples': 79, 'learning_rate': 0.18007414614801606, 'max_depth': 27, 'min_gain_to_split': 0.8015686188129657, 'min_sum_hessian_in_leaf': 0.7699176250548414}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:15:53,858] Trial 148 finished with value: 0.5409791815515665 and parameters: {'lambda_l1': 2.5555183448106516e-06, 'lambda_l2': 5.831387444868433e-06, 'num_leaves': 115, 'feature_fraction': 0.985451945375876, 'bagging_fraction': 0.7102002427835478, 'bagging_freq': 5, 'min_child_samples': 86, 'learning_rate': 0.15114400707273015, 'max_depth': 25, 'min_gain_to_split': 0.3275083150803305, 'min_sum_hessian_in_leaf': 0.9339374236971253}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:16:03,454] Trial 149 finished with value: 0.5509394248018161 and parameters: {'lambda_l1': 1.7078212495703044e-06, 'lambda_l2': 1.4036239242045004e-06, 'num_leaves': 96, 'feature_fraction': 0.9645123283766404, 'bagging_fraction': 0.6925678313953969, 'bagging_freq': 5, 'min_child_samples': 81, 'learning_rate': 0.25020371313404594, 'max_depth': 23, 'min_gain_to_split': 0.5882886855855002, 'min_sum_hessian_in_leaf': 0.496343202571337}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:16:21,537] Trial 150 finished with value: 0.5511221343205179 and parameters: {'lambda_l1': 1.6671229856635965e-07, 'lambda_l2': 3.6488957338074346e-06, 'num_leaves': 128, 'feature_fraction': 0.9557171392957394, 'bagging_fraction': 0.7144634190069238, 'bagging_freq': 5, 'min_child_samples': 93, 'learning_rate': 0.0962082667698461, 'max_depth': 26, 'min_gain_to_split': 1.0033449877101346, 'min_sum_hessian_in_leaf': 1.3899766609225719}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:16:37,537] Trial 151 finished with value: 0.5403263550780049 and parameters: {'lambda_l1': 1.9386898137034697e-06, 'lambda_l2': 4.98944148859555e-06, 'num_leaves': 115, 'feature_fraction': 0.9916208750506894, 'bagging_fraction': 0.7096191170808114, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.15934080098299716, 'max_depth': 25, 'min_gain_to_split': 0.31164301456435983, 'min_sum_hessian_in_leaf': 0.9514479149058179}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:16:53,616] Trial 152 finished with value: 0.5403732971290528 and parameters: {'lambda_l1': 6.852808630710441e-06, 'lambda_l2': 2.0309695440778353e-06, 'num_leaves': 119, 'feature_fraction': 0.9999524873799845, 'bagging_fraction': 0.704176296119659, 'bagging_freq': 5, 'min_child_samples': 88, 'learning_rate': 0.1935869350453186, 'max_depth': 25, 'min_gain_to_split': 0.2931167376273773, 'min_sum_hessian_in_leaf': 0.7288181231432831}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:17:10,560] Trial 153 finished with value: 0.54302067724308 and parameters: {'lambda_l1': 5.621223240751528e-06, 'lambda_l2': 2.1718720457562857e-06, 'num_leaves': 119, 'feature_fraction': 0.998960140444544, 'bagging_fraction': 0.6992482493675802, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.13691104037211355, 'max_depth': 27, 'min_gain_to_split': 0.439072083030669, 'min_sum_hessian_in_leaf': 0.036470657666701295}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:17:25,481] Trial 154 finished with value: 0.5404380547528511 and parameters: {'lambda_l1': 1.4341244366573732e-06, 'lambda_l2': 4.00874374155535e-06, 'num_leaves': 111, 'feature_fraction': 0.9858446379825421, 'bagging_fraction': 0.7292762009636168, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.1961301314158827, 'max_depth': 25, 'min_gain_to_split': 0.29780916606842245, 'min_sum_hessian_in_leaf': 0.6820848900827396}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:17:36,921] Trial 155 finished with value: 0.5521496111073173 and parameters: {'lambda_l1': 3.97142700448134e-06, 'lambda_l2': 1.2632014508860346e-05, 'num_leaves': 100, 'feature_fraction': 0.9997112459030425, 'bagging_fraction': 0.7204450454956677, 'bagging_freq': 5, 'min_child_samples': 90, 'learning_rate': 0.17768930702181346, 'max_depth': 26, 'min_gain_to_split': 0.8033897411999817, 'min_sum_hessian_in_leaf': 0.41077213175145694}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:17:49,581] Trial 156 finished with value: 0.5447512928800626 and parameters: {'lambda_l1': 2.1057289322831025e-06, 'lambda_l2': 6.219429287615364e-07, 'num_leaves': 87, 'feature_fraction': 0.9668365837068321, 'bagging_fraction': 0.7066871120067247, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.2262441299707686, 'max_depth': 29, 'min_gain_to_split': 0.3264220715063527, 'min_sum_hessian_in_leaf': 1.05541507064854}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:17:57,604] Trial 157 finished with value: 0.5704122851427073 and parameters: {'lambda_l1': 8.49547271352566e-06, 'lambda_l2': 7.556216698950329e-06, 'num_leaves': 104, 'feature_fraction': 0.9412179052739915, 'bagging_fraction': 0.7286185967321637, 'bagging_freq': 5, 'min_child_samples': 16, 'learning_rate': 0.1587971479755182, 'max_depth': 24, 'min_gain_to_split': 4.333369566267346, 'min_sum_hessian_in_leaf': 0.8382534459664177}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:18:08,715] Trial 158 finished with value: 0.5639409762351237 and parameters: {'lambda_l1': 9.237776702544513e-07, 'lambda_l2': 9.584950066118482e-07, 'num_leaves': 113, 'feature_fraction': 0.985809563039891, 'bagging_fraction': 0.6879894386734948, 'bagging_freq': 5, 'min_child_samples': 92, 'learning_rate': 0.1344363663004572, 'max_depth': 23, 'min_gain_to_split': 2.003374830408505, 'min_sum_hessian_in_leaf': 0.6325903110382236}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:18:15,793] Trial 159 finished with value: 0.570178961772097 and parameters: {'lambda_l1': 4.06298793011731e-07, 'lambda_l2': 2.4386267235571858e-06, 'num_leaves': 97, 'feature_fraction': 0.957817158234257, 'bagging_fraction': 0.7124665124557175, 'bagging_freq': 5, 'min_child_samples': 78, 'learning_rate': 0.20755086854103716, 'max_depth': 31, 'min_gain_to_split': 2.6475463290986685, 'min_sum_hessian_in_leaf': 0.3434720253191542}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:18:26,378] Trial 160 finished with value: 0.5574622938291758 and parameters: {'lambda_l1': 0.00010906251099386637, 'lambda_l2': 5.203607897852753e-07, 'num_leaves': 119, 'feature_fraction': 0.9347243686790481, 'bagging_fraction': 0.6991277999047993, 'bagging_freq': 5, 'min_child_samples': 89, 'learning_rate': 0.1644630591099394, 'max_depth': 19, 'min_gain_to_split': 1.2974498290628784, 'min_sum_hessian_in_leaf': 1.0628625297065923}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:18:41,344] Trial 161 finished with value: 0.5410323125837518 and parameters: {'lambda_l1': 1.8040359525900611e-06, 'lambda_l2': 4.132837523420012e-06, 'num_leaves': 110, 'feature_fraction': 0.9817606814471815, 'bagging_fraction': 0.7372489445993965, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.2002381772352547, 'max_depth': 25, 'min_gain_to_split': 0.2976060623290189, 'min_sum_hessian_in_leaf': 0.6783667496165444}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:18:57,687] Trial 162 finished with value: 0.5425791480846771 and parameters: {'lambda_l1': 3.3779500616937993e-06, 'lambda_l2': 3.4202876764197187e-06, 'num_leaves': 107, 'feature_fraction': 0.9868459526233261, 'bagging_fraction': 0.7282489523464142, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.12297111905879901, 'max_depth': 28, 'min_gain_to_split': 0.2508253625151812, 'min_sum_hessian_in_leaf': 0.7666074907514073}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:19:09,559] Trial 163 finished with value: 0.5490824368749768 and parameters: {'lambda_l1': 1.341952472705605e-06, 'lambda_l2': 6.158877446535901e-06, 'num_leaves': 93, 'feature_fraction': 0.9693122731357278, 'bagging_fraction': 0.7179929033123859, 'bagging_freq': 5, 'min_child_samples': 80, 'learning_rate': 0.18900742648577132, 'max_depth': 25, 'min_gain_to_split': 0.6242896424364144, 'min_sum_hessian_in_leaf': 0.581058347562271}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:19:14,759] Trial 164 finished with value: 0.5991822532301687 and parameters: {'lambda_l1': 7.095673048224003e-07, 'lambda_l2': 1.0227861540549275e-06, 'num_leaves': 114, 'feature_fraction': 0.9493016711129256, 'bagging_fraction': 0.7040965415025146, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.23454495371279804, 'max_depth': 25, 'min_gain_to_split': 9.658412827602943, 'min_sum_hessian_in_leaf': 0.28389799393286763}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:19:29,780] Trial 165 finished with value: 0.5411061922647006 and parameters: {'lambda_l1': 1.2128991981628386e-06, 'lambda_l2': 1.9105454363268648e-06, 'num_leaves': 125, 'feature_fraction': 0.9776491092305136, 'bagging_fraction': 0.7361207295837403, 'bagging_freq': 5, 'min_child_samples': 88, 'learning_rate': 0.32555069837410283, 'max_depth': 23, 'min_gain_to_split': 0.012004910476836267, 'min_sum_hessian_in_leaf': 0.019294700513501795}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:19:39,688] Trial 166 finished with value: 0.5501844194123005 and parameters: {'lambda_l1': 2.313259232847575e-08, 'lambda_l2': 1.1822316075731997e-05, 'num_leaves': 85, 'feature_fraction': 0.956479267860652, 'bagging_fraction': 0.6826111496066211, 'bagging_freq': 5, 'min_child_samples': 77, 'learning_rate': 0.2527338545533422, 'max_depth': 27, 'min_gain_to_split': 0.5356751365141526, 'min_sum_hessian_in_leaf': 0.905294678443808}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:19:52,178] Trial 167 finished with value: 0.5539491799006171 and parameters: {'lambda_l1': 3.399528421256562e-07, 'lambda_l2': 1.1474829891316052e-06, 'num_leaves': 101, 'feature_fraction': 0.9952707729093818, 'bagging_fraction': 0.7234039177750543, 'bagging_freq': 5, 'min_child_samples': 83, 'learning_rate': 0.1472558628405101, 'max_depth': 24, 'min_gain_to_split': 0.9354611813292341, 'min_sum_hessian_in_leaf': 1.6430982876056162}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:20:04,391] Trial 168 finished with value: 0.5425953451742699 and parameters: {'lambda_l1': 2.575495089141696e-06, 'lambda_l2': 3.0599662268464074e-06, 'num_leaves': 80, 'feature_fraction': 0.9847247573487177, 'bagging_fraction': 0.7535555607500349, 'bagging_freq': 5, 'min_child_samples': 76, 'learning_rate': 0.19597275818199836, 'max_depth': 26, 'min_gain_to_split': 0.2716668646495426, 'min_sum_hessian_in_leaf': 1.1676400097604729}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:20:16,861] Trial 169 finished with value: 0.5497835240743364 and parameters: {'lambda_l1': 6.568738515447612e-08, 'lambda_l2': 3.758595572688835e-07, 'num_leaves': 106, 'feature_fraction': 0.9679836153228997, 'bagging_fraction': 0.6379859810392309, 'bagging_freq': 5, 'min_child_samples': 79, 'learning_rate': 0.16662010705390243, 'max_depth': 22, 'min_gain_to_split': 0.6964217080444703, 'min_sum_hessian_in_leaf': 0.5073718536836701}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:20:32,656] Trial 170 finished with value: 0.6836567419207918 and parameters: {'lambda_l1': 1.4160470247663363e-06, 'lambda_l2': 4.658598090701667e-06, 'num_leaves': 94, 'feature_fraction': 0.9283958649985933, 'bagging_fraction': 0.6685687175948467, 'bagging_freq': 5, 'min_child_samples': 95, 'learning_rate': 0.02279909827681682, 'max_depth': 18, 'min_gain_to_split': 0.013554848355745174, 'min_sum_hessian_in_leaf': 1.4570315223154977}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:20:48,368] Trial 171 finished with value: 0.5390613395521635 and parameters: {'lambda_l1': 1.0543588441311584e-07, 'lambda_l2': 1.6114286145834462e-06, 'num_leaves': 131, 'feature_fraction': 0.9758139459375728, 'bagging_fraction': 0.6740622574803702, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.2648229980068302, 'max_depth': 22, 'min_gain_to_split': 0.01754024740984274, 'min_sum_hessian_in_leaf': 1.1958739009420118}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:01,949] Trial 172 finished with value: 0.5420886900320687 and parameters: {'lambda_l1': 4.32734604556398e-08, 'lambda_l2': 1.6888968417681567e-06, 'num_leaves': 132, 'feature_fraction': 0.9892715790872262, 'bagging_fraction': 0.6918223555472957, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.27493009817297887, 'max_depth': -1, 'min_gain_to_split': 0.30670487650926964, 'min_sum_hessian_in_leaf': 1.2122867689686325}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:13,782] Trial 173 finished with value: 0.5452219804849248 and parameters: {'lambda_l1': 2.462069995676458e-08, 'lambda_l2': 7.050808070698838e-07, 'num_leaves': 119, 'feature_fraction': 0.9731866062202641, 'bagging_fraction': 0.7118856552136904, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.22371372943010898, 'max_depth': 20, 'min_gain_to_split': 0.44854423704836893, 'min_sum_hessian_in_leaf': 0.9202123680644316}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:26,712] Trial 174 finished with value: 0.5465994601057507 and parameters: {'lambda_l1': 2.2233143355785848e-07, 'lambda_l2': 1.2968393999507465e-06, 'num_leaves': 110, 'feature_fraction': 0.9604564642963287, 'bagging_fraction': 0.6742172916694128, 'bagging_freq': 5, 'min_child_samples': 87, 'learning_rate': 0.3518650304302117, 'max_depth': 23, 'min_gain_to_split': 0.26887948823600566, 'min_sum_hessian_in_leaf': 0.669658905676356}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:42,120] Trial 175 finished with value: 0.5427532376910942 and parameters: {'lambda_l1': 5.421651026195704e-07, 'lambda_l2': 2.0776794298899263e-05, 'num_leaves': 127, 'feature_fraction': 0.946126078873085, 'bagging_fraction': 0.6538267104817674, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.29086800264840723, 'max_depth': 21, 'min_gain_to_split': 0.010263784200106221, 'min_sum_hessian_in_leaf': 1.4749403111650574}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:52,134] Trial 176 finished with value: 0.5504396063091213 and parameters: {'lambda_l1': 6.636521043873138e-08, 'lambda_l2': 2.4728644275003465e-06, 'num_leaves': 146, 'feature_fraction': 0.7853755201779745, 'bagging_fraction': 0.7322008185857483, 'bagging_freq': 5, 'min_child_samples': 80, 'learning_rate': 0.24338214273213873, 'max_depth': 24, 'min_gain_to_split': 0.6711582030431041, 'min_sum_hessian_in_leaf': 0.9999088505345105}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:21:58,150] Trial 177 finished with value: 0.5706760294198829 and parameters: {'lambda_l1': 5.025829023623448e-06, 'lambda_l2': 7.086082232728887e-06, 'num_leaves': 99, 'feature_fraction': 0.7029100813117295, 'bagging_fraction': 0.70091862100787, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.42136074882584007, 'max_depth': 22, 'min_gain_to_split': 0.9280527106505478, 'min_sum_hessian_in_leaf': 0.29007877468082516}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:22:11,146] Trial 178 finished with value: 0.5455383903179742 and parameters: {'lambda_l1': 3.028765209518021e-08, 'lambda_l2': 7.356729820829887e-07, 'num_leaves': 116, 'feature_fraction': 0.9784630874423051, 'bagging_fraction': 0.6867872246510028, 'bagging_freq': 5, 'min_child_samples': 90, 'learning_rate': 0.19275802999395292, 'max_depth': 25, 'min_gain_to_split': 0.5112329985619244, 'min_sum_hessian_in_leaf': 0.7605511751173784}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:22:25,524] Trial 179 finished with value: 0.5386501681077405 and parameters: {'lambda_l1': 1.3328610873828645e-07, 'lambda_l2': 3.034762008039297e-07, 'num_leaves': 122, 'feature_fraction': 0.9408587705260991, 'bagging_fraction': 0.7205443795892195, 'bagging_freq': 5, 'min_child_samples': 75, 'learning_rate': 0.3177871039409524, 'max_depth': 27, 'min_gain_to_split': 0.0026616020776909525, 'min_sum_hessian_in_leaf': 1.7555741974751746}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:22:40,054] Trial 180 finished with value: 0.5467763499581698 and parameters: {'lambda_l1': 1.1442799820163145e-07, 'lambda_l2': 2.733614535288176e-07, 'num_leaves': 122, 'feature_fraction': 0.9367834727294837, 'bagging_fraction': 0.7147963688180298, 'bagging_freq': 2, 'min_child_samples': 75, 'learning_rate': 0.338106941052849, 'max_depth': 27, 'min_gain_to_split': 0.01266982310274532, 'min_sum_hessian_in_leaf': 1.850739629354639}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:22:52,413] Trial 181 finished with value: 0.541165350717758 and parameters: {'lambda_l1': 1.6725654408351746e-07, 'lambda_l2': 4.6814166477933364e-07, 'num_leaves': 112, 'feature_fraction': 0.9996359110399174, 'bagging_fraction': 0.7441476514051929, 'bagging_freq': 5, 'min_child_samples': 78, 'learning_rate': 0.30367701354107135, 'max_depth': 28, 'min_gain_to_split': 0.268938659660752, 'min_sum_hessian_in_leaf': 1.736771366459656}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:23:08,517] Trial 182 finished with value: 0.5353046595520261 and parameters: {'lambda_l1': 8.382468750291778e-08, 'lambda_l2': 1.2275358909681426e-06, 'num_leaves': 134, 'feature_fraction': 0.963246627992136, 'bagging_fraction': 0.7252530958262036, 'bagging_freq': 5, 'min_child_samples': 72, 'learning_rate': 0.22736611752037753, 'max_depth': 26, 'min_gain_to_split': 0.006422790369832734, 'min_sum_hessian_in_leaf': 1.3021441633286197}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:23:14,851] Trial 183 finished with value: 0.5710548278973868 and parameters: {'lambda_l1': 8.096627030122491e-08, 'lambda_l2': 1.4461220500834003e-06, 'num_leaves': 136, 'feature_fraction': 0.9499459757759243, 'bagging_fraction': 0.7034585402595606, 'bagging_freq': 5, 'min_child_samples': 72, 'learning_rate': 0.26064342826847814, 'max_depth': 26, 'min_gain_to_split': 3.0393983074888933, 'min_sum_hessian_in_leaf': 1.285625914110819}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:23:25,319] Trial 184 finished with value: 0.5465276227061049 and parameters: {'lambda_l1': 4.5164179194852876e-08, 'lambda_l2': 7.990795177356315e-07, 'num_leaves': 131, 'feature_fraction': 0.9626326289883667, 'bagging_fraction': 0.7206809230467515, 'bagging_freq': 5, 'min_child_samples': 75, 'learning_rate': 0.22394891254029842, 'max_depth': 27, 'min_gain_to_split': 0.6386370530561971, 'min_sum_hessian_in_leaf': 1.5910263837399703}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:23:29,614] Trial 185 finished with value: 0.5923293522743613 and parameters: {'lambda_l1': 1.1946040626470301e-07, 'lambda_l2': 3.766252153286697e-07, 'num_leaves': 140, 'feature_fraction': 0.9295732147096666, 'bagging_fraction': 0.6912997472032323, 'bagging_freq': 5, 'min_child_samples': 69, 'learning_rate': 0.36699881998736184, 'max_depth': 24, 'min_gain_to_split': 7.009382744953602, 'min_sum_hessian_in_leaf': 1.1721956440509291}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:23:45,139] Trial 186 finished with value: 0.5818548884989295 and parameters: {'lambda_l1': 2.76056710179598e-07, 'lambda_l2': 1.9154625233991675e-06, 'num_leaves': 87, 'feature_fraction': 0.9469166555379123, 'bagging_fraction': 0.677318877094027, 'bagging_freq': 5, 'min_child_samples': 67, 'learning_rate': 0.056210211551100966, 'max_depth': 22, 'min_gain_to_split': 3.608001537594496, 'min_sum_hessian_in_leaf': 1.3703548163839612}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:24:00,284] Trial 187 finished with value: 0.5407192894516673 and parameters: {'lambda_l1': 7.112330053838291e-08, 'lambda_l2': 1.1057336980287537e-06, 'num_leaves': 128, 'feature_fraction': 0.9159840311958167, 'bagging_fraction': 0.6627762408354927, 'bagging_freq': 5, 'min_child_samples': 72, 'learning_rate': 0.26626896366271163, 'max_depth': 20, 'min_gain_to_split': 0.030275440358263073, 'min_sum_hessian_in_leaf': 1.0453633231733626}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:24:14,890] Trial 188 finished with value: 0.5923509197070663 and parameters: {'lambda_l1': 1.663025274737307e-08, 'lambda_l2': 5.207639802488021e-07, 'num_leaves': 76, 'feature_fraction': 0.9709769047824367, 'bagging_fraction': 0.7084220848667206, 'bagging_freq': 5, 'min_child_samples': 77, 'learning_rate': 0.0476805951195923, 'max_depth': 26, 'min_gain_to_split': 1.121420659418099, 'min_sum_hessian_in_leaf': 1.7357013882118897}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:24:24,172] Trial 189 finished with value: 0.546418447829653 and parameters: {'lambda_l1': 4.0031531441263114e-08, 'lambda_l2': 2.483441407081354e-06, 'num_leaves': 124, 'feature_fraction': 0.9581455683825324, 'bagging_fraction': 0.741192337144967, 'bagging_freq': 5, 'min_child_samples': 80, 'learning_rate': 0.3154621673361601, 'max_depth': 23, 'min_gain_to_split': 0.4538798994548464, 'min_sum_hessian_in_leaf': 1.4704312735332252}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:24:37,058] Trial 190 finished with value: 0.540882565232552 and parameters: {'lambda_l1': 1.5661045761335608e-07, 'lambda_l2': 2.328770245466131e-07, 'num_leaves': 89, 'feature_fraction': 0.9411634600890952, 'bagging_fraction': 0.7230660337804149, 'bagging_freq': 5, 'min_child_samples': 44, 'learning_rate': 0.21774815935101927, 'max_depth': 21, 'min_gain_to_split': 0.27934365361837127, 'min_sum_hessian_in_leaf': 0.43660248364859167}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:24:52,705] Trial 191 finished with value: 0.5386883163516699 and parameters: {'lambda_l1': 0.0017498241460098493, 'lambda_l2': 3.777330600518238e-06, 'num_leaves': 118, 'feature_fraction': 0.9885515070376325, 'bagging_fraction': 0.7285252525714708, 'bagging_freq': 5, 'min_child_samples': 74, 'learning_rate': 0.18256515157588474, 'max_depth': 25, 'min_gain_to_split': 0.26647109101283445, 'min_sum_hessian_in_leaf': 0.8558596332672254}. Best is trial 143 with value: 0.5342876835841576.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:25:12,608] Trial 192 finished with value: 0.5334179904969364 and parameters: {'lambda_l1': 0.0019808359187077603, 'lambda_l2': 1.2234779753413408e-06, 'num_leaves': 181, 'feature_fraction': 0.976593763466587, 'bagging_fraction': 0.7527613295727873, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.1834170913893933, 'max_depth': 28, 'min_gain_to_split': 0.014936741645289683, 'min_sum_hessian_in_leaf': 0.803615881839677}. Best is trial 192 with value: 0.5334179904969364.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:25:25,859] Trial 193 finished with value: 0.5436908416285314 and parameters: {'lambda_l1': 0.001855213191653729, 'lambda_l2': 1.6721159248145598e-06, 'num_leaves': 163, 'feature_fraction': 0.9798422572625618, 'bagging_fraction': 0.7560817336738208, 'bagging_freq': 5, 'min_child_samples': 70, 'learning_rate': 0.16743377395168543, 'max_depth': 29, 'min_gain_to_split': 0.7161847041510777, 'min_sum_hessian_in_leaf': 0.8278285160737124}. Best is trial 192 with value: 0.5334179904969364.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:25:47,506] Trial 194 finished with value: 0.5369701763537236 and parameters: {'lambda_l1': 0.007575882855998449, 'lambda_l2': 1.0881762057145335e-06, 'num_leaves': 193, 'feature_fraction': 0.9899177217745729, 'bagging_fraction': 0.7321498276726626, 'bagging_freq': 5, 'min_child_samples': 74, 'learning_rate': 0.1444500559509864, 'max_depth': 27, 'min_gain_to_split': 0.2818937099834823, 'min_sum_hessian_in_leaf': 1.0831258996319124}. Best is trial 192 with value: 0.5334179904969364.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:25:59,031] Trial 195 finished with value: 0.5737495674615214 and parameters: {'lambda_l1': 0.006046087002040145, 'lambda_l2': 9.599338397621176e-07, 'num_leaves': 185, 'feature_fraction': 0.9659519178207382, 'bagging_fraction': 0.7342440226260415, 'bagging_freq': 5, 'min_child_samples': 74, 'learning_rate': 0.1086824431729469, 'max_depth': 28, 'min_gain_to_split': 5.4103444607916344, 'min_sum_hessian_in_leaf': 1.1130296607215213}. Best is trial 192 with value: 0.5334179904969364.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:26:21,962] Trial 196 finished with value: 0.5328140830331785 and parameters: {'lambda_l1': 0.003139748020570568, 'lambda_l2': 1.2458051706979832e-06, 'num_leaves': 211, 'feature_fraction': 0.9870029226605638, 'bagging_fraction': 0.7518097129979053, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.14231456370140003, 'max_depth': 26, 'min_gain_to_split': 0.03209800311922901, 'min_sum_hessian_in_leaf': 1.2891192151630717}. Best is trial 196 with value: 0.5328140830331785.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:26:45,148] Trial 197 finished with value: 0.5303822047134745 and parameters: {'lambda_l1': 0.009097691407666069, 'lambda_l2': 6.190374079519156e-07, 'num_leaves': 209, 'feature_fraction': 0.9752428029716693, 'bagging_fraction': 0.7560749464410575, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.12097792269103949, 'max_depth': 30, 'min_gain_to_split': 0.015681987381216567, 'min_sum_hessian_in_leaf': 1.3308218415872366}. Best is trial 197 with value: 0.5303822047134745.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:27:06,774] Trial 198 finished with value: 0.5321067690357756 and parameters: {'lambda_l1': 0.01490297277062312, 'lambda_l2': 5.503174882362017e-07, 'num_leaves': 182, 'feature_fraction': 0.9803505446033463, 'bagging_fraction': 0.7508253249184476, 'bagging_freq': 5, 'min_child_samples': 68, 'learning_rate': 0.12087901375805513, 'max_depth': 33, 'min_gain_to_split': 0.042018458554583506, 'min_sum_hessian_in_leaf': 1.61500059644495}. Best is trial 197 with value: 0.5303822047134745.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:27:31,180] Trial 199 finished with value: 0.5311190268599832 and parameters: {'lambda_l1': 0.014673978052959943, 'lambda_l2': 3.6566188054930663e-07, 'num_leaves': 210, 'feature_fraction': 0.9537412601955957, 'bagging_fraction': 0.7609184260020572, 'bagging_freq': 5, 'min_child_samples': 68, 'learning_rate': 0.10090743056351408, 'max_depth': 34, 'min_gain_to_split': 0.04035058062696842, 'min_sum_hessian_in_leaf': 1.8834198430703497}. Best is trial 197 with value: 0.5303822047134745.\n",
      "[I 2023-12-06 19:27:31,181] A new study created in memory with name: no-name-3f91ac20-8904-4dad-a522-558dae20a0a9\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for working days: {'lambda_l1': 0.009097691407666069, 'lambda_l2': 6.190374079519156e-07, 'num_leaves': 209, 'feature_fraction': 0.9752428029716693, 'bagging_fraction': 0.7560749464410575, 'bagging_freq': 5, 'min_child_samples': 71, 'learning_rate': 0.12097792269103949, 'max_depth': 30, 'min_gain_to_split': 0.015681987381216567, 'min_sum_hessian_in_leaf': 1.3308218415872366}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 19:27:33,061] Trial 0 finished with value: 0.7121449574196014 and parameters: {'lambda_l1': 9.95532218636515e-06, 'lambda_l2': 2.2031396391463156, 'num_leaves': 103, 'feature_fraction': 0.4441231596630856, 'bagging_fraction': 0.7997812352372544, 'bagging_freq': 3, 'min_child_samples': 93, 'learning_rate': 0.7256230672303101, 'max_depth': 12, 'min_gain_to_split': 14.001875275635877, 'min_sum_hessian_in_leaf': 6.765156714364593}. Best is trial 0 with value: 0.7121449574196014.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:27:51,222] Trial 1 finished with value: 1.3298463541329515 and parameters: {'lambda_l1': 0.00010936160032919669, 'lambda_l2': 0.3905937348707614, 'num_leaves': 245, 'feature_fraction': 0.7450723024889649, 'bagging_fraction': 0.7407421103513574, 'bagging_freq': 2, 'min_child_samples': 62, 'learning_rate': 0.002436869683365678, 'max_depth': 34, 'min_gain_to_split': 4.794677744361709, 'min_sum_hessian_in_leaf': 2.331312117707083}. Best is trial 0 with value: 0.7121449574196014.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:27:55,885] Trial 2 finished with value: 1.3836493390206734 and parameters: {'lambda_l1': 0.04363708744681223, 'lambda_l2': 4.0012181065092635e-06, 'num_leaves': 25, 'feature_fraction': 0.5755845938418857, 'bagging_fraction': 0.48604359716985873, 'bagging_freq': 1, 'min_child_samples': 68, 'learning_rate': 0.0026606612382573135, 'max_depth': 50, 'min_gain_to_split': 7.842299457677416, 'min_sum_hessian_in_leaf': 1.4394577535247903}. Best is trial 0 with value: 0.7121449574196014.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:06,820] Trial 3 finished with value: 0.9834623766895264 and parameters: {'lambda_l1': 1.2607833713253658e-05, 'lambda_l2': 0.008714146654163207, 'num_leaves': 145, 'feature_fraction': 0.9592093651099128, 'bagging_fraction': 0.7439326695293739, 'bagging_freq': 1, 'min_child_samples': 18, 'learning_rate': 0.007791014153217443, 'max_depth': 26, 'min_gain_to_split': 10.783339581849061, 'min_sum_hessian_in_leaf': 5.840334589504543}. Best is trial 0 with value: 0.7121449574196014.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:21,359] Trial 4 finished with value: 1.345194246387905 and parameters: {'lambda_l1': 8.772770982632068e-08, 'lambda_l2': 0.0355990373519287, 'num_leaves': 184, 'feature_fraction': 0.9697466211543015, 'bagging_fraction': 0.6263470110064734, 'bagging_freq': 5, 'min_child_samples': 69, 'learning_rate': 0.0022268672718623868, 'max_depth': 34, 'min_gain_to_split': 14.498736016533572, 'min_sum_hessian_in_leaf': 8.905283710726412}. Best is trial 0 with value: 0.7121449574196014.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:24,501] Trial 5 finished with value: 0.629041521069202 and parameters: {'lambda_l1': 5.513898718768837e-05, 'lambda_l2': 0.47596541139426274, 'num_leaves': 220, 'feature_fraction': 0.5008920845731624, 'bagging_fraction': 0.9432371871252581, 'bagging_freq': 3, 'min_child_samples': 9, 'learning_rate': 0.23537041905114103, 'max_depth': 17, 'min_gain_to_split': 13.418977558060542, 'min_sum_hessian_in_leaf': 3.080926269559383}. Best is trial 5 with value: 0.629041521069202.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:26,122] Trial 6 finished with value: 1.3815524224984 and parameters: {'lambda_l1': 1.4026798567864072e-05, 'lambda_l2': 1.2093430224997029e-06, 'num_leaves': 4, 'feature_fraction': 0.8673656327661741, 'bagging_fraction': 0.547229259704715, 'bagging_freq': 6, 'min_child_samples': 57, 'learning_rate': 0.003747324054653774, 'max_depth': 11, 'min_gain_to_split': 4.350380595480802, 'min_sum_hessian_in_leaf': 7.462957977457854}. Best is trial 5 with value: 0.629041521069202.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:43,795] Trial 7 finished with value: 1.4015005800711833 and parameters: {'lambda_l1': 2.457329221196936e-07, 'lambda_l2': 3.195664484234469, 'num_leaves': 234, 'feature_fraction': 0.4031301503697553, 'bagging_fraction': 0.6203996420433235, 'bagging_freq': 3, 'min_child_samples': 15, 'learning_rate': 0.002082931359274862, 'max_depth': 47, 'min_gain_to_split': 12.109625000622326, 'min_sum_hessian_in_leaf': 8.105625359483433}. Best is trial 5 with value: 0.629041521069202.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:46,175] Trial 8 finished with value: 0.6999427599084707 and parameters: {'lambda_l1': 0.00369151842698471, 'lambda_l2': 4.357575770606224e-05, 'num_leaves': 9, 'feature_fraction': 0.7355397267107209, 'bagging_fraction': 0.4202313523902593, 'bagging_freq': 4, 'min_child_samples': 26, 'learning_rate': 0.11945625826534602, 'max_depth': 39, 'min_gain_to_split': 13.577612145976879, 'min_sum_hessian_in_leaf': 8.022300035582385}. Best is trial 5 with value: 0.629041521069202.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:28:57,505] Trial 9 finished with value: 1.4431877142000826 and parameters: {'lambda_l1': 0.07837615028983139, 'lambda_l2': 0.04315877527930655, 'num_leaves': 113, 'feature_fraction': 0.5776457406356231, 'bagging_fraction': 0.877413067196439, 'bagging_freq': 4, 'min_child_samples': 95, 'learning_rate': 0.0014429752603447473, 'max_depth': 26, 'min_gain_to_split': 11.09800219119549, 'min_sum_hessian_in_leaf': 4.561781819771944}. Best is trial 5 with value: 0.629041521069202.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:12,426] Trial 10 finished with value: 0.5582578289621613 and parameters: {'lambda_l1': 1.1171660630588167, 'lambda_l2': 2.1232157588631198e-08, 'num_leaves': 175, 'feature_fraction': 0.5510595341157843, 'bagging_fraction': 0.9535009207627863, 'bagging_freq': 7, 'min_child_samples': 35, 'learning_rate': 0.04935988748267486, 'max_depth': -1, 'min_gain_to_split': 0.07635189111518681, 'min_sum_hessian_in_leaf': 0.011868495237746579}. Best is trial 10 with value: 0.5582578289621613.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:28,293] Trial 11 finished with value: 0.550178329344041 and parameters: {'lambda_l1': 3.9414227569794136, 'lambda_l2': 1.28788457817222e-08, 'num_leaves': 191, 'feature_fraction': 0.5410782684838555, 'bagging_fraction': 0.9868529794902486, 'bagging_freq': 7, 'min_child_samples': 37, 'learning_rate': 0.06351915203271477, 'max_depth': -1, 'min_gain_to_split': 0.16735141654224517, 'min_sum_hessian_in_leaf': 0.07026441546212708}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:29,567] Trial 12 finished with value: 1.2497965394617592 and parameters: {'lambda_l1': 3.0803790682433094, 'lambda_l2': 1.0851911279031109e-08, 'num_leaves': 173, 'feature_fraction': 0.6145354651293418, 'bagging_fraction': 0.9965097228976619, 'bagging_freq': 7, 'min_child_samples': 37, 'learning_rate': 0.024656888199633926, 'max_depth': 1, 'min_gain_to_split': 0.2796440471059683, 'min_sum_hessian_in_leaf': 0.0646067049303771}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:45,085] Trial 13 finished with value: 0.5766069989250223 and parameters: {'lambda_l1': 8.306162315345366, 'lambda_l2': 1.3217049737493582e-08, 'num_leaves': 191, 'feature_fraction': 0.5077003714869385, 'bagging_fraction': 0.8652097179110725, 'bagging_freq': 7, 'min_child_samples': 40, 'learning_rate': 0.045835648121688895, 'max_depth': -1, 'min_gain_to_split': 0.01364332212037489, 'min_sum_hessian_in_leaf': 0.479865404837028}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:50,106] Trial 14 finished with value: 0.8388207977566118 and parameters: {'lambda_l1': 0.5624582893420371, 'lambda_l2': 2.3623469910463352e-07, 'num_leaves': 70, 'feature_fraction': 0.6468924007975959, 'bagging_fraction': 0.987283979043053, 'bagging_freq': 6, 'min_child_samples': 40, 'learning_rate': 0.02204875481494716, 'max_depth': 6, 'min_gain_to_split': 1.6538284426918692, 'min_sum_hessian_in_leaf': 1.2379697456365688}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:29:54,717] Trial 15 finished with value: 0.6602454603388088 and parameters: {'lambda_l1': 0.4911468077517229, 'lambda_l2': 2.8315833854090567e-07, 'num_leaves': 149, 'feature_fraction': 0.5073638435142434, 'bagging_fraction': 0.8974464728039044, 'bagging_freq': 6, 'min_child_samples': 32, 'learning_rate': 0.06583014908306037, 'max_depth': 6, 'min_gain_to_split': 2.635303537932426, 'min_sum_hessian_in_leaf': 0.09990111580253111}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:30:10,571] Trial 16 finished with value: 0.7729139843186728 and parameters: {'lambda_l1': 0.003516240478468261, 'lambda_l2': 0.0002088543009322196, 'num_leaves': 202, 'feature_fraction': 0.6718831368523723, 'bagging_fraction': 0.8281573155914903, 'bagging_freq': 7, 'min_child_samples': 50, 'learning_rate': 0.014572013164750087, 'max_depth': 19, 'min_gain_to_split': 2.3786987558579575, 'min_sum_hessian_in_leaf': 3.1337240642040602}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:30:14,128] Trial 17 finished with value: 0.6844573268366574 and parameters: {'lambda_l1': 9.04227701952185, 'lambda_l2': 8.295831104690388e-08, 'num_leaves': 165, 'feature_fraction': 0.5690260858032097, 'bagging_fraction': 0.931020611468497, 'bagging_freq': 5, 'min_child_samples': 49, 'learning_rate': 0.08252380970381175, 'max_depth': 5, 'min_gain_to_split': 4.468250789169205, 'min_sum_hessian_in_leaf': 1.7234553204422858}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:30:23,358] Trial 18 finished with value: 0.5584169578041371 and parameters: {'lambda_l1': 0.4059863900764793, 'lambda_l2': 5.788069404528652e-06, 'num_leaves': 89, 'feature_fraction': 0.4549876004590479, 'bagging_fraction': 0.9487746458383496, 'bagging_freq': 5, 'min_child_samples': 82, 'learning_rate': 0.1531517791574463, 'max_depth': -1, 'min_gain_to_split': 0.23093752087018216, 'min_sum_hessian_in_leaf': 4.088514163234499}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:30:34,183] Trial 19 finished with value: 0.6058700704779552 and parameters: {'lambda_l1': 0.02548619815816978, 'lambda_l2': 5.4830975738235124e-08, 'num_leaves': 209, 'feature_fraction': 0.7037934742073997, 'bagging_fraction': 0.822679120216347, 'bagging_freq': 7, 'min_child_samples': 25, 'learning_rate': 0.04365419086787132, 'max_depth': 12, 'min_gain_to_split': 7.00844581596861, 'min_sum_hessian_in_leaf': 0.9819802811089603}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:30:53,128] Trial 20 finished with value: 0.8947881495130033 and parameters: {'lambda_l1': 1.6642016467632705, 'lambda_l2': 1.0460329969768717e-06, 'num_leaves': 256, 'feature_fraction': 0.5396635230650892, 'bagging_fraction': 0.9929003733269076, 'bagging_freq': 6, 'min_child_samples': 48, 'learning_rate': 0.010789228133373501, 'max_depth': 19, 'min_gain_to_split': 1.5513710701945036, 'min_sum_hessian_in_leaf': 2.0063748713729215}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:01,346] Trial 21 finished with value: 0.5604855172827838 and parameters: {'lambda_l1': 0.7903495951667716, 'lambda_l2': 1.2012156336904954e-05, 'num_leaves': 75, 'feature_fraction': 0.44316688356358874, 'bagging_fraction': 0.930017786520261, 'bagging_freq': 5, 'min_child_samples': 75, 'learning_rate': 0.1598436032156724, 'max_depth': -1, 'min_gain_to_split': 0.14075867805899017, 'min_sum_hessian_in_leaf': 4.400706872880441}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:04,764] Trial 22 finished with value: 0.6285374635336952 and parameters: {'lambda_l1': 0.21003060964434273, 'lambda_l2': 5.177573244410215e-08, 'num_leaves': 79, 'feature_fraction': 0.47272299011039925, 'bagging_fraction': 0.913150027076982, 'bagging_freq': 6, 'min_child_samples': 80, 'learning_rate': 0.21167442594015307, 'max_depth': 5, 'min_gain_to_split': 1.372769461579933, 'min_sum_hessian_in_leaf': 3.0235457971335826}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:07,090] Trial 23 finished with value: 0.8213551463690338 and parameters: {'lambda_l1': 1.8394458863195486, 'lambda_l2': 2.126106595414844e-06, 'num_leaves': 127, 'feature_fraction': 0.42347832809908464, 'bagging_fraction': 0.9603311529433974, 'bagging_freq': 5, 'min_child_samples': 89, 'learning_rate': 0.07713299337006765, 'max_depth': 3, 'min_gain_to_split': 2.9673298746926067, 'min_sum_hessian_in_leaf': 0.8008918080351461}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:12,651] Trial 24 finished with value: 0.6964946078399061 and parameters: {'lambda_l1': 0.14461673075622014, 'lambda_l2': 3.195873538802987e-07, 'num_leaves': 38, 'feature_fraction': 0.4721502748339184, 'bagging_fraction': 0.8702714001787264, 'bagging_freq': 7, 'min_child_samples': 83, 'learning_rate': 0.03649948214672847, 'max_depth': 9, 'min_gain_to_split': 0.0007703375435851312, 'min_sum_hessian_in_leaf': 0.10157252720233334}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:16,555] Trial 25 finished with value: 0.5831010845605152 and parameters: {'lambda_l1': 9.760054211764924, 'lambda_l2': 1.0237890009724949e-08, 'num_leaves': 148, 'feature_fraction': 0.539444419034783, 'bagging_fraction': 0.9442471958401785, 'bagging_freq': 6, 'min_child_samples': 28, 'learning_rate': 0.3174344199335236, 'max_depth': -1, 'min_gain_to_split': 1.1262488788968628, 'min_sum_hessian_in_leaf': 3.735991118218455}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:22,258] Trial 26 finished with value: 0.5883879682881938 and parameters: {'lambda_l1': 0.014904910836245537, 'lambda_l2': 2.2063969099297492e-05, 'num_leaves': 103, 'feature_fraction': 0.6280821943029599, 'bagging_fraction': 0.9596596444798199, 'bagging_freq': 7, 'min_child_samples': 42, 'learning_rate': 0.11579353095983123, 'max_depth': 9, 'min_gain_to_split': 3.814130538871952, 'min_sum_hessian_in_leaf': 5.2013796703176824}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:29,508] Trial 27 finished with value: 0.6202048157451798 and parameters: {'lambda_l1': 0.36115173958949337, 'lambda_l2': 4.178378744331801e-06, 'num_leaves': 53, 'feature_fraction': 0.4080350225534417, 'bagging_fraction': 0.9011406772382072, 'bagging_freq': 5, 'min_child_samples': 57, 'learning_rate': 0.05724981930127546, 'max_depth': 15, 'min_gain_to_split': 3.0897879498318384, 'min_sum_hessian_in_leaf': 2.2877049095160857}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:31,403] Trial 28 finished with value: 1.0687924398373818 and parameters: {'lambda_l1': 2.1825569140384604, 'lambda_l2': 7.261941025574316e-08, 'num_leaves': 131, 'feature_fraction': 0.4687827625981812, 'bagging_fraction': 0.8519584730045365, 'bagging_freq': 4, 'min_child_samples': 34, 'learning_rate': 0.029834758829015016, 'max_depth': 2, 'min_gain_to_split': 1.019257874420079, 'min_sum_hessian_in_leaf': 0.955883348636483}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:35,682] Trial 29 finished with value: 0.5894916743972367 and parameters: {'lambda_l1': 0.13050676467342998, 'lambda_l2': 4.364548501376918e-07, 'num_leaves': 92, 'feature_fraction': 0.44881124427117536, 'bagging_fraction': 0.7930481387969535, 'bagging_freq': 2, 'min_child_samples': 21, 'learning_rate': 0.2659587842807558, 'max_depth': 22, 'min_gain_to_split': 2.015825683747756, 'min_sum_hessian_in_leaf': 6.095272247075467}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:38,637] Trial 30 finished with value: 0.5910930254633819 and parameters: {'lambda_l1': 0.006799695215423541, 'lambda_l2': 0.00012066528869551691, 'num_leaves': 165, 'feature_fraction': 0.6012469858993249, 'bagging_fraction': 0.996496576883109, 'bagging_freq': 4, 'min_child_samples': 10, 'learning_rate': 0.5427980360293028, 'max_depth': 8, 'min_gain_to_split': 0.9363073854204288, 'min_sum_hessian_in_leaf': 1.593623535880462}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:45,663] Trial 31 finished with value: 0.5705161475000246 and parameters: {'lambda_l1': 0.5391156794272508, 'lambda_l2': 1.8006939181671276e-05, 'num_leaves': 54, 'feature_fraction': 0.43531519990690487, 'bagging_fraction': 0.9145878029523808, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.13812648088314275, 'max_depth': -1, 'min_gain_to_split': 0.15651934548498017, 'min_sum_hessian_in_leaf': 4.1917017027344485}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:47,781] Trial 32 finished with value: 0.741012205681754 and parameters: {'lambda_l1': 0.0007536162733086776, 'lambda_l2': 0.0009978602705213288, 'num_leaves': 85, 'feature_fraction': 0.5293619331704084, 'bagging_fraction': 0.9487532594128613, 'bagging_freq': 6, 'min_child_samples': 80, 'learning_rate': 0.15386118737683785, 'max_depth': 3, 'min_gain_to_split': 2.105647312101988, 'min_sum_hessian_in_leaf': 2.5202904386186984}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:49,564] Trial 33 finished with value: 0.7299045551964248 and parameters: {'lambda_l1': 0.05572729347486047, 'lambda_l2': 9.916164158248717e-06, 'num_leaves': 106, 'feature_fraction': 0.4472028469711527, 'bagging_fraction': 0.8955233140296367, 'bagging_freq': 5, 'min_child_samples': 89, 'learning_rate': 0.44410553528577296, 'max_depth': 2, 'min_gain_to_split': 0.8325779000351485, 'min_sum_hessian_in_leaf': 3.848736877888153}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:57,241] Trial 34 finished with value: 0.585424782981334 and parameters: {'lambda_l1': 0.998566769726242, 'lambda_l2': 4.8057091870121236e-06, 'num_leaves': 122, 'feature_fraction': 0.4968554542977467, 'bagging_fraction': 0.9662385375914463, 'bagging_freq': 7, 'min_child_samples': 99, 'learning_rate': 0.09347809666162644, 'max_depth': 13, 'min_gain_to_split': 3.230577226288725, 'min_sum_hessian_in_leaf': 5.2051230162325535}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:31:59,998] Trial 35 finished with value: 0.6814985763844886 and parameters: {'lambda_l1': 0.21075617226590526, 'lambda_l2': 1.4559760232928647e-06, 'num_leaves': 57, 'feature_fraction': 0.40044539590657524, 'bagging_fraction': 0.9228365553359316, 'bagging_freq': 2, 'min_child_samples': 65, 'learning_rate': 0.878335093451435, 'max_depth': 30, 'min_gain_to_split': 1.899918852597919, 'min_sum_hessian_in_leaf': 1.4238294717214344}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:04,266] Trial 36 finished with value: 0.6088029167962056 and parameters: {'lambda_l1': 2.658856842663309, 'lambda_l2': 5.536533249947227e-06, 'num_leaves': 225, 'feature_fraction': 0.5555963499441434, 'bagging_fraction': 0.7830195500485556, 'bagging_freq': 4, 'min_child_samples': 74, 'learning_rate': 0.18838801191309917, 'max_depth': -1, 'min_gain_to_split': 5.436609125461709, 'min_sum_hessian_in_leaf': 0.6402231541255361}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:12,506] Trial 37 finished with value: 0.6094602407695884 and parameters: {'lambda_l1': 0.023294702832159668, 'lambda_l2': 3.670626231097365e-05, 'num_leaves': 183, 'feature_fraction': 0.5862980724476093, 'bagging_fraction': 0.8395784165904354, 'bagging_freq': 3, 'min_child_samples': 57, 'learning_rate': 0.05854118269013107, 'max_depth': 8, 'min_gain_to_split': 0.645215333048107, 'min_sum_hessian_in_leaf': 5.945070562267671}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:18,199] Trial 38 finished with value: 0.6044577674354619 and parameters: {'lambda_l1': 0.0652364052296449, 'lambda_l2': 0.000794453322147135, 'num_leaves': 32, 'feature_fraction': 0.4868166742908688, 'bagging_fraction': 0.7322606292273803, 'bagging_freq': 5, 'min_child_samples': 45, 'learning_rate': 0.10018764955181313, 'max_depth': 42, 'min_gain_to_split': 0.9662027247307199, 'min_sum_hessian_in_leaf': 2.435934196552407}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:20,970] Trial 39 finished with value: 0.6743087898943352 and parameters: {'lambda_l1': 1.162653832065679, 'lambda_l2': 7.201967384650282e-07, 'num_leaves': 66, 'feature_fraction': 0.5300911112855622, 'bagging_fraction': 0.9303270799496492, 'bagging_freq': 6, 'min_child_samples': 60, 'learning_rate': 0.1607331910108607, 'max_depth': 4, 'min_gain_to_split': 2.1424015112784893, 'min_sum_hessian_in_leaf': 9.97404934502241}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:22,337] Trial 40 finished with value: 0.8711861273781016 and parameters: {'lambda_l1': 4.045799310078994, 'lambda_l2': 7.970731912493714e-05, 'num_leaves': 137, 'feature_fraction': 0.44345119639904607, 'bagging_fraction': 0.9711713769863547, 'bagging_freq': 1, 'min_child_samples': 74, 'learning_rate': 0.3076864750356667, 'max_depth': 1, 'min_gain_to_split': 0.007444746772652833, 'min_sum_hessian_in_leaf': 4.744976674428037}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:29,138] Trial 41 finished with value: 0.5768620797044303 and parameters: {'lambda_l1': 0.5547096437251489, 'lambda_l2': 1.474975000278023e-05, 'num_leaves': 48, 'feature_fraction': 0.43231669933003763, 'bagging_fraction': 0.8934913330547545, 'bagging_freq': 5, 'min_child_samples': 73, 'learning_rate': 0.14983537719244738, 'max_depth': -1, 'min_gain_to_split': 0.5062445971158256, 'min_sum_hessian_in_leaf': 4.257211513801374}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:30,547] Trial 42 finished with value: 1.0226668771097651 and parameters: {'lambda_l1': 0.7477763677377148, 'lambda_l2': 9.969201684366923e-06, 'num_leaves': 23, 'feature_fraction': 0.46632932727673426, 'bagging_fraction': 0.9269533835511339, 'bagging_freq': 5, 'min_child_samples': 70, 'learning_rate': 0.09895319340115272, 'max_depth': 1, 'min_gain_to_split': 1.6630148011620376, 'min_sum_hessian_in_leaf': 3.848334189609567}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:40,994] Trial 43 finished with value: 0.570774838088113 and parameters: {'lambda_l1': 0.243820333537543, 'lambda_l2': 2.2576235505827064e-06, 'num_leaves': 95, 'feature_fraction': 0.4332115383001799, 'bagging_fraction': 0.9996410268821833, 'bagging_freq': 4, 'min_child_samples': 86, 'learning_rate': 0.06493640747216244, 'max_depth': -1, 'min_gain_to_split': 0.028178838436894477, 'min_sum_hessian_in_leaf': 6.498341594668758}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:46,278] Trial 44 finished with value: 0.603656707853451 and parameters: {'lambda_l1': 5.165775785065106, 'lambda_l2': 2.2776036184357773e-08, 'num_leaves': 74, 'feature_fraction': 0.5115778889668812, 'bagging_fraction': 0.8827176797018966, 'bagging_freq': 6, 'min_child_samples': 78, 'learning_rate': 0.1395699602725857, 'max_depth': 7, 'min_gain_to_split': 1.004362268707183, 'min_sum_hessian_in_leaf': 5.364713790641662}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:49,092] Trial 45 finished with value: 0.6609436177447882 and parameters: {'lambda_l1': 1.1851841440164166, 'lambda_l2': 1.4626143758184137e-07, 'num_leaves': 198, 'feature_fraction': 0.4850369124822354, 'bagging_fraction': 0.967248690458081, 'bagging_freq': 5, 'min_child_samples': 65, 'learning_rate': 0.21110299151447331, 'max_depth': 4, 'min_gain_to_split': 2.642829031427211, 'min_sum_hessian_in_leaf': 4.50574379228055}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:55,291] Trial 46 finished with value: 0.5822511861062616 and parameters: {'lambda_l1': 3.4248506524866578, 'lambda_l2': 2.82654666113206e-08, 'num_leaves': 65, 'feature_fraction': 0.5611079028524972, 'bagging_fraction': 0.8635456742201381, 'bagging_freq': 7, 'min_child_samples': 92, 'learning_rate': 0.12035354429199469, 'max_depth': 11, 'min_gain_to_split': 1.48311394052185, 'min_sum_hessian_in_leaf': 3.248415244969867}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:32:56,868] Trial 47 finished with value: 1.0617726683343887 and parameters: {'lambda_l1': 0.10200946027526513, 'lambda_l2': 7.56807212638496e-07, 'num_leaves': 17, 'feature_fraction': 0.45479343239043535, 'bagging_fraction': 0.9185076005138226, 'bagging_freq': 3, 'min_child_samples': 35, 'learning_rate': 0.07778145618109944, 'max_depth': 1, 'min_gain_to_split': 0.38861349589312855, 'min_sum_hessian_in_leaf': 1.949439400146678}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:08,953] Trial 48 finished with value: 0.6102559350088914 and parameters: {'lambda_l1': 0.4503354640617081, 'lambda_l2': 2.0561225646186875e-07, 'num_leaves': 115, 'feature_fraction': 0.419010613011505, 'bagging_fraction': 0.9449747020743031, 'bagging_freq': 4, 'min_child_samples': 54, 'learning_rate': 0.04319775393117259, 'max_depth': 33, 'min_gain_to_split': 3.589974943820434, 'min_sum_hessian_in_leaf': 5.65380740393369}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:13,891] Trial 49 finished with value: 0.6851365238497422 and parameters: {'lambda_l1': 0.0452781989380983, 'lambda_l2': 2.4384229292147012e-08, 'num_leaves': 215, 'feature_fraction': 0.5112024577273859, 'bagging_fraction': 0.9762472309437092, 'bagging_freq': 6, 'min_child_samples': 29, 'learning_rate': 0.050970617103314554, 'max_depth': 6, 'min_gain_to_split': 2.4482995347849026, 'min_sum_hessian_in_leaf': 4.825984994806935}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:15,150] Trial 50 finished with value: 1.1952873430117132 and parameters: {'lambda_l1': 6.32409944300672, 'lambda_l2': 1.0524766259624204e-07, 'num_leaves': 181, 'feature_fraction': 0.5910292860814568, 'bagging_fraction': 0.912374551320598, 'bagging_freq': 7, 'min_child_samples': 21, 'learning_rate': 0.034786139397241934, 'max_depth': 1, 'min_gain_to_split': 0.5884359596252823, 'min_sum_hessian_in_leaf': 0.2878129434577805}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:25,581] Trial 51 finished with value: 0.5718027888697612 and parameters: {'lambda_l1': 0.2695231514636667, 'lambda_l2': 2.6951604417419197e-05, 'num_leaves': 88, 'feature_fraction': 0.4247738424144124, 'bagging_fraction': 0.9959145339931362, 'bagging_freq': 4, 'min_child_samples': 87, 'learning_rate': 0.07348121250054515, 'max_depth': -1, 'min_gain_to_split': 0.24213530665577382, 'min_sum_hessian_in_leaf': 6.44775602063498}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:35,967] Trial 52 finished with value: 0.582142878830525 and parameters: {'lambda_l1': 0.9260427104051419, 'lambda_l2': 2.062508804590258e-06, 'num_leaves': 92, 'feature_fraction': 0.43838230418039836, 'bagging_fraction': 0.948693423943946, 'bagging_freq': 4, 'min_child_samples': 83, 'learning_rate': 0.057136777222832544, 'max_depth': -1, 'min_gain_to_split': 0.04283122744250087, 'min_sum_hessian_in_leaf': 1.2118926884254215}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:38,253] Trial 53 finished with value: 0.7774570112456302 and parameters: {'lambda_l1': 0.18900082385408, 'lambda_l2': 2.2554257401215185e-06, 'num_leaves': 99, 'feature_fraction': 0.4012148728923568, 'bagging_fraction': 0.9977373078626611, 'bagging_freq': 5, 'min_child_samples': 95, 'learning_rate': 0.11506871233178294, 'max_depth': 3, 'min_gain_to_split': 1.4419928343217523, 'min_sum_hessian_in_leaf': 7.1388228967041165}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:41,979] Trial 54 finished with value: 0.7005281305958204 and parameters: {'lambda_l1': 0.3757814392173112, 'lambda_l2': 3.9371962221144495e-07, 'num_leaves': 43, 'feature_fraction': 0.48672288847188744, 'bagging_fraction': 0.9759626827964191, 'bagging_freq': 3, 'min_child_samples': 100, 'learning_rate': 0.07047901144340508, 'max_depth': 5, 'min_gain_to_split': 0.7078219171260705, 'min_sum_hessian_in_leaf': 0.381321736424433}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:43,419] Trial 55 finished with value: 1.2667952768740285 and parameters: {'lambda_l1': 1.6087872171700333, 'lambda_l2': 1.0587326639814035e-05, 'num_leaves': 60, 'feature_fraction': 0.4592442288270883, 'bagging_fraction': 0.9418938687342678, 'bagging_freq': 4, 'min_child_samples': 87, 'learning_rate': 0.02208112744054704, 'max_depth': 1, 'min_gain_to_split': 0.005503857229021664, 'min_sum_hessian_in_leaf': 4.282384554011183}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:46,205] Trial 56 finished with value: 0.6800511264892106 and parameters: {'lambda_l1': 3.269531186123515, 'lambda_l2': 6.412795915802316e-07, 'num_leaves': 159, 'feature_fraction': 0.42334087449176555, 'bagging_fraction': 0.8842975363684027, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.16558595189787506, 'max_depth': 4, 'min_gain_to_split': 1.426162211469803, 'min_sum_hessian_in_leaf': 0.6269870096172918}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:33:53,590] Trial 57 finished with value: 0.5808760226727987 and parameters: {'lambda_l1': 0.09323835002145225, 'lambda_l2': 1.409864618001623e-07, 'num_leaves': 76, 'feature_fraction': 0.5171901796471395, 'bagging_fraction': 0.9815863636682959, 'bagging_freq': 6, 'min_child_samples': 76, 'learning_rate': 0.08729023730047297, 'max_depth': 10, 'min_gain_to_split': 2.068410655886164, 'min_sum_hessian_in_leaf': 6.542146033099385}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:06,833] Trial 58 finished with value: 0.5828839570612179 and parameters: {'lambda_l1': 0.3299431400770745, 'lambda_l2': 4.432443505264378e-08, 'num_leaves': 142, 'feature_fraction': 0.4901662934705234, 'bagging_fraction': 0.9075174027138067, 'bagging_freq': 7, 'min_child_samples': 40, 'learning_rate': 0.04487999680234675, 'max_depth': 49, 'min_gain_to_split': 1.2390258892295605, 'min_sum_hessian_in_leaf': 0.025629771388205477}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:11,827] Trial 59 finished with value: 0.5659371881312925 and parameters: {'lambda_l1': 0.8036294818654404, 'lambda_l2': 1.053909401158239e-08, 'num_leaves': 113, 'feature_fraction': 0.5507419245512162, 'bagging_fraction': 0.952504029886668, 'bagging_freq': 5, 'min_child_samples': 70, 'learning_rate': 0.2553342447572064, 'max_depth': 14, 'min_gain_to_split': 0.5503852616577822, 'min_sum_hessian_in_leaf': 5.637425538716718}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:17,545] Trial 60 finished with value: 0.5691675282028033 and parameters: {'lambda_l1': 8.802659874700158, 'lambda_l2': 1.4592821213688962e-08, 'num_leaves': 236, 'feature_fraction': 0.5521443029458467, 'bagging_fraction': 0.8551532656837092, 'bagging_freq': 5, 'min_child_samples': 68, 'learning_rate': 0.24235120342589528, 'max_depth': 15, 'min_gain_to_split': 0.6193051954879457, 'min_sum_hessian_in_leaf': 4.991709420088234}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:23,615] Trial 61 finished with value: 0.572927701718139 and parameters: {'lambda_l1': 6.269774877160237, 'lambda_l2': 1.0339224202770944e-08, 'num_leaves': 229, 'feature_fraction': 0.5369140596178613, 'bagging_fraction': 0.9334620821073227, 'bagging_freq': 5, 'min_child_samples': 70, 'learning_rate': 0.26245248211447053, 'max_depth': 22, 'min_gain_to_split': 0.5575748080825302, 'min_sum_hessian_in_leaf': 4.9832547143511245}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:28,819] Trial 62 finished with value: 0.5784504217891355 and parameters: {'lambda_l1': 9.224563239710553, 'lambda_l2': 1.881850294055781e-08, 'num_leaves': 249, 'feature_fraction': 0.5666327879388995, 'bagging_fraction': 0.9592394450081227, 'bagging_freq': 5, 'min_child_samples': 66, 'learning_rate': 0.224464543483372, 'max_depth': 16, 'min_gain_to_split': 1.176607341765046, 'min_sum_hessian_in_leaf': 5.624855335940834}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:36,374] Trial 63 finished with value: 0.5628646201431569 and parameters: {'lambda_l1': 2.027944197080591, 'lambda_l2': 3.8167452418440945e-08, 'num_leaves': 237, 'feature_fraction': 0.5528325287693655, 'bagging_fraction': 0.8707633957047808, 'bagging_freq': 6, 'min_child_samples': 61, 'learning_rate': 0.18944904709237004, 'max_depth': 19, 'min_gain_to_split': 0.5768119982807105, 'min_sum_hessian_in_leaf': 5.408916070559253}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:39,698] Trial 64 finished with value: 0.5852223033207443 and parameters: {'lambda_l1': 1.9365421319482117, 'lambda_l2': 4.7145827203569564e-08, 'num_leaves': 237, 'feature_fraction': 0.6113199998172908, 'bagging_fraction': 0.8501436918431116, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 0.37153657273294305, 'max_depth': 19, 'min_gain_to_split': 1.687808133433152, 'min_sum_hessian_in_leaf': 5.088489180671497}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:46,614] Trial 65 finished with value: 0.5627691089232847 and parameters: {'lambda_l1': 3.2134941761845472, 'lambda_l2': 3.474024018446173e-08, 'num_leaves': 208, 'feature_fraction': 0.5544955631808018, 'bagging_fraction': 0.8709154438917961, 'bagging_freq': 6, 'min_child_samples': 62, 'learning_rate': 0.18692956272717165, 'max_depth': 14, 'min_gain_to_split': 0.6101402440628396, 'min_sum_hessian_in_leaf': 6.069437045353498}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:51,696] Trial 66 finished with value: 0.5860542826283794 and parameters: {'lambda_l1': 2.3449466363185296, 'lambda_l2': 8.565249641039877e-08, 'num_leaves': 213, 'feature_fraction': 0.5856035979794438, 'bagging_fraction': 0.8755848699044597, 'bagging_freq': 6, 'min_child_samples': 63, 'learning_rate': 0.18554296640319634, 'max_depth': 24, 'min_gain_to_split': 2.605495026360276, 'min_sum_hessian_in_leaf': 6.212586932198582}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:54,613] Trial 67 finished with value: 0.6021767187392177 and parameters: {'lambda_l1': 0.7775555111653135, 'lambda_l2': 3.638144969040345e-08, 'num_leaves': 198, 'feature_fraction': 0.6279718637355596, 'bagging_fraction': 0.8160281442299325, 'bagging_freq': 7, 'min_child_samples': 53, 'learning_rate': 0.5688827014231099, 'max_depth': 27, 'min_gain_to_split': 1.8645680146015753, 'min_sum_hessian_in_leaf': 5.466982382612487}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:34:58,628] Trial 68 finished with value: 0.5833066965192165 and parameters: {'lambda_l1': 4.042116219643745, 'lambda_l2': 2.0971514892250547e-07, 'num_leaves': 207, 'feature_fraction': 0.5455152828758325, 'bagging_fraction': 0.8948144251801878, 'bagging_freq': 6, 'min_child_samples': 62, 'learning_rate': 0.3459442500039017, 'max_depth': 18, 'min_gain_to_split': 1.0933774761047304, 'min_sum_hessian_in_leaf': 5.803812460850992}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:04,365] Trial 69 finished with value: 0.5616340977681207 and parameters: {'lambda_l1': 1.355520369099555, 'lambda_l2': 6.843879466326729e-08, 'num_leaves': 112, 'feature_fraction': 0.6520519511642296, 'bagging_fraction': 0.954882673996058, 'bagging_freq': 7, 'min_child_samples': 47, 'learning_rate': 0.1916671883883199, 'max_depth': 13, 'min_gain_to_split': 0.595810359453859, 'min_sum_hessian_in_leaf': 6.084719012529287}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:12,477] Trial 70 finished with value: 0.5736696646055207 and parameters: {'lambda_l1': 1.5156314780238866, 'lambda_l2': 6.388103245657999e-08, 'num_leaves': 189, 'feature_fraction': 0.5708029028626865, 'bagging_fraction': 0.93676310170773, 'bagging_freq': 7, 'min_child_samples': 47, 'learning_rate': 0.10768608638539402, 'max_depth': 22, 'min_gain_to_split': 2.2590448130147323, 'min_sum_hessian_in_leaf': 7.174491175275507}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:18,411] Trial 71 finished with value: 0.5592606762046841 and parameters: {'lambda_l1': 0.6878998508653118, 'lambda_l2': 1.8008521871953774e-08, 'num_leaves': 109, 'feature_fraction': 0.6509665897462705, 'bagging_fraction': 0.96278349519394, 'bagging_freq': 7, 'min_child_samples': 44, 'learning_rate': 0.1894658957405737, 'max_depth': 14, 'min_gain_to_split': 0.5861619669194856, 'min_sum_hessian_in_leaf': 5.979720905292237}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:24,708] Trial 72 finished with value: 0.5610207729462915 and parameters: {'lambda_l1': 2.41995772567368, 'lambda_l2': 2.8103827023464258e-08, 'num_leaves': 174, 'feature_fraction': 0.658740384774195, 'bagging_fraction': 0.9777511402945156, 'bagging_freq': 7, 'min_child_samples': 44, 'learning_rate': 0.1871651065441293, 'max_depth': 13, 'min_gain_to_split': 0.7828022285331311, 'min_sum_hessian_in_leaf': 6.10768213832769}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:32,468] Trial 73 finished with value: 0.5596836451363674 and parameters: {'lambda_l1': 4.54097256511266, 'lambda_l2': 1.829436518560342e-08, 'num_leaves': 161, 'feature_fraction': 0.6649822692620124, 'bagging_fraction': 0.9793687210945954, 'bagging_freq': 7, 'min_child_samples': 44, 'learning_rate': 0.1258681939576474, 'max_depth': 13, 'min_gain_to_split': 1.0931580751224723, 'min_sum_hessian_in_leaf': 5.974627984070829}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:40,600] Trial 74 finished with value: 0.5579599705896433 and parameters: {'lambda_l1': 0.14872489521988103, 'lambda_l2': 1.7886174400712548e-08, 'num_leaves': 172, 'feature_fraction': 0.6610422920481192, 'bagging_fraction': 0.9798944077134227, 'bagging_freq': 7, 'min_child_samples': 42, 'learning_rate': 0.1260009000402163, 'max_depth': 12, 'min_gain_to_split': 1.2333585047500308, 'min_sum_hessian_in_leaf': 6.770202832658393}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:47,701] Trial 75 finished with value: 0.5714943256835715 and parameters: {'lambda_l1': 0.4772299305640857, 'lambda_l2': 2.02873839898916e-08, 'num_leaves': 158, 'feature_fraction': 0.7017569549510698, 'bagging_fraction': 0.9791425751146362, 'bagging_freq': 7, 'min_child_samples': 44, 'learning_rate': 0.1287379971361602, 'max_depth': 9, 'min_gain_to_split': 1.1915092829132485, 'min_sum_hessian_in_leaf': 1.0312054330914346}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:35:57,444] Trial 76 finished with value: 0.5643875575653792 and parameters: {'lambda_l1': 0.16723409113001486, 'lambda_l2': 1.6678329235447635e-08, 'num_leaves': 174, 'feature_fraction': 0.674160142234374, 'bagging_fraction': 0.9643358187666068, 'bagging_freq': 7, 'min_child_samples': 37, 'learning_rate': 0.08595207765324232, 'max_depth': 11, 'min_gain_to_split': 1.7132612064013104, 'min_sum_hessian_in_leaf': 6.851534112189655}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:05,482] Trial 77 finished with value: 0.5562114436649376 and parameters: {'lambda_l1': 0.13595356656948568, 'lambda_l2': 1.2066722424259267e-07, 'num_leaves': 173, 'feature_fraction': 0.7188407647836837, 'bagging_fraction': 0.9838394677725635, 'bagging_freq': 7, 'min_child_samples': 31, 'learning_rate': 0.1254075153404333, 'max_depth': 12, 'min_gain_to_split': 1.042475153282317, 'min_sum_hessian_in_leaf': 6.8382358246477555}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:10,347] Trial 78 finished with value: 0.5922049498296256 and parameters: {'lambda_l1': 0.07536762080768218, 'lambda_l2': 1.2048739031273258e-07, 'num_leaves': 155, 'feature_fraction': 0.7289184664274431, 'bagging_fraction': 0.9839761374932658, 'bagging_freq': 7, 'min_child_samples': 33, 'learning_rate': 0.1419430933162458, 'max_depth': 7, 'min_gain_to_split': 2.8368600127352543, 'min_sum_hessian_in_leaf': 7.836085768848454}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:11,869] Trial 79 finished with value: 0.8720168403904749 and parameters: {'lambda_l1': 0.14447468350985956, 'lambda_l2': 2.5087149074570713e-07, 'num_leaves': 170, 'feature_fraction': 0.6899996308329858, 'bagging_fraction': 0.9304276945853925, 'bagging_freq': 7, 'min_child_samples': 30, 'learning_rate': 0.10004893927511625, 'max_depth': 2, 'min_gain_to_split': 1.2955932960655319, 'min_sum_hessian_in_leaf': 6.857040433445909}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:19,619] Trial 80 finished with value: 0.5675103753623904 and parameters: {'lambda_l1': 0.31688679291292793, 'lambda_l2': 1.803008752052217e-08, 'num_leaves': 192, 'feature_fraction': 0.6349449174387307, 'bagging_fraction': 0.9632733216208843, 'bagging_freq': 7, 'min_child_samples': 39, 'learning_rate': 0.11706560306096522, 'max_depth': 39, 'min_gain_to_split': 2.190151162474089, 'min_sum_hessian_in_leaf': 0.3573337293468118}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:26,724] Trial 81 finished with value: 0.5556984671531507 and parameters: {'lambda_l1': 0.6765803113112693, 'lambda_l2': 6.896935686854786e-08, 'num_leaves': 177, 'feature_fraction': 0.6582451555977189, 'bagging_fraction': 0.9880403374550515, 'bagging_freq': 7, 'min_child_samples': 43, 'learning_rate': 0.15263773281747534, 'max_depth': 16, 'min_gain_to_split': 0.8658051140111468, 'min_sum_hessian_in_leaf': 5.841061741088776}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:37,654] Trial 82 finished with value: 0.5501813124324079 and parameters: {'lambda_l1': 0.033665160787649, 'lambda_l2': 8.588026234645881e-08, 'num_leaves': 179, 'feature_fraction': 0.6081814984681443, 'bagging_fraction': 0.9875931071967388, 'bagging_freq': 7, 'min_child_samples': 51, 'learning_rate': 0.1439206834416043, 'max_depth': 12, 'min_gain_to_split': 0.22447894936126006, 'min_sum_hessian_in_leaf': 5.818825526697448}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:36:49,237] Trial 83 finished with value: 0.5535571619567341 and parameters: {'lambda_l1': 0.03849731848517396, 'lambda_l2': 5.1197195135793395e-08, 'num_leaves': 179, 'feature_fraction': 0.6101778722400528, 'bagging_fraction': 0.9984520399129904, 'bagging_freq': 7, 'min_child_samples': 51, 'learning_rate': 0.08679389573608966, 'max_depth': 16, 'min_gain_to_split': 0.9893437421161648, 'min_sum_hessian_in_leaf': 5.836471709281264}. Best is trial 11 with value: 0.550178329344041.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:37:03,663] Trial 84 finished with value: 0.5438557158302612 and parameters: {'lambda_l1': 0.021968512758544688, 'lambda_l2': 6.12386841328257e-08, 'num_leaves': 179, 'feature_fraction': 0.6019271742331431, 'bagging_fraction': 0.9962968674881792, 'bagging_freq': 7, 'min_child_samples': 26, 'learning_rate': 0.07613325801141124, 'max_depth': 17, 'min_gain_to_split': 0.3760348420498488, 'min_sum_hessian_in_leaf': 6.574713075009415}. Best is trial 84 with value: 0.5438557158302612.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:37:17,986] Trial 85 finished with value: 0.5415895190375821 and parameters: {'lambda_l1': 0.03363827510437601, 'lambda_l2': 9.338674267565155e-08, 'num_leaves': 179, 'feature_fraction': 0.6035188124072914, 'bagging_fraction': 0.9999807994707987, 'bagging_freq': 7, 'min_child_samples': 24, 'learning_rate': 0.08580339923768039, 'max_depth': 17, 'min_gain_to_split': 0.32367292352300114, 'min_sum_hessian_in_leaf': 6.315139067605256}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:37:30,552] Trial 86 finished with value: 0.55549709729123 and parameters: {'lambda_l1': 0.01950149995860667, 'lambda_l2': 8.401528156907746e-08, 'num_leaves': 179, 'feature_fraction': 0.6030013855982513, 'bagging_fraction': 0.9962036206046044, 'bagging_freq': 7, 'min_child_samples': 13, 'learning_rate': 0.0660131883462754, 'max_depth': 17, 'min_gain_to_split': 1.7278924928187056, 'min_sum_hessian_in_leaf': 6.3497839608761115}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:37:41,158] Trial 87 finished with value: 0.5557990201851404 and parameters: {'lambda_l1': 0.027660092737880008, 'lambda_l2': 8.413200723747331e-08, 'num_leaves': 183, 'feature_fraction': 0.6003897047313733, 'bagging_fraction': 0.9964024839424926, 'bagging_freq': 7, 'min_child_samples': 14, 'learning_rate': 0.0858039612168978, 'max_depth': 17, 'min_gain_to_split': 1.7887328088484897, 'min_sum_hessian_in_leaf': 6.351558613518045}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:37:52,009] Trial 88 finished with value: 0.5533284334157251 and parameters: {'lambda_l1': 0.023196369434454824, 'lambda_l2': 1.4665170383962984e-07, 'num_leaves': 180, 'feature_fraction': 0.6042300228818098, 'bagging_fraction': 0.9966666898629986, 'bagging_freq': 7, 'min_child_samples': 12, 'learning_rate': 0.08386211377139507, 'max_depth': 17, 'min_gain_to_split': 1.6110652775746421, 'min_sum_hessian_in_leaf': 5.802209197536881}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:38:04,771] Trial 89 finished with value: 0.553135897862613 and parameters: {'lambda_l1': 0.019506403800116912, 'lambda_l2': 6.950086015099586e-08, 'num_leaves': 179, 'feature_fraction': 0.6032121549013594, 'bagging_fraction': 0.9992913955348044, 'bagging_freq': 7, 'min_child_samples': 6, 'learning_rate': 0.06841031044682659, 'max_depth': 20, 'min_gain_to_split': 1.7150180280759169, 'min_sum_hessian_in_leaf': 6.5130205486457164}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:38:17,453] Trial 90 finished with value: 0.5592153671295316 and parameters: {'lambda_l1': 0.009796085478492861, 'lambda_l2': 3.1911250814896646e-07, 'num_leaves': 194, 'feature_fraction': 0.6147076173984733, 'bagging_fraction': 0.9962485502205876, 'bagging_freq': 7, 'min_child_samples': 7, 'learning_rate': 0.06412321419198876, 'max_depth': 20, 'min_gain_to_split': 2.5010025162680245, 'min_sum_hessian_in_leaf': 6.32250122060931}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:38:28,297] Trial 91 finished with value: 0.5560086558593687 and parameters: {'lambda_l1': 0.02921681581522848, 'lambda_l2': 7.714101074346594e-08, 'num_leaves': 181, 'feature_fraction': 0.595924322378055, 'bagging_fraction': 0.9983362867487092, 'bagging_freq': 7, 'min_child_samples': 12, 'learning_rate': 0.08214920657206135, 'max_depth': 17, 'min_gain_to_split': 1.8033566343989715, 'min_sum_hessian_in_leaf': 6.350468161682219}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:38:43,066] Trial 92 finished with value: 0.5417396228054674 and parameters: {'lambda_l1': 0.018455297797987425, 'lambda_l2': 1.8056581599323925e-07, 'num_leaves': 185, 'feature_fraction': 0.605295215420152, 'bagging_fraction': 0.9877157565756273, 'bagging_freq': 7, 'min_child_samples': 15, 'learning_rate': 0.07260313114292995, 'max_depth': 17, 'min_gain_to_split': 0.31705260437729743, 'min_sum_hessian_in_leaf': 5.768590484067289}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:38:57,403] Trial 93 finished with value: 0.5509598416920927 and parameters: {'lambda_l1': 0.014038605178866622, 'lambda_l2': 1.923352263151239e-07, 'num_leaves': 167, 'feature_fraction': 0.5828871375205281, 'bagging_fraction': 0.9692393813369057, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.053651066780922456, 'max_depth': 21, 'min_gain_to_split': 0.2564000779771514, 'min_sum_hessian_in_leaf': 5.6964493687960305}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:39:11,856] Trial 94 finished with value: 0.5521316982894384 and parameters: {'lambda_l1': 0.01265302013456491, 'lambda_l2': 1.560158606546741e-07, 'num_leaves': 165, 'feature_fraction': 0.5815095229437857, 'bagging_fraction': 0.9697492088447853, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.05444715315485296, 'max_depth': 21, 'min_gain_to_split': 0.38792623906219975, 'min_sum_hessian_in_leaf': 6.577696731094983}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:39:26,380] Trial 95 finished with value: 0.5598260919545262 and parameters: {'lambda_l1': 0.004786041557042582, 'lambda_l2': 1.7478127110535302e-07, 'num_leaves': 167, 'feature_fraction': 0.5777633948392551, 'bagging_fraction': 0.9680042927593704, 'bagging_freq': 7, 'min_child_samples': 17, 'learning_rate': 0.04655069186856634, 'max_depth': 21, 'min_gain_to_split': 0.23733474962673595, 'min_sum_hessian_in_leaf': 6.576338795912978}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:39:41,843] Trial 96 finished with value: 0.5459447569084688 and parameters: {'lambda_l1': 0.01044027680899101, 'lambda_l2': 1.8992470851108555e-07, 'num_leaves': 188, 'feature_fraction': 0.5783317040897206, 'bagging_fraction': 0.9492843297682972, 'bagging_freq': 7, 'min_child_samples': 24, 'learning_rate': 0.060116846918492076, 'max_depth': 26, 'min_gain_to_split': 0.2630614541106715, 'min_sum_hessian_in_leaf': 5.345438854578603}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:39:57,272] Trial 97 finished with value: 0.5495001462449072 and parameters: {'lambda_l1': 0.012306719580086813, 'lambda_l2': 4.525413795070833e-07, 'num_leaves': 187, 'feature_fraction': 0.5868480945834433, 'bagging_fraction': 0.9386358617748649, 'bagging_freq': 7, 'min_child_samples': 23, 'learning_rate': 0.055142457528200614, 'max_depth': 24, 'min_gain_to_split': 0.3243476538767343, 'min_sum_hessian_in_leaf': 5.379292255402173}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:40:11,171] Trial 98 finished with value: 0.5541329029057374 and parameters: {'lambda_l1': 0.015441609016230035, 'lambda_l2': 4.471490209158556e-07, 'num_leaves': 150, 'feature_fraction': 0.5849520955195907, 'bagging_fraction': 0.9464517681425121, 'bagging_freq': 7, 'min_child_samples': 22, 'learning_rate': 0.053930054318850014, 'max_depth': 24, 'min_gain_to_split': 0.2639682263310817, 'min_sum_hessian_in_leaf': 5.297234782192561}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:40:27,102] Trial 99 finished with value: 0.5468179163417554 and parameters: {'lambda_l1': 0.010442117162909567, 'lambda_l2': 3.182112894247361e-07, 'num_leaves': 188, 'feature_fraction': 0.5725406668819801, 'bagging_fraction': 0.953646234715691, 'bagging_freq': 7, 'min_child_samples': 27, 'learning_rate': 0.060173691695439575, 'max_depth': 28, 'min_gain_to_split': 0.31200252570693454, 'min_sum_hessian_in_leaf': 4.607412528603794}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:40:42,962] Trial 100 finished with value: 0.577907178171294 and parameters: {'lambda_l1': 0.00977114542279324, 'lambda_l2': 5.243036741314848e-07, 'num_leaves': 188, 'feature_fraction': 0.5714010644719568, 'bagging_fraction': 0.9246101585649478, 'bagging_freq': 7, 'min_child_samples': 25, 'learning_rate': 0.03664988120840919, 'max_depth': 27, 'min_gain_to_split': 0.3147936272346165, 'min_sum_hessian_in_leaf': 4.679050636882232}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:40:59,485] Trial 101 finished with value: 0.5444885774814351 and parameters: {'lambda_l1': 0.0018034741468974519, 'lambda_l2': 2.872846732258322e-07, 'num_leaves': 201, 'feature_fraction': 0.5804793255742735, 'bagging_fraction': 0.9697945533434721, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.059675296748254045, 'max_depth': 29, 'min_gain_to_split': 0.2979087348422691, 'min_sum_hessian_in_leaf': 5.5214925512420185}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:41:16,241] Trial 102 finished with value: 0.5486728218735987 and parameters: {'lambda_l1': 0.0025975392368255373, 'lambda_l2': 3.1892943594484664e-07, 'num_leaves': 202, 'feature_fraction': 0.5783723545845735, 'bagging_fraction': 0.9535643949482586, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.05349901569379367, 'max_depth': 29, 'min_gain_to_split': 0.31061788097756915, 'min_sum_hessian_in_leaf': 5.218164547276585}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:41:32,697] Trial 103 finished with value: 0.5610674502511911 and parameters: {'lambda_l1': 0.004593229785067099, 'lambda_l2': 9.842499325051562e-07, 'num_leaves': 203, 'feature_fraction': 0.5625905189923373, 'bagging_fraction': 0.9418108790361229, 'bagging_freq': 7, 'min_child_samples': 27, 'learning_rate': 0.04135194505072145, 'max_depth': 32, 'min_gain_to_split': 0.0169094847996476, 'min_sum_hessian_in_leaf': 5.149284641549845}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:41:49,823] Trial 104 finished with value: 0.5486180488911836 and parameters: {'lambda_l1': 0.002778008052345148, 'lambda_l2': 3.013559129029562e-07, 'num_leaves': 218, 'feature_fraction': 0.6244551848412648, 'bagging_fraction': 0.9555629731705887, 'bagging_freq': 7, 'min_child_samples': 23, 'learning_rate': 0.05245714602754159, 'max_depth': 29, 'min_gain_to_split': 0.3092660444819122, 'min_sum_hessian_in_leaf': 5.5281764456082945}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:42:05,721] Trial 105 finished with value: 0.5491209874127568 and parameters: {'lambda_l1': 0.0015653809263004622, 'lambda_l2': 3.0653409156990065e-07, 'num_leaves': 218, 'feature_fraction': 0.6201943034769588, 'bagging_fraction': 0.954056786083332, 'bagging_freq': 7, 'min_child_samples': 23, 'learning_rate': 0.06283666346767139, 'max_depth': 26, 'min_gain_to_split': 0.9249565435326789, 'min_sum_hessian_in_leaf': 4.8934711760976235}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:42:23,978] Trial 106 finished with value: 0.5533387520477356 and parameters: {'lambda_l1': 0.0019889197686468996, 'lambda_l2': 4.4263375291442283e-07, 'num_leaves': 223, 'feature_fraction': 0.6315792523633529, 'bagging_fraction': 0.9520561584438718, 'bagging_freq': 7, 'min_child_samples': 23, 'learning_rate': 0.050181518946129995, 'max_depth': 29, 'min_gain_to_split': 0.886317169081642, 'min_sum_hessian_in_leaf': 4.883837047554074}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:42:38,812] Trial 107 finished with value: 0.5479720356064397 and parameters: {'lambda_l1': 0.002341089806801795, 'lambda_l2': 2.6815979582712713e-07, 'num_leaves': 199, 'feature_fraction': 0.6253838709376092, 'bagging_fraction': 0.9186108573329386, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.0722149648275657, 'max_depth': 30, 'min_gain_to_split': 0.8122470621126504, 'min_sum_hessian_in_leaf': 5.258302354944756}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:42:54,932] Trial 108 finished with value: 0.5488879100090072 and parameters: {'lambda_l1': 0.0032156406958065383, 'lambda_l2': 2.7622101755973663e-07, 'num_leaves': 214, 'feature_fraction': 0.6217679888575729, 'bagging_fraction': 0.9134363585647729, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.06279075900867445, 'max_depth': 30, 'min_gain_to_split': 0.8249697077662228, 'min_sum_hessian_in_leaf': 5.506092047383669}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:43:11,519] Trial 109 finished with value: 0.5473564352140394 and parameters: {'lambda_l1': 0.0017779234330455983, 'lambda_l2': 2.75983677550738e-07, 'num_leaves': 216, 'feature_fraction': 0.6208251581577596, 'bagging_fraction': 0.9160187135550906, 'bagging_freq': 6, 'min_child_samples': 16, 'learning_rate': 0.06245394871207496, 'max_depth': 30, 'min_gain_to_split': 0.725266339534197, 'min_sum_hessian_in_leaf': 4.499887315831237}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:43:25,014] Trial 110 finished with value: 0.5525081972436826 and parameters: {'lambda_l1': 0.00641057075757373, 'lambda_l2': 8.291420938789806e-07, 'num_leaves': 199, 'feature_fraction': 0.6365877470014689, 'bagging_fraction': 0.9003313722446066, 'bagging_freq': 6, 'min_child_samples': 16, 'learning_rate': 0.07183779140096261, 'max_depth': 30, 'min_gain_to_split': 1.3584838015883645, 'min_sum_hessian_in_leaf': 4.548542121184944}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:43:42,049] Trial 111 finished with value: 0.5491617078057441 and parameters: {'lambda_l1': 0.0025057929150399524, 'lambda_l2': 2.678937187693804e-07, 'num_leaves': 216, 'feature_fraction': 0.6223557771829289, 'bagging_fraction': 0.9159704405539845, 'bagging_freq': 6, 'min_child_samples': 19, 'learning_rate': 0.06034982979474897, 'max_depth': 29, 'min_gain_to_split': 0.7492382776528094, 'min_sum_hessian_in_leaf': 4.748125936531878}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:43:57,607] Trial 112 finished with value: 0.547874637109847 and parameters: {'lambda_l1': 0.0026552835951229054, 'lambda_l2': 1.3915731027389683e-06, 'num_leaves': 230, 'feature_fraction': 0.6208384926352104, 'bagging_fraction': 0.9190061288886034, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.07228491921652495, 'max_depth': 36, 'min_gain_to_split': 0.8091259489062177, 'min_sum_hessian_in_leaf': 5.095807446588249}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:44:10,313] Trial 113 finished with value: 0.551687783787781 and parameters: {'lambda_l1': 0.0011466811651737099, 'lambda_l2': 1.3580588944747915e-06, 'num_leaves': 204, 'feature_fraction': 0.6439825871940317, 'bagging_fraction': 0.9115451847413316, 'bagging_freq': 6, 'min_child_samples': 10, 'learning_rate': 0.07541760914782263, 'max_depth': 35, 'min_gain_to_split': 1.4127415728887962, 'min_sum_hessian_in_leaf': 5.516599019542836}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:44:28,572] Trial 114 finished with value: 0.5547992424735223 and parameters: {'lambda_l1': 0.0030703603218054107, 'lambda_l2': 6.791889439146906e-07, 'num_leaves': 231, 'feature_fraction': 0.6229671796924144, 'bagging_fraction': 0.927476719105808, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.04533316264231825, 'max_depth': 32, 'min_gain_to_split': 0.48393299087410546, 'min_sum_hessian_in_leaf': 5.1847584324064115}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:44:39,970] Trial 115 finished with value: 0.5521315911198454 and parameters: {'lambda_l1': 0.003442816175455563, 'lambda_l2': 2.595764777315753e-07, 'num_leaves': 212, 'feature_fraction': 0.5924596950779835, 'bagging_fraction': 0.906076110428806, 'bagging_freq': 6, 'min_child_samples': 25, 'learning_rate': 0.10470310971601843, 'max_depth': 35, 'min_gain_to_split': 0.8016157537408775, 'min_sum_hessian_in_leaf': 5.5000210684509385}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:45:00,264] Trial 116 finished with value: 0.5834418727190566 and parameters: {'lambda_l1': 0.0007250174302395853, 'lambda_l2': 9.9828173771184e-07, 'num_leaves': 244, 'feature_fraction': 0.6428794500414491, 'bagging_fraction': 0.9362544171471534, 'bagging_freq': 6, 'min_child_samples': 16, 'learning_rate': 0.029819093441694772, 'max_depth': 28, 'min_gain_to_split': 0.0062836302021623824, 'min_sum_hessian_in_leaf': 4.421587088802758}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:45:17,194] Trial 117 finished with value: 0.5452126963199174 and parameters: {'lambda_l1': 0.00803402431791287, 'lambda_l2': 3.5906995029122266e-07, 'num_leaves': 226, 'feature_fraction': 0.6180348358790098, 'bagging_fraction': 0.8900471538677474, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.07443838359446474, 'max_depth': 31, 'min_gain_to_split': 0.44902185344817036, 'min_sum_hessian_in_leaf': 5.076170202375924}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:45:31,199] Trial 118 finished with value: 0.5482409031321993 and parameters: {'lambda_l1': 0.006622399472017158, 'lambda_l2': 5.888785073105109e-07, 'num_leaves': 224, 'feature_fraction': 0.5668999458790168, 'bagging_fraction': 0.8874954814889213, 'bagging_freq': 6, 'min_child_samples': 28, 'learning_rate': 0.09817627190457466, 'max_depth': 32, 'min_gain_to_split': 0.45747764267315283, 'min_sum_hessian_in_leaf': 5.016191257745537}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:45:41,219] Trial 119 finished with value: 0.5573791952173172 and parameters: {'lambda_l1': 0.00795891095104286, 'lambda_l2': 6.126997588579966e-07, 'num_leaves': 225, 'feature_fraction': 0.5955943508707217, 'bagging_fraction': 0.9211767008442012, 'bagging_freq': 6, 'min_child_samples': 28, 'learning_rate': 0.10230064066803567, 'max_depth': 37, 'min_gain_to_split': 1.4022072331015445, 'min_sum_hessian_in_leaf': 5.02799709250991}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:45:58,056] Trial 120 finished with value: 0.5481183985503904 and parameters: {'lambda_l1': 0.008552188277459358, 'lambda_l2': 1.5767673316007393e-06, 'num_leaves': 243, 'feature_fraction': 0.5664093617326469, 'bagging_fraction': 0.8963509471182337, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.07525278736474354, 'max_depth': 33, 'min_gain_to_split': 0.5107559443462096, 'min_sum_hessian_in_leaf': 4.649590992194305}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:46:16,220] Trial 121 finished with value: 0.5459960229868547 and parameters: {'lambda_l1': 0.005593451449563417, 'lambda_l2': 1.5653430924671644e-06, 'num_leaves': 254, 'feature_fraction': 0.5720391509453038, 'bagging_fraction': 0.8973544137664323, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.07442373950414878, 'max_depth': 32, 'min_gain_to_split': 0.39827460351969207, 'min_sum_hessian_in_leaf': 4.651862308951}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:46:32,879] Trial 122 finished with value: 0.5488827700157971 and parameters: {'lambda_l1': 0.00573224244416879, 'lambda_l2': 2.0855622336349928e-06, 'num_leaves': 253, 'feature_fraction': 0.5724233731315973, 'bagging_fraction': 0.8910934468370206, 'bagging_freq': 6, 'min_child_samples': 26, 'learning_rate': 0.07523522591760824, 'max_depth': 31, 'min_gain_to_split': 0.5644515530217045, 'min_sum_hessian_in_leaf': 4.7395877650337574}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:46:44,737] Trial 123 finished with value: 0.556642726677382 and parameters: {'lambda_l1': 0.0075526845312373315, 'lambda_l2': 1.404524528655119e-06, 'num_leaves': 242, 'feature_fraction': 0.5630773407721692, 'bagging_fraction': 0.8836911169750754, 'bagging_freq': 6, 'min_child_samples': 29, 'learning_rate': 0.09306191151320947, 'max_depth': 34, 'min_gain_to_split': 1.1641875448078463, 'min_sum_hessian_in_leaf': 4.487091731019643}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:47:01,800] Trial 124 finished with value: 0.5499519944218374 and parameters: {'lambda_l1': 0.0049400794809238225, 'lambda_l2': 3.184689155561627e-06, 'num_leaves': 255, 'feature_fraction': 0.5357634417109695, 'bagging_fraction': 0.9034672485492549, 'bagging_freq': 6, 'min_child_samples': 25, 'learning_rate': 0.07562165094522791, 'max_depth': 33, 'min_gain_to_split': 0.6690995212366448, 'min_sum_hessian_in_leaf': 4.627185423983254}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:47:18,562] Trial 125 finished with value: 0.5431231597150763 and parameters: {'lambda_l1': 0.047225449712826016, 'lambda_l2': 1.0775692579433919e-06, 'num_leaves': 231, 'feature_fraction': 0.561503971776358, 'bagging_fraction': 0.8757803630143712, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.10376213162007547, 'max_depth': 37, 'min_gain_to_split': 0.0017696629727160795, 'min_sum_hessian_in_leaf': 4.183906602452632}. Best is trial 85 with value: 0.5415895190375821.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:47:36,270] Trial 126 finished with value: 0.5399287614070716 and parameters: {'lambda_l1': 0.052314327096630225, 'lambda_l2': 3.32988129651596e-06, 'num_leaves': 231, 'feature_fraction': 0.5265850969320467, 'bagging_fraction': 0.8774863575800759, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.07035755881536468, 'max_depth': 37, 'min_gain_to_split': 0.0011816927254341136, 'min_sum_hessian_in_leaf': 4.062565356348579}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:47:54,615] Trial 127 finished with value: 0.560113096819965 and parameters: {'lambda_l1': 0.053017540318737816, 'lambda_l2': 3.903544916286539e-06, 'num_leaves': 235, 'feature_fraction': 0.5290329467695597, 'bagging_fraction': 0.8656741141224911, 'bagging_freq': 6, 'min_child_samples': 10, 'learning_rate': 0.04030762125881078, 'max_depth': 39, 'min_gain_to_split': 0.03216934506067004, 'min_sum_hessian_in_leaf': 3.9071998005738164}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:48:06,820] Trial 128 finished with value: 0.5499163112463228 and parameters: {'lambda_l1': 0.06593908046783512, 'lambda_l2': 1.0293573853616468e-06, 'num_leaves': 196, 'feature_fraction': 0.6140002703465948, 'bagging_fraction': 0.9197465624207171, 'bagging_freq': 6, 'min_child_samples': 14, 'learning_rate': 0.09196928007350359, 'max_depth': 36, 'min_gain_to_split': 0.9198977942683514, 'min_sum_hessian_in_leaf': 4.036738474711427}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:48:22,253] Trial 129 finished with value: 0.5553247106735177 and parameters: {'lambda_l1': 0.048223462251445116, 'lambda_l2': 1.1978412770498207e-07, 'num_leaves': 228, 'feature_fraction': 0.5931029085005487, 'bagging_fraction': 0.8830175717750799, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.06619729599578296, 'max_depth': 41, 'min_gain_to_split': 1.4415491674477006, 'min_sum_hessian_in_leaf': 4.209296864983264}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:48:31,445] Trial 130 finished with value: 0.5557117096254963 and parameters: {'lambda_l1': 0.020718666952078746, 'lambda_l2': 1.8507101945560067e-07, 'num_leaves': 248, 'feature_fraction': 0.5493609194651672, 'bagging_fraction': 0.9326600897536875, 'bagging_freq': 1, 'min_child_samples': 21, 'learning_rate': 0.10801194200864532, 'max_depth': 38, 'min_gain_to_split': 1.093046030261858, 'min_sum_hessian_in_leaf': 4.267367986523607}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:48:48,736] Trial 131 finished with value: 0.548848587798993 and parameters: {'lambda_l1': 0.013329635040291285, 'lambda_l2': 2.8318143473958543e-06, 'num_leaves': 240, 'feature_fraction': 0.5220889719000812, 'bagging_fraction': 0.8945851533362987, 'bagging_freq': 6, 'min_child_samples': 32, 'learning_rate': 0.07616420070400634, 'max_depth': 33, 'min_gain_to_split': 0.44470585653801853, 'min_sum_hessian_in_leaf': 4.434138089180738}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:49:06,560] Trial 132 finished with value: 0.5410759301478192 and parameters: {'lambda_l1': 0.01071415376667983, 'lambda_l2': 5.927402195600465e-06, 'num_leaves': 232, 'feature_fraction': 0.5575306107799372, 'bagging_fraction': 0.8598083656675967, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.07044454981159474, 'max_depth': 31, 'min_gain_to_split': 0.013478706752106821, 'min_sum_hessian_in_leaf': 3.6644277919114527}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:49:24,381] Trial 133 finished with value: 0.5447178776605852 and parameters: {'lambda_l1': 0.030585317480288893, 'lambda_l2': 1.4848555467469374e-06, 'num_leaves': 231, 'feature_fraction': 0.5421103834069344, 'bagging_fraction': 0.8399413113502977, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.06358963939030964, 'max_depth': 41, 'min_gain_to_split': 0.07595696343351005, 'min_sum_hessian_in_leaf': 3.627342519709352}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:49:42,655] Trial 134 finished with value: 0.546925574125708 and parameters: {'lambda_l1': 0.03770212447144307, 'lambda_l2': 7.990725564321625e-06, 'num_leaves': 232, 'feature_fraction': 0.5443344824992934, 'bagging_fraction': 0.8417151737944473, 'bagging_freq': 6, 'min_child_samples': 8, 'learning_rate': 0.061390531623306197, 'max_depth': 46, 'min_gain_to_split': 0.14240287626800704, 'min_sum_hessian_in_leaf': 3.587958804527366}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:49:59,821] Trial 135 finished with value: 0.547235416849409 and parameters: {'lambda_l1': 0.031995367205734405, 'lambda_l2': 5.583016508127996e-06, 'num_leaves': 221, 'feature_fraction': 0.5416738767449034, 'bagging_fraction': 0.8271380164499891, 'bagging_freq': 6, 'min_child_samples': 8, 'learning_rate': 0.05967905778087579, 'max_depth': 42, 'min_gain_to_split': 0.1367284660841891, 'min_sum_hessian_in_leaf': 3.4966089764464674}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:50:17,955] Trial 136 finished with value: 0.5490827816743447 and parameters: {'lambda_l1': 0.04114483742472362, 'lambda_l2': 5.138939923999932e-06, 'num_leaves': 233, 'feature_fraction': 0.5420922334988435, 'bagging_fraction': 0.8378527171828958, 'bagging_freq': 6, 'min_child_samples': 7, 'learning_rate': 0.047706839847428226, 'max_depth': 43, 'min_gain_to_split': 0.0006334120724157954, 'min_sum_hessian_in_leaf': 3.5829923717010135}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:50:35,883] Trial 137 finished with value: 0.5442385144090476 and parameters: {'lambda_l1': 0.028306584281412007, 'lambda_l2': 6.21056077100605e-06, 'num_leaves': 223, 'feature_fraction': 0.5060002627760776, 'bagging_fraction': 0.854036798471059, 'bagging_freq': 6, 'min_child_samples': 11, 'learning_rate': 0.058815553329996835, 'max_depth': 45, 'min_gain_to_split': 0.0038602016236942652, 'min_sum_hessian_in_leaf': 3.4719373517392595}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:50:53,939] Trial 138 finished with value: 0.5446436076816379 and parameters: {'lambda_l1': 0.08370357158590537, 'lambda_l2': 8.469772102961571e-06, 'num_leaves': 238, 'feature_fraction': 0.5008298517632734, 'bagging_fraction': 0.8664677599885429, 'bagging_freq': 6, 'min_child_samples': 10, 'learning_rate': 0.0919260141964095, 'max_depth': 46, 'min_gain_to_split': 0.02044753093332806, 'min_sum_hessian_in_leaf': 3.9527282015401126}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:51:11,489] Trial 139 finished with value: 0.5482011384609664 and parameters: {'lambda_l1': 0.06340503213489634, 'lambda_l2': 2.9089065902496212e-06, 'num_leaves': 248, 'feature_fraction': 0.5031980748524533, 'bagging_fraction': 0.8654720270314162, 'bagging_freq': 6, 'min_child_samples': 13, 'learning_rate': 0.08395213133925013, 'max_depth': 46, 'min_gain_to_split': 0.375448744258313, 'min_sum_hessian_in_leaf': 4.069735458740353}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:51:29,901] Trial 140 finished with value: 0.5459980726044642 and parameters: {'lambda_l1': 0.09134625446317006, 'lambda_l2': 1.7199315231292688e-05, 'num_leaves': 239, 'feature_fraction': 0.5252130763180918, 'bagging_fraction': 0.8572850017860507, 'bagging_freq': 5, 'min_child_samples': 11, 'learning_rate': 0.09306733785396949, 'max_depth': 43, 'min_gain_to_split': 0.00419100783740361, 'min_sum_hessian_in_leaf': 3.797975117488579}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:51:47,992] Trial 141 finished with value: 0.5470777509154887 and parameters: {'lambda_l1': 0.019954335361054815, 'lambda_l2': 7.94836418887542e-06, 'num_leaves': 240, 'feature_fraction': 0.5202377781112114, 'bagging_fraction': 0.8522192701572839, 'bagging_freq': 5, 'min_child_samples': 11, 'learning_rate': 0.09627168756160788, 'max_depth': 44, 'min_gain_to_split': 0.00986224307780692, 'min_sum_hessian_in_leaf': 3.8029149221710186}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:52:02,204] Trial 142 finished with value: 0.5524200807228092 and parameters: {'lambda_l1': 0.09918612407643852, 'lambda_l2': 1.373667544745201e-05, 'num_leaves': 253, 'feature_fraction': 0.5253201409231893, 'bagging_fraction': 0.8584748336629198, 'bagging_freq': 6, 'min_child_samples': 5, 'learning_rate': 0.11129851435233443, 'max_depth': 50, 'min_gain_to_split': 0.40640473462033033, 'min_sum_hessian_in_leaf': 3.351250985940803}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:52:18,579] Trial 143 finished with value: 0.5453186529569638 and parameters: {'lambda_l1': 0.08251776463575214, 'lambda_l2': 1.8915629995397576e-05, 'num_leaves': 209, 'feature_fraction': 0.5526859001400215, 'bagging_fraction': 0.8745962350484486, 'bagging_freq': 6, 'min_child_samples': 14, 'learning_rate': 0.08701770325683933, 'max_depth': 47, 'min_gain_to_split': 0.33513539304730516, 'min_sum_hessian_in_leaf': 3.692776156922894}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:52:33,971] Trial 144 finished with value: 0.5501072951544805 and parameters: {'lambda_l1': 0.08696902730093703, 'lambda_l2': 1.9777482252602022e-05, 'num_leaves': 226, 'feature_fraction': 0.5042660835492395, 'bagging_fraction': 0.8758037375861244, 'bagging_freq': 6, 'min_child_samples': 14, 'learning_rate': 0.08620680928919691, 'max_depth': 45, 'min_gain_to_split': 0.5695224319637469, 'min_sum_hessian_in_leaf': 3.9680989972688825}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:52:49,540] Trial 145 finished with value: 0.5520088835569095 and parameters: {'lambda_l1': 0.0271452450486232, 'lambda_l2': 6.985903270442969e-06, 'num_leaves': 210, 'feature_fraction': 0.5565670390605479, 'bagging_fraction': 0.8449425546001381, 'bagging_freq': 5, 'min_child_samples': 11, 'learning_rate': 0.11565549537698394, 'max_depth': 48, 'min_gain_to_split': 0.012058106554194037, 'min_sum_hessian_in_leaf': 3.6639345755110733}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:53:01,759] Trial 146 finished with value: 0.5568510802054918 and parameters: {'lambda_l1': 0.05880586019962705, 'lambda_l2': 4.33408540954617e-06, 'num_leaves': 237, 'feature_fraction': 0.5143109888085426, 'bagging_fraction': 0.859804277183744, 'bagging_freq': 6, 'min_child_samples': 17, 'learning_rate': 0.09209029142966409, 'max_depth': 48, 'min_gain_to_split': 1.0801813771548867, 'min_sum_hessian_in_leaf': 3.1987352539193252}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:53:19,405] Trial 147 finished with value: 0.54928882511247 and parameters: {'lambda_l1': 0.016443933888930062, 'lambda_l2': 3.0482512019134228e-05, 'num_leaves': 246, 'feature_fraction': 0.5326355602906299, 'bagging_fraction': 0.8185007600711419, 'bagging_freq': 5, 'min_child_samples': 15, 'learning_rate': 0.08067399235699947, 'max_depth': 41, 'min_gain_to_split': 0.396164640944418, 'min_sum_hessian_in_leaf': 2.9643332824425936}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:53:26,640] Trial 148 finished with value: 0.5887444874425272 and parameters: {'lambda_l1': 0.09206196641347074, 'lambda_l2': 1.1231230570982246e-05, 'num_leaves': 229, 'feature_fraction': 0.49846188888599086, 'bagging_fraction': 0.8718481448732232, 'bagging_freq': 6, 'min_child_samples': 12, 'learning_rate': 0.1032013717960324, 'max_depth': 43, 'min_gain_to_split': 4.88845023438579, 'min_sum_hessian_in_leaf': 3.7801170140992766}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:53:43,959] Trial 149 finished with value: 0.5608485676377104 and parameters: {'lambda_l1': 0.034014091138911746, 'lambda_l2': 1.877448191880625e-05, 'num_leaves': 223, 'feature_fraction': 0.48126988586852826, 'bagging_fraction': 0.806816838561261, 'bagging_freq': 6, 'min_child_samples': 9, 'learning_rate': 0.048876771028816116, 'max_depth': 47, 'min_gain_to_split': 0.705142924054379, 'min_sum_hessian_in_leaf': 4.072425137034362}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:53:52,795] Trial 150 finished with value: 0.5603708312397719 and parameters: {'lambda_l1': 0.0466507914078529, 'lambda_l2': 3.2346338962985804e-06, 'num_leaves': 207, 'feature_fraction': 0.5156582891626131, 'bagging_fraction': 0.8556692682451439, 'bagging_freq': 6, 'min_child_samples': 18, 'learning_rate': 0.12865042480169603, 'max_depth': 40, 'min_gain_to_split': 1.1407401099224548, 'min_sum_hessian_in_leaf': 3.338806682974823}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:54:11,735] Trial 151 finished with value: 0.5489828401430099 and parameters: {'lambda_l1': 0.010769473446197312, 'lambda_l2': 6.089318525387885e-05, 'num_leaves': 236, 'feature_fraction': 0.5515741001543557, 'bagging_fraction': 0.8342973889039323, 'bagging_freq': 7, 'min_child_samples': 24, 'learning_rate': 0.066295323982163, 'max_depth': 26, 'min_gain_to_split': 0.3530912545746491, 'min_sum_hessian_in_leaf': 4.224286615334508}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:54:27,500] Trial 152 finished with value: 0.5458363382876897 and parameters: {'lambda_l1': 0.019382104771899625, 'lambda_l2': 2.298310304505339e-06, 'num_leaves': 186, 'feature_fraction': 0.5750302717847825, 'bagging_fraction': 0.8468705901681531, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.0571199413709024, 'max_depth': 27, 'min_gain_to_split': 0.020407964390709632, 'min_sum_hessian_in_leaf': 3.8558025982071173}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:54:43,672] Trial 153 finished with value: 0.566849394482532 and parameters: {'lambda_l1': 0.019400631704550947, 'lambda_l2': 2.025756482558674e-06, 'num_leaves': 192, 'feature_fraction': 0.558916516041816, 'bagging_fraction': 0.8735846179448443, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.040847874809154396, 'max_depth': 44, 'min_gain_to_split': 0.2264555017466266, 'min_sum_hessian_in_leaf': 3.7577502027950636}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:54:57,130] Trial 154 finished with value: 0.5508441991374322 and parameters: {'lambda_l1': 0.025334553430643857, 'lambda_l2': 6.7299068221102194e-06, 'num_leaves': 185, 'feature_fraction': 0.5299597765660674, 'bagging_fraction': 0.8453582095889081, 'bagging_freq': 6, 'min_child_samples': 19, 'learning_rate': 0.0849933523504846, 'max_depth': 45, 'min_gain_to_split': 0.6736278849218995, 'min_sum_hessian_in_leaf': 3.4067933322917483}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:55:14,149] Trial 155 finished with value: 0.5421478654133607 and parameters: {'lambda_l1': 0.07099260790629772, 'lambda_l2': 4.280029886944195e-06, 'num_leaves': 220, 'feature_fraction': 0.5811324451296849, 'bagging_fraction': 0.8350296307228471, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.06989764629399182, 'max_depth': 46, 'min_gain_to_split': 0.03231398184804729, 'min_sum_hessian_in_leaf': 3.9127478594905165}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:55:24,175] Trial 156 finished with value: 0.6069763568783021 and parameters: {'lambda_l1': 0.01394393833400315, 'lambda_l2': 3.3579706675640946e-06, 'num_leaves': 222, 'feature_fraction': 0.5783373540471785, 'bagging_fraction': 0.8305949803196053, 'bagging_freq': 6, 'min_child_samples': 17, 'learning_rate': 0.05445978502948566, 'max_depth': 25, 'min_gain_to_split': 9.401336590045878, 'min_sum_hessian_in_leaf': 4.120069630719252}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:55:38,713] Trial 157 finished with value: 0.5497537844250134 and parameters: {'lambda_l1': 0.041088309029629476, 'lambda_l2': 1.6630376163429491e-06, 'num_leaves': 207, 'feature_fraction': 0.5938329698742972, 'bagging_fraction': 0.8801307056822925, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.07200956449274393, 'max_depth': 48, 'min_gain_to_split': 0.8167314524025631, 'min_sum_hessian_in_leaf': 3.5964604390660213}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:55:55,642] Trial 158 finished with value: 0.5540512306324642 and parameters: {'lambda_l1': 0.1944410840860924, 'lambda_l2': 1.0739352856244689e-06, 'num_leaves': 220, 'feature_fraction': 0.5601484903094418, 'bagging_fraction': 0.8246753349957231, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.049205031050888054, 'max_depth': 27, 'min_gain_to_split': 0.3281396030352571, 'min_sum_hessian_in_leaf': 3.071470018743906}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:56:12,052] Trial 159 finished with value: 0.5477627551926627 and parameters: {'lambda_l1': 0.06195450331858097, 'lambda_l2': 2.2606890590896547e-06, 'num_leaves': 213, 'feature_fraction': 0.57975859235463, 'bagging_fraction': 0.8419702420333478, 'bagging_freq': 6, 'min_child_samples': 13, 'learning_rate': 0.06774017881765611, 'max_depth': 23, 'min_gain_to_split': 0.5359243517997472, 'min_sum_hessian_in_leaf': 4.318152136178}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:56:29,651] Trial 160 finished with value: 0.5406830766076898 and parameters: {'lambda_l1': 0.1248719005992273, 'lambda_l2': 9.651275119878788e-06, 'num_leaves': 229, 'feature_fraction': 0.601204058225216, 'bagging_fraction': 0.8725056761851052, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.05968700113863596, 'max_depth': 47, 'min_gain_to_split': 0.00034610853365030225, 'min_sum_hessian_in_leaf': 4.035448816813196}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:56:47,048] Trial 161 finished with value: 0.5434207888722945 and parameters: {'lambda_l1': 0.13380239958820303, 'lambda_l2': 4.784624336595895e-06, 'num_leaves': 228, 'feature_fraction': 0.6018578855105089, 'bagging_fraction': 0.8676017437778781, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.058621014324272344, 'max_depth': 47, 'min_gain_to_split': 0.05580242956212592, 'min_sum_hessian_in_leaf': 4.011104381632536}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:57:04,331] Trial 162 finished with value: 0.5435569529822091 and parameters: {'lambda_l1': 0.1206802700357618, 'lambda_l2': 1.0008571230458319e-05, 'num_leaves': 227, 'feature_fraction': 0.6030309283521705, 'bagging_fraction': 0.8659841021983578, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.05707588834461786, 'max_depth': 47, 'min_gain_to_split': 0.022548943310902663, 'min_sum_hessian_in_leaf': 3.9646849045375583}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:57:21,649] Trial 163 finished with value: 0.5554441489422215 and parameters: {'lambda_l1': 0.1314985432385049, 'lambda_l2': 1.0218242690324342e-05, 'num_leaves': 226, 'feature_fraction': 0.600082150225312, 'bagging_fraction': 0.8627531808723711, 'bagging_freq': 6, 'min_child_samples': 19, 'learning_rate': 0.04239445083672904, 'max_depth': 50, 'min_gain_to_split': 0.00911715205128566, 'min_sum_hessian_in_leaf': 3.9570619844754553}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:57:38,487] Trial 164 finished with value: 0.5537464924051904 and parameters: {'lambda_l1': 0.2046402536743771, 'lambda_l2': 6.124621055616641e-06, 'num_leaves': 232, 'feature_fraction': 0.6063097788798862, 'bagging_fraction': 0.8474425255877206, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.05613883282969339, 'max_depth': 47, 'min_gain_to_split': 0.8990368496095867, 'min_sum_hessian_in_leaf': 3.8877538876091973}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:57:55,488] Trial 165 finished with value: 0.5723676008676722 and parameters: {'lambda_l1': 0.11530675608457756, 'lambda_l2': 4.208733062232087e-06, 'num_leaves': 218, 'feature_fraction': 0.5896137146159952, 'bagging_fraction': 0.8814344438571428, 'bagging_freq': 6, 'min_child_samples': 17, 'learning_rate': 0.035099892765169546, 'max_depth': 46, 'min_gain_to_split': 0.01880695720542641, 'min_sum_hessian_in_leaf': 3.562636489953137}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:58:13,249] Trial 166 finished with value: 0.5529003634478857 and parameters: {'lambda_l1': 0.06684336768940159, 'lambda_l2': 8.76050623642648e-06, 'num_leaves': 229, 'feature_fraction': 0.603300367509123, 'bagging_fraction': 0.8694100749048524, 'bagging_freq': 6, 'min_child_samples': 20, 'learning_rate': 0.05098434995148725, 'max_depth': 45, 'min_gain_to_split': 0.6223328934606104, 'min_sum_hessian_in_leaf': 3.6934067766524636}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:58:22,279] Trial 167 finished with value: 0.5925828603736265 and parameters: {'lambda_l1': 0.2627876520658674, 'lambda_l2': 1.4308186237921946e-05, 'num_leaves': 222, 'feature_fraction': 0.587475276786444, 'bagging_fraction': 0.7861789065778458, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.06782549323907497, 'max_depth': 48, 'min_gain_to_split': 6.29067984939408, 'min_sum_hessian_in_leaf': 3.4140228159648895}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:58:39,242] Trial 168 finished with value: 0.5469306074060942 and parameters: {'lambda_l1': 0.1289023791151173, 'lambda_l2': 4.187599871078929e-06, 'num_leaves': 234, 'feature_fraction': 0.6114399145532955, 'bagging_fraction': 0.80575192531612, 'bagging_freq': 6, 'min_child_samples': 22, 'learning_rate': 0.08056335286784855, 'max_depth': 49, 'min_gain_to_split': 0.3285463958230212, 'min_sum_hessian_in_leaf': 4.020718719678102}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:58:55,029] Trial 169 finished with value: 0.5566266248891445 and parameters: {'lambda_l1': 0.03152615242305531, 'lambda_l2': 3.337470243568731e-05, 'num_leaves': 212, 'feature_fraction': 0.5615472150774338, 'bagging_fraction': 0.8371116408708117, 'bagging_freq': 6, 'min_child_samples': 24, 'learning_rate': 0.05792402032614198, 'max_depth': 46, 'min_gain_to_split': 1.017046327137635, 'min_sum_hessian_in_leaf': 4.161762695452039}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:59:12,618] Trial 170 finished with value: 0.552137848167973 and parameters: {'lambda_l1': 0.07762256099413743, 'lambda_l2': 1.161456289481381e-05, 'num_leaves': 229, 'feature_fraction': 0.5400903466280969, 'bagging_fraction': 0.8509720827914259, 'bagging_freq': 6, 'min_child_samples': 17, 'learning_rate': 0.04602839528511862, 'max_depth': 47, 'min_gain_to_split': 0.018520137414696353, 'min_sum_hessian_in_leaf': 3.87925699243733}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:59:28,341] Trial 171 finished with value: 0.5458678852167294 and parameters: {'lambda_l1': 0.02273251675433071, 'lambda_l2': 7.0958290578470945e-06, 'num_leaves': 195, 'feature_fraction': 0.57525275182248, 'bagging_fraction': 0.8833517807470692, 'bagging_freq': 6, 'min_child_samples': 24, 'learning_rate': 0.06562033907545557, 'max_depth': 44, 'min_gain_to_split': 0.29929255937683363, 'min_sum_hessian_in_leaf': 3.1825591707705616}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 19:59:44,142] Trial 172 finished with value: 0.5477310714522529 and parameters: {'lambda_l1': 0.02363595825973159, 'lambda_l2': 6.1657537465477026e-06, 'num_leaves': 201, 'feature_fraction': 0.5905939236151736, 'bagging_fraction': 0.8872189759330512, 'bagging_freq': 2, 'min_child_samples': 19, 'learning_rate': 0.0669885172487361, 'max_depth': 45, 'min_gain_to_split': 0.5693144957633598, 'min_sum_hessian_in_leaf': 3.2006060456784375}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:00:00,032] Trial 173 finished with value: 0.5464337458022805 and parameters: {'lambda_l1': 0.05306452311783888, 'lambda_l2': 2.5035349416580453e-06, 'num_leaves': 218, 'feature_fraction': 0.5507423605098817, 'bagging_fraction': 0.8767123769259569, 'bagging_freq': 6, 'min_child_samples': 30, 'learning_rate': 0.08826562960179539, 'max_depth': 44, 'min_gain_to_split': 0.3231163580961195, 'min_sum_hessian_in_leaf': 3.543854525469302}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:00:15,582] Trial 174 finished with value: 0.5516422866472488 and parameters: {'lambda_l1': 0.04133540507802127, 'lambda_l2': 8.679603400817243e-06, 'num_leaves': 194, 'feature_fraction': 0.5708610241918615, 'bagging_fraction': 0.8659781404440661, 'bagging_freq': 6, 'min_child_samples': 21, 'learning_rate': 0.058021194195093106, 'max_depth': 49, 'min_gain_to_split': 0.6290580995711617, 'min_sum_hessian_in_leaf': 2.9635372978654915}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:00:32,359] Trial 175 finished with value: 0.5460740479242461 and parameters: {'lambda_l1': 0.018683645844533903, 'lambda_l2': 4.8731257836837e-06, 'num_leaves': 225, 'feature_fraction': 0.6370785118828307, 'bagging_fraction': 0.8553605851454609, 'bagging_freq': 6, 'min_child_samples': 13, 'learning_rate': 0.07960613226898763, 'max_depth': 46, 'min_gain_to_split': 0.28942359228487863, 'min_sum_hessian_in_leaf': 3.6606939976491697}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:00:39,849] Trial 176 finished with value: 0.5758622751846388 and parameters: {'lambda_l1': 0.10567026524851647, 'lambda_l2': 2.2846663137845022e-05, 'num_leaves': 207, 'feature_fraction': 0.6080522379676124, 'bagging_fraction': 0.8320604430041879, 'bagging_freq': 6, 'min_child_samples': 23, 'learning_rate': 0.10742066846863703, 'max_depth': 47, 'min_gain_to_split': 3.0523603894429403, 'min_sum_hessian_in_leaf': 3.3588137544452414}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:00:50,906] Trial 177 finished with value: 0.5721412837009536 and parameters: {'lambda_l1': 0.02848786457070531, 'lambda_l2': 3.0688623233964294e-06, 'num_leaves': 242, 'feature_fraction': 0.5835767618433069, 'bagging_fraction': 0.8141417314247315, 'bagging_freq': 6, 'min_child_samples': 9, 'learning_rate': 0.06834440333047456, 'max_depth': 42, 'min_gain_to_split': 3.423270180179249, 'min_sum_hessian_in_leaf': 3.9437359205362035}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:01:08,363] Trial 178 finished with value: 0.5643382706189507 and parameters: {'lambda_l1': 0.1728627137808417, 'lambda_l2': 1.2741860313859823e-05, 'num_leaves': 234, 'feature_fraction': 0.5993689980034828, 'bagging_fraction': 0.8903600264318254, 'bagging_freq': 6, 'min_child_samples': 16, 'learning_rate': 0.038137683061672416, 'max_depth': 18, 'min_gain_to_split': 0.0074600710522768066, 'min_sum_hessian_in_leaf': 4.299712016558426}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:01:22,291] Trial 179 finished with value: 0.5854902526983129 and parameters: {'lambda_l1': 0.04940188938737006, 'lambda_l2': 5.506963814881044e-06, 'num_leaves': 216, 'feature_fraction': 0.49495194712530577, 'bagging_fraction': 0.8687260026511373, 'bagging_freq': 6, 'min_child_samples': 27, 'learning_rate': 0.046647978041021027, 'max_depth': 44, 'min_gain_to_split': 3.7266485427105493, 'min_sum_hessian_in_leaf': 2.903431877897049}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:01:34,026] Trial 180 finished with value: 0.5793246370815862 and parameters: {'lambda_l1': 0.01564429274289723, 'lambda_l2': 9.610440261799482e-07, 'num_leaves': 238, 'feature_fraction': 0.5721024256873725, 'bagging_fraction': 0.8998816441398193, 'bagging_freq': 6, 'min_child_samples': 25, 'learning_rate': 0.06052417515702233, 'max_depth': 47, 'min_gain_to_split': 4.248739537458458, 'min_sum_hessian_in_leaf': 3.7481024914217027}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:01:50,036] Trial 181 finished with value: 0.5466025396850298 and parameters: {'lambda_l1': 0.009978747871957403, 'lambda_l2': 3.774795572964892e-06, 'num_leaves': 198, 'feature_fraction': 0.5845397105743941, 'bagging_fraction': 0.9759733114705794, 'bagging_freq': 7, 'min_child_samples': 21, 'learning_rate': 0.054974089857642426, 'max_depth': 28, 'min_gain_to_split': 0.28520325039836175, 'min_sum_hessian_in_leaf': 4.077177302156173}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:02:03,982] Trial 182 finished with value: 0.5514767392411706 and parameters: {'lambda_l1': 0.07395184099039286, 'lambda_l2': 8.217722000588753e-06, 'num_leaves': 189, 'feature_fraction': 0.560488478600263, 'bagging_fraction': 0.8786165026382032, 'bagging_freq': 6, 'min_child_samples': 24, 'learning_rate': 0.07513082452783072, 'max_depth': 45, 'min_gain_to_split': 0.7856100032263093, 'min_sum_hessian_in_leaf': 4.365320728487583}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:02:18,972] Trial 183 finished with value: 0.5419099958204786 and parameters: {'lambda_l1': 0.029553128435766948, 'lambda_l2': 2.0541478230790874e-06, 'num_leaves': 184, 'feature_fraction': 0.5768730582165084, 'bagging_fraction': 0.8581740409026906, 'bagging_freq': 7, 'min_child_samples': 19, 'learning_rate': 0.06323968594344445, 'max_depth': 25, 'min_gain_to_split': 0.002635278683024536, 'min_sum_hessian_in_leaf': 3.4542530769006023}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:02:34,065] Trial 184 finished with value: 0.5416280312324833 and parameters: {'lambda_l1': 0.03259010893271807, 'lambda_l2': 2.196511556244196e-06, 'num_leaves': 194, 'feature_fraction': 0.5444317915724315, 'bagging_fraction': 0.8488452981328708, 'bagging_freq': 6, 'min_child_samples': 19, 'learning_rate': 0.09412375991279069, 'max_depth': 49, 'min_gain_to_split': 0.016014219043167684, 'min_sum_hessian_in_leaf': 3.4172052909590884}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:02:50,993] Trial 185 finished with value: 0.5431405353098915 and parameters: {'lambda_l1': 0.037876191530197924, 'lambda_l2': 1.8760368379923224e-06, 'num_leaves': 229, 'feature_fraction': 0.5377615571425806, 'bagging_fraction': 0.8496390395715835, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.09378935929940001, 'max_depth': 48, 'min_gain_to_split': 0.001453256284933202, 'min_sum_hessian_in_leaf': 3.398775011818104}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:03:04,643] Trial 186 finished with value: 0.5540240808274138 and parameters: {'lambda_l1': 0.037541848748771506, 'lambda_l2': 1.3641009644166103e-06, 'num_leaves': 228, 'feature_fraction': 0.5096833005013621, 'bagging_fraction': 0.825708404719717, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.09564795833889952, 'max_depth': 47, 'min_gain_to_split': 0.5763608487739935, 'min_sum_hessian_in_leaf': 3.423605654186032}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:03:19,924] Trial 187 finished with value: 0.5490178533771017 and parameters: {'lambda_l1': 0.07113151691794185, 'lambda_l2': 8.71732831984604e-07, 'num_leaves': 221, 'feature_fraction': 0.5364637690229586, 'bagging_fraction': 0.8592129091682728, 'bagging_freq': 7, 'min_child_samples': 15, 'learning_rate': 0.08707910889982898, 'max_depth': 49, 'min_gain_to_split': 0.49998313341123, 'min_sum_hessian_in_leaf': 3.4985596222426976}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:03:29,915] Trial 188 finished with value: 0.5599278864261967 and parameters: {'lambda_l1': 0.11760004481905295, 'lambda_l2': 2.5171443215390185e-06, 'num_leaves': 231, 'feature_fraction': 0.5500143193402621, 'bagging_fraction': 0.7977738494276958, 'bagging_freq': 7, 'min_child_samples': 13, 'learning_rate': 0.12059894467542172, 'max_depth': 49, 'min_gain_to_split': 0.9271979071274129, 'min_sum_hessian_in_leaf': 3.22445007396538}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:03:46,337] Trial 189 finished with value: 0.5562074339952158 and parameters: {'lambda_l1': 0.03380873646763442, 'lambda_l2': 1.7322016009323713e-06, 'num_leaves': 234, 'feature_fraction': 0.5234805633177985, 'bagging_fraction': 0.76611627982555, 'bagging_freq': 7, 'min_child_samples': 19, 'learning_rate': 0.09955253609656238, 'max_depth': 50, 'min_gain_to_split': 0.2467057006620163, 'min_sum_hessian_in_leaf': 2.773984403498816}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:04:03,499] Trial 190 finished with value: 0.5434221351833151 and parameters: {'lambda_l1': 0.2724847106809781, 'lambda_l2': 4.978012307164279e-07, 'num_leaves': 226, 'feature_fraction': 0.5378875113939893, 'bagging_fraction': 0.8406466026840878, 'bagging_freq': 7, 'min_child_samples': 16, 'learning_rate': 0.08228827622583385, 'max_depth': 38, 'min_gain_to_split': 0.013038242148907975, 'min_sum_hessian_in_leaf': 3.694911237100802}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:04:20,650] Trial 191 finished with value: 0.5432867129274792 and parameters: {'lambda_l1': 0.3877471707971322, 'lambda_l2': 6.409814053823666e-07, 'num_leaves': 225, 'feature_fraction': 0.54733659253636, 'bagging_fraction': 0.848751157333924, 'bagging_freq': 7, 'min_child_samples': 16, 'learning_rate': 0.0815190618722379, 'max_depth': 35, 'min_gain_to_split': 0.025490343941612304, 'min_sum_hessian_in_leaf': 3.6573717186873838}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:04:37,855] Trial 192 finished with value: 0.5435518311827237 and parameters: {'lambda_l1': 0.20119889749484077, 'lambda_l2': 4.586021620218716e-07, 'num_leaves': 226, 'feature_fraction': 0.5413699236605665, 'bagging_fraction': 0.8369577230619917, 'bagging_freq': 7, 'min_child_samples': 17, 'learning_rate': 0.0769311324787893, 'max_depth': 38, 'min_gain_to_split': 0.029621758659697198, 'min_sum_hessian_in_leaf': 3.492296888324249}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:04:55,096] Trial 193 finished with value: 0.5525101508867152 and parameters: {'lambda_l1': 0.20820585679980844, 'lambda_l2': 6.944044174788837e-07, 'num_leaves': 243, 'feature_fraction': 0.5370606833853716, 'bagging_fraction': 0.8179066380277075, 'bagging_freq': 7, 'min_child_samples': 17, 'learning_rate': 0.10437323795284573, 'max_depth': 38, 'min_gain_to_split': 0.00024272260600152274, 'min_sum_hessian_in_leaf': 3.345854841667088}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:05:12,237] Trial 194 finished with value: 0.5428677573689368 and parameters: {'lambda_l1': 0.34991991068725786, 'lambda_l2': 4.895772965713499e-07, 'num_leaves': 225, 'feature_fraction': 0.512811946467621, 'bagging_fraction': 0.8388178509308086, 'bagging_freq': 7, 'min_child_samples': 19, 'learning_rate': 0.07896794568448137, 'max_depth': 37, 'min_gain_to_split': 0.016642942034235154, 'min_sum_hessian_in_leaf': 3.5454376582331277}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:05:29,475] Trial 195 finished with value: 0.5432544909478568 and parameters: {'lambda_l1': 0.361275645875128, 'lambda_l2': 4.5258003377273355e-07, 'num_leaves': 224, 'feature_fraction': 0.508455017340115, 'bagging_fraction': 0.8336989999581179, 'bagging_freq': 7, 'min_child_samples': 16, 'learning_rate': 0.08165969239390987, 'max_depth': 37, 'min_gain_to_split': 0.003077047783557479, 'min_sum_hessian_in_leaf': 3.4658829064163914}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:05:46,738] Trial 196 finished with value: 0.543104091500237 and parameters: {'lambda_l1': 0.36649046119268497, 'lambda_l2': 5.159777690294267e-07, 'num_leaves': 224, 'feature_fraction': 0.5080275060544726, 'bagging_fraction': 0.8361188742968728, 'bagging_freq': 7, 'min_child_samples': 17, 'learning_rate': 0.08224076528657892, 'max_depth': 37, 'min_gain_to_split': 0.0022009554133096253, 'min_sum_hessian_in_leaf': 3.162426692712294}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:06:02,294] Trial 197 finished with value: 0.5520759533797859 and parameters: {'lambda_l1': 0.5078855585892066, 'lambda_l2': 5.732785534067395e-07, 'num_leaves': 222, 'feature_fraction': 0.5189165520183174, 'bagging_fraction': 0.8302540499257541, 'bagging_freq': 7, 'min_child_samples': 16, 'learning_rate': 0.07526590249156263, 'max_depth': 37, 'min_gain_to_split': 0.6131584885961141, 'min_sum_hessian_in_leaf': 3.1708980251745746}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:06:17,065] Trial 198 finished with value: 0.5552882284888001 and parameters: {'lambda_l1': 0.34589176292871326, 'lambda_l2': 6.159180761815201e-07, 'num_leaves': 226, 'feature_fraction': 0.5136124357529883, 'bagging_fraction': 0.8133288704298676, 'bagging_freq': 7, 'min_child_samples': 15, 'learning_rate': 0.1137686858974219, 'max_depth': 37, 'min_gain_to_split': 0.2622053350637384, 'min_sum_hessian_in_leaf': 3.429431754134638}. Best is trial 126 with value: 0.5399287614070716.\n",
      "/var/folders/0g/j83b4crs755b7yry_myrznlm0000gn/T/ipykernel_99826/3933651336.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
      "[I 2023-12-06 20:06:34,030] Trial 199 finished with value: 0.543838249272007 and parameters: {'lambda_l1': 0.3307050558884582, 'lambda_l2': 5.195272392967957e-07, 'num_leaves': 219, 'feature_fraction': 0.48805812622141337, 'bagging_fraction': 0.8482981666783755, 'bagging_freq': 7, 'min_child_samples': 18, 'learning_rate': 0.07934255902468693, 'max_depth': 35, 'min_gain_to_split': 0.011681624820025223, 'min_sum_hessian_in_leaf': 2.792002257650158}. Best is trial 126 with value: 0.5399287614070716.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for non-working days: {'lambda_l1': 0.052314327096630225, 'lambda_l2': 3.32988129651596e-06, 'num_leaves': 231, 'feature_fraction': 0.5265850969320467, 'bagging_fraction': 0.8774863575800759, 'bagging_freq': 6, 'min_child_samples': 15, 'learning_rate': 0.07035755881536468, 'max_depth': 37, 'min_gain_to_split': 0.0011816927254341136, 'min_sum_hessian_in_leaf': 4.062565356348579}\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function with cross-validation\n",
    "def objective(trial, X, y):\n",
    "    # Define hyperparameters\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1.0),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 50),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-3, 10)\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    rmses = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    return avg_rmse\n",
    "\n",
    "# Create and optimize the study for working days\n",
    "study_w = optuna.create_study(direction=\"minimize\")\n",
    "study_w.optimize(lambda trial: objective(trial, X_train_w, y_train_w), n_trials=200)\n",
    "print(\"Best parameters for working days:\", study_w.best_params)\n",
    "\n",
    "# Create and optimize the study for non-working days\n",
    "study_nw = optuna.create_study(direction=\"minimize\")\n",
    "study_nw.optimize(lambda trial: objective(trial, X_train_nw, y_train_nw), n_trials=200)\n",
    "print(\"Best parameters for non-working days:\", study_nw.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009097691407666069, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009097691407666069\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.190374079519156e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.190374079519156e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7560749464410575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7560749464410575\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.015681987381216567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.015681987381216567\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.3308218415872366, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.3308218415872366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9752428029716693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9752428029716693\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009097691407666069, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009097691407666069\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.190374079519156e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.190374079519156e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7560749464410575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7560749464410575\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.015681987381216567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.015681987381216567\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.3308218415872366, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.3308218415872366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9752428029716693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9752428029716693\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1281\n",
      "[LightGBM] [Info] Number of data points in the train set: 325137, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 3.136118\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.052314327096630225, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.052314327096630225\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.32988129651596e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.32988129651596e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8774863575800759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8774863575800759\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0011816927254341136, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0011816927254341136\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.062565356348579, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.062565356348579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5265850969320467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5265850969320467\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.052314327096630225, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.052314327096630225\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.32988129651596e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.32988129651596e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8774863575800759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8774863575800759\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0011816927254341136, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0011816927254341136\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.062565356348579, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.062565356348579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5265850969320467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5265850969320467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 130026, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 2.829719\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009097691407666069, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009097691407666069\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.3308218415872366, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.3308218415872366\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9752428029716693, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9752428029716693\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7560749464410575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7560749464410575\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.190374079519156e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.190374079519156e-07\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.015681987381216567, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.015681987381216567\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.052314327096630225, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.052314327096630225\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.062565356348579, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.062565356348579\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5265850969320467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5265850969320467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8774863575800759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8774863575800759\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.32988129651596e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.32988129651596e-06\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0011816927254341136, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0011816927254341136\n",
      "RMSE for working days: 0.6217419255232475\n",
      "RMSE for non-working days: 0.7301311735189945\n"
     ]
    }
   ],
   "source": [
    "# Optimized parameters for working and non-working days\n",
    "params_w = {\n",
    "    'lambda_l1': 0.009097691407666069,\n",
    "    'lambda_l2': 6.190374079519156e-07,\n",
    "    'num_leaves': 209,\n",
    "    'feature_fraction': 0.9752428029716693,\n",
    "    'bagging_fraction': 0.7560749464410575,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 71,\n",
    "    'learning_rate': 0.12097792269103949,\n",
    "    'max_depth': 30,\n",
    "    'min_gain_to_split': 0.015681987381216567,\n",
    "    'min_sum_hessian_in_leaf': 1.3308218415872366\n",
    "}\n",
    "\n",
    "params_nw = {\n",
    "    'lambda_l1': 0.052314327096630225,\n",
    "    'lambda_l2': 3.32988129651596e-06,\n",
    "    'num_leaves': 231,\n",
    "    'feature_fraction': 0.5265850969320467,\n",
    "    'bagging_fraction': 0.8774863575800759,\n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 15,\n",
    "    'learning_rate': 0.07035755881536468,\n",
    "    'max_depth': 37,\n",
    "    'min_gain_to_split': 0.0011816927254341136,\n",
    "    'min_sum_hessian_in_leaf': 4.062565356348579\n",
    "}\n",
    "\n",
    "# Initialize and fit LightGBM models with optimized parameters\n",
    "lgbm_model_w = lgb.LGBMRegressor(**params_w)\n",
    "lgbm_model_nw = lgb.LGBMRegressor(**params_nw)\n",
    "\n",
    "lgbm_model_w.fit(X_train_w, y_train_w)\n",
    "lgbm_model_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_w = lgbm_model_w.predict(X_test_w)\n",
    "y_pred_nw = lgbm_model_nw.predict(X_test_nw)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6217419255232475\n",
      "RMSE for non-working days: 0.7301311735189945\n"
     ]
    }
   ],
   "source": [
    "# Define LightGBM model for working days\n",
    "params_w = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 0.009097691407666069,\n",
    "    'lambda_l2': 6.190374079519156e-07,\n",
    "    'num_leaves': 209,\n",
    "    'feature_fraction': 0.9752428029716693,\n",
    "    'bagging_fraction': 0.7560749464410575,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 71,\n",
    "    'learning_rate': 0.12097792269103949,\n",
    "    'max_depth': 30,\n",
    "    'min_gain_to_split': 0.015681987381216567,\n",
    "    'min_sum_hessian_in_leaf': 1.3308218415872366\n",
    "}\n",
    "model_w = lgb.LGBMRegressor(**params_w)\n",
    "model_w.fit(X_train_w, y_train_w)\n",
    "\n",
    "# Define LightGBM model for non-working days\n",
    "params_nw = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 0.052314327096630225,\n",
    "    'lambda_l2': 3.32988129651596e-06,\n",
    "    'num_leaves': 231,\n",
    "    'feature_fraction': 0.5265850969320467,\n",
    "    'bagging_fraction': 0.8774863575800759,\n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 15,\n",
    "    'learning_rate': 0.07035755881536468,\n",
    "    'max_depth': 37,\n",
    "    'min_gain_to_split': 0.0011816927254341136,\n",
    "    'min_sum_hessian_in_leaf': 4.062565356348579\n",
    "}\n",
    "model_nw = lgb.LGBMRegressor(**params_nw)\n",
    "model_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Predictions\n",
    "y_pred_w = model_w.predict(X_test_w)\n",
    "y_pred_nw = model_nw.predict(X_test_nw)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(\"RMSE for working days:\", rmse_w)\n",
    "print(\"RMSE for non-working days:\", rmse_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for working days: 0.6750874672964752\n",
      "RMSE for non-working days: 0.7145001343482172\n"
     ]
    }
   ],
   "source": [
    "# Consistent random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Define LightGBM model for working days\n",
    "params_w = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 2.348881295853308e-05,\n",
    "    'lambda_l2': 3.6010467344475403,\n",
    "    'num_leaves': 188,\n",
    "    'feature_fraction': 0.759195090518222,\n",
    "    'bagging_fraction': 0.4936111842654619,\n",
    "    'bagging_freq': 2,\n",
    "    'min_child_samples': 10\n",
    "}\n",
    "\n",
    "# Define LightGBM model for non-working days\n",
    "params_nw = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 0.052314327096630225,\n",
    "    'lambda_l2': 3.32988129651596e-06,\n",
    "    'num_leaves': 231,\n",
    "    'feature_fraction': 0.5265850969320467,\n",
    "    'bagging_fraction': 0.8774863575800759,\n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 15,\n",
    "    'learning_rate': 0.07035755881536468,\n",
    "    'max_depth': 37,\n",
    "    'min_gain_to_split': 0.0011816927254341136,\n",
    "    'min_sum_hessian_in_leaf': 4.062565356348579\n",
    "}\n",
    "\n",
    "# Update models with a consistent random seed\n",
    "model_w = lgb.LGBMRegressor(**params_w, random_state=random_seed)\n",
    "model_nw = lgb.LGBMRegressor(**params_nw, random_state=random_seed)\n",
    "\n",
    "# Train the models\n",
    "model_w.fit(X_train_w, y_train_w)\n",
    "model_nw.fit(X_train_nw, y_train_nw)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_w = model_w.predict(X_test_w)\n",
    "y_pred_nw = model_nw.predict(X_test_nw)\n",
    "rmse_w = np.sqrt(mean_squared_error(y_test_w, y_pred_w))\n",
    "rmse_nw = np.sqrt(mean_squared_error(y_test_nw, y_pred_nw))\n",
    "\n",
    "print(f\"RMSE for working days: {rmse_w}\")\n",
    "print(f\"RMSE for non-working days: {rmse_nw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more reliable optuna tuning for lgb\n",
    "# Define the objective function with cross-validation\n",
    "def objective(trial, X, y):\n",
    "    # Define hyperparameters\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100)\n",
    "    }\n",
    "\n",
    "    rmses = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**param)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "        y_pred = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    return avg_rmse\n",
    "\n",
    "# Create and optimize the study for working days\n",
    "study_w = optuna.create_study(direction=\"minimize\")\n",
    "study_w.optimize(lambda trial: objective(trial, X_train_w, y_train_w), n_trials=100)\n",
    "print(\"Best parameters for working days:\", study_w.best_params)\n",
    "\n",
    "# Create and optimize the study for non-working days\n",
    "study_nw = optuna.create_study(direction=\"minimize\")\n",
    "study_nw.optimize(lambda trial: objective(trial, X_train_nw, y_train_nw), n_trials=100)\n",
    "print(\"Best parameters for non-working days:\", study_nw.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "In conclusion, our exhaustive pursuit of model optimization through hyperparameter tuning using grid search cross-validation and Optuna has provided valuable enhancements to the predictive performance of the four prominent models: XGBoost, RandomForest, Catboost, and LGBM. This meticulous tuning process allowed us to fine-tune the models' parameters, elevating their accuracy and robustness.\n",
    "\n",
    "After performing hyperparameter tuning, we conclude that the LGBM (Light Gradient Boosting Machine) model emerged as the frontrunner, delivering the most superior performance with the optimized hyperparameters. The LGBM model demonstrated a remarkable ability to capture intricate patterns in the data, showcasing its effectiveness in predicting bike counts.\n",
    "\n",
    "Looking ahead, equipped with the finely-tuned LGBM model and its optimal parameters, we are prepared to deploy our predictive capabilities in real-world situations. We hold confidence in the performance of our selected model, anticipating that its heightened accuracy will translate well to Kaggle's test set. We expect the RMSE results on the provided test set to closely align with our refined predictions, affirming the effectiveness of our approach in predicting bike counts across diverse scenarios. This undertaking signifies a notable advancement towards implementing a reliable and accurate model in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikes-count",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
